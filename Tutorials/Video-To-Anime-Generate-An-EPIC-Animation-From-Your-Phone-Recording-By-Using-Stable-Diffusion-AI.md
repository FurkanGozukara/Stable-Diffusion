# Video To Anime - Generate An EPIC Animation From Your Phone Recording By Using Stable Diffusion AI

## Full tutorial link > https://www.youtube.com/watch?v=kmT-z2lqEPQ

[![Video To Anime - Generate An EPIC Animation From Your Phone Recording By Using Stable Diffusion AI](https://img.youtube.com/vi/kmT-z2lqEPQ/sddefault.jpg)](https://www.youtube.com/watch?v=kmT-z2lqEPQ "Video To Anime - Generate An EPIC Animation From Your Phone Recording By Using Stable Diffusion AI")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Video-To-Anime-Generate-An-EPIC-Animation-From-Your-Phone-Recording-By-Using-Stable-Diffusion-AI.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Video-To-Anime-Generate-An-EPIC-Animation-From-Your-Phone-Recording-By-Using-Stable-Diffusion-AI.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


RunPod: [https://bit.ly/RunPodIO.](https://bit.ly/RunPodIO.) Discord : [https://bit.ly/SECoursesDiscord.](https://bit.ly/SECoursesDiscord.) Turn your real video into an animation with just 1 click by using Stable Diffusion for free. If I have been of assistance to you and you would like to show your support for my work, please consider becoming a patron on ü•∞ [https://www.patreon.com/SECourses](https://www.patreon.com/SECourses)

Playlist of StableDiffusion Tutorials, Automatic1111 and Google Colab Guides, DreamBooth, Textual Inversion / Embedding, LoRA, AI Upscaling, Pix2Pix, Img2Img:

[https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3](https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3)

Davinci Resolve Free: [https://bit.ly/DavinciResolv](https://bit.ly/DavinciResolv)

FFmpeg: [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)

Davinci Resolve Tutorial: [https://youtu.be/_-yYRGKyz8E](https://youtu.be/_-yYRGKyz8E)

Gist file where commands, scripts, settings shared: [https://bit.ly/VideoToAnimeGistFile](https://bit.ly/VideoToAnimeGistFile)

How to install Automatic1111: [https://youtu.be/AZg6vzWHOTA](https://youtu.be/AZg6vzWHOTA)

How to use custom models on Automatic1111: [https://youtu.be/aAyvsX-EpG4](https://youtu.be/aAyvsX-EpG4)

How to use RunPod tutorial : [https://youtu.be/QN1vdGhjcRc](https://youtu.be/QN1vdGhjcRc)

How to install DreamBooth on RunPod IO : [https://youtu.be/oI0GEnrySS0](https://youtu.be/oI0GEnrySS0)

How to train yourself and a style tutorial : [https://youtu.be/m-UVVY_syP0](https://youtu.be/m-UVVY_syP0)

Pre-generated classification images:

[https://www.patreon.com/posts/10598-aesthetic-80588052](https://www.patreon.com/posts/10598-aesthetic-80588052)

Master tutorial for DreamBooth: [https://youtu.be/Bdl-jWR3Ukc](https://youtu.be/Bdl-jWR3Ukc)

DreamBooth best settings experiment: [https://youtu.be/sRdtVanSRl4](https://youtu.be/sRdtVanSRl4)

What is ControlNet, how to install and use it: [https://youtu.be/vhqqmkTBMlU](https://youtu.be/vhqqmkTBMlU)

The used script in this video : [https://bit.ly/FrameRenderScript](https://bit.ly/FrameRenderScript)

Upscale models database: [https://upscale.wiki/wiki/Model_Database](https://upscale.wiki/wiki/Model_Database)

[00:00:00](https://youtu.be/kmT-z2lqEPQ?t=0) How to turn a video into an animation in a fully automated manner for free

[00:00:54](https://youtu.be/kmT-z2lqEPQ?t=54) Introduction to Davinci Resolve free edition

[00:01:08](https://youtu.be/kmT-z2lqEPQ?t=68) Introduction to FFmpeg

[00:01:15](https://youtu.be/kmT-z2lqEPQ?t=75) Short tutorial video for Davinci Resolve

[00:01:19](https://youtu.be/kmT-z2lqEPQ?t=79) How to prepare your real video footage

[00:01:32](https://youtu.be/kmT-z2lqEPQ?t=92) How to change timeline resolution in Davinci Resolve

[00:02:00](https://youtu.be/kmT-z2lqEPQ?t=120) Imported video image scaling Davinci Resolve - mismatched resolution files

[00:02:12](https://youtu.be/kmT-z2lqEPQ?t=132) Edit tab and video importing in Davinci Resolve

[00:02:21](https://youtu.be/kmT-z2lqEPQ?t=141) Where to see properties of your video in Davinci Resolve

[00:02:36](https://youtu.be/kmT-z2lqEPQ?t=156) How to crop a video into square or any aspect ratio with Davinci Resolve

[00:03:17](https://youtu.be/kmT-z2lqEPQ?t=197) Negative side of using distant position

[00:03:49](https://youtu.be/kmT-z2lqEPQ?t=229) How to export / render your video in Davinci Resolve with best settings

[00:04:30](https://youtu.be/kmT-z2lqEPQ?t=270) How to export all frames of a video by using FFmpeg

[00:05:16](https://youtu.be/kmT-z2lqEPQ?t=316) Parameters of extracting all frames of a video by using FFmpeg

[00:05:30](https://youtu.be/kmT-z2lqEPQ?t=330) File names importance for batch processing scripts

[00:06:31](https://youtu.be/kmT-z2lqEPQ?t=391) How to install and use Automatic1111 Web UI

[00:06:57](https://youtu.be/kmT-z2lqEPQ?t=417) Which training dataset I made to train myself from video exported frames

[00:07:26](https://youtu.be/kmT-z2lqEPQ?t=446) Why and how I used RunPod IO for training

[00:08:00](https://youtu.be/kmT-z2lqEPQ?t=480) Why I trained myself and a style into SD 1.5 for video to animation

[00:08:47](https://youtu.be/kmT-z2lqEPQ?t=527) How to train yourself and a style tutorial

[00:09:08](https://youtu.be/kmT-z2lqEPQ?t=548) How to do 2 concept training in Stable Diffusion 1.5 DreamBooth

[00:09:38](https://youtu.be/kmT-z2lqEPQ?t=578) What DreamBooth settings I have used to train myself and style into SD 1.5 in this tutorial

[00:11:37](https://youtu.be/kmT-z2lqEPQ?t=697) Master tutorial for DreamBooth

[00:12:03](https://youtu.be/kmT-z2lqEPQ?t=723) What is ControlNet, how to install and use it

[00:12:24](https://youtu.be/kmT-z2lqEPQ?t=744) Settings change of ControlNet to use in video to anime process

[00:12:52](https://youtu.be/kmT-z2lqEPQ?t=772) Multi-frame video rendering for Stable Diffusion script for video to animation with consistency

[00:13:37](https://youtu.be/kmT-z2lqEPQ?t=817) How install external scripts to Automatic1111 Web UI

[00:14:44](https://youtu.be/kmT-z2lqEPQ?t=884) How to change commit version of git repos, ex. Automatic1111 web UI

[00:15:57](https://youtu.be/kmT-z2lqEPQ?t=957) When you are ready to start processing real video frames into anime

[00:16:16](https://youtu.be/kmT-z2lqEPQ?t=976) You don't have to do pre-training to follow this tutorial

[00:16:46](https://youtu.be/kmT-z2lqEPQ?t=1006) First step of video to animation

[00:17:31](https://youtu.be/kmT-z2lqEPQ?t=1051) Importance of first generated frame

[00:17:39](https://youtu.be/kmT-z2lqEPQ?t=1059) How to generate your first converted driving frame

[00:18:59](https://youtu.be/kmT-z2lqEPQ?t=1139) What kind of initial frame to image conversation you should aim

[00:20:10](https://youtu.be/kmT-z2lqEPQ?t=1210) What is the difference if we don't train ourselves and just use a custom model

[00:20:48](https://youtu.be/kmT-z2lqEPQ?t=1248) Next step after you got first converted frame of your anime video

[00:21:20](https://youtu.be/kmT-z2lqEPQ?t=1280) The settings used in img2img tab for batch frame processing

[00:21:57](https://youtu.be/kmT-z2lqEPQ?t=1317) Multi-frame Video rendering for StableDiffusion settings

[00:23:25](https://youtu.be/kmT-z2lqEPQ?t=1405) How to upscale all video to animation generated frames

[00:23:43](https://youtu.be/kmT-z2lqEPQ?t=1423) How to fix naming of the batch generated images for upscaling

[00:25:19](https://youtu.be/kmT-z2lqEPQ?t=1519) How to do batch upscaling by AI in Automatic1111 Web UI

[00:26:05](https://youtu.be/kmT-z2lqEPQ?t=1565) How to improve faces, eyes, when doing upscaling by AI

[00:26:25](https://youtu.be/kmT-z2lqEPQ?t=1585) How to animate generated frame images

[00:26:40](https://youtu.be/kmT-z2lqEPQ?t=1600) How to import images as an image sequence into Davinci Resolve for animating

[00:27:31](https://youtu.be/kmT-z2lqEPQ?t=1651) Clip attributes fixing

[00:27:39](https://youtu.be/kmT-z2lqEPQ?t=1659) First time playing our animated video

[00:27:50](https://youtu.be/kmT-z2lqEPQ?t=1670) How to improve flickering problem with a very simple trick

[00:28:30](https://youtu.be/kmT-z2lqEPQ?t=1710) How to move clip frame by frame in Davinci Resolve

[00:29:05](https://youtu.be/kmT-z2lqEPQ?t=1745) Which composite mode to reduce flickering problem in Davinci Resolve

[00:29:40](https://youtu.be/kmT-z2lqEPQ?t=1780) How to apply deflickering in Davinci Resolve

[00:30:35](https://youtu.be/kmT-z2lqEPQ?t=1835) How animation made in this video could have been improved significantly

[00:31:54](https://youtu.be/kmT-z2lqEPQ?t=1914) Which other technique I have tested - img2img alternative test

[00:32:33](https://youtu.be/kmT-z2lqEPQ?t=1953) img2img alternative test video to animation results

[00:33:15](https://youtu.be/kmT-z2lqEPQ?t=1995) Searched for freely available deflickering tools - models - libraries

[00:33:43](https://youtu.be/kmT-z2lqEPQ?t=2023) All-In-One-Deflicker

[00:34:55](https://youtu.be/kmT-z2lqEPQ?t=2095) My videos have fully corrected subtitles



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=0) Greetings everyone, I am excited to share with you my latest project, a tutorial for

- [00:00:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=5) how to turn a real video into any style animation or anime like Corridor Crew did.

- [00:00:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=11) The methodology I have developed is fully automated.

- [00:00:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=15) For the past 5 days, I have been working on perfecting the workflow and I am thrilled

- [00:00:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=20) to present my findings to you today.

- [00:00:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=23) I want to highlight that the animation you are currently viewing has been made solely

- [00:00:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=28) using the Automatic1111 web UI and Stable Diffusion 1.5 version.

- [00:00:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=33) No hand-picked frames, no Photoshop, no inpainting or famous deflicker of DaVinci Resolve were

- [00:00:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=40) used.

- [00:00:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=41) Furthermore, I have now more experience to make it even better.

- [00:00:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=45) This means that the animation has enormous potential for further improvement.

- [00:00:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=49) First of all, you need to begin with preparation of the real video that you want to turn into

- [00:00:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=53) an animation.

- [00:00:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=54) For this task, we are going to use DaVinci Resolve Free Edition.

- [00:00:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=58) DaVinci Resolve Free Edition is a free software that doesn't require you to purchase and it

- [00:01:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=63) is not a trial.

- [00:01:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=64) They also have a studio version which has extra features.

- [00:01:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=67) Additionally, we are going to use FFmpeg which is the best open source video editing library.

- [00:01:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=73) I have a short video for DaVinci Resolve in my channel if you want to learn more about

- [00:01:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=78) it.

- [00:01:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=79) Start with a new DaVinci Resolve project, click untitled project.

- [00:01:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=81) Next we will modify our timeline resolution.

- [00:01:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=85) This is important.

- [00:01:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=86) Depending on what aspect ratio you want to obtain, change the timeline resolution according

- [00:01:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=91) to that.

- [00:01:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=92) To change the timeline resolution, click the right bottom project settings icon here.

- [00:01:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=97) It will open you these project settings.

- [00:01:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=99) In here, select your timeline resolution according to your video's resolution and the aspect

- [00:01:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=105) ratio that you want.

- [00:01:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=106) My video's resolution is over 2K therefore, I am selecting 2160x2160.

- [00:01:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=113) Change your timeline frame rate according to your video's timeline frame rate.

- [00:01:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=117) And there is another important thing which is image scaling.

- [00:02:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=121) In here you will see mismatched resolution files.

- [00:02:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=124) Select center crop with no resizing.

- [00:02:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=126) With this way we will be able to extract our video with the aspect ratio we want.

- [00:02:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=132) Click save.

- [00:02:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=133) Then go to the edit tab in here.

- [00:02:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=134) This is the tab.

- [00:02:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=135) Then drag and drop your original video to this area.

- [00:02:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=139) It will open the file here.

- [00:02:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=141) When you click this file, there will be a file icon appear here.

- [00:02:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=145) Click it.

- [00:02:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=146) It will show you the properties of your video, your video's frame rate, your video's resolution.

- [00:02:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=152) Then drag and drop your video to here.

- [00:02:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=154) I am in the edit tab.

- [00:02:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=156) What we are going to do is cropping our file into square aspect ratio because we are going

- [00:02:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=162) to train our subject by using DreamBooth and obtain better quality when we are turning

- [00:02:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=168) our video into an animation.

- [00:02:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=170) And since 512 and 512 is the native resolution of the Stable Diffusion 1.5 version, I am

- [00:02:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=177) going to crop my video as square.

- [00:03:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=180) So first select your clip here, then click video here, there you will see zoom and position.

- [00:03:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=187) Select zoom and position of your video as you want.

- [00:03:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=192) This is really important.

- [00:03:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=193) In the beginning, I have used a distance position like this.

- [00:03:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=197) However, this distant position caused me to have worse eyes.

- [00:03:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=202) Therefore, if you zoom it a little bit more, it will be able to handle eyes and the face

- [00:03:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=208) better.

- [00:03:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=209) So as you get distance, the small objects in your video will have harder time to keep

- [00:03:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=215) up the transformation into an animation or anime.

- [00:03:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=219) So by using the zoom and position here, set the position that you want to use.

- [00:03:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=225) For this tutorial this is the position that I have used.

- [00:03:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=229) Then in the bottom, you will see an icon which is like a rocket.

- [00:03:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=234) Click it.

- [00:03:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=235) This is the section where you can render your video.

- [00:03:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=238) In here render your video as 512 and 512 or the aspect ratio that you want to use.

- [00:04:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=245) For this tutorial, I have used 512 and 512 because I am going to do DreamBooth training,

- [00:04:10](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=250) but you can also do training with other aspect ratios.

- [00:04:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=253) Then select the file name and the location.

- [00:04:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=256) I prefer using mp4 and codec as h265, encoder auto.

- [00:04:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=263) This is the frame rate of my video.

- [00:04:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=265) Then click the add to render queue button and click render all.

- [00:04:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=268) It will render your video.

- [00:04:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=270) Once the export has been completed, we will extract every frame of the video.

- [00:04:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=275) For this task, we are going to use FFmpeg.

- [00:04:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=278) You can open CMD window, type ffmpeg and if you are getting results, then it is installed

- [00:04:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=284) in your computer.

- [00:04:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=286) If you are not getting results, click, download, download windows, extract it into any folder.

- [00:04:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=292) Copy your exported video into a new folder, start CMD inside this folder.

- [00:04:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=298) Then we are going to use this command to export every frame of the video.

- [00:05:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=304) You see I am directly calling ffmpeg.

- [00:05:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=307) If you didn't install it properly, then you can give full path of the ffmpeg here to execute

- [00:05:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=313) this command.

- [00:05:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=314) There are several parameters.

- [00:05:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=315) We are setting the FPS of the video to extract every frame.

- [00:05:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=319) Then I am defining start number.

- [00:05:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=322) Why?

- [00:05:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=323) Because when using Automatic1111 web UI or other scripts, they are using the python sort

- [00:05:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=328) method of the file names.

- [00:05:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=331) So if your file names are like this, then you are going to have problem when sorting.

- [00:05:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=337) Therefore, starting file names like this will ensure the consistency of the file order.

- [00:05:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=343) If you have more than 10,000 frames, then make this number 5 and the starting number

- [00:05:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=349) as 10,000.

- [00:05:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=350) So you will have numbered frames between 10,000 to 99,000.

- [00:05:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=356) This is the logic of this command that we are going to execute.

- [00:06:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=360) So this is the input file name.

- [00:06:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=362) If your input file name have spaces or other characters, make it inside quotation mark

- [00:06:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=368) like this.

- [00:06:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=369) Let's execute this and see the output.

- [00:06:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=372) So currently my CMD window is inside test folder is entered.

- [00:06:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=376) It will quickly extract all of the PNG files and you see frames are getting extracted like

- [00:06:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=384) we are wanting.

- [00:06:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=385) For the rest of the tutorial we are going to use Automatic1111 web UI.

- [00:06:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=390) If you don't know how to install and use Automatic1111 web UI, I suggest you to watch my these two

- [00:06:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=396) videos.

- [00:06:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=397) First one is easiest way to install and run Stable Diffusion web UI and the second one

- [00:06:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=402) is how to use Stable Diffusion version 2.1 and different models in the web UI.

- [00:06:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=407) Stable Diffusion Automatic1111 web UI is the most advanced, open source UI that is developed

- [00:06:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=414) to use Stable Diffusion.

- [00:06:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=416) Then from exported frames, I have picked 137 frames like you are seeing on the screen right

- [00:07:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=424) now.

- [00:07:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=425) I have used these selected frames to train myself into SD 1.5 version.

- [00:07:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=429) However, now I see that these many frames were an overkill.

- [00:07:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=433) You probably need to pick only several positions of your video and train them.

- [00:07:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=439) Also make sure that you have included close shot of the face.

- [00:07:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=443) I didn't do that in this training.

- [00:07:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=446) For training, I have used RunPod IO.

- [00:07:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=448) The reason why I have used RunPod IO is that I have 12 GB VRAM having RTX 3060.

- [00:07:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=454) However, when I am using the best settings that I have found for DreamBooth, 12 GB is

- [00:07:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=461) not enough.

- [00:07:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=462) Therefore, I have used RunPod IO for training only.

- [00:07:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=466) I have an excellent RunPod IO tutorial on my channel, this is the video for it if you

- [00:07:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=470) want to learn it.

- [00:07:51](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=471) I have used DreamBooth and if you don't know how to install DreamBooth on RunPod IO, I

- [00:07:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=475) have another excellent tutorial that explains how to install DreamBooth, this is the video.

- [00:08:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=480) So the reason that I have teached myself and a style to the SD 1.5 version is that this

- [00:08:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=487) way, I was able to obtain consistency in my animation video just like Corridor Crew did

- [00:08:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=493) in their famous anime video.

- [00:08:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=496) However, using RunPod IO is definitely not necessary for this tutorial.

- [00:08:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=500) You can use your PC, you can even use LoRA or Textual Inversion if your graphic card

- [00:08:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=507) is not strong enough.

- [00:08:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=508) You can use some lesser VRAM demanding settings of DreamBooth extension.

- [00:08:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=514) All of them are possible options for this tutorial.

- [00:08:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=518) Since I am using Automatic1111 web UI, the procedure is same on every platform wherever

- [00:08:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=524) you can run the Automatic1111 web UI.

- [00:08:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=527) So in my Midjourney level quality video, I have shown how to teach a style and yourself

- [00:08:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=533) into the SD 1.5 version.

- [00:08:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=535) You can watch this video to learn it.

- [00:08:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=537) For today's tutorial, I had 274 style images, therefore different than this video, I did

- [00:09:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=546) two concept training.

- [00:09:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=548) So this is the first concept where I did set my training images myself and the second concept

- [00:09:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=554) where I did set my style images.

- [00:09:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=557) Why?

- [00:09:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=558) Because number of training images myself is 137 and number of training images style is

- [00:09:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=564) 274.

- [00:09:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=565) Therefore, the ratio is only 1 over 2 and it is not very imbalanced.

- [00:09:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=573) So I was able to train both of them at the same training with two concepts.

- [00:09:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=578) So let me quickly show you the settings I have used.

- [00:09:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=580) I have trained it up to 60 epochs.

- [00:09:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=583) I have saved every 4 epochs because I have a lot of training images.

- [00:09:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=586) Batch size 1, gradient accumulation steps 1.

- [00:09:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=589) I didn't use class image generation of the DreamBooth extension, I generated with text

- [00:09:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=595) to image tab.

- [00:09:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=596) Pre-generated classification images are posted on our Patreon, 6080 photo of man classification

- [00:10:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=603) images and 10,598 aesthetic word classification images.

- [00:10:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=609) Set gradients to none when zeroing.

- [00:10:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=611) Gradient checkpointing is not checked.

- [00:10:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=613) Learning rate is 1e-7 because I am using Lion optimizer, constant with warmup.

- [00:10:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=621) Image processing max resolution is 512px, use EMA.

- [00:10:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=625) I am using EMA because it is improving the training success rate significantly.

- [00:10:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=631) Optimizer is Lion, mixed precision BF16, memory attention is default.

- [00:10:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=635) I didn't use Xformers because I have used 20GB having RAM pod, cache latents, train

- [00:10:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=640) UNET, step ratio of text encoder is 0.7 because I am teaching both a person and a style.

- [00:10:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=648) Offset noise 0, freeze clip normalization layers unchecked, clip skip 1, weight decay

- [00:10:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=654) is 0.1 because we are using Lion optimizer and the other things are default.

- [00:11:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=660) I have done this training on Xformers 0.0.17 development 476, however, this is removed

- [00:11:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=668) from the pre-compiled wheels, therefore, now you need to use Torch version 2 and the latest

- [00:11:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=674) development version of 0.0.17 for training.

- [00:11:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=678) In the concept tab, for training myself, I have used OHWX Man.

- [00:11:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=683) OHWX is the rare token, "photo of man" is the class token.

- [00:11:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=688) In the second concept tab, for training the style, I have used BBUK Aesthetic.

- [00:11:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=693) So BBUK is the rare token, Aesthetic is the class token.

- [00:11:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=697) If you want to learn more about DreamBooth training, I have this excellent tutorial.

- [00:11:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=702) It is covering many of the topics.

- [00:11:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=704) Moreover, in this epic tutorial video, I have compared many of the DreamBooth settings and

- [00:11:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=710) found out the best settings for you.

- [00:11:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=712) By watching this tutorial, you will have much more knowledge about DreamBooth training and

- [00:11:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=717) what parameters you should use.

- [00:11:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=719) For video to animation, we are going to use ControlNet.

- [00:12:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=722) If you don't know what is ControlNet, I have this great tutorial that I am teaching how

- [00:12:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=728) to install ControlNet and use it, this one.

- [00:12:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=731) Also, I have several other tutorials for ControlNet, for example, this one and this one.

- [00:12:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=736) So by watching these three videos, you will have great knowledge about how to use ControlNet,

- [00:12:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=741) how to install it and how to utilize it.

- [00:12:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=744) We have to do a settings change for using ControlNet.

- [00:12:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=748) Go to the settings in your web UI.

- [00:12:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=750) In here, go to the ControlNet tab and check these boxes.

- [00:12:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=754) Allow other scripts to control this extension.

- [00:12:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=757) This is really important.

- [00:12:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=759) You need to have this to be able to use the script that I am going to show you in this

- [00:12:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=764) tutorial for video to animation.

- [00:12:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=767) After doing this, apply settings and perhaps restart your web UI to be sure.

- [00:12:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=772) For processing frames of our real video, we are going to use this excellent script, MultiFrame

- [00:12:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=778) Video Rendering for Stable Diffusion.

- [00:13:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=780) This is a free script.

- [00:13:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=781) This is a single page script.

- [00:13:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=783) So in this page, the script developer explaining how it works and what are the parameters that

- [00:13:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=788) you can use.

- [00:13:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=789) To download it, click download.

- [00:13:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=791) It will ask you whether you want to donate or not and it will show you the script version

- [00:13:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=795) here.

- [00:13:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=796) If you donate to the developer, it is great, but you don't have to donate.

- [00:13:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=801) Just click No thanks, just take me to the downloads.

- [00:13:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=803) Then it will open this page and you can click download and you see the file has been downloaded.

- [00:13:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=808) It's a simple file, only 10 kilobytes.

- [00:13:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=811) When you open it, you will see the entire script like this, the version and the script

- [00:13:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=816) itself.

- [00:13:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=817) So cut this script, go to your Automatic1111 web UI folder and in here, go to scripts folder

- [00:13:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=824) and paste it there.

- [00:13:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=825) So this is the folder where you need to put this script.

- [00:13:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=828) If the script doesn't work with the latest version of Automatic1111 web UI, I have used

- [00:13:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=834) this specific commit.

- [00:13:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=835) The used commit hash and the script are posted on my gist.

- [00:14:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=840) I will put the link of this gist file into the description of the video.

- [00:14:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=844) You see the used commit hash ID and the used multi-frame render.py file.

- [00:14:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=849) Why I am putting this because in future when you are watching this video, if it is not

- [00:14:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=854) working, you can revert back to this commit hash ID and use this script.

- [00:14:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=859) As I am recording this video, the script is not working with the latest version of Automatic1111

- [00:14:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=864) web UI because the web UI got updates in the last two days and I have used this script

- [00:14:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=871) two days ago.

- [00:14:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=872) So now I will revert back to this commit to show you how it works and how you can revert

- [00:14:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=878) to this commit ID.

- [00:14:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=880) Close your web UI instance.

- [00:14:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=882) Start CMD in your web UI.

- [00:14:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=884) Then type git checkout and paste the commit hash ID like this.

- [00:14:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=889) Hit enter and now you will see head is now this one.

- [00:14:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=893) If you get error and if it asks you to git stash, then you can run git stash command

- [00:14:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=899) before running git checkout.

- [00:15:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=901) Then let's say you want to return back the latest version, you need to do git checkout,

- [00:15:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=906) then type master and it will return back to the master branch and it will get the latest

- [00:15:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=913) version again.

- [00:15:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=914) You see it is saying switch it to branch master and it says that your branch is up to date

- [00:15:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=918) with the origin master.

- [00:15:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=920) Then you can use git pull to update if there is any new updates.

- [00:15:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=924) I made a single change in the script file in this line reference images.

- [00:15:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=929) I have changed file count equal to directory.

- [00:15:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=933) By default it was equal to multiple.

- [00:15:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=936) By changing this to directory, I am able to upload entire directory instead of selecting

- [00:15:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=942) each one of the images.

- [00:15:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=943) So you can also make this change.

- [00:15:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=945) It is not necessary but I find this better.

- [00:15:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=947) And if the author of this script watches this video, please allow us to enter path of the

- [00:15:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=954) directory instead of uploading them.

- [00:15:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=957) Once you have verified that your trained model is loaded, your ControlNet is installed and

- [00:16:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=962) working and in the img2img tab in the very bottom in the script tab you see beta multi

- [00:16:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=968) frame video rendering script.

- [00:16:10](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=970) You are ready to start processing your frames to turn them into an animation or anime.

- [00:16:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=976) So for this thing to work actually, you don't need to train your face or your style.

- [00:16:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=982) However, training yourself into the model will improve your consistency and if you also

- [00:16:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=987) train your style, it will even improve it your consistency further.

- [00:16:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=992) So without training your style or yourself into the model, you can still perfectly use

- [00:16:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=996) custom models for what we are going to do.

- [00:16:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1000) But if you do train yourself then it will improve your consistency.

- [00:16:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1004) First decide your prompt.

- [00:16:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1006) So this is my prompt photo of OHWX man.

- [00:16:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1009) OHWX is the rare token that I used to train myself by bbuk aesthetic.

- [00:16:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1016) So bbuk is the another rare token that I have used to train the style that I wanted.

- [00:17:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1021) Aesthetic is my class token and their prompt weight is 1.2 and the other prompts here and

- [00:17:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1029) in the negative prompt I used these.

- [00:17:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1032) Sampling method is Eular A. Sampling steps is 20.

- [00:17:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1036) I find that 7.5 CFG scale works better, but this is of course for my trained model.

- [00:17:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1043) You may need to change these parameters.

- [00:17:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1046) You may need to try different parameters for your trained model or if you use custom model.

- [00:17:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1051) The first image that you are going to generate is extremely important because the rest of

- [00:17:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1056) the frames will be generated based on this.

- [00:17:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1059) So this will determine your style.

- [00:17:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1062) Restore faces I am using this.

- [00:17:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1064) And in the ControlNet load your first frame.

- [00:17:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1067) So this is my first frame I am loading it, the frame is loaded, click enable.

- [00:17:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1072) I am using Canny this is working pretty well Canny here.

- [00:17:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1077) Canny low threshold and Canny high threshold.

- [00:17:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1079) This is significantly changing the output that you are going to get.

- [00:18:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1082) I find that 75 is working better.

- [00:18:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1085) When you click preview annotator result, you will see what kind of effect it is doing.

- [00:18:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1091) You see when I lower these values, it is going to keep more precise shape in the map.

- [00:18:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1098) It will also introduce more stylizing to your output.

- [00:18:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1101) However, it will also make it harder to obtain consistency.

- [00:18:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1105) So you may want to try 75, 50, 100, 150 and see how well you are performing with each

- [00:18:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1113) one.

- [00:18:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1114) I find that 75 is working best for me for my model.

- [00:18:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1118) Once you set these parameters, hit, generate, and get what you want.

- [00:18:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1123) For example: this is an image I got with this prompt.

- [00:18:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1126) This is very similar to the one that I have shown in video.

- [00:18:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1130) Let's change the prompts and see what other kind of results we can get.

- [00:18:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1135) Ok this is another result I got.

- [00:18:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1137) I have changed the prompt like this.

- [00:18:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1139) So you see when you want to turn your video into an animation, you should wear a cloth

- [00:19:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1146) that you want to be appear in the animated video.

- [00:19:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1149) I have wore a black shirt.

- [00:19:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1152) Therefore, I should make my desired output as a black shirt.

- [00:19:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1157) Otherwise it will be hard for model to keep consistency.

- [00:19:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1160) So if I use this prompt, then this cloth may likely to change.

- [00:19:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1166) So wear a clothing that you want to be similar to be in your animated video.

- [00:19:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1174) So this is really important.

- [00:19:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1175) Wear a cloth that you want to be similar in your animated video.

- [00:19:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1181) And it will improve your consistency.

- [00:19:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1182) It will decrease the flickering that you are going to get.

- [00:19:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1186) So this is not a good example.

- [00:19:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1188) This shirt should be completely black.

- [00:19:51](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1191) You can also use this, but it will increase your inconsistency.

- [00:19:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1195) So if you wear a majestic cloth, then you will be able to get a majestic output much

- [00:20:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1201) more easier.

- [00:20:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1202) So your target image should have a similar cloth that you have wore in your original

- [00:20:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1209) video like here.

- [00:20:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1211) Now you may wonder why you should do DreamBooth training.

- [00:20:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1214) You see when I use a custom model for example rev animated the face I am going to get is

- [00:20:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1222) completely different.

- [00:20:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1223) Nothing like me at all.

- [00:20:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1225) I have changed the prompt photo of a man obviously and I have removed the style and you see this

- [00:20:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1231) is the result I am getting.

- [00:20:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1233) Yes it may look better because I didn't target this style.

- [00:20:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1237) This will also make it harder for you to keep the consistent style.

- [00:20:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1241) So teaching style and yourself in the model will get you much more success.

- [00:20:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1248) Once you are satisfied with the output image, then go to here and click send to image to

- [00:20:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1254) image tab.

- [00:20:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1255) When your image is moved to image to image verify all of the variables are correct.

- [00:21:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1261) For example now CFG scale is 7 I am making this 7.5 the prompts are looking correct.

- [00:21:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1268) Ok now here comes the important part.

- [00:21:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1271) Make sure that the seed is written correctly.

- [00:21:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1274) It is same as the one that you have used in here in text to image tab.

- [00:21:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1279) Then make the denoising strength one.

- [00:21:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1282) The author of the script said that you can try different values.

- [00:21:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1285) I found that one is working best, but I can't say it will work best for you as well.

- [00:21:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1290) So you need to test this.

- [00:21:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1292) In the ControlNet we are going to enable.

- [00:21:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1295) You see it is already enabled but some of the settings are missing, so uncheck this.

- [00:21:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1300) Check again.

- [00:21:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1301) So change the preprocessor from here, then change back to canny and the missing settings

- [00:21:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1306) will appear.

- [00:21:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1307) Set the settings same as the one in the text to image tab.

- [00:21:51](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1311) Make sure that it is enabled.

- [00:21:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1312) Do not upload anything here because the script will upload and use it.

- [00:21:57](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1317) Then time to set up our script.

- [00:21:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1319) In the very bottom you will see beta multi frame rendering.

- [00:22:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1323) Select it.

- [00:22:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1324) Make the initial denoise strength one.

- [00:22:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1326) Select append integrated prompt none third frame.

- [00:22:10](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1330) This is really important.

- [00:22:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1331) Choose first gen.

- [00:22:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1332) This is the best one working.

- [00:22:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1334) Pick enable color correction.

- [00:22:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1336) Do not check unfreeze seed but you can play with this and see how dramatic it is changing

- [00:22:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1342) whether it is making better or not.

- [00:22:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1344) And the Loopback source.

- [00:22:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1345) I am making this first gen.

- [00:22:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1347) Now this is also really important.

- [00:22:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1348) Do not forget to upload guide images.

- [00:22:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1351) Ok since I changed the script this part I am able to select folder.

- [00:22:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1356) So I will select folder.

- [00:22:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1358) So select folder.

- [00:22:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1359) It will not display anything.

- [00:22:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1360) Hit upload.

- [00:22:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1361) It will ask you how many files you want to use.

- [00:22:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1365) You see it is displaying one thousand, five hundred twenty five files to this site.

- [00:22:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1369) Do you want to upload.

- [00:22:51](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1371) Hit upload then go to the top and here click generate.

- [00:22:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1376) It will start processing images.

- [00:22:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1379) You should see messages like this in your CMD window.

- [00:23:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1381) You shouldn't see any errors.

- [00:23:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1384) So this is my CMD window.

- [00:23:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1385) Right now it is processing the images.

- [00:23:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1387) So the generated images will be inside image to images folder.

- [00:23:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1391) Click here.

- [00:23:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1392) It will open image to images folder.

- [00:23:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1394) Go to the latest one and in here you will start seeing images appearing like this.

- [00:23:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1399) So this script is generating three images at once to keep the consistency.

- [00:23:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1405) Then once all of the frames are generated, move them into a new folder.

- [00:23:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1409) If you want to upscale them, you have to fix their naming.

- [00:23:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1413) This naming will cause problems because when the upscaler works, it will sort the names

- [00:23:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1420) and it won't be looking like this.

- [00:23:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1423) So for fixing names, I have an easy script.

- [00:23:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1427) This script is also posted on the gist file.

- [00:23:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1430) So for using this script, click raw.

- [00:23:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1433) Right click.

- [00:23:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1434) Save as.

- [00:23:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1435) Save into any folder you want like here.

- [00:23:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1438) Test.py.

- [00:23:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1439) Make sure that you are saving the extension as py file because we will execute it as a

- [00:24:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1445) python.

- [00:24:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1446) Then right, click and edit it.

- [00:24:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1448) I am using notepad plus plus.

- [00:24:10](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1450) There are two things that you need to change.

- [00:24:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1452) The first thing is changing the folder path.

- [00:24:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1455) This is really important.

- [00:24:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1457) So this is my folder path.

- [00:24:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1458) Therefore I am copying it, pasting it here.

- [00:24:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1462) Change the backslash into forward slash.

- [00:24:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1465) This is how python works.

- [00:24:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1467) Then the initial starting count.

- [00:24:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1469) This is really important since I have less than 10,000 I am setting the initial count

- [00:24:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1474) as 1000 and it will look for all of the files starting with a1.

- [00:24:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1480) So what we need to do is select all of the images, then go to the first image right,

- [00:24:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1486) click, click, rename type a1 hit enter.

- [00:24:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1490) Then it will rename all of the files starting from a1 as you can see.

- [00:24:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1495) Then go to the folder where you have downloaded the python file open CMD window type python

- [00:25:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1501) test.py.

- [00:25:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1502) This is the file I have saved.

- [00:25:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1504) Hit enter.

- [00:25:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1505) Now when you open the raw images, you will see they are named as starting from 1000 up

- [00:25:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1512) to the final image that we have.

- [00:25:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1514) This is really really important if you do batch upscaling, otherwise it will break your

- [00:25:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1519) animation sequence.

- [00:25:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1521) Then go to the extras tab in your web ui, go to the batch from directory, give the input

- [00:25:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1528) directory, then set an output directory.

- [00:25:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1531) Anything can be like anything.

- [00:25:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1533) You can uncheck this show result images how much you want to upscale I have upscaled it

- [00:25:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1538) four times.

- [00:25:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1539) Select your upscaler since I am aiming an anime style I have used R-ESGRAN 4x+ Anime6b.

- [00:25:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1547) If you are aiming more realistic style then I suggest you to use 4x UltraSharp.

- [00:25:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1552) This is a custom model that you can download from wiki upscale model database.

- [00:25:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1558) You can download other different upscalers from here as well.

- [00:26:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1561) Then you may want to also improve the face quality.

- [00:26:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1565) For doing that, make GFPGAN visibility as one.

- [00:26:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1569) This will improve faces, eyes and hit generate and it will upscale all of the images.

- [00:26:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1575) So after the upscaling have been completed, you will get all of the images in your target

- [00:26:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1580) destination folder and now we are ready to animate our frames.

- [00:26:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1585) To do that, open your DaVinci Resolve free edition set your timeline resolution for example.

- [00:26:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1591) I will make the timeline 2k like here: set your timeline frame rate.

- [00:26:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1596) Click save!

- [00:26:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1597) we are going to import all of the images as an image sequence.

- [00:26:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1601) So to do that, go to the first tab in the DaVinci Resolve and in here.

- [00:26:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1605) Click this three dots icon, change frame display mode to sequence.

- [00:26:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1609) Then we need to rename these upscaled images to be able to import into DaVinci Resolve.

- [00:26:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1616) Select all of the images right click.

- [00:26:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1619) Rename.

- [00:27:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1620) The images need to start with a letter so you can give any name like a.

- [00:27:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1625) Hit enter.

- [00:27:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1626) All of the images are renamed, then select all of them, drag and drop to this area and

- [00:27:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1633) you will see they are imported as an image sequence.

- [00:27:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1637) Then drag and drop to here.

- [00:27:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1638) So we have our clip now.

- [00:27:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1640) Go to the edit tab.

- [00:27:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1642) Now we can use our clip.

- [00:27:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1643) Drag and drop it here.

- [00:27:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1646) Make it starting from the beginning.

- [00:27:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1647) Right, click and in here you will see clip attributes.

- [00:27:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1652) Click this from here you can change the video frame rate to the original one since our timeline

- [00:27:37](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1657) frame rate were already correct.

- [00:27:39](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1659) So this is correct and now you can play it like this.

- [00:27:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1662) So you see our frames are now completely animated as we are expecting.

- [00:27:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1668) However, there are flickering issue and this is a really big issue.

- [00:27:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1673) So if you don't have DaVinci Resolve studio edition which is about 300 dollars, there

- [00:27:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1679) is a very nice trick that you can apply to reduce flickering.

- [00:28:04](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1684) To do that right, click here.

- [00:28:06](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1686) Add a track and move your clip to the video 2 and right click here and paste.

- [00:28:13](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1693) So I have copy pasted my clip and the upper clip.

- [00:28:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1697) We are going to reduce its opacity to 50 percent.

- [00:28:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1701) Then zoom in your timeline to maximum and in the right tab right.

- [00:28:26](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1706) Click here.

- [00:28:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1707) Change it the source frame.

- [00:28:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1709) This will allow you to move clip by frame by frame.

- [00:28:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1712) So move your clip by one frame.

- [00:28:34](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1714) You see like this.

- [00:28:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1715) Now it is one frame moved.

- [00:28:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1718) So what we did is we are reducing flickering with this strategy.

- [00:28:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1723) 50 percent opacity of the duplicated clip and it is one frame later than the original

- [00:28:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1729) frame and now you will notice that the flickering is greatly reduced.

- [00:28:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1734) This is the best thing that you can do in the DaVinci Resolve free edition.

- [00:28:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1738) However, if you have studio edition then you can apply deflickering.

- [00:29:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1743) Also, I have noticed that if you change composite mode to darken, it is better than the normal

- [00:29:10](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1750) mode.

- [00:29:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1751) Let me demonstrate you.

- [00:29:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1752) So let's zoom it to here and this is normal mode.

- [00:29:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1757) You see.

- [00:29:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1758) Check this area and now I will make it darken mode.

- [00:29:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1761) You see it is looking much better than the normal mode if you ask my opinion so it is

- [00:29:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1768) up to you.

- [00:29:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1769) You can also look for other options here.

- [00:29:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1771) It will significantly change the result that you are going to get.

- [00:29:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1776) So darken composite mode is the best one I believe.

- [00:29:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1780) To apply deflickering go to the fusion tab in here, in the studio edition you will have

- [00:29:46](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1786) deflickering in the open fx.

- [00:29:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1788) For example, I have flicker free.

- [00:29:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1790) Just double click it and it will add it here.

- [00:29:53](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1793) You can add the deflickering multiple times, however it will increase your rendering time

- [00:30:00](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1800) exponentially so be careful with that.

- [00:30:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1803) You can also delete the ones that you have added.

- [00:30:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1805) Then for exporting go to the export tab here.

- [00:30:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1809) Set up your settings as you want to export as we have shown.

- [00:30:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1814) MP4, h265 encoder, auto, resolution is this one.

- [00:30:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1820) The frame rate is set, quality is best.

- [00:30:23](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1823) You can also change the advanced settings or other settings you see and then add render

- [00:30:29](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1829) queue it will ask you where you want to save it with the name and then you will have your

- [00:30:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1835) animated video.

- [00:30:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1836) For this tutorial video I didn't use any in painting or hand picking the frames.

- [00:30:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1843) So you can generate multiple frames and if one of the frame is looking bad then you can

- [00:30:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1850) replace it with another generated frame with the same frame sequence.

- [00:30:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1855) Or alternatively you can use in painting.

- [00:30:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1858) So you see by using inpainting I am able to fix eyes into much better quality.

- [00:31:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1865) This is a very bad eyes as you can see then I am just selecting it like this.

- [00:31:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1871) Entering my base prompts, clicking restore faces, selecting in paint masked, masked content

- [00:31:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1877) original, only masked mask blur is 4, the denoising strength.

- [00:31:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1882) I did set it as 0.2, CFG as 7.5 and no other settings and generate multiple images like

- [00:31:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1891) this and choose the one that you liked.

- [00:31:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1893) With this way you can improve your animation quality much more.

- [00:31:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1898) You can fix the errors or alternatively as I said, you can make multiple batch generation

- [00:31:45](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1905) and replace the bad ones with good ones.

- [00:31:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1908) I didn't do any of this for this tutorial.

- [00:31:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1910) However, you can do this to improve your animation quality much more.

- [00:31:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1914) Before I have found out this strategy initially used image to image technique which is you

- [00:32:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1921) are entering your prompt as usual, going to image to image tab, uploading your image and

- [00:32:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1927) in the very bottom you will see image to image alternative test.

- [00:32:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1932) Now this method is the one that is usually explained in the other tutorial videos, existing

- [00:32:18](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1938) tutorial videos.

- [00:32:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1939) However, this is much harder.

- [00:32:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1941) You have to play with these settings and see which one is working best.

- [00:32:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1945) Even if you find them, the quality you are going to get is nothing like the one that

- [00:32:31](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1951) I have shown.

- [00:32:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1952) Let me show you.

- [00:32:33](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1953) So after playing multiple days with image to image alternative test method, these are

- [00:32:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1958) the images that I were able to get.

- [00:32:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1960) You see it is very lesser stylized.

- [00:32:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1962) It is almost as real image.

- [00:32:44](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1964) Also, the consistency is nothing like the one we have in here.

- [00:32:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1968) So you are losing the consistency you are losing stylizing.

- [00:32:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1972) You have much worse flicking or the issues like this with this method.

- [00:32:58](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1978) So the method I have shown is much much better than the usually shown in the videos image

- [00:33:03](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1983) to image alternative test.

- [00:33:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1985) So you see, I am saving your days of work time.

- [00:33:08](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1988) I have spent five days to prepare this tutorial.

- [00:33:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1992) Actually, even more than five days right now.

- [00:33:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1995) I also searched for freely available deflicker options.

- [00:33:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=1999) For example, I have tested AbyszOne lab extension to reduce flickering.

- [00:33:24](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2004) However, the results I got was not very good.

- [00:33:28](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2008) Even I have opened an issue.

- [00:33:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2010) We have made a lot of back and forth discussion with the developer, but I wasn't able to get

- [00:33:35](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2015) good results.

- [00:33:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2016) This also took a lot of time of me while doing research for this tutorial.

- [00:33:40](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2020) Then also I have found this repository which is very freshly released all in one deflicker.

- [00:33:47](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2027) They are using ai to reduce flickering as you can see in this video.

- [00:33:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2032) However, their training is reducing the quality of the video significantly.

- [00:33:56](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2036) Let me show you the output I got from this model by using the default settings.

- [00:34:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2042) They have so many parameters that you can't even believe so it is really hard to get good

- [00:34:07](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2047) results with this one.

- [00:34:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2049) It looks very potential.

- [00:34:10](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2050) It looks very promising.

- [00:34:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2051) However, it is really hard to obtain good results.

- [00:34:15](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2055) So this is the result I got from using this newly freshly released ai-based deflickering

- [00:34:21](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2061) repository.

- [00:34:22](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2062) The quality is reduced significantly then the raw image we got.

- [00:34:27](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2067) The fps is also very reduced.

- [00:34:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2070) It is producing 10 fps unfortunately.

- [00:34:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2072) My video is 30 fps as you have seen.

- [00:34:36](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2076) I also opened thread on their GitHub page and I hope they improve and release better

- [00:34:41](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2081) configuration for us to use them.

- [00:34:43](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2083) I hope you have enjoyed this video because I have spent over five days to prepare this

- [00:34:49](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2089) video.

- [00:34:50](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2090) I have done a lot of research.

- [00:34:52](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2092) Please like, subscribe, leave a comment.

- [00:34:54](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2094) This is the best video to animation video available on the YouTube right now.

- [00:34:59](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2099) Also, all of my videos have manually fixed subtitles and I am also translating these

- [00:35:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2105) subtitles into different languages as well so you can watch them with the subtitles in

- [00:35:11](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2111) your language.

- [00:35:12](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2112) Please like subscribe, share, leave a comment if you support us by joining our youtube channel,

- [00:35:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2117) I would appreciate it very much.

- [00:35:19](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2119) This is the join button.

- [00:35:20](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2120) Also, if you support us on patreon, I would appreciate it very very much.

- [00:35:25](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2125) Just click the support me on patreon link here or in our videos.

- [00:35:30](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2130) In the description and in the comment.

- [00:35:32](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2132) You will see our patreon link and also you will see our discord link.

- [00:35:38](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2138) Click our discord link and you will see our discord page here.

- [00:35:42](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2142) You can join our discord server, ask me your questions, discuss AI and Stable Diffusion

- [00:35:48](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2148) with other wonderful people we have.

- [00:35:51](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2151) Currently you see we have 1600 members.

- [00:35:55](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2155) I am also expecting you to join and if you want to learn more about Stable Diffusion,

- [00:36:01](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2161) you can watch my excellent tutorials.

- [00:36:02](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2162) They all have subtitles as I said.

- [00:36:05](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2165) I am also replying every one of the comment you make.

- [00:36:09](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2169) If I didn't reply, that means that youtube didn't show me that comment.

- [00:36:14](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2174) So join our discord and mention me there.

- [00:36:16](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2176) I will hopefully reply you in our discord as soon as possible.

- [00:36:17](https://www.youtube.com/watch?v=kmT-z2lqEPQ&t=2177) Hopefully see you in another awesome video.

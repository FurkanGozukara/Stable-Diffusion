# Zero to Hero ControlNet Tutorial: Stable Diffusion Web UI Extension | Complete Feature Guide

## Full tutorial link > https://www.youtube.com/watch?v=3E5fhFQUVLo

[![Zero to Hero ControlNet Tutorial: Stable Diffusion Web UI Extension | Complete Feature Guide](https://img.youtube.com/vi/3E5fhFQUVLo/sddefault.jpg)](https://www.youtube.com/watch?v=3E5fhFQUVLo "Zero to Hero ControlNet Tutorial: Stable Diffusion Web UI Extension | Complete Feature Guide")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Zero-to-Hero-ControlNet-Tutorial-Stable-Diffusion-Web-UI-Extension-Complete-Feature-Guide.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Zero-to-Hero-ControlNet-Tutorial-Stable-Diffusion-Web-UI-Extension-Complete-Feature-Guide.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


I show how to install Automatic1111 Web UI & ControlNet extension installation from scratch in this video. Moreover I show how to make amazing QR codes and inpainting and out painting of ControlNet which are very similar to Photoshop generative fill and Midjourney zoom out.  Furthermore, I explain and show what are Canny, Depth, Normal, OpenPose, MLSD, Lineart, SoftEdge, Scribble, Seg, Shuffle, Tile, Inpaint, IP2P, Reference, T2IA features of ControlNet.

Source GitHub Readme File ‚§µÔ∏è

[https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/ControlNet-Tutorial-How-To-Install-Extension-Become-A-Master.md](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/ControlNet-Tutorial-How-To-Install-Extension-Become-A-Master.md)

Our Discord server ‚§µÔ∏è

[https://bit.ly/SECoursesDiscord](https://bit.ly/SECoursesDiscord)

Auto Install Scripts (windows) ‚§µÔ∏è

[https://www.patreon.com/posts/automatic-and-84875387](https://www.patreon.com/posts/automatic-and-84875387)

Auto Install Scripts (runpod) ‚§µÔ∏è

[https://www.patreon.com/posts/84896373](https://www.patreon.com/posts/84896373)

If I have been of assistance to you and you would like to show your support for my work, please consider becoming a patron on ü•∞ ‚§µÔ∏è

[https://www.patreon.com/SECourses](https://www.patreon.com/SECourses)

[00:00:00](https://youtu.be/3E5fhFQUVLo?t=0) Introduction to most advanced zero to hero ControlNet tutorial

[00:02:55](https://youtu.be/3E5fhFQUVLo?t=175) How to install Stable Diffusion Automatic1111 Web UI from scratch

[00:05:05](https://youtu.be/3E5fhFQUVLo?t=305) How to see extensions of files like .bat

[00:06:15](https://youtu.be/3E5fhFQUVLo?t=375) Where to find command line arguments of Automatic1111 and what are they

[00:06:46](https://youtu.be/3E5fhFQUVLo?t=406) How to run Stable Diffusion and ControlNet on a weak GPU

[00:07:37](https://youtu.be/3E5fhFQUVLo?t=457) Where to put downloaded Stable Diffusion model files

[00:08:29](https://youtu.be/3E5fhFQUVLo?t=509) How to give different folder path as the model path - you can store models on another drive

[00:09:15](https://youtu.be/3E5fhFQUVLo?t=555) How to start using Stable Diffusion via Automatic1111 Web UI

[00:10:00](https://youtu.be/3E5fhFQUVLo?t=600) Command line interface freezing behaviour

[00:10:13](https://youtu.be/3E5fhFQUVLo?t=613) How to improve image generation of Stable Diffusion with better VAE file

[00:11:39](https://youtu.be/3E5fhFQUVLo?t=699) Default VAE vs best VAE comparison

[00:11:50](https://youtu.be/3E5fhFQUVLo?t=710) How to set quick shortcuts for VAE and Clip Skip for Automatic1111 Web UI

[00:12:30](https://youtu.be/3E5fhFQUVLo?t=750) How to upgrade xFormers to the latest version in Automatic1111

[00:13:40](https://youtu.be/3E5fhFQUVLo?t=820) What is xFormers and other optimizers

[00:14:26](https://youtu.be/3E5fhFQUVLo?t=866) How to install ControlNet extension of Automatic1111 Web UI

[00:18:00](https://youtu.be/3E5fhFQUVLo?t=1080) How to download ControlNet models

[00:19:40](https://youtu.be/3E5fhFQUVLo?t=1180) How to use custom Stable Diffusion models with Automatic1111 Web UI

[00:21:24](https://youtu.be/3E5fhFQUVLo?t=1284) How to update ControlNet extension to the latest version

[00:22:53](https://youtu.be/3E5fhFQUVLo?t=1373) Set this true, allow other scripts to control ControlNet extension

[00:24:37](https://youtu.be/3E5fhFQUVLo?t=1477) How to make amazing QR code images with ControlNet

[00:30:59](https://youtu.be/3E5fhFQUVLo?t=1859) Best settings for QR code image generation

[00:31:44](https://youtu.be/3E5fhFQUVLo?t=1904) What is Depth ControlNet option and how to use it

[00:33:28](https://youtu.be/3E5fhFQUVLo?t=2008) Depth_leres++ of ControlNet

[00:34:15](https://youtu.be/3E5fhFQUVLo?t=2055) Depth_zoe of ControlNet

[00:34:22](https://youtu.be/3E5fhFQUVLo?t=2062) Official information of Depth maps

[00:34:49](https://youtu.be/3E5fhFQUVLo?t=2089) ControlNet Normal map

[00:35:34](https://youtu.be/3E5fhFQUVLo?t=2134) Normal Midas map

[00:36:05](https://youtu.be/3E5fhFQUVLo?t=2165) Official information of Normal maps

[00:34:49](https://youtu.be/3E5fhFQUVLo?t=2089) ControlNet Canny model

[00:37:42](https://youtu.be/3E5fhFQUVLo?t=2262) Official information of Canny

[00:37:55](https://youtu.be/3E5fhFQUVLo?t=2275) ControlNet MLSD straight lines model

[00:39:08](https://youtu.be/3E5fhFQUVLo?t=2348) Official information of MLSD straight lines

[00:39:18](https://youtu.be/3E5fhFQUVLo?t=2358) ControlNet Scribble model

[00:40:28](https://youtu.be/3E5fhFQUVLo?t=2428) How to use your own scribble images and turn them into amazing artworks

[00:40:45](https://youtu.be/3E5fhFQUVLo?t=2445) When to select none in pre-processor section

[00:41:20](https://youtu.be/3E5fhFQUVLo?t=2480) My prompt is more important

[00:41:36](https://youtu.be/3E5fhFQUVLo?t=2496) ControlNet is more important

[00:42:01](https://youtu.be/3E5fhFQUVLo?t=2521) Official information of Scribble

[00:42:11](https://youtu.be/3E5fhFQUVLo?t=2531) ControlNet Softedge model

[00:43:12](https://youtu.be/3E5fhFQUVLo?t=2592) Official information of SoftEdge

[00:43:22](https://youtu.be/3E5fhFQUVLo?t=2602) ControlNet Segmentation (Seg) model

[00:43:55](https://youtu.be/3E5fhFQUVLo?t=2635) How to modify your prompt to properly utilize segmentation

[00:44:10](https://youtu.be/3E5fhFQUVLo?t=2650) Association of prompt with segments the ControlNet finds

[00:44:41](https://youtu.be/3E5fhFQUVLo?t=2681) How to turn your wall into a painting with ControlNet

[00:45:33](https://youtu.be/3E5fhFQUVLo?t=2733) Why I selected none preprocessor

[00:43:06](https://youtu.be/3E5fhFQUVLo?t=2586) Official information of segmentation (Seg)

[00:46:16](https://youtu.be/3E5fhFQUVLo?t=2776) Open pose module of ControlNet

[00:46:40](https://youtu.be/3E5fhFQUVLo?t=2800) How to install and use OpenPose editor

[00:50:58](https://youtu.be/3E5fhFQUVLo?t=3058) Official information of OpenPose

[00:51:08](https://youtu.be/3E5fhFQUVLo?t=3068) ControlNet Lineart model

[00:51:36](https://youtu.be/3E5fhFQUVLo?t=3096) Preprocessor preview bug

[00:54:21](https://youtu.be/3E5fhFQUVLo?t=3261) Real lineart into amazing art example

[00:56:34](https://youtu.be/3E5fhFQUVLo?t=3394) How to generate amazing logo images by using Lineart of ControlNet

[00:58:16](https://youtu.be/3E5fhFQUVLo?t=3496) Difference between just resize, crop and resize, and resize and fill

[00:59:02](https://youtu.be/3E5fhFQUVLo?t=3542) ControlNet Shuffle model

[01:00:50](https://youtu.be/3E5fhFQUVLo?t=3650) Official information of Shuffle

[01:02:36](https://youtu.be/3E5fhFQUVLo?t=3756) What is multi-ControlNet and how to use it

[01:04:05](https://youtu.be/3E5fhFQUVLo?t=3845) Instruct pix2pix of ControlNet

[01:06:00](https://youtu.be/3E5fhFQUVLo?t=3960) Inpainting feature of ControlNet

[01:07:49](https://youtu.be/3E5fhFQUVLo?t=4069) ControlNet inpainting vs Automatic1111 inpainting

[01:07:59](https://youtu.be/3E5fhFQUVLo?t=4079) How to get true power of inpainting of ControlNet (hint: with tiling)

[01:09:00](https://youtu.be/3E5fhFQUVLo?t=4140) How to upscale and add details to the images with inpainting + tiling

[01:09:30](https://youtu.be/3E5fhFQUVLo?t=4170) The tile color fix + sharp to obtain even better results

[01:10:35](https://youtu.be/3E5fhFQUVLo?t=4235) Tile color fix + sharp vs old tile resample result comparison

[01:11:20](https://youtu.be/3E5fhFQUVLo?t=4280) How to use generative fill feature of Photoshop in ControlNet to remove objects

[01:12:58](https://youtu.be/3E5fhFQUVLo?t=4378) How to outpaint (zoom out feature of midjourney 5.2) image with ControlNet

[01:14:17](https://youtu.be/3E5fhFQUVLo?t=4457) The logic of outpainting

[01:14:40](https://youtu.be/3E5fhFQUVLo?t=4480) How to continue outpainting easily

[01:16:06](https://youtu.be/3E5fhFQUVLo?t=4566) Tiling of ControlNet - ultimate game changer for upscaling

[01:17:19](https://youtu.be/3E5fhFQUVLo?t=4639) How to turn your image into a fully stylized image with tiling without training

[01:20:57](https://youtu.be/3E5fhFQUVLo?t=4857) Reference only feature of ControlNet

[01:22:29](https://youtu.be/3E5fhFQUVLo?t=4949) Official information of Reference mode

[01:22:39](https://youtu.be/3E5fhFQUVLo?t=4959) Style Transfer (T2IA) of ControlNet

[01:26:54](https://youtu.be/3E5fhFQUVLo?t=5214) How to install and use ControlNet on RunPod



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=0) Greetings everyone. In this video, I will show&nbsp; you how to install Stable Diffusion Automatic&nbsp;&nbsp;

- [00:00:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5) 1111 web UI from scratch. How to install the&nbsp; most amazing and most advanced extension of&nbsp;&nbsp;

- [00:00:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=11) Stable Diffusion community, ControlNet from&nbsp; scratch. How to generate amazing QR codes by&nbsp;&nbsp;

- [00:00:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=17) using ControlNet with a very easy workflow with&nbsp; using only single ControlNet. What is the Depth&nbsp;&nbsp;

- [00:00:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=24) feature of ControlNet and how to use it to&nbsp; generate images like this. What is Normal&nbsp;&nbsp;

- [00:00:29](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=29) map of ControlNet and how to utilize Normal maps&nbsp; to generate images like these. What is Lineart of&nbsp;&nbsp;

- [00:00:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=35) ControlNet and how to generate amazing pictures&nbsp; from Lineart images like this. What is Canny of&nbsp;&nbsp;

- [00:00:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=41) ControlNet and how to utilize Canny of ControlNet&nbsp; properly. From this image to this image. What is&nbsp;&nbsp;

- [00:00:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=47) Scribble of ControlNet and how to use Scribble&nbsp; of ControlNet. What is SoftEdge of ControlNet and&nbsp;&nbsp;

- [00:00:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=48) how to use SoftEdge of&nbsp; ControlNet. What is segmentation&nbsp;&nbsp;

- [00:00:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=56) of ControlNet and how utilize segmentation of&nbsp; ControlNet. What is OpenPose of ControlNet and&nbsp;&nbsp;

- [00:00:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=57) how to utilize OpenPose of ControlNet. What&nbsp; is Shuffling of ControlNet and how to utilize&nbsp;&nbsp;

- [00:01:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=67) Shuffling with Canny to generate amazing pictures&nbsp; like this. What is instruct pix2pix feature of&nbsp;&nbsp;

- [00:01:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=72) ControlNet and how can you utilize instruct&nbsp; pix2pix of ControlNet. How to combine tiling&nbsp;&nbsp;

- [00:01:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=79) and inpainting of ControlNet to improve images&nbsp; resolution and quality significantly like this.&nbsp;&nbsp;

- [00:01:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=86) How to use generative fill feature of ControlNet&nbsp; like in Photoshop for free. How to use outpainting&nbsp;&nbsp;

- [00:01:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=93) of ControlNet similar to the Midjourney or&nbsp; generative fill of Photoshop as you are seeing&nbsp;&nbsp;

- [00:01:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=98) right now. How to continue outpainting very&nbsp; easily. I will show you that. What is tiling of&nbsp;&nbsp;

- [00:01:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=104) ControlNet and how you can use it to turn yourself&nbsp; into an avatar image like this very easily. What&nbsp;&nbsp;

- [00:01:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=111) is Reference of ControlNet and how you can use&nbsp; Reference to generate images. What is T2IA of&nbsp;&nbsp;

- [00:01:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=117) ControlNet and how you can use style transfer&nbsp; of ControlNet to generate amazing stylized&nbsp;&nbsp;

- [00:02:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=123) images. How to use ControlNet on RunPod and how&nbsp; to download ControlNet models on RunPod. How to&nbsp;&nbsp;

- [00:02:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=131) update ControlNet on RunPod. I have prepared an&nbsp; amazing GitHub readme file for this tutorial. All&nbsp;&nbsp;

- [00:02:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=138) of the links and the commands that we are going&nbsp; to use are posted on this GitHub readme file. This&nbsp;&nbsp;

- [00:02:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=144) readme file will get updated if it be necessary.&nbsp; So this is your number one source for this&nbsp;&nbsp;

- [00:02:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=151) tutorial. The link for this file will be in the&nbsp; description of the video and also in the pinned&nbsp;&nbsp;

- [00:02:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=156) comments of the video. As some of you may already&nbsp; know, I have Stable Diffusion GitHub repository.&nbsp;&nbsp;

- [00:02:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=162) I am posting all of the useful stuff here. My&nbsp; previous tutorials, the readme files of the&nbsp;&nbsp;

- [00:02:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=168) other tutorials, and many other things. So if you&nbsp; star it, fork it and watch it. I would appreciate&nbsp;&nbsp;

- [00:02:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=173) that very much. So, we will begin with cloning&nbsp; and installing the Automatic1111 web UI. For this&nbsp;&nbsp;

- [00:03:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=180) tutorial, you need to have Python to be installed&nbsp; along with Git. If you don't know how to install&nbsp;&nbsp;

- [00:03:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=186) python. I have an excellent tutorial for that.&nbsp; Just click this. It will open you this tutorial.&nbsp;&nbsp;

- [00:03:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=192) Watch it and you will learn how to use python how&nbsp; to install python at the level that is required&nbsp;&nbsp;

- [00:03:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=198) to use Stable Diffusion. Installing Automatic1111&nbsp; web UI is so simple. However, for your easiness,&nbsp;&nbsp;

- [00:03:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=204) I prepared also automatic installer: open this&nbsp; link. You will find some information and attached&nbsp;&nbsp;

- [00:03:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=212) scripts here. Download control_net_install.bat&nbsp; file and control_net_downloader.py file and&nbsp;&nbsp;

- [00:03:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=219) auto_install_SD_web_ui.bat file. If&nbsp; you are not my Patreon supporter,&nbsp;&nbsp;

- [00:03:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=223) don't worry because everything that these scripts&nbsp; doing are also documented here and I will show&nbsp;&nbsp;

- [00:03:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=230) you them. So this is optional. This will make your&nbsp; installation easier. I will make two installation&nbsp;&nbsp;

- [00:03:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=237) in my E volume. So let's make a folder name it&nbsp; as auto and also another folder as manual. So&nbsp;&nbsp;

- [00:04:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=245) in auto we will do automatic installation and in&nbsp; manual we will do manual installation. You will&nbsp;&nbsp;

- [00:04:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=249) see both of them. So let's begin with automatic&nbsp; installation. I copy the files downloaded, paste&nbsp;&nbsp;

- [00:04:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=256) them into my auto folder and I just double click&nbsp; the auto_install_SD_web_ui.bat file. It will ask&nbsp;&nbsp;

- [00:04:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=263) you. Run anyway. You can right click this script,&nbsp; edit, and see inside of it. It is so simple and&nbsp;&nbsp;

- [00:04:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=270) let's also begin our manual installation. So&nbsp; for manual installation we will begin with git&nbsp;&nbsp;

- [00:04:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=276) clone. Copy this command, open a new cmd window&nbsp; inside your manual folder, or wherever you want&nbsp;&nbsp;

- [00:04:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=283) to install. Right click and paste the command and&nbsp; hit enter. It will clone the repository into that&nbsp;&nbsp;

- [00:04:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=289) folder. Meanwhile, automatic installation is&nbsp; running. Then we will add xFormers. Because I&nbsp;&nbsp;

- [00:04:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=295) prefer using xFormers. It is really good when&nbsp; you are working with higher resolution images&nbsp;&nbsp;

- [00:05:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=300) and when you are doing training. So enter inside&nbsp; the cloned folder. Find webui-user.bat file. If&nbsp;&nbsp;

- [00:05:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=309) you are not seeing the extensions of files like&nbsp; me, go to view tab here and here check the file&nbsp;&nbsp;

- [00:05:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=315) name extensions. It will show you the file&nbsp; extensions. Right click, click edit. Add this&nbsp;&nbsp;

- [00:05:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=320) as a command line argument here, save and then&nbsp; just double click it. It will make a new virtual&nbsp;&nbsp;

- [00:05:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=327) environment and start installing Automatic1111&nbsp; web UI for Stable Diffusion. Automatic 1111 web&nbsp;&nbsp;

- [00:05:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=333) UI is the best interface best ui for using Stable&nbsp; Diffusion. It has over 85,000 stars on GitHub and&nbsp;&nbsp;

- [00:05:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=344) this is magnificent. This is amazing. This is the&nbsp; best UI that I am using for Stable Diffusion. I&nbsp;&nbsp;

- [00:05:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=350) will show you what it is if you don't know it,&nbsp; but I am pretty sure most of my viewers already&nbsp;&nbsp;

- [00:05:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=355) knowing this. You will see it is installing every&nbsp; libraries like this when it is running on the cmd&nbsp;&nbsp;

- [00:06:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=361) window. Cmd window is our number one source&nbsp; of information to see what is happening when&nbsp;&nbsp;

- [00:06:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=367) using Stable Diffusion or when using ControlNet.&nbsp; Also, if you want to learn more about set command&nbsp;&nbsp;

- [00:06:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=373) line arguments like this, there is a link of wiki&nbsp; page for Automatic 1111 web UI. Click this link,&nbsp;&nbsp;

- [00:06:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=379) you will see all of the command line arguments&nbsp; here. You can read this page and see what kind&nbsp;&nbsp;

- [00:06:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=386) of arguments you can give. For example, you can&nbsp; give the folder of models so that you can use&nbsp;&nbsp;

- [00:06:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=391) single folder for multiple Automatic1111 web UI&nbsp; installations. You can set a lot of folders here.&nbsp;&nbsp;

- [00:06:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=398) There are also a lot of other options here. You&nbsp; can look all of them and see which one of them&nbsp;&nbsp;

- [00:06:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=403) are useful for you. For example, if you have a GPU&nbsp; that is not strong, you can add --lowvram. It will&nbsp;&nbsp;

- [00:06:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=412) optimize your Automatic1111 web UI to use lesser&nbsp; vram. This will help you significantly if you have&nbsp;&nbsp;

- [00:06:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=419) low vram having gpu. If you get out of vram memory&nbsp; error, you can use lowvram or medvram. First,&nbsp;&nbsp;

- [00:07:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=425) try medvram. If medvram fails, then use lowvram.&nbsp; Moreover, if you have a low ram in your computer,&nbsp;&nbsp;

- [00:07:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=432) you can use lowram option as well. So as I said,&nbsp; check all of the options here. Since we did a&nbsp;&nbsp;

- [00:07:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=438) fresh installation, it will download the default&nbsp; 1.5 pruned Stable Diffusion model file. However,&nbsp;&nbsp;

- [00:07:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=446) if you have model file already, you can close the&nbsp; screen at this point and copy paste the model. Let&nbsp;&nbsp;

- [00:07:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=453) me show you. By the way, this is the automatic&nbsp; installation. So I closed the window. I have a&nbsp;&nbsp;

- [00:07:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=458) lot of models inside my F drive 0 models. From&nbsp; here let's copy the 1.5 pruned.ckpt. This is the&nbsp;&nbsp;

- [00:07:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=465) base model. You can also use other models. So I&nbsp; copied it. Go to the auto, go to inside Stable&nbsp;&nbsp;

- [00:07:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=472) Diffusion web UI folder go to inside models, go to&nbsp; inside Stable Diffusion and paste it here. You see&nbsp;&nbsp;

- [00:07:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=479) this is the previous file that it was downloading.&nbsp; However, since we have closed the window, it was&nbsp;&nbsp;

- [00:08:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=485) not completed so I will delete it and for starting&nbsp; I just need to double click webui-user file.&nbsp;&nbsp;

- [00:08:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=491) However, automatic installation automatically&nbsp; upgrades xFormers to latest version so I will&nbsp;&nbsp;

- [00:08:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=498) delete this command so that it won't reinstall&nbsp; it again and double click it. Meanwhile, manual&nbsp;&nbsp;

- [00:08:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=504) installation is also downloading the model file.&nbsp; So let's also close it. For manual installation I&nbsp;&nbsp;

- [00:08:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=510) will say that use this particular folder, let's&nbsp; copy the path, go to our manual installation,&nbsp;&nbsp;

- [00:08:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=516) open Stable Diffusion web UI, right click and&nbsp; edit the webui-user file and here I will add the&nbsp;&nbsp;

- [00:08:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=525) ckpt command. The command can be found here. ckpt&nbsp; directory edit and then copy paste the path which&nbsp;&nbsp;

- [00:08:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=533) is let's copy it again zero models like this.&nbsp; Okay, don't forget to put quotation marks, save&nbsp;&nbsp;

- [00:09:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=541) it. And let's also start our manual installations.&nbsp; For starting it and for installing it we use&nbsp;&nbsp;

- [00:09:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=547) webui-user.bat file and it will start the manual&nbsp; installation of Stable Diffusion. Once it is&nbsp;&nbsp;

- [00:09:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=554) started you will see a url like this: you need&nbsp; to open this in your browser. So you can copy it,&nbsp;&nbsp;

- [00:09:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=560) paste it into your browser and you see this is&nbsp; our Stable Diffusion web UI interface. Now you&nbsp;&nbsp;

- [00:09:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=567) can use text to image to generate images. You will&nbsp; see the models are listed here, click refresh and&nbsp;&nbsp;

- [00:09:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=574) you will see the new models if you download&nbsp; them. For example, let's type as a cute cat&nbsp;&nbsp;

- [00:09:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=580) and just hit generate. There are so many other&nbsp; options. Hopefully I will make another tutorial&nbsp;&nbsp;

- [00:09:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=586) that I will cover much more information about how&nbsp; to use Stable Diffusion web UI, Automatic1111 web&nbsp;&nbsp;

- [00:09:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=592) UI. In the very bottom of the screen you see the&nbsp; user python version, Torch version, xFormers,&nbsp;&nbsp;

- [00:09:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=599) Gradio version. By the way it was frozen because&nbsp; when you click the command line interface it may&nbsp;&nbsp;

- [00:10:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=606) get frozen. So just click the command line&nbsp; interface and hit enter to unfreeze it and&nbsp;&nbsp;

- [00:10:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=611) we got the result. But this is not good and we can&nbsp; improve this with better VAE file. So I have also&nbsp;&nbsp;

- [00:10:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=619) shown how to download VAE file in here. We will&nbsp; do that. So open this link and this will download&nbsp;&nbsp;

- [00:10:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=626) the best VAE file. The manual installation is also&nbsp; loaded. Let's also open it. You will notice that&nbsp;&nbsp;

- [00:10:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=632) this is running on the one increased port. So this&nbsp; is the automatic installation. This is the manual&nbsp;&nbsp;

- [00:10:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=639) installation and in manual installation I have&nbsp; so many different models as you are seeing right&nbsp;&nbsp;

- [00:10:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=645) now because we did set its model folder to another&nbsp; folder and it sees all of the models there. Okay,&nbsp;&nbsp;

- [00:10:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=653) VAE file is downloaded, copy it, you need to&nbsp; put VAE file inside, Stable Diffusion, inside&nbsp;&nbsp;

- [00:10:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=659) models inside VAE folder, copy paste it there.&nbsp; Let's also do the same for manual installation&nbsp;&nbsp;

- [00:11:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=665) as well and VAE is put. So this was the cat image&nbsp; we got with the default VAE. So let's also check&nbsp;&nbsp;

- [00:11:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=672) it out with the best VAE. So I copied the seed&nbsp; and I don't change anything else and it should&nbsp;&nbsp;

- [00:11:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=677) produce the same image. Okay, let's open the image&nbsp; in a new tab, then go to the settings in here,&nbsp;&nbsp;

- [00:11:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=683) go to the Stable Diffusion in here, refresh it&nbsp; and you will see default VAE selection. Let's&nbsp;&nbsp;

- [00:11:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=690) select it and apply and go to text image tab and&nbsp; generate again and let's compare the result. Okay,&nbsp;&nbsp;

- [00:11:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=697) this is the default way of the model and&nbsp; this is the improved VAE. Improved VAE&nbsp;&nbsp;

- [00:11:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=702) is definitely better and it will definitely&nbsp; improve your overall image quality. Moreover,&nbsp;&nbsp;

- [00:11:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=708) you may have noticed it in some tutorials. There&nbsp; are some quick shortcuts in the above part of the&nbsp;&nbsp;

- [00:11:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=715) screen. Go to the settings, in here click the&nbsp; user interface tab, in here wou will see info,&nbsp;&nbsp;

- [00:12:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=722) quick list settings. Click here and it will&nbsp; allow you to add quick selections to your web&nbsp;&nbsp;

- [00:12:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=727) UI interface. So from here I will select VAE, you&nbsp; see SD VAE and then you can also select clip skip&nbsp;&nbsp;

- [00:12:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=737) which is used in some of the models and then all&nbsp; you need to do is apply settings and reload ui and&nbsp;&nbsp;

- [00:12:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=744) ui is reloaded. Now I see quick VAE selection and&nbsp; I see quick click skipping. You see. So as a next&nbsp;&nbsp;

- [00:12:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=751) step I will upgrade also xFormers of the manual&nbsp; installation. Let's close both of them. First you&nbsp;&nbsp;

- [00:12:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=757) need to activate the virtual environment of Stable&nbsp; Diffusion because whatever you do is installed&nbsp;&nbsp;

- [00:12:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=764) inside the virtual environment in python with&nbsp; Stable Diffusion. As I said, watch this tutorial&nbsp;&nbsp;

- [00:12:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=770) if you don't know about virtual environments&nbsp; and python. So copy this. Enter inside your&nbsp;&nbsp;

- [00:12:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=776) installation folder. It will be inside manual&nbsp; Stable Diffusion. Open a new cmd here. Now this&nbsp;&nbsp;

- [00:13:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=783) cmd windows in this folder. It is very important&nbsp; where your cmd window is open. Copy, right click,&nbsp;&nbsp;

- [00:13:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=790) paste, hit enter. I have given incorrect version&nbsp; why? Because I wanted to list all of the versions&nbsp;&nbsp;

- [00:13:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=797) available to install and currently this is the&nbsp; latest version. So hit enter and then type like&nbsp;&nbsp;

- [00:13:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=803) this pip Install xFormers==0.0.21.dev553 and it&nbsp; will install the latest xFormers version. This is&nbsp;&nbsp;

- [00:13:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=817) how I find the latest version and install it. You&nbsp; may wonder what is xFormers why we are installing?&nbsp;&nbsp;

- [00:13:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=823) xFormers is an optimization library that increases&nbsp; the speed of the generation significantly. There&nbsp;&nbsp;

- [00:13:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=829) are also other optimization techniques. I added&nbsp; the link here. Open it and you can read the&nbsp;&nbsp;

- [00:13:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=835) available Stable Diffusion web UI optimizations&nbsp; here. You can use other optimization techniques&nbsp;&nbsp;

- [00:14:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=841) as well. So all of the optimizations are written&nbsp; here. These are the command line arguments.&nbsp;&nbsp;

- [00:14:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=846) I prefer to use xFormers over opt sdp attention&nbsp; because it supports I think higher resolution and&nbsp;&nbsp;

- [00:14:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=853) also it is better for training with DreamBooth&nbsp; or LoRA. Okay, we have installed our Stable&nbsp;&nbsp;

- [00:14:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=859) Diffusion web UI. We have installed the best VAE.&nbsp; Now it is time to install the famous ControlNet.&nbsp;&nbsp;

- [00:14:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=866) A lot of ControlNet information is found in&nbsp; this link. I put it here. This is the official&nbsp;&nbsp;

- [00:14:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=871) repository of the ControlNet. You can learn much&nbsp; more about ControlNet in here. So let's begin&nbsp;&nbsp;

- [00:14:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=877) with installation. There are two ways that you can&nbsp; install. I will show both of them. For automatic&nbsp;&nbsp;

- [00:14:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=883) installation I have a script that I have prepared&nbsp; which I have shown in the beginning of the video.&nbsp;&nbsp;

- [00:14:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=888) Just double click control net install. It will&nbsp; clone it. If it already exists it will update it,&nbsp;&nbsp;

- [00:14:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=894) then it will download automatically the missing&nbsp; model files. After this operation is completed,&nbsp;&nbsp;

- [00:15:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=900) all you need to do is restart your web UI with&nbsp; webUI-user file. Let's continue with manual&nbsp;&nbsp;

- [00:15:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=907) installation. So there are two ways of manual&nbsp; installation. First one is manually cloning the&nbsp;&nbsp;

- [00:15:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=913) repository. To do that copy this link git clone&nbsp; enter inside Stable Diffusion web ui folder. Enter&nbsp;&nbsp;

- [00:15:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=920) inside extensions. Open a new cmd here. Copy paste&nbsp; it. It will clone the ControlNet into the correct&nbsp;&nbsp;

- [00:15:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=927) folder. Then start your web ui and it will install&nbsp; the necessary dependencies. The second way is like&nbsp;&nbsp;

- [00:15:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=934) this: let me show you. To show you, first I will&nbsp; delete the cloned extension. Start your web UI&nbsp;&nbsp;

- [00:15:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=940) as usual. Sometimes this automatic installation is&nbsp; not working. Therefore, learning how to install an&nbsp;&nbsp;

- [00:15:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=947) extension manually is the best approach. Okay, web&nbsp; UI started. Let's open it. Go to the extensions&nbsp;&nbsp;

- [00:15:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=953) here. Click available and click load from and&nbsp; in here search for ControlNet. You will see&nbsp;&nbsp;

- [00:16:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=961) ControlNet with the name of SD web UI ControlNet.&nbsp; When you click the name of the extension in the&nbsp;&nbsp;

- [00:16:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=969) left panel, it will open the repository that it&nbsp; is going to install and this is the correct SD&nbsp;&nbsp;

- [00:16:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=974) web UI ControlNet repository. Click, install, and&nbsp; look at the messages in the cmd window of Stable&nbsp;&nbsp;

- [00:16:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=982) Diffusion web UI. Meanwhile, it is installing.&nbsp; It also prevented us to click anything else. It&nbsp;&nbsp;

- [00:16:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=988) says processing. If this screen is frozen, click&nbsp; the screen of the cmd and hit enter. I see that&nbsp;&nbsp;

- [00:16:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=995) it has already cloned the repository. However,&nbsp; still, we are waiting. Maybe it is bugged again&nbsp;&nbsp;

- [00:16:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1001) because it shouldn't take this long and it should&nbsp; install the dependencies after restart. But let's&nbsp;&nbsp;

- [00:16:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1008) wait a little bit more. Okay, it looks like the&nbsp; installation procedure has been changed with this&nbsp;&nbsp;

- [00:16:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1013) way, so it tried to install the dependencies of&nbsp; the extension as well. However, we have OS error&nbsp;&nbsp;

- [00:17:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1020) access denied. Because the virtual environment was&nbsp; active. The Stable Diffusion web UI was already&nbsp;&nbsp;

- [00:17:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1027) working. So I closed this window and I will&nbsp; restart the web UI. Then this time it should&nbsp;&nbsp;

- [00:17:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1032) install all of the requirements properly. You&nbsp; see it says that it is installing requirements&nbsp;&nbsp;

- [00:17:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1037) and this is the commit hash of my currently used&nbsp; web ui. And meanwhile, the automatic installer is&nbsp;&nbsp;

- [00:17:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1044) downloading all of the ControlNet models. You need&nbsp; to download these models. I will show in a moment&nbsp;&nbsp;

- [00:17:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1051) web UI started. Let's open it. And now you will&nbsp; see ControlNet in the text image in bottom here&nbsp;&nbsp;

- [00:17:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1059) under seed. This is the ControlNet extension. In&nbsp; image the image you will see ControlNet extension&nbsp;&nbsp;

- [00:17:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1065) as well. Pretty much wherever it is supported&nbsp; you will see the ControlNet extension like this.&nbsp;&nbsp;

- [00:17:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1071) However, now we are missing the ControlNet models&nbsp; because we haven't downloaded any of them yet.&nbsp;&nbsp;

- [00:17:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1077) So you won't see any models here. However, you&nbsp; will see the preprocessors. So how are we going&nbsp;&nbsp;

- [00:18:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1083) to download the models manually. You see there&nbsp; is a link I have put here. This is the latest&nbsp;&nbsp;

- [00:18:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1088) control net version 1.1. Click it. You will see&nbsp; the model files here. The model files are the&nbsp;&nbsp;

- [00:18:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1094) ones that are over 1 gigabytes. To download them&nbsp; click this download icon. Let me zoom in more.&nbsp;&nbsp;

- [00:18:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1101) You can download only the models that you need.&nbsp; However, for demonstration, let's begin with&nbsp;&nbsp;

- [00:18:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1107) downloading Canny for example. Click this. It will&nbsp; start downloading. If you open your downloads,&nbsp;&nbsp;

- [00:18:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1113) you will see the downloaded file like this. Okay,&nbsp; the download has been completed. Cut the file,&nbsp;&nbsp;

- [00:18:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1119) move into your installation, inside extensions.&nbsp; This is important. This is where we put the&nbsp;&nbsp;

- [00:18:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1125) ControlNet models. Inside sd-webui-ControlNet,&nbsp; inside models. This is where you need to put&nbsp;&nbsp;

- [00:18:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1133) your models. You see all of the yaml files are&nbsp; here. Yaml files are configuration files. They&nbsp;&nbsp;

- [00:18:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1139) are automatically downloaded with the extension.&nbsp; However, you have to manually download the pth&nbsp;&nbsp;

- [00:19:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1144) model files which are over 1 gigabyte. Then,&nbsp; when I refresh here, I should see the model. Yes,&nbsp;&nbsp;

- [00:19:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1151) now I can see the model and now I can use Canny&nbsp; with this one. With this approach, you need to&nbsp;&nbsp;

- [00:19:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1158) download all of the models that you want to use&nbsp; and put them inside to that particular folder.&nbsp;&nbsp;

- [00:19:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1164) Alternatively, you can use my auto downloader&nbsp; script. It will download all of the models for&nbsp;&nbsp;

- [00:19:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1170) you automatically into the correct folder before&nbsp; starting, showing you how to utilize all of the&nbsp;&nbsp;

- [00:19:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1177) different models of ControlNet. Let me also show&nbsp; you how to use custom models with Stable Diffusion&nbsp;&nbsp;

- [00:19:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1185) Automatic1111 web UI. You can download the models&nbsp; from Hugging Face or from CivitAI. I prefer&nbsp;&nbsp;

- [00:19:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1192) Hugging Face because in Hugging Face we can find&nbsp; full precision models. For example, DreamShaper.&nbsp;&nbsp;

- [00:19:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1199) This is one of the most famous models. By the way.&nbsp; If you want to see famous models on Hugging Face,&nbsp;&nbsp;

- [00:20:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1204) click the Stable Diffusion. It will list you&nbsp; Stable Diffusion models sorted by most downloads.&nbsp;&nbsp;

- [00:20:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1211) You can also sort them by recently updated or&nbsp; from most likes. So from here you can see the&nbsp;&nbsp;

- [00:20:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1217) most downloaded models and you can look each one&nbsp; of them. So in DreamShaper when you click files&nbsp;&nbsp;

- [00:20:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1223) and versions, you will see all of the model files&nbsp; uploaded by the developer of this model. You will&nbsp;&nbsp;

- [00:20:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1230) see different options such as pruned. I prefer&nbsp; full models. Baked VAE means that this model&nbsp;&nbsp;

- [00:20:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1237) has its VAE baked. Therefore, you can either&nbsp; use its own VAE or the VAE file we downloaded.&nbsp;&nbsp;

- [00:20:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1245) Let's download this model. When you click this&nbsp; icon, it will start downloading. The model file&nbsp;&nbsp;

- [00:20:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1250) has been downloaded. Whether you download it&nbsp; from Hugging Face or from CivitAI, you need&nbsp;&nbsp;

- [00:20:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1257) to put the model inside models directory, Stable&nbsp; Diffusion web UI models, Stable Diffusion and put&nbsp;&nbsp;

- [00:21:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1264) the models here. You see since the previous model&nbsp; downloading has been terminated by us manually,&nbsp;&nbsp;

- [00:21:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1270) it is not fully downloaded so I will delete it.&nbsp; If your model download didn't complete, you will&nbsp;&nbsp;

- [00:21:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1276) get an error while trying to use it. The automatic&nbsp; downloader is still downloading the files because&nbsp;&nbsp;

- [00:21:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1282) there are 14 different models. Let's say you&nbsp; want to also update the ControlNet extension to&nbsp;&nbsp;

- [00:21:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1290) the latest version. So for updating an extension&nbsp; to the latest version, there are two approaches.&nbsp;&nbsp;

- [00:21:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1296) The first one is manual updating which will work&nbsp; every time. Go inside your extensions folder,&nbsp;&nbsp;

- [00:21:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1304) enter inside the extension, open a new cmd when&nbsp; you are inside the extension folder type git pull.&nbsp;&nbsp;

- [00:21:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1311) This is manual updating. This will work always.&nbsp; And the second way is let's open our web UI.&nbsp;&nbsp;

- [00:21:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1318) Go to extensions tab in the web UI. Click check&nbsp; for updates. It will check for updates and if it&nbsp;&nbsp;

- [00:22:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1326) is not latest version, click apply and restart ui.&nbsp; It will update the extension to the latest. Then&nbsp;&nbsp;

- [00:22:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1334) you can restart the web ui by closing cmd and&nbsp; reopening it. Automatic installation is fully&nbsp;&nbsp;

- [00:22:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1340) completed, all models downloaded. I will continue&nbsp; with automatic installation because I have shown&nbsp;&nbsp;

- [00:22:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1345) everything with the manual installation by now.&nbsp; Start the web UI with web user file. I just double&nbsp;&nbsp;

- [00:22:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1351) click this bat file. I always use this file to&nbsp; install and start my Automatic1111 web UI. Okay,&nbsp;&nbsp;

- [00:22:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1358) the web ui has started. I know from this local&nbsp; url. It automatically loads the VAE file we&nbsp;&nbsp;

- [00:22:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1365) did set. Applying the optimization xFormers,&nbsp; everything is loaded. Let's open the url. There&nbsp;&nbsp;

- [00:22:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1372) is one crucial thing that you need to do before&nbsp; start using the ControlNet. Go to settings. In&nbsp;&nbsp;

- [00:23:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1380) here you will see ControlNet settings, click it&nbsp; and in here you should select this option. Allow&nbsp;&nbsp;

- [00:23:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1387) other scripts to control this extension. This is&nbsp; really important because in many of the scripts&nbsp;&nbsp;

- [00:23:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1394) that you may likely to use in future it will&nbsp; require this option to be selected. There are&nbsp;&nbsp;

- [00:23:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1399) also other options here you can use, for example,&nbsp; passing ControlNet parameters with send to image&nbsp;&nbsp;

- [00:23:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1406) to image. You can also check this and there is&nbsp; one more thing. Model cache size. You can cache&nbsp;&nbsp;

- [00:23:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1413) multiple models in your vram. However, use this&nbsp; if you have sufficient amount of vram. Otherwise,&nbsp;&nbsp;

- [00:23:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1421) don't use this because you may get out of vram&nbsp; memory error. I have RTX3090, therefore I will&nbsp;&nbsp;

- [00:23:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1427) use it. You can also allow max models amount that&nbsp; you can use at the same time. By default it is 3&nbsp;&nbsp;

- [00:23:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1434) and it is pretty sufficient. Apply it. After apply&nbsp; we need to restart so I will close and restart. I&nbsp;&nbsp;

- [00:24:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1442) also have updated the readme file and added this&nbsp; section as well. You see I will update this file&nbsp;&nbsp;

- [00:24:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1448) as it is necessary. Even after this video you can&nbsp; make a comment to this video. I will update this&nbsp;&nbsp;

- [00:24:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1454) file if it is being necessary. You can also open&nbsp; issue or discussion in my GitHub repository. Okay,&nbsp;&nbsp;

- [00:24:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1461) web has been restarted now we will begin. In left&nbsp; up you will see the available models. Whatever the&nbsp;&nbsp;

- [00:24:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1467) model you select here, it will be used in all&nbsp; of the ControlNet actions that you are using&nbsp;&nbsp;

- [00:24:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1473) and the VAE file you selected here will be used.&nbsp; I will begin with showing you how to generate QR&nbsp;&nbsp;

- [00:24:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1479) codes with ControlNet like you are seeing right&nbsp; now. This one is working. First use this link to&nbsp;&nbsp;

- [00:24:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1486) generate your QR code. Open it, select the action&nbsp; whatever you want to generate your QR code for. I&nbsp;&nbsp;

- [00:24:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1493) will generate for our channel. I am not using any&nbsp; shorting. Make error correction level high block&nbsp;&nbsp;

- [00:25:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1500) in pixel size. Now this is important. Depending&nbsp; on your target resolution, make this bigger or&nbsp;&nbsp;

- [00:25:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1506) smaller. I will make this as 30. When I generate&nbsp; code the generated image is like this. When I open&nbsp;&nbsp;

- [00:25:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1513) it in a new tab it shows me 1050 pixels by 1050&nbsp; pixels. Save it as I save it as downloaded folder.&nbsp;&nbsp;

- [00:25:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1522) Select your model, type your query. I will use a&nbsp; simple query like this: portrait photo of naruto&nbsp;&nbsp;

- [00:25:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1530) anime hero. Now there are so many different ways&nbsp; to generate working QR code. Some of them are very&nbsp;&nbsp;

- [00:25:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1536) complex and hard to use. However, I will show you&nbsp; an easy one that won't use a lot of vram memory.&nbsp;&nbsp;

- [00:25:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1543) Select DPM++ 2M SDE Karras make the sampling steps&nbsp; like 50. Set your target resolution that you want.&nbsp;&nbsp;

- [00:25:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1551) I will select it as 768. Open your control net,&nbsp; load your downloaded QR code like you are seeing&nbsp;&nbsp;

- [00:26:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1560) right now. Enable pixel perfect. We will use&nbsp; inpaint model and from inpaint select inpaint&nbsp;&nbsp;

- [00:26:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1567) global harmonious. This is the preprocessor&nbsp; and as a model it will select inpaint so you&nbsp;&nbsp;

- [00:26:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1573) must have downloaded this model to work. Then&nbsp; the very important parameters that you can set&nbsp;&nbsp;

- [00:26:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1579) is the control weight. As you increase control&nbsp; weight, you will get lesser of your image and&nbsp;&nbsp;

- [00:26:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1586) you will get more of an image like QR code.&nbsp; Starting control step: as you start later,&nbsp;&nbsp;

- [00:26:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1592) you will get a better image with lesser like QR&nbsp; code. And if you start earlier you will get more&nbsp;&nbsp;

- [00:26:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1599) like a QR code. Ending: you want this to be as&nbsp; much as possibly lower. So starting control step&nbsp;&nbsp;

- [00:26:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1607) will be as much as possibly higher, ending control&nbsp; step will be as much as possibly lower. However,&nbsp;&nbsp;

- [00:26:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1613) this totally depends on whatever the image and the&nbsp; model you are using so therefore you have to try&nbsp;&nbsp;

- [00:27:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1620) different values. If your QR code is not working,&nbsp; try to increase this. Try to decrease this and try&nbsp;&nbsp;

- [00:27:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1626) to increase this. Find a sweet spot that works&nbsp; for you. Then let's generate eight images and&nbsp;&nbsp;

- [00:27:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1633) see which one of them will work. Not every time&nbsp; every image you generate will work. So you have&nbsp;&nbsp;

- [00:27:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1638) to generate multiples and see which one of them&nbsp; is working. By the way, this is a pretty simple&nbsp;&nbsp;

- [00:27:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1643) prompt so you can use better prompts to get better&nbsp; images. This is just for demonstration of how to&nbsp;&nbsp;

- [00:27:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1651) generate QR code with ControlNet and I think this&nbsp; is the easiest workflow that you will find on the&nbsp;&nbsp;

- [00:27:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1657) internet. So the codes are being generated right&nbsp; now. Since I have a powerful gpu, I made the batch&nbsp;&nbsp;

- [00:27:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1663) size eight. However, if you don't have a powerful&nbsp; gpu, then make the batch size one. Moreover,&nbsp;&nbsp;

- [00:27:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1669) if your gpu don't have such amount of vram, make&nbsp; this low vram. Okay, results are generated. Now&nbsp;&nbsp;

- [00:27:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1677) what you need to do is click the image, open your&nbsp; QR code application and start looking at them. For&nbsp;&nbsp;

- [00:28:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1684) example. This is working very well. As you are&nbsp; seeing right now this one is not working. This&nbsp;&nbsp;

- [00:28:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1689) one is working. This one is not working. This one&nbsp; is working. You see, we have got a lot of working&nbsp;&nbsp;

- [00:28:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1695) images. Therefore, to get a better image, what we&nbsp; can do, we can try to reduce ending control step&nbsp;&nbsp;

- [00:28:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1703) and try again. And if it works then it is better&nbsp; because we will get a better image. Let's try. So&nbsp;&nbsp;

- [00:28:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1708) generating eight different images for RTX3090&nbsp; is taking about one minute. For resolution 768&nbsp;&nbsp;

- [00:28:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1716) 768. Also, I am using xFormers, Torch version&nbsp; 2. Okay, the images are coming. So what does&nbsp;&nbsp;

- [00:28:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1725) these values means? The control weight means that&nbsp; how much should the ControlNet affect the output.&nbsp;&nbsp;

- [00:28:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1732) This is the weight. This is the importance and&nbsp; effect of the ControlNet. Starting control step:&nbsp;&nbsp;

- [00:28:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1738) this means that when I said sampling steps 50,&nbsp; the ControlNet will start after 20 step has been&nbsp;&nbsp;

- [00:29:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1745) generated. An ending control step means that&nbsp; it will stop using ControlNet when generating&nbsp;&nbsp;

- [00:29:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1752) images after like 36 steps, you can multiply&nbsp; them with this. Okay, images are generated.&nbsp;&nbsp;

- [00:29:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1758) So let's see which one of them is working. I have&nbsp; opened my QR code. Okay, this one working. Okay,&nbsp;&nbsp;

- [00:29:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1765) this one is also working very well. Okay, this&nbsp; one is also working. Wow. Amazing. This one is&nbsp;&nbsp;

- [00:29:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1770) also working. Amazing and this one is also&nbsp; working. You see, I have tried four and four&nbsp;&nbsp;

- [00:29:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1775) of them and in all of them we have got a working&nbsp; output. So therefore I can try to reduce ending&nbsp;&nbsp;

- [00:29:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1781) control step one more time and repeat the process&nbsp; until I get a non-working image. With this way&nbsp;&nbsp;

- [00:29:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1788) I will have amazing QR code images. By the way,&nbsp; as I said, this is not a good prompt. Therefore,&nbsp;&nbsp;

- [00:29:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1794) I am pretty sure you will get much more amazing&nbsp; results than me. And now we are seeing the results&nbsp;&nbsp;

- [00:29:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1799) with ending control step 70%. Okay, the first one&nbsp; is working okay, the second one didn't work. Let's&nbsp;&nbsp;

- [00:30:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1806) try third. Okay, third one is working, the fourth&nbsp; is working and the fifth is working. You see,&nbsp;&nbsp;

- [00:30:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1812) we are still getting very well working images so&nbsp; I can even try to further reduce this down like&nbsp;&nbsp;

- [00:30:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1818) the 60 percent and I can try one more time. Okay,&nbsp; time to test with 60 percent ending. Okay, first&nbsp;&nbsp;

- [00:30:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1826) one is not working, the second one not working.&nbsp; Third one not working. Fourth one not working&nbsp;&nbsp;

- [00:30:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1832) fifth also failed. Sixth also failed. Seventh and&nbsp; eight all failed. Let's try one more time. Okay,&nbsp;&nbsp;

- [00:30:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1840) this time also all failed. So you see you need to&nbsp; increase ending control step. One more time with&nbsp;&nbsp;

- [00:30:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1847) 60 percent and starting control step 40 percent&nbsp; and control weight 60 percent. It didn't work.&nbsp;&nbsp;

- [00:30:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1853) However, you can try. You understand the logic.&nbsp; Before showing you all of the ControlNet control&nbsp;&nbsp;

- [00:30:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1859) types. Let me show you the best settings for QR&nbsp; code generation. I have used sampling steps 50,&nbsp;&nbsp;

- [00:31:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1867) DPM++ 2M SDE Karras, resolution is 768 768 but&nbsp; probably you can use any resolution. CFG scale&nbsp;&nbsp;

- [00:31:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1876) 7 probably you can use any CFG scale as well. So&nbsp; used only single ControlNet, enable pixel perfect,&nbsp;&nbsp;

- [00:31:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1884) inpaint, inpaint global harmonious, ControlNet&nbsp; inpaint model, control weight is 60 percent,&nbsp;&nbsp;

- [00:31:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1891) starting control step is 40 percent and ending&nbsp; control step is 65 percent and control mode is&nbsp;&nbsp;

- [00:31:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1899) balanced, crop and resize and this one you are&nbsp; seeing right now is working very well. So let's&nbsp;&nbsp;

- [00:31:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1905) begin with the first ControlNet option Depth.&nbsp; Control Net works with maps in most cases and&nbsp;&nbsp;

- [00:31:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1912) they have multiple maps options. So I will upload&nbsp; my own picture this one and let's enable it pixel&nbsp;&nbsp;

- [00:32:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1920) perfect and let's use Depth as an option. You&nbsp; see there are several preprocessors that you can&nbsp;&nbsp;

- [00:32:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1926) select and when you click this run preprocessor&nbsp; it will show you what will this image turn into&nbsp;&nbsp;

- [00:32:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1932) as a Depth map. When you first time you try to&nbsp; use ControlNet, it will download the necessary&nbsp;&nbsp;

- [00:32:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1938) model. Currently it is downloading Midas model to&nbsp; be able to preprocess with Depth midas as you are&nbsp;&nbsp;

- [00:32:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1947) seeing right now and on the screen you are seeing&nbsp; it is downloading the Depth midas model. This&nbsp;&nbsp;

- [00:32:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1952) will happen only one time for each new model.&nbsp; New preprocessor that you use. So it will use&nbsp;&nbsp;

- [00:32:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1959) this preprocessor to get the map of this image.&nbsp; Then it will use the Depth model to generate&nbsp;&nbsp;

- [00:32:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1965) image. So this is the preprocessor preview. Let's&nbsp; generate an image based on this Depth model. So I&nbsp;&nbsp;

- [00:32:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1973) have typed an awesome intricate portrait photo of&nbsp; handsome actor. This is the result we got. So you&nbsp;&nbsp;

- [00:33:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1980) see this result is based on this Depth map. So it&nbsp; used this Depth map and it generated this amazing&nbsp;&nbsp;

- [00:33:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1987) picture with just this simple prompt, no negative&nbsp; prompts, sampling steps 20 and Eular a. I can also&nbsp;&nbsp;

- [00:33:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=1995) change resolution. Let's try with 768 and 768 and&nbsp; now we are going to get another picture. So this&nbsp;&nbsp;

- [00:33:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2002) is the result you see based on this Depth map. So&nbsp; you can also try other preprocessors. For example,&nbsp;&nbsp;

- [00:33:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2008) let's try Depth_leres++. If you want to see&nbsp; what kind of map image it will generate,&nbsp;&nbsp;

- [00:33:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2014) just click this preview icon. It will generate&nbsp; the preview. Since this is also first time it&nbsp;&nbsp;

- [00:33:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2020) is downloading 500 megabytes. It also shows where&nbsp; these files are downloaded. It is being downloaded&nbsp;&nbsp;

- [00:33:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2027) into sd web ui control that extension folder&nbsp; into annotator downloads leres you are seeing&nbsp;&nbsp;

- [00:33:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2035) right now. Okay, this is the result of Depth&nbsp; leres++. Let's generate an image. So you see&nbsp;&nbsp;

- [00:34:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2042) each Depth map will generate different maps and&nbsp; it will affect your results differently. So this&nbsp;&nbsp;

- [00:34:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2049) is another result we got with the same prompt and&nbsp; different Depth map. There is also Depth leres.&nbsp;&nbsp;

- [00:34:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2056) Each time it may use different models. Depth zoe.&nbsp; So it is also going to download this Depth_zoe and&nbsp;&nbsp;

- [00:34:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2063) it is 1.34 gigabytes. On the official ControlNet&nbsp; GitHub page this is the information they provide&nbsp;&nbsp;

- [00:34:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2072) for Depth 1.1 version. Okay here we see the result&nbsp; of using Depth_zoe. Let's generate an image with&nbsp;&nbsp;

- [00:34:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2080) Depth zoe. Each Depth map will be different and&nbsp; based on whatever you want to achieve you can try&nbsp;&nbsp;

- [00:34:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2087) them and this is another image we got. So the next&nbsp; one is ControlNet Normal maps. Let's select Normal&nbsp;&nbsp;

- [00:34:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2094) from here. So these are pre-made selections. When&nbsp; you click them they will automatically load the&nbsp;&nbsp;

- [00:35:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2100) pre-made selections. These are coming from the&nbsp; developer. So when I click Normal it select the&nbsp;&nbsp;

- [00:35:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2106) Normal_bae and Normal_bae model. Let's click the&nbsp; preview and see what kind of result we are going&nbsp;&nbsp;

- [00:35:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2112) to get. Again since this is a fresh installation,&nbsp; it is downloading the model file only one time and&nbsp;&nbsp;

- [00:35:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2118) this is the Normal map. Let's also use the same&nbsp; seed to see the effect difference. Let's hit&nbsp;&nbsp;

- [00:35:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2124) generate so with same seed with different map&nbsp; we will see what kind of image we are going to&nbsp;&nbsp;

- [00:35:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2130) get and this is the result of Normal map. Almost&nbsp; completely different images based on your needs,&nbsp;&nbsp;

- [00:35:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2137) you can try different control types. Let's look&nbsp; for Midas. So this is the Midas result. Let's&nbsp;&nbsp;

- [00:35:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2144) click, generate and see the difference. Okay, this&nbsp; is the Midas result. Let's also try none. Okay,&nbsp;&nbsp;

- [00:35:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2151) when I use none, that means that the image I&nbsp; uploaded is like a map like this so it won't work&nbsp;&nbsp;

- [00:35:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2158) properly. Let's try and this is the result we&nbsp; got because it used this base image as a map&nbsp;&nbsp;

- [00:36:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2164) which is not a map. And this is the description&nbsp; the developers provided for Normal maps in the&nbsp;&nbsp;

- [00:36:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2170) version 1.1. And the next one is Canny. I like&nbsp; this model a lot. This is amazing one. Let's try&nbsp;&nbsp;

- [00:36:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2176) it. So I click Canny and I click run preprocessor&nbsp; and this is the Canny preprocessor result. You see&nbsp;&nbsp;

- [00:36:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2184) this turned into this. In Canny there are several&nbsp; options that you can set Canny low threshold and&nbsp;&nbsp;

- [00:36:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2190) high threshold. This will determine your output&nbsp; and it will affect it significantly. For example,&nbsp;&nbsp;

- [00:36:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2196) let's try 1 and 1 and let's see the result. So&nbsp; this is the result of 1 and 1. Let's first try&nbsp;&nbsp;

- [00:36:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2202) with 1 and 1. This is the result we get when Canny&nbsp; threshold is 1 and 1. Let's open it in another tab&nbsp;&nbsp;

- [00:36:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2208) and let's make the threshold as 100 and 100 click&nbsp; preview. So this is the 100. Let's generate and&nbsp;&nbsp;

- [00:36:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2217) now we got completely different. By the way, you&nbsp; see, the face is very similar to my original face.&nbsp;&nbsp;

- [00:37:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2223) Original image because Canny threshold maps your&nbsp; face exactly as it is and it makes the generated&nbsp;&nbsp;

- [00:37:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2231) face similar to yours. So from this to this.&nbsp; Let's also make it like 200 and 200 and this is&nbsp;&nbsp;

- [00:37:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2239) the result of 200 you see 200, 100 and only 1.&nbsp; Let's try another preprocessor. It says invert&nbsp;&nbsp;

- [00:37:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2246) from white bg black line when I click preview this&nbsp; is the preview. Let's try with it. By the way,&nbsp;&nbsp;

- [00:37:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2252) also in Canny or other models you can set the&nbsp; control weight and have different effects. Okay&nbsp;&nbsp;

- [00:37:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2258) with invert we got completely unrelated thing.&nbsp; And this is the description of the developers&nbsp;&nbsp;

- [00:37:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2264) for Canny model for 1.1 version, just pause the&nbsp; video and read it if you wish. The link for this&nbsp;&nbsp;

- [00:37:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2271) page is here as I have shown in the beginning.&nbsp; Okay now MLSD straight lines. This is another&nbsp;&nbsp;

- [00:37:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2278) model. I never used this model actually so&nbsp; let's select MLSD. Let's click preview. Okay&nbsp;&nbsp;

- [00:38:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2284) this is what we get because it is trying to get&nbsp; I think the straight lines and in this image we&nbsp;&nbsp;

- [00:38:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2289) don't have much straight lines. So for testing&nbsp; straight lines I will use this downloaded image&nbsp;&nbsp;

- [00:38:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2294) which is this one. Let's click preview and now&nbsp; when I use a room I get some straight lines as&nbsp;&nbsp;

- [00:38:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2302) expected. I also need to change the prompt like&nbsp; a room and let's try. Whenever you change your&nbsp;&nbsp;

- [00:38:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2308) model it will cache it in the memory so it will&nbsp; take some time. Okay now you see it is working.&nbsp;&nbsp;

- [00:38:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2314) We got a room that is very similar in structure&nbsp; and shape to the input image as you are seeing&nbsp;&nbsp;

- [00:38:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2320) right now. So this is what MLSD is used for.&nbsp; There are also different options for example,&nbsp;&nbsp;

- [00:38:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2326) let's try threshold like this and let's see the&nbsp; preview. Let's make it like this and this is the&nbsp;&nbsp;

- [00:38:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2332) preview. As you increase the value threshold you&nbsp; will get different results and this is when the&nbsp;&nbsp;

- [00:38:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2337) both threshold is minimum. Let's try again and&nbsp; we get this image. It is almost same with the&nbsp;&nbsp;

- [00:39:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2343) same seed. It also has invert from white bg black&nbsp; line. Let's click preview and this is what we get&nbsp;&nbsp;

- [00:39:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2349) when we invert it. Completely unrelated. This is&nbsp; the description that developers has written for&nbsp;&nbsp;

- [00:39:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2355) MLSD if you want to read and Scribble. Scribble is&nbsp; amazing. I will show you. Scribble turns scribbles&nbsp;&nbsp;

- [00:39:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2363) into full images. So I loaded back my image. Let's&nbsp; select Scribble. Okay, it selects Scribble pidinet&nbsp;&nbsp;

- [00:39:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2370) let's click preview. It turned my image into&nbsp; a scribble as you are seeing and let's try the&nbsp;&nbsp;

- [00:39:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2376) result. I just typed a handsome man it is going&nbsp; to use this scribble. This is the result we got.&nbsp;&nbsp;

- [00:39:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2382) It looks pretty unrelated. It generated this image&nbsp; from this scribble map that is why. Actually it is&nbsp;&nbsp;

- [00:39:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2392) kind of matching. You see it found something&nbsp; like this in here and it turned that into a&nbsp;&nbsp;

- [00:39:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2398) face because I just typed a handsome man. So&nbsp; what else we can do We can select Scribble hed&nbsp;&nbsp;

- [00:40:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2404) as a preprocessor. It will change the map. With&nbsp; Scribble hed I think we got more details than&nbsp;&nbsp;

- [00:40:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2410) this one obviously. Let's try. This is the result&nbsp; we get with Scribble hed. Let's try Scribble xdog&nbsp;&nbsp;

- [00:40:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2417) this is the preview. I think this will be more&nbsp; detailed, more similar. This is the result we&nbsp;&nbsp;

- [00:40:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2424) got. Yeah. Let's say you have your own scribble.&nbsp; So what you need to do: Upload your scribble into&nbsp;&nbsp;

- [00:40:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2430) here. I will upload it from a downloaded photo and&nbsp; make the preprocessor none because this is already&nbsp;&nbsp;

- [00:40:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2437) like a scribble. And let's change the prompt. A&nbsp; mighty dragon and see what we are going to get.&nbsp;&nbsp;

- [00:40:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2444) So you see if your image is already preprocessed,&nbsp; then you select none in the preprocessor and this&nbsp;&nbsp;

- [00:40:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2452) is the result we got from this scribble to&nbsp; this. Why this result is not very good because&nbsp;&nbsp;

- [00:40:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2458) my uploaded image dimension is 612 by 428.&nbsp; Therefore, I need to change this 612 by 428&nbsp;&nbsp;

- [00:41:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2470) and now we will get much better results. Let's&nbsp; see. Okay. You see now we got a very close to&nbsp;&nbsp;

- [00:41:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2477) our scribble like this like you are seeing&nbsp; right now. You can also change my prompt is&nbsp;&nbsp;

- [00:41:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2483) more important. Let's try with that. My prompt&nbsp; is more important than the ControlNet and this&nbsp;&nbsp;

- [00:41:29](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2489) is the result we get. A mighty dragon from this&nbsp; scribble. It is pretty much close actually. Let's&nbsp;&nbsp;

- [00:41:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2496) also try with ControlNet is more important. Now&nbsp; it will try to match the full Scribble into this.&nbsp;&nbsp;

- [00:41:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2502) Actually it is not very like right now. Let's&nbsp; see maybe we need to. Also let's also try with&nbsp;&nbsp;

- [00:41:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2510) a scribble hed. Oh no. Because scribble is not&nbsp; as strong as lineart which I will show. But this&nbsp;&nbsp;

- [00:41:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2518) is how you can use scribble. Okay in Scribble the&nbsp; developers gave this example also this example as&nbsp;&nbsp;

- [00:42:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2525) you are seeing and this is the description of the&nbsp; Scribble given by the developers. So the SoftEdge.&nbsp;&nbsp;

- [00:42:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2531) This is another control. With SoftEdge it also&nbsp; turns your image into like a scribble but with&nbsp;&nbsp;

- [00:42:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2538) soft edges. So let's select SoftEdge from here.&nbsp; Let's click the preview with SoftEdge. So this&nbsp;&nbsp;

- [00:42:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2545) is the SoftEdge preview. It has soft edges. Let's&nbsp; return back to older resolution and hit generate.&nbsp;&nbsp;

- [00:42:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2552) Okay here we see the results of SoftEdge. This&nbsp; is the map the ControlNet generated and this is&nbsp;&nbsp;

- [00:42:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2559) the result. I think this is pretty cool. Pretty&nbsp; amazing. There are also others options that you&nbsp;&nbsp;

- [00:42:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2565) can try for example SoftEdge hedsafe safe. Let's&nbsp; also try it. Okay, this is another one as you&nbsp;&nbsp;

- [00:42:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2571) are seeing. Pretty cool. Let's try pidisafe&nbsp; and this is the result we get with pidisafe.&nbsp;&nbsp;

- [00:42:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2578) Okay finally we have hed. Let's try with hed.&nbsp; I hope I am pronouncing the keywords correctly.&nbsp;&nbsp;

- [00:43:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2584) These are hard to pronounce and this is the result&nbsp; of hed. You see it is almost like stylized image&nbsp;&nbsp;

- [00:43:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2590) of me. Maybe I don't know. It's up to you. This is&nbsp; the description that the developers have written&nbsp;&nbsp;

- [00:43:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2595) for SoftEdge 1.1 version and the next one is&nbsp; segmentation. It will turn image into segments.&nbsp;&nbsp;

- [00:43:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2603) Let's try it. So for segmentation I select this.&nbsp; Let's see how it will segment my own image. By the&nbsp;&nbsp;

- [00:43:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2610) way, in the first time, segmentation will download&nbsp; additional model files. This is the result we get&nbsp;&nbsp;

- [00:43:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2615) with the segmentation seg ofade 20k. Let's try the&nbsp; result. From this segmentation we got this result.&nbsp;&nbsp;

- [00:43:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2623) You see in the main subject we have a man, then&nbsp; we have a background where I sit a chair and in&nbsp;&nbsp;

- [00:43:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2631) the top we have another man. Why? Because in our&nbsp; prompt we only have a handsome man. So if I change&nbsp;&nbsp;

- [00:43:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2637) it like this sitting on a chair having a forest&nbsp; picture behind the wall hanging, let's try it.&nbsp;&nbsp;

- [00:44:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2643) Okay now you see everything pretty much changed.&nbsp; We have the man, we have the armchair and we have&nbsp;&nbsp;

- [00:44:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2650) the picture behind the wall hanging. So you see&nbsp; it associated the prompt with the segments that&nbsp;&nbsp;

- [00:44:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2657) we have. We have wall, we have picture, we have&nbsp; man and we have armchair. This is amazing. So try&nbsp;&nbsp;

- [00:44:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2663) to understand how this is working. Try to use&nbsp; this according to your purpose. Let's also try&nbsp;&nbsp;

- [00:44:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2670) other segmentations. Seg ofcoco. Each time it will&nbsp; download a different model unfortunately. Okay,&nbsp;&nbsp;

- [00:44:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2677) this preprocessor seg ofcoco generated pretty&nbsp; different segmentation. This was the previous one&nbsp;&nbsp;

- [00:44:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2684) and you see, this is the new one so it missed the&nbsp; painting hanging on my wall. It added a different&nbsp;&nbsp;

- [00:44:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2691) layer to my armchair. Let's try this one result.&nbsp; For this one probably I also need to modify&nbsp;&nbsp;

- [00:44:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2697) this prompt. Okay, you see now the back of my&nbsp; wall became a forest painting and this is pretty&nbsp;&nbsp;

- [00:45:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2706) amazing. This is wild actually. Okay, let's&nbsp; try seg ufake 20k. Let's click the preview.&nbsp;&nbsp;

- [00:45:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2714) Is also downloading another model, but this one&nbsp; is smaller one. But this is amazing. This is just&nbsp;&nbsp;

- [00:45:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2720) a thing that I have discovered. How to make your&nbsp; background as a painting, your wall as a painting.&nbsp;&nbsp;

- [00:45:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2728) So the smallest model performing the worst.&nbsp; As expected. Seg ufade 20k it is just pretty&nbsp;&nbsp;

- [00:45:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2736) useless. If you have your single image as like&nbsp; this, then you select none from here. As I have&nbsp;&nbsp;

- [00:45:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2744) shown in another example, this is the logic of&nbsp; how preprocessor works. If your image is already&nbsp;&nbsp;

- [00:45:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2750) preprocessed, then you select none from here.&nbsp; For example, let me save this as into downloads,&nbsp;&nbsp;

- [00:45:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2756) upload it, from here. Then I select none and I&nbsp; hit generate and it should generate same image&nbsp;&nbsp;

- [00:46:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2763) of this one. And yes, it generated same image of&nbsp; this one because I have uploaded a map instead&nbsp;&nbsp;

- [00:46:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2770) of a full image and this is the description that&nbsp; developers have written for segmentation. OpenPose&nbsp;&nbsp;

- [00:46:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2777) is another very powerful feature of ControlNet.&nbsp; It has so many options as you are seeing. So I&nbsp;&nbsp;

- [00:46:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2784) have uploaded one of my ai generated image. Let's&nbsp; select OpenPose and OpenPose full. Let's see the&nbsp;&nbsp;

- [00:46:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2791) result of OpenPose full and this is the result&nbsp; of OpenPose full. There is also edit option,&nbsp;&nbsp;

- [00:46:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2797) but it is requiring OpenPose editor so we can&nbsp; also install this. So this is the link. Let&nbsp;&nbsp;

- [00:46:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2803) me also show you how to install it. I copied the&nbsp; link, then I go to extensions, install from url,&nbsp;&nbsp;

- [00:46:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2809) paste it, and install. Okay, it is installed.&nbsp; Then I need to apply and restart ui. Okay,&nbsp;&nbsp;

- [00:46:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2816) I am doing that right now. It is restarted. Let's&nbsp; click this to get the last values, and then let's&nbsp;&nbsp;

- [00:47:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2823) open ControlNet. Let's open my ai generated image.&nbsp; Enable, pixel perfect. OpenPose, OpenPose full,&nbsp;&nbsp;

- [00:47:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2832) click preview it generated OpenPose. Okay,&nbsp; I think it requires restart of web UI. Yeah,&nbsp;&nbsp;

- [00:47:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2840) it was supposed to be added in the extension&nbsp; it is displaying here. Okay, let me restart it.&nbsp;&nbsp;

- [00:47:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2847) So I closed cmd and restarting the cmd from&nbsp; web UI to start it. When restarting web UI,&nbsp;&nbsp;

- [00:47:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2854) you see it displays whatever the arguments used.&nbsp; Whatever, the other options are loaded. Okay,&nbsp;&nbsp;

- [00:47:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2861) web UI restarted. Let's see if it is available&nbsp; now. Let's load, enable pixel perfect. OpenPose&nbsp;&nbsp;

- [00:47:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2868) preview okay, now I have edit option so probably&nbsp; we needed to restart. Okay, but it is not working.&nbsp;&nbsp;

- [00:47:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2876) Weird so looks like this extension is not. Oh,&nbsp; when I click it again edit: it appeared so from&nbsp;&nbsp;

- [00:48:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2884) this edit you can change the pose. So this is&nbsp; nose. Wherever you want nose to be positioned,&nbsp;&nbsp;

- [00:48:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2890) you can change it. These are the eyes positions.&nbsp; You can change them. This is the ear. This is the&nbsp;&nbsp;

- [00:48:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2896) body torso, the shoulders, the torso. So this is&nbsp; what it is useful for. Send pose to ControlNet.&nbsp;&nbsp;

- [00:48:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2905) Now this is the changed pose and let's try. By the&nbsp; way, this prompt won't work so let's make it like&nbsp;&nbsp;

- [00:48:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2912) this. Okay, let's generate another one with this&nbsp; post. Okay, so this is the result we are getting&nbsp;&nbsp;

- [00:48:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2917) with this OpenPose like this. However, this is not&nbsp; matching this one because of the resolution. For&nbsp;&nbsp;

- [00:48:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2925) this to be matching, I think I need 768 by 1024.&nbsp; Let's try again. Okay now it is more matching. As&nbsp;&nbsp;

- [00:48:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2933) you are seeing it is trying to match to this pose.&nbsp; So this is full pose. There are also face only.&nbsp;&nbsp;

- [00:48:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2939) When I click face only it will only put the face&nbsp; not the body position. Let me show you the result.&nbsp;&nbsp;

- [00:49:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2946) So it will try match the face not the body. It&nbsp; is still similar. Let's also try with hand but&nbsp;&nbsp;

- [00:49:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2954) we don't have any hand in this picture so this&nbsp; is another good example. Okay, I think we can try&nbsp;&nbsp;

- [00:49:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2959) with this one. Let's see. Okay, it shows hands as&nbsp; well right now let's try the pose like this. Okay,&nbsp;&nbsp;

- [00:49:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2967) it matched pretty much. Well. Yeah, so from this&nbsp; pose, this original image, we generated this image&nbsp;&nbsp;

- [00:49:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2975) and it is looking amazing. quality Yes, looking&nbsp; pretty amazing. Pretty accurate as well. So this&nbsp;&nbsp;

- [00:49:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2981) is how you can use OpenPose control. I can click&nbsp; this edit and I can edit the generated pose from&nbsp;&nbsp;

- [00:49:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2989) here. I can set it whatever I want. For example,&nbsp; let's make this like this: let's see what we will&nbsp;&nbsp;

- [00:49:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=2995) get. So I click send pose to ControlNet. Okay, now&nbsp; the hands are not matching though. The hands are&nbsp;&nbsp;

- [00:50:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3001) gone. Okay, I think hands are shown here. So okay.&nbsp; Let's reset zoom and okay it says space f drag&nbsp;&nbsp;

- [00:50:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3009) mouse so I will click space f. Okay, currently I&nbsp; am hitting space and f keys so that I am able to&nbsp;&nbsp;

- [00:50:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3017) drag and move the picture like you are seeing. So&nbsp; let's also move the hands. Okay, oh, each hand is&nbsp;&nbsp;

- [00:50:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3025) like this. Let's reset zoom. No. Okay, okay. Space&nbsp; f zoom in, select all hand, move hand to here and&nbsp;&nbsp;

- [00:50:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3035) then select this hand and move hand to here as&nbsp; well. Send pose to ControlNet and generate. I&nbsp;&nbsp;

- [00:50:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3041) wonder what kind of result we will get from this&nbsp; pose. Wow. Amazing. You see the hands are now here&nbsp;&nbsp;

- [00:50:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3047) like this. They are not completely same, but it&nbsp; matched the hand to the position of the arm and&nbsp;&nbsp;

- [00:50:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3054) it is amazing. This is another cherry pick as you&nbsp; are seeing right now. This is a live action. So&nbsp;&nbsp;

- [00:50:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3059) this is how you can use OpenPose and this is the&nbsp; description that the developers has written on&nbsp;&nbsp;

- [00:51:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3065) their page and the next one is Lineart. Lineart is&nbsp; actually the amazing one for turning sketches into&nbsp;&nbsp;

- [00:51:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3073) full arts. So let's load again our dragon image.&nbsp; I set its original resolution. Mighty dragon and I&nbsp;&nbsp;

- [00:51:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3081) select the lineart from here. But I will make the&nbsp; line art preprocessor none and let's hit generate&nbsp;&nbsp;

- [00:51:29](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3089) and see what kind of result we are going to get.&nbsp; Okay, it didn't work interestingly. We got a very&nbsp;&nbsp;

- [00:51:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3095) different oh oh it is using my other preprocessor&nbsp; probably I need to. Okay, it looks like this is a&nbsp;&nbsp;

- [00:51:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3102) bug because it used the previous preprocessor.&nbsp; Let's click the preprocessor preview so it is&nbsp;&nbsp;

- [00:51:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3107) changed and try again. We just discovered a bug&nbsp; in the control net. Okay now you see it is keeping&nbsp;&nbsp;

- [00:51:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3114) the entire shape and the structure very well. This&nbsp; is the result we got. This can be improved a lot.&nbsp;&nbsp;

- [00:52:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3122) Let me add some beautifying prompts. I added some&nbsp; beautifying prompts but still not very good. Let's&nbsp;&nbsp;

- [00:52:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3128) also try high resolution fix. By the way, still,&nbsp; I am using the same seed. That is why I am getting&nbsp;&nbsp;

- [00:52:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3133) same image when I generate multiple. Okay, I will&nbsp; change the preprocessor lineart anime and this&nbsp;&nbsp;

- [00:52:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3140) will turn into let's see. Okay line art anime is&nbsp; downloading a preprocessor model and let's change&nbsp;&nbsp;

- [00:52:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3147) the high resolution fix and I will make this&nbsp; double size like this. This is what we got from&nbsp;&nbsp;

- [00:52:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3153) line art anime. Let's try like this: double size&nbsp; of the original resolution. Okay, we are getting&nbsp;&nbsp;

- [00:52:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3160) yeah, this is the result we got from line art&nbsp; anime. Still not very good. Let's try line art&nbsp;&nbsp;

- [00:52:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3166) anime denoise I wonder what kind of output this is&nbsp; giving. This is also downloading another model. It&nbsp;&nbsp;

- [00:52:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3173) is almost looking like same as the previous one.&nbsp; Okay, we got this result. Not very good either.&nbsp;&nbsp;

- [00:53:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3180) Lineart coarse, each time it is downloading new&nbsp; models. Okay, let's try this one. By the way,&nbsp;&nbsp;

- [00:53:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3186) the preview resolution is half of what we are&nbsp; generating right now. Also, this is a pretty&nbsp;&nbsp;

- [00:53:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3192) big resolution. This time I will try line art with&nbsp; a real image that is from twitter. Let's download&nbsp;&nbsp;

- [00:53:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3198) it. Let's upload it. Let's select our line art&nbsp; realistic and click preview: okay, this is the&nbsp;&nbsp;

- [00:53:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3205) realistic preview we got. By the way, we should&nbsp; get the resolution of this image so it is 736 to&nbsp;&nbsp;

- [00:53:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3212) 1104 and then we need to change also the prompt.&nbsp; A man is against a mighty dragon. Okay, let's hit,&nbsp;&nbsp;

- [00:53:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3223) generate and see what kind of result we will get.&nbsp; It is pretty amazing, but it is not as good as the&nbsp;&nbsp;

- [00:53:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3230) original image of course, but it is pretty amazing&nbsp; when considered. We can also try several different&nbsp;&nbsp;

- [00:53:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3236) seeds. Let's make it batch size 8. Okay, we got&nbsp; the results. Let's look each one of them. This,&nbsp;&nbsp;

- [00:54:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3243) this, this and this one. Wow. Pretty amazing.&nbsp; This one. So you see you can turn your line arts,&nbsp;&nbsp;

- [00:54:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3251) sketches into amazing pictures, drawings before&nbsp; moving into next one. I want to show you an&nbsp;&nbsp;

- [00:54:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3259) example from a real line art. Free line art from&nbsp; deviantart for example. This one. Let's download&nbsp;&nbsp;

- [00:54:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3266) it. This is a free dragon line art so you can&nbsp; use this, generate image and use it as you&nbsp;&nbsp;

- [00:54:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3271) wish. The resolution is 866 to 684. Okay, I did&nbsp; set the resolution. Let's load it. Let's select&nbsp;&nbsp;

- [00:54:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3280) preprocessor none from here. And how would you&nbsp; describe this? I typed this: masterpiece amazing&nbsp;&nbsp;

- [00:54:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3287) colorful flying dragon creature. I wonder what&nbsp; kind of result we will get. Right now producing&nbsp;&nbsp;

- [00:54:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3293) eight of them with page size 8. Again, we got&nbsp; the same results as the previous one with the&nbsp;&nbsp;

- [00:54:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3299) new resolution because it is still using the&nbsp; preprocessor preview. You see when I changed&nbsp;&nbsp;

- [00:55:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3304) the prompt it changed the result significantly.&nbsp; However, it is using the previous dimension and&nbsp;&nbsp;

- [00:55:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3310) this preprocessor. So let's click the preprocessor&nbsp; here to refresh it and try again. Okay, we got the&nbsp;&nbsp;

- [00:55:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3316) results. So this is the used line art as a map.&nbsp; This is the first result. Second one, third one,&nbsp;&nbsp;

- [00:55:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3324) fourth, fifth, sixth one. Oh this is a pretty&nbsp; cool one actually, it's just missing some of the&nbsp;&nbsp;

- [00:55:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3330) colorings. So you see you can change your prompt&nbsp; and try different ones. Oh this one is also pretty&nbsp;&nbsp;

- [00:55:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3336) amazing. I wonder what we would get with high&nbsp; resolution fix: use this seed and just only one&nbsp;&nbsp;

- [00:55:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3343) batch size. Okay with high resolution fix: this is&nbsp; the output and this is looking amazing. But in the&nbsp;&nbsp;

- [00:55:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3350) wing of the creature we have a repeating issue.&nbsp; I wonder if this can be fixed. Probably hard,&nbsp;&nbsp;

- [00:55:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3357) maybe with lower denoising strength. This is what&nbsp; we got with lower the noise but this was a too&nbsp;&nbsp;

- [00:56:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3363) low. So let's try like this. You see when you go&nbsp; below certain denoising strength then you lose the&nbsp;&nbsp;

- [00:56:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3370) clearness, sharpness or maybe focus of the image&nbsp; we can say. It is not anymore like fully focused,&nbsp;&nbsp;

- [00:56:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3379) it is like blurry image. Okay this is another&nbsp; image we have. So you see developers are showing&nbsp;&nbsp;

- [00:56:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3385) also. Same if you have a line art like this a&nbsp; sketch then you select none as a preprocessor&nbsp;&nbsp;

- [00:56:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3391) and you generate images like this. You can use&nbsp; line art for making amazing logos as well. Let&nbsp;&nbsp;

- [00:56:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3398) me show you. So I have downloaded the ChatGPT&nbsp; logo here. Select lineart from here as usual.&nbsp;&nbsp;

- [00:56:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3407) You don't need to change anything. Enable. Pixel&nbsp; perfect, select resize and fill because we will&nbsp;&nbsp;

- [00:56:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3414) make it expanded. Select your resolution from here&nbsp; like 768 by 512 and type such as aerial glacier.&nbsp;&nbsp;

- [00:57:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3424) Like this hit generate. It is totally up to your&nbsp; imagination that how you prompt for example this&nbsp;&nbsp;

- [00:57:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3431) is the first example. Let's make it batch size 8.&nbsp; Okay we got some amazing results. First second,&nbsp;&nbsp;

- [00:57:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3439) wow. Third one amazing. Fourth oww fifth one.&nbsp; This is also nice. Sixth, seven and eight okay&nbsp;&nbsp;

- [00:57:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3447) here another one. Aerial desert. First&nbsp; one oh second one pretty good. Third one,&nbsp;&nbsp;

- [00:57:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3453) fourth one fifth one. This is looking pretty&nbsp; decent. So these are the other results. It is&nbsp;&nbsp;

- [00:57:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3460) totally up to you as I said and here we see&nbsp; aerial jungle. So these are the results. Wow&nbsp;&nbsp;

- [00:57:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3467) amazing one. This is also pretty cool. Wow. This&nbsp; is also good. This is also good. Some very good&nbsp;&nbsp;

- [00:57:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3474) results. It is important that you select resize&nbsp; and fill. Because this logo this scribble is 512&nbsp;&nbsp;

- [00:58:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3483) and 512 which is one over one aspect ratio. It is&nbsp; important that to select resize and fill. So this&nbsp;&nbsp;

- [00:58:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3491) is resize and fill result you see. This is the&nbsp; map it generated. Let me show the crop and resize&nbsp;&nbsp;

- [00:58:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3499) difference using the same seed. So this is crop&nbsp; and resize difference as you are seeing right now:&nbsp;&nbsp;

- [00:58:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3506) resize and fill, crop and resize. Let me make it&nbsp; just resize and this is the result of just resize.&nbsp;&nbsp;

- [00:58:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3513) The just resize is worst. I think resize and fill&nbsp; is the best and this is crop and resize so it will&nbsp;&nbsp;

- [00:58:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3521) affect the result that you are going to get when&nbsp; you are working with non-matching aspect ratio.&nbsp;&nbsp;

- [00:58:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3527) So this is the aspect ratio that I am generating&nbsp; and the aspect ratio of the logo is not matching&nbsp;&nbsp;

- [00:58:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3533) with this one. This can be applied pretty much&nbsp; anything. To make good text to make to make logos.&nbsp;&nbsp;

- [00:59:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3541) This is another logic of using line art. So the&nbsp; next option is Shuffle. This is a new feature that&nbsp;&nbsp;

- [00:59:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3547) comes with ControlNet 1.1. It shuffles the image.&nbsp; It is pretty interesting so let's see what kind of&nbsp;&nbsp;

- [00:59:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3556) result we will get. I will select the Shuffle&nbsp; from here. I will click pre. Oh, there is no&nbsp;&nbsp;

- [00:59:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3561) preview but I need to delete this preview. Maybe&nbsp; close? no. Okay, let's refresh the page to be&nbsp;&nbsp;

- [00:59:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3568) sure. Let's upload our shuffling image. I will use&nbsp; this image for shuffling. Let's select Shuffle and&nbsp;&nbsp;

- [00:59:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3577) I entered the original resolution of the&nbsp; image and how should we shuffle it? Okay,&nbsp;&nbsp;

- [00:59:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3582) I just typed. Amazing dragon oh I forgotten to&nbsp; enable. Let's enable pixel perfect and let's&nbsp;&nbsp;

- [00:59:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3589) Shuffle again. It is loading the model, it is&nbsp; setting the proper resolution. Okay, I see. So&nbsp;&nbsp;

- [00:59:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3597) you see when we used Shuffle it almost uses the&nbsp; same colors and it Shuffled them like this. So&nbsp;&nbsp;

- [01:00:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3604) this is the image it generated based on the colors&nbsp; used in this image and this is the completely&nbsp;&nbsp;

- [01:00:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3611) Shuffled output. Actually, this is pretty amazing.&nbsp; Maybe we can try to generate a lower resolution to&nbsp;&nbsp;

- [01:00:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3618) get a better one. Wow, I see this is pretty&nbsp; amazing. Not the dimension is matching so we&nbsp;&nbsp;

- [01:00:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3625) can try as half of the original dimension. We can&nbsp; keep the aspect ratio. So this is the half of the&nbsp;&nbsp;

- [01:00:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3631) original resolution image. So here I have reduced&nbsp; the dimension according to the aspect ratio of&nbsp;&nbsp;

- [01:00:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3638) the original image. This is the result we got and&nbsp; this is the shuffling. You can play with this and&nbsp;&nbsp;

- [01:00:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3643) if you find it useful let me know in the comments.&nbsp; This is pretty interesting feature. This is also&nbsp;&nbsp;

- [01:00:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3649) pretty new. So this is the description of the&nbsp; developers written. For example, they have given&nbsp;&nbsp;

- [01:00:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3655) this image and Shuffled it as ironman. Wow, this&nbsp; is pretty interesting. Let's try this. So I will&nbsp;&nbsp;

- [01:01:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3662) test it with this image. Let's save it as ironman&nbsp; png: let's refresh the page. I will turn this into&nbsp;&nbsp;

- [01:01:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3669) spider-man. Spider-man select the image from here.&nbsp; Enable pixart perfect Shuffle. By the way, Shuffle&nbsp;&nbsp;

- [01:01:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3676) has none other preprocessor. We have a preview.&nbsp; Okay, this is the shuffling preview and let's set&nbsp;&nbsp;

- [01:01:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3684) the resolution same and let's hit generate.&nbsp; With shuffling ironman into spider-man okay,&nbsp;&nbsp;

- [01:01:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3690) it is not very like as the developers show. Maybe&nbsp; I can try superman. I wonder what we will get. The&nbsp;&nbsp;

- [01:01:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3697) spider-man is not very like. So this is Shuffled&nbsp; into this superman. I don't know if it is working&nbsp;&nbsp;

- [01:01:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3703) or not. It doesn't look like. Yeah, maybe uncheck&nbsp; this and try again. Okay, without pixel perfect,&nbsp;&nbsp;

- [01:01:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3709) it still doesn't look like shuffling as shown&nbsp; here because it is supposed to turn this image&nbsp;&nbsp;

- [01:01:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3716) into ironman. However, in our case it doesn't&nbsp; look like turning this image into this one. It&nbsp;&nbsp;

- [01:02:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3723) is a little bit similar, but not like yeah. Maybe&nbsp; I can try with my own image. So let's turn myself&nbsp;&nbsp;

- [01:02:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3729) into superman. Okay, so it turned this image into&nbsp; this one. Pretty different. Maybe because of the&nbsp;&nbsp;

- [01:02:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3736) aspect ratio let's try it. So let's try with 768.&nbsp; Okay, so it tries to match the colors and turn it&nbsp;&nbsp;

- [01:02:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3745) into this one. This is very interesting. This is&nbsp; the Shuffled image and this is the other image.&nbsp;&nbsp;

- [01:02:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3750) Anyway, I never used shuffling in any of my daily&nbsp; life, but it is supposed to work like this. Okay,&nbsp;&nbsp;

- [01:02:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3756) multi ControlNet. Multi ControlNet is extremely&nbsp; important feature. So they used this image as a&nbsp;&nbsp;

- [01:02:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3765) base image and then they used Shuffle image as&nbsp; a this image. Let's also download it. Let's load&nbsp;&nbsp;

- [01:02:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3770) them. So the first image will be used as Canny. It&nbsp; is enabled. The second ControlNet will be used for&nbsp;&nbsp;

- [01:02:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3777) shuffling enable, pixel perfect, shuffle. So we&nbsp; got this one and we got canny. Let's try ironman.&nbsp;&nbsp;

- [01:03:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3785) I wonder what kind of result we will get. Now&nbsp; it will use two images together. Okay, I see it&nbsp;&nbsp;

- [01:03:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3792) Shuffled ironman with this skin and it generated&nbsp; this image. Pretty pretty decent actually. Pretty&nbsp;&nbsp;

- [01:03:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3801) amazing also. So this is the resolution of line&nbsp; art. Let's select proper resolution. So I changed&nbsp;&nbsp;

- [01:03:29](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3809) the resolution according to the dimension of the&nbsp; ironman image. Yeah, we got a pretty decent output&nbsp;&nbsp;

- [01:03:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3816) from shuffling and from Canny. Sorry I said that&nbsp; line arts but they used Canny. Not line art. So&nbsp;&nbsp;

- [01:03:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3823) let's try also with line art and see what kind of&nbsp; result we will get. This is Canny plus shuffling.&nbsp;&nbsp;

- [01:03:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3829) It is pretty amazing actually and this is line&nbsp; art plus shuffling I see. Wow. Interesting. I&nbsp;&nbsp;

- [01:03:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3838) think this is still early days of shuffling&nbsp; so it may get better over time. These are the&nbsp;&nbsp;

- [01:04:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3844) outputs they had. Now instruct pix2pix. This is&nbsp; another feature of ControlNet. So let's refresh&nbsp;&nbsp;

- [01:04:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3851) the page. I will try with my own image. So&nbsp; I have uploaded my image. I click enable,&nbsp;&nbsp;

- [01:04:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3857) select IP2P. This is instruct pix2pix. It doesn't&nbsp; have any preprocessor. This works with giving&nbsp;&nbsp;

- [01:04:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3865) natural commands. So what can we say: we can say&nbsp; that turn hair color into red. I wonder if it&nbsp;&nbsp;

- [01:04:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3873) will work? Let's hit generate so it is loading the&nbsp; instruct pix2pix model. Okay, it didn't work very&nbsp;&nbsp;

- [01:04:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3880) well. It turned entire image into red. What else&nbsp; can we try? Okay, make the man in picture have&nbsp;&nbsp;

- [01:04:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3886) longer beard but it changed the face completely.&nbsp; It is supposed to obey our commands and make it&nbsp;&nbsp;

- [01:04:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3894) on fire. For example, they have provided in their&nbsp; page. So I have uploaded an image of a horse and&nbsp;&nbsp;

- [01:05:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3901) I said make the horse wearing an armor. It is&nbsp; pretty much turned it into correcting but it&nbsp;&nbsp;

- [01:05:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3909) changed the background. The quality decreased it.&nbsp; So instruct pix2pix of ControlNet is not working&nbsp;&nbsp;

- [01:05:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3915) very well. There is actually an original&nbsp; instruct pix2pix and it was working better.&nbsp;&nbsp;

- [01:05:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3920) This is the original paper of instruct pix2pix.&nbsp; This was better than ControlNet instruct pix2pix&nbsp;&nbsp;

- [01:05:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3927) and I think it is still like that. So ControlNet&nbsp; instruct pix2pix is not as good as the original&nbsp;&nbsp;

- [01:05:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3933) instruct pix2pix paper. It is supposed to work&nbsp; very well. Let's try make it winter. This looks&nbsp;&nbsp;

- [01:05:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3940) like a another prompt. Make it winter. By the way&nbsp; the results will depend on our selected diffusion&nbsp;&nbsp;

- [01:05:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3946) model. Okay, this is what we get with dream&nbsp; shaper. Let's also try with the base model. Okay,&nbsp;&nbsp;

- [01:05:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3952) let's hit generate with the base model. Maybe&nbsp; it will work better. I'm not sure. Okay,&nbsp;&nbsp;

- [01:05:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3957) it is not working good yeah. Inpaint. This is a&nbsp; new feature of ControlNet. This is the description&nbsp;&nbsp;

- [01:06:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3964) they have written. There are several options of&nbsp; inpainting with control net. So they have some&nbsp;&nbsp;

- [01:06:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3971) guidelines linked here. I am going to use this in&nbsp; my upcoming full realism model. Let me show you an&nbsp;&nbsp;

- [01:06:20](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3980) example. So you see on the left I am. This middle&nbsp; one is trained model generated ai image and on the&nbsp;&nbsp;

- [01:06:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3987) right you see the output of ControlNet inpainting&nbsp; and tiling output. I will show this. Hopefully in&nbsp;&nbsp;

- [01:06:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=3995) my upcoming tutorial I will show how to generate&nbsp; studio quality images so stay subscribed. For&nbsp;&nbsp;

- [01:06:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4003) testing inpainting. I generated an ai image a&nbsp; man yielding a mighty sword like this. Let's&nbsp;&nbsp;

- [01:06:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4010) send it into send to inpaint. And let's select&nbsp; from ControlNet and select inpaint mode. Enable,&nbsp;&nbsp;

- [01:06:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4018) pixel perfect and let's modify the face to improve&nbsp; it like this. Let's inpaint. I will also inpaint&nbsp;&nbsp;

- [01:07:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4027) without control net to check out the difference.&nbsp; Okay, it says that a1111 inpaint and ControlNet&nbsp;&nbsp;

- [01:07:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4033) in paint duplicated. ControlNet support enabled.&nbsp; Okay so this is the output we get with in paint of&nbsp;&nbsp;

- [01:07:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4041) ControlNet based on this mask. Actually it doesn't&nbsp; look good to me. inpaint global harmonious. Let's&nbsp;&nbsp;

- [01:07:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4048) try with it. Okay, this is what we have still not&nbsp; looking very well and this is the result. With the&nbsp;&nbsp;

- [01:07:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4055) third inpainting option inpaint only + lama. Okay&nbsp; let's try without enabling the ControlNet and this&nbsp;&nbsp;

- [01:07:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4063) time I will set only masked because this is the&nbsp; inpaint of the automatic1111. It is 75 percent.&nbsp;&nbsp;

- [01:07:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4071) Maybe we should try like 45 and let's see the&nbsp; result. It looks like Automatic1111 inpaint is&nbsp;&nbsp;

- [01:07:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4077) working better at this example. You can get the&nbsp; true power of inpainting of ControlNet when you&nbsp;&nbsp;

- [01:08:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4084) utilize it along with tiling feature. So let's&nbsp; open our image, send to inpaint. Select inpaint&nbsp;&nbsp;

- [01:08:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4092) not masked. Select resize by 2x. You can also&nbsp; increase this. Increase denoising strength to 1&nbsp;&nbsp;

- [01:08:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4099) because we will utilize tiling. Open ControlNet&nbsp; enable, pixel perfect, inpaint, inpaint only is&nbsp;&nbsp;

- [01:08:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4107) selected. Then get your controlnet unit one enable&nbsp; pixel perfect select tile and let's hit generate&nbsp;&nbsp;

- [01:08:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4114) and here we got the amazing results. You will be&nbsp; amazed by the results. So this is the result of&nbsp;&nbsp;

- [01:08:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4120) inpainting + tiling of ControlNet. Let's compare&nbsp; them. This is the new result we got and this is&nbsp;&nbsp;

- [01:08:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4128) the original image. You see it has significantly&nbsp; improved the face quality the hands quality. I&nbsp;&nbsp;

- [01:08:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4136) see some errors in the feat so we can generate&nbsp; multiple ones, but with this feature you can both&nbsp;&nbsp;

- [01:09:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4143) upscale and improve the quality significantly.&nbsp; This is where comes the power of ControlNet&nbsp;&nbsp;

- [01:09:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4150) inpainting when combined with tiling. You see from&nbsp; this image to this image. As some of you may have&nbsp;&nbsp;

- [01:09:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4157) noticed, we have lost some of the coloring when&nbsp; we have used inpainting plus tiling feature. The&nbsp;&nbsp;

- [01:09:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4165) developers also were aware of this issue and they&nbsp; have released a new preprocessor. The tile color&nbsp;&nbsp;

- [01:09:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4172) fix plus sharp. So go to your tiling ControlNet&nbsp; in the preprocessor section. Try tile color fix&nbsp;&nbsp;

- [01:09:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4180) plus sharp. Let me demonstrate you the its&nbsp; results. Moreover, you can change variation&nbsp;&nbsp;

- [01:09:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4185) and sharpness with this preprocessor and it will&nbsp; affect your results. The developer has shown some&nbsp;&nbsp;

- [01:09:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4192) comparisons. So this is the input image they used.&nbsp; You see it is only 480 pixels by 640 pixels and&nbsp;&nbsp;

- [01:10:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4200) then they have used tiling. 100 percent denoising&nbsp; strength, no extra upscaler, super resolution&nbsp;&nbsp;

- [01:10:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4207) or other things. Old man best quality. If you&nbsp; wonder what is T2I and I2I. This is text to image&nbsp;&nbsp;

- [01:10:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4215) and this is image to image. With ControlNet Tile&nbsp; resample, this is the result. With color fix this&nbsp;&nbsp;

- [01:10:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4221) is the result and with color fix plus sharpness,&nbsp; this is the result. Here our new result. Let me&nbsp;&nbsp;

- [01:10:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4227) compare. This is regular Tile resample. This is&nbsp; Tile resample plus sharpness correction. Let's&nbsp;&nbsp;

- [01:10:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4234) look at them side by side. So here right now on&nbsp; the left we are seeing the original raw output on&nbsp;&nbsp;

- [01:10:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4240) the middle Tile resample. On the right we see Tile&nbsp; resample plus color correction plus sharpness fix.&nbsp;&nbsp;

- [01:10:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4249) You see it is much more colorful. It is looking&nbsp; much more sharp. So you can also change the&nbsp;&nbsp;

- [01:10:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4255) settings here and see how they are affecting.&nbsp; For example, let's make some experimentation:&nbsp;&nbsp;

- [01:11:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4260) variation 16. So here we are seeing the variation&nbsp; 8 and here we are seeing the variation 16, 8, 16,&nbsp;&nbsp;

- [01:11:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4268) 8, 16 so it changed the colors position looks&nbsp; like. It is up to you to test and see whichever&nbsp;&nbsp;

- [01:11:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4277) one you like more. I think variation 8 has&nbsp; more details. Now I will show you the famous&nbsp;&nbsp;

- [01:11:23](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4283) generative fill feature of ControlNet which has&nbsp; arrived recently to the ControlNet. I am pretty&nbsp;&nbsp;

- [01:11:29](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4289) sure you have heard the amazing generative fill of&nbsp; Photoshop. Now we have similar feature with Stable&nbsp;&nbsp;

- [01:11:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4296) Diffusion automatic1111 web UI with the extension&nbsp; of ControlNet. This is their new preprocessor for&nbsp;&nbsp;

- [01:11:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4303) outpainting and inpainting as a generative fill&nbsp; of Photoshop. So they have used this as an example&nbsp;&nbsp;

- [01:11:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4310) image. I will also use it. Let's save image as&nbsp; into our downloads. Let's refresh our web UI.&nbsp;&nbsp;

- [01:11:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4316) Load image into your ControlNet. When you are&nbsp; using generative fill feature of ControlNet,&nbsp;&nbsp;

- [01:12:03](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4323) you don't type any prompt. Make the cfg like 4.&nbsp; So let's say you want to inpaint and remove an&nbsp;&nbsp;

- [01:12:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4331) object. How can you do that. Mask the object that&nbsp; you want to remove like this. Then in the bottom&nbsp;&nbsp;

- [01:12:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4338) enable pixel perfect. Inpaint. Select inpaint&nbsp; only + lama. This is better than inpaint only&nbsp;&nbsp;

- [01:12:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4348) for generative fill feature of ControlNet for&nbsp; removing objects or outpainting image. I will&nbsp;&nbsp;

- [01:12:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4354) also show outpainting logic So that's it. Let's&nbsp; hit generate. By the way, this is not the correct&nbsp;&nbsp;

- [01:12:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4361) dimension of the image so it will get changed but&nbsp; still working very well. You see, we have masked&nbsp;&nbsp;

- [01:12:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4367) this area. It has removed that image completely&nbsp; and perfectly fine. So this is generative fill&nbsp;&nbsp;

- [01:12:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4373) feature of ControlNet. You can use this to remove&nbsp; images. Then let's also check out how to outpaint.&nbsp;&nbsp;

- [01:13:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4381) The original image we downloaded is 500 by 750&nbsp; pixels. So we are going to change the output&nbsp;&nbsp;

- [01:13:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4388) resolution to the opposite. Like this, this means&nbsp; that it will expand the image in width and it will&nbsp;&nbsp;

- [01:13:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4396) crop the image in height. For outpainting the&nbsp; work you need to select resize and fill option&nbsp;&nbsp;

- [01:13:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4401) in ControlNet. This is really important. You&nbsp; don't need to type anything. Okay, this is the&nbsp;&nbsp;

- [01:13:27](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4407) first result we got as an outpainting. It is not&nbsp; fabulous, but we can do more trials and see if we&nbsp;&nbsp;

- [01:13:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4414) will get better. By the way, this is DreamShaper&nbsp; model. Whatever the model you use will make a&nbsp;&nbsp;

- [01:13:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4418) lot of difference. After changing resolution to&nbsp; 768 and 512 making the model realistic vision,&nbsp;&nbsp;

- [01:13:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4426) I have a very decent result. So on the left you&nbsp; see the original image and on the right we see the&nbsp;&nbsp;

- [01:13:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4434) expanded image. This is how we were able to expand&nbsp; outpaint this left image into the right image. By&nbsp;&nbsp;

- [01:14:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4444) the way, if you have noticed that the toothbrushes&nbsp; are gone, why? Because I have masked them,&nbsp;&nbsp;

- [01:14:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4453) therefore they are removed when the image were&nbsp; being expanded. So the logic of outpainting is&nbsp;&nbsp;

- [01:14:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4459) that the changing the aspect ratio of the image to&nbsp; expand it and also selecting resize and fill. You&nbsp;&nbsp;

- [01:14:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4468) don't type anything, you select your base model,&nbsp; you select your cfg scale and that's it. With that&nbsp;&nbsp;

- [01:14:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4474) way you can outpaint images in Stable Diffusion.&nbsp; Here another example and let's say you want to&nbsp;&nbsp;

- [01:14:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4480) continue outpainting. How can you do easily.&nbsp; Drag and drop the image here and then change the&nbsp;&nbsp;

- [01:14:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4488) resolution and the aspect ratio. So for example,&nbsp; let's make it as 1024 height and keep the width&nbsp;&nbsp;

- [01:14:58](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4498) same. So with this way you can continue doing&nbsp; outpainting very easily. And here we got a decent&nbsp;&nbsp;

- [01:15:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4506) example result when we further expanded, further&nbsp; outpainted the image. Because I have used very&nbsp;&nbsp;

- [01:15:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4515) high resolution. You should try to increase width&nbsp; and height with small increments. Otherwise, you&nbsp;&nbsp;

- [01:15:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4522) will have hard time to get decent images. So try&nbsp; to increase width and height in small increases.&nbsp;&nbsp;

- [01:15:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4530) For example, then I can drag and drop this one&nbsp; here and I can increase like 920. So with this&nbsp;&nbsp;

- [01:15:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4539) way you can continue outpainting and expand your&nbsp; image. When you continue outpainting your image&nbsp;&nbsp;

- [01:15:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4545) like this. It is being similar to the mid-journey&nbsp; new zoom out feature that has just arrived this&nbsp;&nbsp;

- [01:15:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4553) week. So you see ControlNet is getting better and&nbsp; better. Competing with the millions of dollars&nbsp;&nbsp;

- [01:16:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4560) having companies. So we should keep supporting the&nbsp; ControlNet developers. So the tiling: this is a&nbsp;&nbsp;

- [01:16:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4567) new feature of ControlNet and it is amazing. When&nbsp; you use tiling, it will keep the original image as&nbsp;&nbsp;

- [01:16:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4575) much as possible and it will also apply the other&nbsp; rules that you are doing. This is super useful for&nbsp;&nbsp;

- [01:16:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4581) upscaling images. For example, they show that they&nbsp; turned this image into this image with upscaling,&nbsp;&nbsp;

- [01:16:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4588) it keeps the original image. It keeps the shape&nbsp; of the original image and yet it upscales it. It&nbsp;&nbsp;

- [01:16:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4594) adds it a full details, new details. This tiling&nbsp; can be used for so many things. They have shown&nbsp;&nbsp;

- [01:16:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4602) an example here. For example, with tiling, they&nbsp; turned this very less detailed image on here you&nbsp;&nbsp;

- [01:16:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4610) see into a very detailed image like this. Tiling&nbsp; is a very powerful feature of the ControlNet.&nbsp;&nbsp;

- [01:16:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4617) From this image to this image you see. It adds&nbsp; so many details from this image to this image.&nbsp;&nbsp;

- [01:17:05](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4625) Can you see: this is the original image and this&nbsp; is the tiled upscaled image. It is amazing and I&nbsp;&nbsp;

- [01:17:13](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4633) also just demonstrated how to use it to you. You&nbsp; can use tiling with many stuff. Actually you can&nbsp;&nbsp;

- [01:17:19](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4639) use it to stylize our original image. Let me show&nbsp; you that. Let's refresh the page. Let's go to the&nbsp;&nbsp;

- [01:17:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4646) image to image. I will upload my own image. Let's&nbsp; add this one. Okay, I just typed a simple prompt,&nbsp;&nbsp;

- [01:17:33](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4653) a handsome man. Then I will select my image from&nbsp; here. Enable, pixel perfect, Tile and let's make&nbsp;&nbsp;

- [01:17:41](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4661) denoise 1 because I am using Tile and let's hit&nbsp; generate. So now I get a stylized image of myself&nbsp;&nbsp;

- [01:17:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4668) like this. It is not very like me, but let's also&nbsp; try to combine it with another ControlNet model&nbsp;&nbsp;

- [01:17:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4676) such as Canny. Let's make the Canny weight as 50&nbsp; percent and try again. Okay now it is more like me&nbsp;&nbsp;

- [01:18:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4684) from this to this. Actually we can make the Canny&nbsp; weight 1 and try again. So with tiling it will&nbsp;&nbsp;

- [01:18:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4692) keep the original image as much as possible. Okay&nbsp; now you see you see without training and without&nbsp;&nbsp;

- [01:18:18](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4698) anything it almost generated a stylized image&nbsp; of myself. Tiling will keep the original image&nbsp;&nbsp;

- [01:18:25](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4705) and with also Canny we keep the shape and we can&nbsp; get like this. We can add some more details. Okay&nbsp;&nbsp;

- [01:18:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4711) let's try. Awesome intricate cgi rendered man.&nbsp; Okay, now you see I am rendered as cgi. Let's try&nbsp;&nbsp;

- [01:18:38](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4718) a picture of a man in disney a style and let's&nbsp; try. It is also keeping the background image,&nbsp;&nbsp;

- [01:18:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4726) background objects. Okay, like this. Not very&nbsp; good. Maybe try as pixar anime style. I wonder&nbsp;&nbsp;

- [01:18:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4733) what we will get. So you see, this is how you can&nbsp; utilize multi-ControlNet styling, multi-ControlNet&nbsp;&nbsp;

- [01:19:00](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4740) tiling. Let's try this: cgi 3d rendered portrait&nbsp; photo of a man. Okay, not very good. Let's try&nbsp;&nbsp;

- [01:19:06](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4746) like this. It will totally depend on your input.&nbsp; Let's try a simple thing: photo of a man. So it&nbsp;&nbsp;

- [01:19:12](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4752) will be in the style of the DreamShaper. So&nbsp; this is it. Maybe we should add some styling.&nbsp;&nbsp;

- [01:19:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4757) okay here. A man sitting on an armchair in&nbsp; gta style. Maybe we should add gta 5. Okay,&nbsp;&nbsp;

- [01:19:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4764) now you see from this to this, perhaps we can&nbsp; make it obey our prompt more. Let's say my prompt&nbsp;&nbsp;

- [01:19:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4772) is more important with the Canny. Wow. Nice from&nbsp; this to this. So you can play with these values.&nbsp;&nbsp;

- [01:19:40](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4780) Perhaps you can reduce the weights of the Canny&nbsp; and other things. For example, let's make this 50.&nbsp;&nbsp;

- [01:19:47](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4787) It will add more details. Let's make the control&nbsp; weight 75 percent and try again. But this is fully&nbsp;&nbsp;

- [01:19:53](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4793) stylized image. Oh yes, there's another stylized&nbsp; image. Perhaps. Let's try like this. Let's make&nbsp;&nbsp;

- [01:20:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4801) this like 90 percent and try again. Let's also&nbsp; add our eyeglasses. A man with eyeglasses. Okay,&nbsp;&nbsp;

- [01:20:11](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4811) like this. By the way none of these are&nbsp; cherry-picked okay looking pretty well. Yeah,&nbsp;&nbsp;

- [01:20:17](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4817) so you can turn yourself into any style. Perhaps&nbsp; let's make this one. Let's make this as 200 and&nbsp;&nbsp;

- [01:20:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4824) 200 and try like this. Okay, nice, very nice.&nbsp; You can also reduce the tiling power. Let's make&nbsp;&nbsp;

- [01:20:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4832) this as 80 percent and try again. And this is the&nbsp; output we get. So if you reduce the tiling power,&nbsp;&nbsp;

- [01:20:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4839) you will get away from your original image. Let's&nbsp; try with 1.2 tiling power tiling weight. Okay,&nbsp;&nbsp;

- [01:20:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4848) it is now more like me I think. So you can play&nbsp; with this and see what you can get. Okay, so we&nbsp;&nbsp;

- [01:20:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4855) have got two options left, which is Reference only&nbsp; the first one. So the Reference only is similar&nbsp;&nbsp;

- [01:21:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4862) to in-paint based Reference. But it does not make&nbsp; your image disordered. So this is the description&nbsp;&nbsp;

- [01:21:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4868) that the developers has given for Reference only.&nbsp; Let's test it out. I will refresh the page. A man&nbsp;&nbsp;

- [01:21:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4875) sitting in arm chairs. Let's upload our Reference&nbsp; image here and let's select the Reference. It&nbsp;&nbsp;

- [01:21:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4884) selected reference only. Okay, let's try. This is&nbsp; the first time I am using this. Actually, I never&nbsp;&nbsp;

- [01:21:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4890) used it. Okay, it is not very like me. I wonder&nbsp; how we can improve it. Okay, so this is used in&nbsp;&nbsp;

- [01:21:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4897) yes, this is used in text to image. I think we&nbsp; need a realistic model for this to work. I wonder&nbsp;&nbsp;

- [01:21:45](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4905) what else we can use? Yes, Reference only. Let's&nbsp; try one. Okay, nothing like let's try zero ten.&nbsp;&nbsp;

- [01:21:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4914) Let's try with a realistic model like realistic&nbsp; vision version two. Okay, I make the prompt photo&nbsp;&nbsp;

- [01:22:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4921) of a man. Wow. Now we get somewhat similar thing.&nbsp; Let's try with style fidelity unbalanced to zero.&nbsp;&nbsp;

- [01:22:09](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4929) I wonder what we will get. Okay, this is with&nbsp; zero. Let's make it as five percent. Okay like&nbsp;&nbsp;

- [01:22:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4936) this. Let's change the prompt like this. Okay,&nbsp; I don't know. Let's try again. Wow. It tries to&nbsp;&nbsp;

- [01:22:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4942) make something similar but the results are not&nbsp; very good. Okay with Reference only. So far we&nbsp;&nbsp;

- [01:22:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4948) didn't get anything good, but you understand the&nbsp; logic, you can try it. So this is the description&nbsp;&nbsp;

- [01:22:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4954) of the developer. The last remaining model&nbsp; is style transfer T2IA adapter models. It is&nbsp;&nbsp;

- [01:22:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4962) downloaded from this url. I also have updated the&nbsp; GitHub readme file style transfer models T2IA. In&nbsp;&nbsp;

- [01:22:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4970) the readme file you will find this link. So from&nbsp; here you need to download the models that you want&nbsp;&nbsp;

- [01:22:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4976) to use. Let's try style transfer model which is&nbsp; this one co-adapter style transfer and also let's&nbsp;&nbsp;

- [01:23:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4987) try this T2IA adapter style. In the description&nbsp; it says add style adapter and in the other one&nbsp;&nbsp;

- [01:23:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=4994) it doesn't say. So these two are style adapters.&nbsp; Okay, it says that co-adapter is not implemented&nbsp;&nbsp;

- [01:23:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5001) yet so it won't be useful. So the style adapter&nbsp; is used like this source image, input and output.&nbsp;&nbsp;

- [01:23:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5008) Okay, let's give it a try. So I cut the copied&nbsp; model, paste it into extensions, ControlNet,&nbsp;&nbsp;

- [01:23:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5015) models. Yes, then let's refresh our page. Okay now&nbsp; I will show you how you can use style adapter. Let&nbsp;&nbsp;

- [01:23:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5024) me refresh. Go to text to image, type your prompt.&nbsp; A mighty dragon like this. Select ControlNet,&nbsp;&nbsp;

- [01:23:51](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5031) upload your style image. I want to generate a&nbsp; dragon with this style. Enable. Select t2 from&nbsp;&nbsp;

- [01:23:59](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5039) here. The model is selected as T2IA adapter style.&nbsp; Select your preprocessor as style clip vision and&nbsp;&nbsp;

- [01:24:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5047) then select your desired width and height. For&nbsp; example, let's make it like this: 1024, 768 and&nbsp;&nbsp;

- [01:24:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5055) this is the output we got. It is similar to the&nbsp; style, not perfect of course. And if you wonder&nbsp;&nbsp;

- [01:24:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5062) what would happen without selecting style adapter,&nbsp; let me show you. So this is another image. Let's&nbsp;&nbsp;

- [01:24:28](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5068) try with high resolution fix. Okay we got so many&nbsp; repeating maybe try like this. Okay so this is the&nbsp;&nbsp;

- [01:24:35](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5075) image. Let's also make the seed same and when I&nbsp; disable this style transfer, style clip vision,&nbsp;&nbsp;

- [01:24:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5082) let's see what result we are going to get. You see&nbsp; we get completely different thing not even related&nbsp;&nbsp;

- [01:24:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5089) to this style. Let's enable again and with style&nbsp; transfer we get somewhat similar style. I think&nbsp;&nbsp;

- [01:24:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5096) it is working decent. If you prefer you can also&nbsp; download color transfer. It is working like this.&nbsp;&nbsp;

- [01:25:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5102) This is the color source, this is input and this&nbsp; is the output. It tries to match the colors of the&nbsp;&nbsp;

- [01:25:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5108) picture and in style it tries to match the style&nbsp; of the source. You see it didn't use any image as&nbsp;&nbsp;

- [01:25:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5114) a input in the color, we use an image as an input.&nbsp; So the other says that if you have 4 gigabyte vram&nbsp;&nbsp;

- [01:25:22](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5122) having gpu and if you enable low vram, you can&nbsp; go up to 768 by 832 pixels resolution when using&nbsp;&nbsp;

- [01:25:32](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5132) ControlNet. This is all for today. Please join&nbsp; our Discord channel. When you click this link,&nbsp;&nbsp;

- [01:25:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5137) you will get to this page. Join to our server.&nbsp; You can follow me from twitter. When you click&nbsp;&nbsp;

- [01:25:43](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5143) this link, you will see my twitter account. This&nbsp; is our youtube channel as you already know. If&nbsp;&nbsp;

- [01:25:49](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5149) you support me on Patreon, I would appreciate that&nbsp; very much. When you click this link, you will get&nbsp;&nbsp;

- [01:25:54](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5154) to this page. Your Patreon support is tremendously&nbsp; important for me. Currently we have over 200&nbsp;&nbsp;

- [01:26:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5161) supporters. I appreciate them very much. I am&nbsp; posting a lot of special content here. Actually,&nbsp;&nbsp;

- [01:26:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5167) these are content that I show in my videos,&nbsp; but instead of writing the code yourself, you&nbsp;&nbsp;

- [01:26:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5174) are able to download the code from here directly.&nbsp; So it will make your life easier and it will help&nbsp;&nbsp;

- [01:26:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5181) me to continue producing more higher quality&nbsp; content. It will allow me to do more research,&nbsp;&nbsp;

- [01:26:26](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5186) more work for you. Also, please, like subscribe,&nbsp; leave a comment. Tell me your ideas, tell me your&nbsp;&nbsp;

- [01:26:34](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5194) opinions. If you also support me by joining on&nbsp; Youtube, I would appreciate that very much. On&nbsp;&nbsp;

- [01:26:39](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5199) our Youtube page you will find our Patreon Discord&nbsp; and my linkedin link. In the description of this&nbsp;&nbsp;

- [01:26:46](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5206) video, you will find the GitHub readme file&nbsp; link like this and also in the pinned comment&nbsp;&nbsp;

- [01:26:52](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5212) you will find the GitHub readme file like this.&nbsp; If you don't have a good gpu, then you can use&nbsp;&nbsp;

- [01:26:57](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5217) this software on RunPod as well. Everything is&nbsp; same. Let me show you how to use this on RunPod.&nbsp;&nbsp;

- [01:27:04](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5224) To use the ControlNet on RunPod. Let's go to our&nbsp; RunPod. By clicking this link, you will get RunPod&nbsp;&nbsp;

- [01:27:10](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5230) page. You can either sign up if you don't have an&nbsp; account or login. Let's login. Okay, I have logged&nbsp;&nbsp;

- [01:27:16](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5236) in my account, community cloud. Let's select a&nbsp; pod like RTX3090. Look for Stable Diffusion web&nbsp;&nbsp;

- [01:27:24](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5244) automatic. This is important. This template comes&nbsp; with ControlNet. Continue, deploy. If you don't&nbsp;&nbsp;

- [01:27:30](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5250) know how to use RunPod, I have an excellent two&nbsp; tutorials. Watch both of them. You see the links&nbsp;&nbsp;

- [01:27:36](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5256) are here in the end of the readme file. So the&nbsp; logic is saying you just need to download the&nbsp;&nbsp;

- [01:27:42](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5262) model files. You can download them one by one or&nbsp; you can use my automatic script which is posted&nbsp;&nbsp;

- [01:27:48](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5268) here. So let's download our automatic downloader&nbsp; script first in the attached cdnRunPod.py file.&nbsp;&nbsp;

- [01:27:55](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5275) Let's connect to jupyter lab. The models will be&nbsp; downloaded into the same folder. Let's open the&nbsp;&nbsp;

- [01:28:01](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5281) models folder. For example let's download this&nbsp; model file. Right click this arrow, copy link&nbsp;&nbsp;

- [01:28:07](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5287) address. Enter inside the extensions. ControlNet,&nbsp; models ControlNet models, open a new terminal&nbsp;&nbsp;

- [01:28:15](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5295) inside. Here you see currently I am inside models.&nbsp; wget Paste the link and it will download the model&nbsp;&nbsp;

- [01:28:21](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5301) into models folder. Alternatively, you can upload&nbsp; my script to here, open a new terminal and copy&nbsp;&nbsp;

- [01:28:31](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5311) the name of the file. You can right click,&nbsp; rename, select all copy type python, the name&nbsp;&nbsp;

- [01:28:37](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5317) of the file hit enter. It will skip installation&nbsp; of the ControlNet. It will then update it to the&nbsp;&nbsp;

- [01:28:44](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5324) latest version with git pull. Then it will start&nbsp; downloading all of the model files. If one of the&nbsp;&nbsp;

- [01:28:50](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5330) model file exists then it will skip it. If not&nbsp; exist, it will download it. So this is how you&nbsp;&nbsp;

- [01:28:56](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5336) use ControlNet models on RunPod. Then just click&nbsp; connect. Click connect to 3000 port. You see&nbsp;&nbsp;

- [01:29:02](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5342) it comes with ControlNet extension. Click here.&nbsp; Refresh the models. As the models get downloaded,&nbsp;&nbsp;

- [01:29:08](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5348) they will appear here. You just need to click&nbsp; refresh. The rest is same. The usage is same&nbsp;&nbsp;

- [01:29:14](https://www.youtube.com/watch?v=3E5fhFQUVLo&t=5354) as I have shown in this video. Thank you very&nbsp; much for watching. Hopefully see you later.

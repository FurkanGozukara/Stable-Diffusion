# Z-Image Turbo LoRA training with AI Toolkit and Z-Image ControlNet Full Tutorial for Highest Quality

## Full tutorial link > https://www.youtube.com/watch?v=ezD6QO14kRc

[![Z-Image Turbo LoRA training with AI Toolkit and Z-Image ControlNet Full Tutorial for Highest Quality](https://img.youtube.com/vi/ezD6QO14kRc/sddefault.jpg)](https://www.youtube.com/watch?v=ezD6QO14kRc "Z-Image Turbo LoRA training with AI Toolkit and Z-Image ControlNet Full Tutorial for Highest Quality")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Z-Image-Turbo-LoRA-training-with-AI-Toolkit-and-Z-Image-ControlNet-Full-Tutorial-for-Highest-Quality.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Z-Image-Turbo-LoRA-training-with-AI-Toolkit-and-Z-Image-ControlNet-Full-Tutorial-for-Highest-Quality.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Z-Image Turbo LoRA training with Ostris AI Toolkit + Z-Image Turbo Fun Controlnet Union + 1-click to download and install the very best Z-Image Turbo presets. In this tutorial, I will explain how to setup Z-Image Turbo model properly in your local PC with SwarmUI and download models and use them with highest quality via ready presets. Moreover, I will show to install Z-Image Turbo Fun Controlnet Union to generate amazing quality images with ControlNet preprocessors. Furthermore, I will show how to 1-click install AI Toolkit from Ostris and train Z-Image Turbo model LoRAs with highest quality configs made for every GPU like 8 GB GPUs, 12 GB GPUs, 24 GB GPUs and so on. I did a massive research to prepare these Z-Image Turbo model training configurations.

üëá Links & Resources Mentioned:

Download SwarmUI & Models: [ [https://www.patreon.com/posts/Download-SwarmUI-Models-114517862](https://www.patreon.com/posts/Download-SwarmUI-Models-114517862) ]

Ostris AI Toolkit (SECourses Version): [ [https://www.patreon.com/posts/Ostris-AI-Toolkit-140089077](https://www.patreon.com/posts/Ostris-AI-Toolkit-140089077) ]

Ultimate Batch Image Processing App: [ [https://www.patreon.com/posts/Ultimate-Batch-Image-Processing-App-120352012](https://www.patreon.com/posts/Ultimate-Batch-Image-Processing-App-120352012) ]

SwarmUI with ComfyUI Backend Windows Tutorial: [ [https://youtu.be/c3gEoAyL2IE](https://youtu.be/c3gEoAyL2IE) ]

SwarmUI with ComfyUI Backend RunPod and Massed Compute Cloud Tutorial: [ [https://youtu.be/bBxgtVD3ek4](https://youtu.be/bBxgtVD3ek4) ]

‚è±Ô∏è Video Chapters:

[00:00:00](https://youtu.be/ezD6QO14kRc?t=0) Introduction to Z-Image Turbo Model

[00:00:54](https://youtu.be/ezD6QO14kRc?t=54) FP8 Scaled Version 5.7GB for Low VRAM

[00:01:10](https://youtu.be/ezD6QO14kRc?t=70) ControlNet Union with Z-Image Turbo

[00:01:30](https://youtu.be/ezD6QO14kRc?t=90) LoRA Training with Ostris AI Toolkit

[00:02:00](https://youtu.be/ezD6QO14kRc?t=120) Default vs Custom Training Preset Quality Comparison

[00:03:00](https://youtu.be/ezD6QO14kRc?t=180) RunPod Cloud Training Preview

[00:03:40](https://youtu.be/ezD6QO14kRc?t=220) MassedCompute Cloud Training Preview

[00:04:16](https://youtu.be/ezD6QO14kRc?t=256) Downloading Z-Image Models via SwarmUI

[00:05:00](https://youtu.be/ezD6QO14kRc?t=300) Z-Image Turbo Core Bundle & ControlNet Files

[00:05:58](https://youtu.be/ezD6QO14kRc?t=358) FP8 Scaled Model & Musubi Tuner Converter

[00:07:13](https://youtu.be/ezD6QO14kRc?t=433) Updating ComfyUI for Sage & Flash Attention

[00:08:13](https://youtu.be/ezD6QO14kRc?t=493) Updating SwarmUI & ControlNet Preprocessors

[00:08:52](https://youtu.be/ezD6QO14kRc?t=532) Updating & Importing Latest SwarmUI Presets

[00:09:20](https://youtu.be/ezD6QO14kRc?t=560) Generating with Quality 2 Fast Preset

[00:10:48](https://youtu.be/ezD6QO14kRc?t=648) Generating with Quality 1 Upscale Preset

[00:11:35](https://youtu.be/ezD6QO14kRc?t=695) Quality 1 vs Quality 2 Visual Comparison

[00:12:13](https://youtu.be/ezD6QO14kRc?t=733) Setting up ControlNet Input & Aspect Ratio

[00:13:41](https://youtu.be/ezD6QO14kRc?t=821) ControlNet Strength Settings & Canny Test

[00:15:26](https://youtu.be/ezD6QO14kRc?t=926) Using Depth Preprocessor with Z-Image

[00:15:58](https://youtu.be/ezD6QO14kRc?t=958) Coloring Lineart Drawings with ControlNet

[00:16:58](https://youtu.be/ezD6QO14kRc?t=1018) Lineart Preprocessing Comparison

[00:17:50](https://youtu.be/ezD6QO14kRc?t=1070) Ostris AI Toolkit Installation Prerequisites

[00:19:12](https://youtu.be/ezD6QO14kRc?t=1152) Installing Ostris AI Toolkit on Windows

[00:20:02](https://youtu.be/ezD6QO14kRc?t=1202) First Time UI Setup & Launching Interface

[00:21:04](https://youtu.be/ezD6QO14kRc?t=1264) Loading Custom Training Configs

[00:21:38](https://youtu.be/ezD6QO14kRc?t=1298) Creating a New Dataset Structure

[00:22:24](https://youtu.be/ezD6QO14kRc?t=1344) Ultimate Batch Image Processing App Install

[00:23:17](https://youtu.be/ezD6QO14kRc?t=1397) Dataset Prep Stage 1: Auto-Zooming with SAM2

[00:26:08](https://youtu.be/ezD6QO14kRc?t=1568) Dataset Prep Stage 2: Resizing to Exact Resolution

[00:28:12](https://youtu.be/ezD6QO14kRc?t=1692) How to Select Best Training Images

[00:30:24](https://youtu.be/ezD6QO14kRc?t=1824) Importance of Emotions & Angles in Datasets

[00:31:44](https://youtu.be/ezD6QO14kRc?t=1904) Z-Image Resolution & Aspect Ratio Rules

[00:33:21](https://youtu.be/ezD6QO14kRc?t=2001) Configuring Training Parameters & Epochs

[00:36:52](https://youtu.be/ezD6QO14kRc?t=2212) Resolution Impact on Training Speed

[00:37:46](https://youtu.be/ezD6QO14kRc?t=2266) Starting the Training Job on Windows

[00:38:39](https://youtu.be/ezD6QO14kRc?t=2319) Monitoring Training Progress & VRAM

[00:39:43](https://youtu.be/ezD6QO14kRc?t=2383) Checkpoint Generation Settings

[00:40:40](https://youtu.be/ezD6QO14kRc?t=2440) Resuming Training from Last Checkpoint

[00:42:09](https://youtu.be/ezD6QO14kRc?t=2529) Training Speeds on RTX 5090 vs 4090 vs 3060

[00:43:01](https://youtu.be/ezD6QO14kRc?t=2581) Training Quality: Default vs Custom Preset Comparison

[00:44:21](https://youtu.be/ezD6QO14kRc?t=2661) Testing LoRAs with SwarmUI Grid Generator

[00:46:04](https://youtu.be/ezD6QO14kRc?t=2764) Fixing ControlNet Error in Grid Generation

[00:47:09](https://youtu.be/ezD6QO14kRc?t=2829) Comparing Generated LoRA Checkpoints

[00:47:38](https://youtu.be/ezD6QO14kRc?t=2858) Using Trained LoRA with ControlNet Union

[00:48:10](https://youtu.be/ezD6QO14kRc?t=2890) RunPod: GPU Selection & Template Setup

[00:50:32](https://youtu.be/ezD6QO14kRc?t=3032) RunPod: Port 8675 Config & Initialization

[00:51:36](https://youtu.be/ezD6QO14kRc?t=3096) RunPod: Uploading Installation Files

[00:52:01](https://youtu.be/ezD6QO14kRc?t=3121) RunPod: One-Click Installation Command

[00:54:07](https://youtu.be/ezD6QO14kRc?t=3247) RunPod: Starting AI Toolkit & Proxy Connection

[00:54:38](https://youtu.be/ezD6QO14kRc?t=3278) RunPod: Uploading Dataset via Interface

[00:55:32](https://youtu.be/ezD6QO14kRc?t=3332) RunPod: Starting the Training Job

[00:56:24](https://youtu.be/ezD6QO14kRc?t=3384) RunPod: Speed & Cost Analysis

[00:57:28](https://youtu.be/ezD6QO14kRc?t=3448) RunPod: Auto-Stop Command Setup

[00:58:24](https://youtu.be/ezD6QO14kRc?t=3504) MassedCompute: GPU Selection & Coupon Code

[01:00:16](https://youtu.be/ezD6QO14kRc?t=3616) MassedCompute: ThinLinc Client Setup

[01:01:21](https://youtu.be/ezD6QO14kRc?t=3681) MassedCompute: Transferring Files to Shared Folder

[01:02:55](https://youtu.be/ezD6QO14kRc?t=3775) MassedCompute: Installation Command

[01:05:49](https://youtu.be/ezD6QO14kRc?t=3949) MassedCompute: Connecting via Public URL

[01:06:54](https://youtu.be/ezD6QO14kRc?t=4014) MassedCompute: Starting Training Job

[01:08:43](https://youtu.be/ezD6QO14kRc?t=4123) Downloading Checkpoints & Stopping Instance

üöÄ Master Z-Image Turbo & LoRA Training: The Ultimate Guide!

In this comprehensive tutorial, I show you how to generate ultra-realistic images in seconds using the lightweight Z-Image Turbo model. We cover everything from 1-click installation on SwarmUI (ComfyUI backend) to mastering ControlNet Union for precise image control.

But that‚Äôs not all! I also reveal how to train your own high-quality Z-Image Turbo LoRAs using the Ostris AI Toolkit. I have developed a custom training preset that significantly outperforms the default settings‚Äîyou have to see the comparison to believe it! Whether you are on a local PC, RunPod, or MassedCompute, this guide has you covered.

üî• What You Will Learn:

Z-Image Turbo Setup: How to run this fast, 6GB model (FP8 included) on almost any GPU.

ControlNet Mastery: Use Canny, Depth, and Lineart to control your generations perfectly.

LoRA Training: Step-by-step guide



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=0) Greetings everyone. In this tutorial video, I&nbsp; will show you how to use Z-Image Turbo version.&nbsp;&nbsp;

- [00:00:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=6) It is a very fast, very lightweight model&nbsp; that you can generate amazing high-quality,&nbsp;&nbsp;

- [00:00:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=13) extremely realistic, or stylized images on your&nbsp; local PC. The model is as small as 6 GB with&nbsp;&nbsp;

- [00:00:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=22) maximum quality. And it will run on literally&nbsp; every GPU, and since it is a turbo model,&nbsp;&nbsp;

- [00:00:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=29) it only requires 9 steps. All these&nbsp; images were locally generated ultra-fast,&nbsp;&nbsp;

- [00:00:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=36) like 10 seconds generation time, and they are&nbsp; very high resolution as you are seeing right&nbsp;&nbsp;

- [00:00:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=41) now. I will explain all of these. And all of&nbsp; these images were generated in SwarmUI with&nbsp;&nbsp;

- [00:00:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=47) using the ComfyUI backend with our presets. 1&nbsp; click to install, download, and use right away.

- [00:00:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=54) You probably didn't see before, but I have&nbsp; Z-Image Turbo FP8 scaled. This is 5.7 GB in size,&nbsp;&nbsp;

- [00:01:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=64) so it fits into all GPUs. But this is not&nbsp; all. Furthermore, I will show you how to&nbsp;&nbsp;

- [00:01:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=70) use ControlNet with Z-Image Turbo model.&nbsp; So you see, based on this input image,&nbsp;&nbsp;

- [00:01:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=81) these images were generated. I will show you&nbsp; how to use ControlNet with Z-Image Turbo model.&nbsp;&nbsp;

- [00:01:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=88) But we are not done yet. I will also show you&nbsp; how to train your Z-Image Turbo model LoRAs as&nbsp;&nbsp;

- [00:01:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=96) you are seeing right now. By using the AI&nbsp; Toolkit from Ostris, you will be able to&nbsp;&nbsp;

- [00:01:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=102) train amazing LoRAs even on a very low VRAM&nbsp; having very weak GPU fully locally. I have&nbsp;&nbsp;

- [00:01:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=110) researched it extensively and prepared amazing&nbsp; presets for all GPUs with the highest quality.&nbsp;&nbsp;

- [00:01:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=117) We have presets for 8 GB GPUs to 24 GB GPUs,&nbsp; and each one of them has a very high quality.

- [00:02:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=125) For example, let me show you the default preset of&nbsp; the Ostris AI Toolkit versus our preset. So this&nbsp;&nbsp;

- [00:02:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=134) left image was trained with the default preset&nbsp; of the AI Toolkit that he shows in his tutorial,&nbsp;&nbsp;

- [00:02:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=141) and this is our preset. This is default preset;&nbsp; this is our preset. This is default preset;&nbsp;&nbsp;

- [00:02:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=148) this is our preset. There is a massive quality&nbsp; difference between default versus ours. And&nbsp;&nbsp;

- [00:02:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=154) these are not cherry-picked images; these are grid&nbsp; generations. Another case: this is default preset,&nbsp;&nbsp;

- [00:02:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=159) and this is my preset. This is default preset,&nbsp; and this is my preset. This is default preset,&nbsp;&nbsp;

- [00:02:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=165) and this is my preset. There is a&nbsp; massive difference. So I will show&nbsp;&nbsp;

- [00:02:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=169) how to train with our preset on your PC.&nbsp; This is default preset, and this is our&nbsp;&nbsp;

- [00:02:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=175) preset. Default preset, our preset. You&nbsp; will get amazing quality training images.

- [00:03:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=180) But we are not done yet. I will also show you how&nbsp; to train on RunPod extremely efficiently. With RTX&nbsp;&nbsp;

- [00:03:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=187) 4090, for example, you will be able to train with&nbsp; amazing speed. I will also show how you can turn&nbsp;&nbsp;

- [00:03:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=195) off your pod automatically after training. All&nbsp; of the installation is literally 1 click, and&nbsp;&nbsp;

- [00:03:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=201) my installers install the latest version of the&nbsp; application. I am not using any template, so it&nbsp;&nbsp;

- [00:03:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=208) is not static. We are using the official PyTorch&nbsp; template. Therefore, with any GPU, you will be&nbsp;&nbsp;

- [00:03:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=214) able to 1 click to install and use this amazing&nbsp; trainer on RunPod. But we are not done yet. I will&nbsp;&nbsp;

- [00:03:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=220) also show how to install and use on MassedCompute,&nbsp; our favorite GPU provider, which is very fast. So&nbsp;&nbsp;

- [00:03:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=228) you will be able to install it on MassedCompute&nbsp; and access it from a public URL like this and&nbsp;&nbsp;

- [00:03:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=235) train it like it is in your PC. So easy, so fast,&nbsp; and it will run on cloud, not on your computer.&nbsp;&nbsp;

- [00:04:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=243) And with our SwarmUI presets, you will be able to&nbsp; use this model with highest quality. And with our&nbsp;&nbsp;

- [00:04:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=250) model downloader, you will be able to download the&nbsp; necessary files with just 1 click. So let's begin.

- [00:04:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=256) As a first step, we need to download Z-Image&nbsp; models. For that, we are going to use our SwarmUI&nbsp;&nbsp;

- [00:04:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=262) auto-installer and model downloader. Download the&nbsp; latest zip file as usual as in previous tutorials.&nbsp;&nbsp;

- [00:04:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=268) If you don't know how to install and use SwarmUI,&nbsp; follow this video; it will explain you everything.&nbsp;&nbsp;

- [00:04:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=273) The links will be in the description of the video.&nbsp; Then move and copy the zip file into your SwarmUI&nbsp;&nbsp;

- [00:04:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=279) installation, WinRAR extract here. Overwrite&nbsp; all of the files; this is very important. You&nbsp;&nbsp;

- [00:04:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=285) need to overwrite all the files. Then double click&nbsp; Windows start download models app .bat file run.&nbsp;&nbsp;

- [00:04:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=291) This will start the model downloader. First&nbsp; of all, we need to download Z-Image models.

- [00:04:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=296) We have significantly upgraded our application.&nbsp; We have moved to Gradio version 6. The initial&nbsp;&nbsp;

- [00:05:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=303) loading will take a little bit longer&nbsp; than before, as you are seeing right now,&nbsp;&nbsp;

- [00:05:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=308) but the application will work much better&nbsp; after loaded. Okay, we are loaded right&nbsp;&nbsp;

- [00:05:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=313) now. You see we have significantly improved&nbsp; our interface. We have updated our bundles,&nbsp;&nbsp;

- [00:05:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=319) and you see there is Z-Image Turbo core bundle.&nbsp; This bundle will download Z-Image Turbo BF16,&nbsp;&nbsp;

- [00:05:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=326) Qwen 3 4 billion parameters text encoder.&nbsp; This is necessary for the Z-Image. Z-Image&nbsp;&nbsp;

- [00:05:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=332) Turbo full ControlNet Union. We are going to&nbsp; use this ControlNet Union model to be able to&nbsp;&nbsp;

- [00:05:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=338) generate images with references to images we&nbsp; want with using ControlNet preprocessors. And&nbsp;&nbsp;

- [00:05:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=344) this is the VAE that it uses. So you can click&nbsp; download all models from here, or you can click&nbsp;&nbsp;

- [00:05:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=349) individually these buttons to download.&nbsp; Download all models is the best approach.

- [00:05:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=354) Alternatively, if you have a very low&nbsp; VRAM GPU, in the image generation models,&nbsp;&nbsp;

- [00:05:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=359) you will see Z-Image Turbo models, and you&nbsp; will see we have Z-Image Turbo FP8 scaled.&nbsp;&nbsp;

- [00:06:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=366) This is a model that I have made myself. With&nbsp; our SECourses Musubi Tuner premium application,&nbsp;&nbsp;

- [00:06:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=373) now we can convert Z-Image models into FP8 scaled&nbsp; as well. So let me start the application to show&nbsp;&nbsp;

- [00:06:20](https://www.youtube.com/watch?v=ezD6QO14kRc&t=380) you. This is 5.73 gigabytes in size, so it&nbsp; fits into 6 GB GPUs as well. However, don't&nbsp;&nbsp;

- [00:06:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=388) get confused even if you don't have powerful GPU.&nbsp; With SwarmUI that is using ComfyUI backend, you&nbsp;&nbsp;

- [00:06:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=393) can run any model on any GPU, literally. Because&nbsp; it will use your RAM memory to hold some part of&nbsp;&nbsp;

- [00:06:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=399) the model, and it will work. Don't worry about&nbsp; that. But to get maximum speed, if you want, you&nbsp;&nbsp;

- [00:06:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=405) can use FP8 scaled if you have like 6 gigabytes&nbsp; of GPU or 8 gigabyte or 10 gigabytes of GPU.

- [00:06:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=412) So in our SECourses Musubi Tuner, we have&nbsp; FP8 model converter, and you can convert&nbsp;&nbsp;

- [00:06:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=419) Qwen image and Z-Image models. This is how I&nbsp; converted. Follow the model downloads on the&nbsp;&nbsp;

- [00:07:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=424) CMD window. Also on the very top, you will&nbsp; see that they have been downloaded. Then you&nbsp;&nbsp;

- [00:07:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=429) are ready. So we can move to next step.&nbsp; As a next step, you need to update your&nbsp;&nbsp;

- [00:07:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=433) ComfyUI installation. Get the latest zip file&nbsp; from here. Go to your ComfyUI installation,&nbsp;&nbsp;

- [00:07:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=439) again extract and overwrite all the files.&nbsp; Then double click and run the Windows install&nbsp;&nbsp;

- [00:07:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=445) or update ComfyUI .bat file. This is important.&nbsp; So it will update ComfyUI to the latest version,&nbsp;&nbsp;

- [00:07:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=451) which supports Z-Image models with ControlNet. So&nbsp; my ComfyUI installation were already up to date,&nbsp;&nbsp;

- [00:07:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=458) but still it is updating everything. This&nbsp; ComfyUI installation is perfect. It supports&nbsp;&nbsp;

- [00:07:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=462) Sage Attention, Flash Attention, xFormers,&nbsp; Triton, everything that you need with RTX 5000&nbsp;&nbsp;

- [00:07:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=469) series GPUs support. So this is a very, very good&nbsp; installation. Okay, it has been done. Moreover,&nbsp;&nbsp;

- [00:07:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=475) this ComfyUI installation supporting special&nbsp; samplers and schedulers like bon_tangent,&nbsp;&nbsp;

- [00:08:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=480) Beta 57. You need to use our ComfyUI installation&nbsp; to have these extra samplers and schedulers.

- [00:08:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=487) As a final step, we need to update our&nbsp; SwarmUI. So we have SwarmUI update .bat&nbsp;&nbsp;

- [00:08:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=493) file. This will also install ControlNet&nbsp; preprocessors automatically for you,&nbsp;&nbsp;

- [00:08:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=498) so you won't be needed to install. The update&nbsp; and installation both of them will do. You can&nbsp;&nbsp;

- [00:08:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=503) read the announcements. You should always read&nbsp; the announcements that I have make. You see 3&nbsp;&nbsp;

- [00:08:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=509) December 2025 version 108 announcement. If you&nbsp; don't have it or if you are using somewhere else,&nbsp;&nbsp;

- [00:08:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=516) you can also manually install. You will have&nbsp; a button here that will tell you to install&nbsp;&nbsp;

- [00:08:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=521) ControlNet. But since our installation is&nbsp; doing that automatically, you don't need&nbsp;&nbsp;

- [00:08:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=525) it. Now we have everything ready. Now we need to&nbsp; update our presets. To get the latest presets,&nbsp;&nbsp;

- [00:08:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=532) you can use the import feature as usual. You&nbsp; see there is import, choose file, select the&nbsp;&nbsp;

- [00:08:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=538) latest preset from here and overwrite everything.&nbsp; However, if you want a clean installation that&nbsp;&nbsp;

- [00:09:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=543) will delete all the existing presets and update&nbsp; them to the latest version, which I recommend,&nbsp;&nbsp;

- [00:09:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=548) we have Windows preset delete import file. And&nbsp; click yes, it will backup your preset and update&nbsp;&nbsp;

- [00:09:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=554) the presets like this. Everything is ready.&nbsp; Then refresh your presets and sort by name.

- [00:09:20](https://www.youtube.com/watch?v=ezD6QO14kRc&t=560) Okay, so how we are going to use&nbsp; Z-Image Turbo model? First of all,&nbsp;&nbsp;

- [00:09:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=564) quick tools, reset params to default. This is&nbsp; important. Then we have 2 separate presets for&nbsp;&nbsp;

- [00:09:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=571) Z-Image. You see Quality 1 and Quality 2.&nbsp; Quality 2 is faster. It is only 1 process;&nbsp;&nbsp;

- [00:09:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=578) it doesn't upscale. So let me demonstrate&nbsp; both of them. Direct apply. And for example,&nbsp;&nbsp;

- [00:09:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=583) let's use this prompt. Okay. Copy paste your&nbsp; prompt here. It is all set. You also need to&nbsp;&nbsp;

- [00:09:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=590) set your aspect ratio. I did set base resolution&nbsp; of this model when you download the model that I&nbsp;&nbsp;

- [00:09:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=596) have as a 1536 to 1536. By default, it was 1024.&nbsp; However, I think this model works better with this&nbsp;&nbsp;

- [00:10:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=606) resolution. Sometimes you may get some mistakes,&nbsp; but generate more images. Because it is too fast.&nbsp;&nbsp;

- [00:10:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=611) Let me show you real time. So let's generate&nbsp; 8 images. Generate. After the model loaded,&nbsp;&nbsp;

- [00:10:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=616) let's see the speed. Moreover, you see the&nbsp; models that I upload for you have images,&nbsp;&nbsp;

- [00:10:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=622) have description, so you can read these&nbsp; descriptions, and they are easier to use.

- [00:10:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=627) Okay, the first generation started. The first one&nbsp; will be slower than the other ones. Okay, first&nbsp;&nbsp;

- [00:10:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=632) one is done. So you see it was done in, let's&nbsp; see, 12 seconds. The next one is done in 7.84&nbsp;&nbsp;

- [00:10:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=642) seconds. What about using the more higher quality&nbsp; preset? So let me demonstrate that. I will reuse&nbsp;&nbsp;

- [00:10:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=648) parameters of this one so it will set the seed.&nbsp; Then go back to preset and I will direct apply.&nbsp;&nbsp;

- [00:10:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=655) So this will activate the special refine upscale.&nbsp; Moreover, this is important, you need to download&nbsp;&nbsp;

- [00:11:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=661) the upscale models from here. So we have other&nbsp; models and image upscaling models. So download&nbsp;&nbsp;

- [00:11:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=669) these 3 models to have accurate upscaling. Okay,&nbsp; then generate. Now this will upscale this image,&nbsp;&nbsp;

- [00:11:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=677) but we cannot upscale a lot because this model&nbsp; has limitations. Also sometimes you can see&nbsp;&nbsp;

- [00:11:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=683) some hallucinations at the right or left side of&nbsp; the image because of the high resolution that we&nbsp;&nbsp;

- [00:11:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=689) generate. Sometimes you won't see, sometimes you&nbsp; will see. It depends. So let's have a comparison.&nbsp;&nbsp;

- [00:11:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=695) The left one is the Quality 2, which is way&nbsp; faster to generate. And the right one is the&nbsp;&nbsp;

- [00:11:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=701) Quality 1 preset that we have. So you see how much&nbsp; realism and details we add this way. It changes&nbsp;&nbsp;

- [00:11:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=708) the image because this model is very sensitive to&nbsp; the resolution and upscale. However, it improves&nbsp;&nbsp;

- [00:11:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=716) the quality significantly. So you can test both of&nbsp; the presets and decide which one is working better&nbsp;&nbsp;

- [00:12:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=721) for you, which one is generating better images&nbsp; for your use case, and decide and use that way.

- [00:12:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=728) So how we are going to use the ControlNet? The&nbsp; ControlNet logic is same. So let's reload this&nbsp;&nbsp;

- [00:12:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=734) page, reset params to default. And you can use&nbsp; either of the presets; both of them is working.&nbsp;&nbsp;

- [00:12:20](https://www.youtube.com/watch?v=ezD6QO14kRc&t=740) Let's use the direct apply and Quality 2. Now&nbsp; what is the difference? You need to provide a&nbsp;&nbsp;

- [00:12:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=746) ControlNet input image, which will be the base of&nbsp; your image. For example, let's try this pose. Then&nbsp;&nbsp;

- [00:12:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=753) you need to select your ControlNet preprocessor.&nbsp; This is not mandatory. If you are using already&nbsp;&nbsp;

- [00:12:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=758) a Canny image, you don't need to select this.&nbsp; But if you are not using a preprocessed image,&nbsp;&nbsp;

- [00:12:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=763) you need to select it. Then click this preview&nbsp; to see the preset output. If you have different&nbsp;&nbsp;

- [00:12:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=769) aspect ratio, it will show you mangled preview.&nbsp; So let's click preview. You see this is not&nbsp;&nbsp;

- [00:12:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=776) accurate. So how to make it accurate? You&nbsp; need to have accurate aspect ratio with&nbsp;&nbsp;

- [00:13:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=781) your according to your input image, according&nbsp; to your ControlNet input. How you can set the&nbsp;&nbsp;

- [00:13:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=787) aspect ratio accurately? I have been telling&nbsp; the SwarmUI developer to add this feature,&nbsp;&nbsp;

- [00:13:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=791) but he still didn't add. So you need to choose&nbsp; file, upload your reference image, click res,&nbsp;&nbsp;

- [00:13:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=798) and use the exact aspect ratio or the closest.&nbsp; Let's use the exact aspect ratio. Then disable&nbsp;&nbsp;

- [00:13:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=804) this init image. So we use this init image&nbsp; to set our aspect ratio accordingly. Now&nbsp;&nbsp;

- [00:13:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=811) when I click the preview, it will show me&nbsp; the accurate preview like this. I am ready.

- [00:13:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=815) You don't set ControlNet union type for Z-Image&nbsp; Turbo model. This is a little bit different&nbsp;&nbsp;

- [00:13:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=821) ControlNet than the previous ones that we know.&nbsp; But you can enable and test it; it won't make&nbsp;&nbsp;

- [00:13:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=826) difference. So we don't set it. So the ControlNet&nbsp; strength matters. Let me show you what I mean by&nbsp;&nbsp;

- [00:13:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=832) that. So let's write our prompt and let's set a&nbsp; seed like this and generate. Now the ControlNet&nbsp;&nbsp;

- [00:14:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=840) strength will impact your output. I tested it&nbsp; and I find that between 0.6, 60 percentage, to 1,&nbsp;&nbsp;

- [00:14:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=849) 100 percentage, works. So this is 100 percentage&nbsp; result. Let's see the 60 percentage result. Okay,&nbsp;&nbsp;

- [00:14:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=855) like this. By the way, you see this prompt and&nbsp; this ControlNet is not very related, but it is&nbsp;&nbsp;

- [00:14:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=861) still following it pretty accurately. Okay, this&nbsp; time 60 percentage didn't work well. So let's&nbsp;&nbsp;

- [00:14:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=868) make it 70 percentage. However, image quality&nbsp; increased, so you need to find a balance between&nbsp;&nbsp;

- [00:14:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=873) both of them. We can change the prompt. Let me&nbsp; demonstrate. So let's make this 60 percentage. A&nbsp;&nbsp;

- [00:14:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=879) man wearing an amazing suit. Because this prompt&nbsp; is much more matching to the our ControlNet image.&nbsp;&nbsp;

- [00:14:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=888) You see this one. Okay, now 60 percentage will&nbsp; generate a very accurate image as you are seeing&nbsp;&nbsp;

- [00:14:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=894) right now. Yes. And I can choose the Tier 1&nbsp; like this, direct apply and generate. Then it&nbsp;&nbsp;

- [00:14:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=899) will generate higher quality, higher resolution.&nbsp; So what does this do is that it first render,&nbsp;&nbsp;

- [00:15:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=906) then it does another render over it with upscaling&nbsp; to improve the quality. And yes. You see the same&nbsp;&nbsp;

- [00:15:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=913) pose, different person definitely. However, it is&nbsp; working really good as you are seeing right now.

- [00:15:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=919) So this was the Canny Edge preprocessor. You can&nbsp; use the Depth. Let's see the Depth preprocessing&nbsp;&nbsp;

- [00:15:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=926) from here. When you first time click preview,&nbsp; it will download the necessary model if you&nbsp;&nbsp;

- [00:15:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=931) don't have it. So from the debug menu, you can see&nbsp; whether it is downloading or not. And let's see,&nbsp;&nbsp;

- [00:15:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=937) preview is not done yet. We are still waiting.&nbsp; Probably it is trying to download. Yes,&nbsp;&nbsp;

- [00:15:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=942) you see it has downloaded it here. I can see&nbsp; it. And yes, the Depth has been generated.&nbsp;&nbsp;

- [00:15:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=947) Now generate again. So you can use either&nbsp; way. You can use Canny, you can use Depth,&nbsp;&nbsp;

- [00:15:53](https://www.youtube.com/watch?v=ezD6QO14kRc&t=953) whichever is working best for your case. You&nbsp; can use Lineart. If you have a Lineart drawing,&nbsp;&nbsp;

- [00:15:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=958) you can color it. Let me demonstrate you.&nbsp; Then I will choose that image from here. X,&nbsp;&nbsp;

- [00:16:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=964) choose file. I also need accurate aspect ratio.&nbsp; So let's choose the file from here. Resolution,&nbsp;&nbsp;

- [00:16:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=970) use the closest aspect ratio. And this is it.&nbsp; Then disable init image. And I am not going to&nbsp;&nbsp;

- [00:16:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=977) use any ControlNet preprocessing. And let's try&nbsp; an amazing cell shaded render of a dragon. Okay,&nbsp;&nbsp;

- [00:16:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=985) let's see what we get. Since this is ControlNet&nbsp; Union, it should be able to understand it. By&nbsp;&nbsp;

- [00:16:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=991) the way, this time we can also increase&nbsp; the ControlNet strength if we want. Okay,&nbsp;&nbsp;

- [00:16:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=995) we are getting something. This was a very simple&nbsp; prompt, but I think we will get a good image.&nbsp;&nbsp;

- [00:16:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1001) Yeah, pretty amazing. Pretty amazing result.&nbsp; If I want more matching, more exact matching,&nbsp;&nbsp;

- [00:16:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1007) I can increase this strength. So this is another&nbsp; generation. So as you increase the strength, it&nbsp;&nbsp;

- [00:16:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1012) will more match to the original image. This one is&nbsp; looking like this. So this is the way. We can also&nbsp;&nbsp;

- [00:16:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1018) set the preprocessing to like, let's see what we&nbsp; have, Lineart standard preprocessing. So let's see&nbsp;&nbsp;

- [00:17:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1025) the preview. When you first time click preview,&nbsp; it will download the model. And I am first time&nbsp;&nbsp;

- [00:17:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1030) clicking it, so it is taking time for preview&nbsp; to appear. It is downloading the model. Okay,&nbsp;&nbsp;

- [00:17:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1036) this is another generation. Pretty good. So you&nbsp; see from this simple Lineart, I can generate very,&nbsp;&nbsp;

- [00:17:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1042) very good images like these ones. Okay, it is&nbsp; here. And this is the preview. So I can use&nbsp;&nbsp;

- [00:17:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1047) this preprocessing as well and compare the&nbsp; result. And this is the result with Lineart&nbsp;&nbsp;

- [00:17:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1053) preprocessing. So you see this is entirely&nbsp; different than this version. So you can use&nbsp;&nbsp;

- [00:17:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1057) either way. It is working really good, really&nbsp; amazing. So I recommend you to test your case.

- [00:17:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1063) Okay, now the part that you have been waiting&nbsp; for. How to use Ostris AI Toolkit to train your&nbsp;&nbsp;

- [00:17:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1070) Z-Image Turbo LoRA models. First of all,&nbsp; we need to download and install Ostris AI&nbsp;&nbsp;

- [00:17:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1076) Toolkit. Currently, Ostris AI Toolkit has a bug.&nbsp; Therefore, you need to download this zip file:&nbsp;&nbsp;

- [00:18:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1084) AI Toolkit SECourses Version 2. Until he fixes&nbsp; that bug, I made a pull request which fixes the&nbsp;&nbsp;

- [00:18:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1092) bug of the CPU offloading. So I will update this&nbsp; post. So when you are watching this tutorial, if&nbsp;&nbsp;

- [00:18:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1098) you don't see this AI Toolkit SECourses Version 2,&nbsp; then you need to download this official version,&nbsp;&nbsp;

- [00:18:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1103) which installs from the official repository. This&nbsp; will install from my forked repository. Then move&nbsp;&nbsp;

- [00:18:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1109) the zip file into the drive where you want to&nbsp; install and extract all. Enter inside the folder.&nbsp;&nbsp;

- [00:18:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1116) So you see we have Windows Install, Windows First&nbsp; Time UI Setup, Windows Start, and Windows Update&nbsp;&nbsp;

- [00:18:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1122) .bat files. But before starting installation,&nbsp; you need to read the Windows requirements. We&nbsp;&nbsp;

- [00:18:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1128) have the classical requirements, but additionally,&nbsp; you need to download Node.js. I am using Node.js&nbsp;&nbsp;

- [00:18:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1134) version 22.20.0. The direct link is here. You&nbsp; just need to download it, start it, next. So&nbsp;&nbsp;

- [00:19:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1142) you see I already have. You just need to click&nbsp; next, next, next, next. That is it. Nothing else.

- [00:19:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1147) So after you have followed both of the&nbsp; requirements, click Windows install .bat file&nbsp;&nbsp;

- [00:19:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1152) run. This will install the Ostris AI Toolkit with&nbsp; Flash Attention, Sage Attention, xFormers with&nbsp;&nbsp;

- [00:19:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1159) Torch 2.8, CUDA 12.9. And my installation supports&nbsp; all of the GPUs starting from RTX 1000 series to&nbsp;&nbsp;

- [00:19:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1168) 5000 series. Or on cloud GPUs, it supports&nbsp; A100, H100, B200, whatever the GPU that you&nbsp;&nbsp;

- [00:19:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1176) use on cloud. So wait for initial installation to&nbsp; be completed. Okay, so the installation has been&nbsp;&nbsp;

- [00:19:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1182) completed. You can scroll up and see if there are&nbsp; any errors. There shouldn't be. This is important:&nbsp;&nbsp;

- [00:19:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1188) you need to have Python 3.10.11 installed.&nbsp; Then press any key to continue. Second thing&nbsp;&nbsp;

- [00:19:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1195) is Windows First Time UI Setup. This is 1 time,&nbsp; and you need to run this. Do not run this again&nbsp;&nbsp;

- [00:20:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1202) after you have made the initial installation. For&nbsp; this to work, as I said, you need to have Node.js&nbsp;&nbsp;

- [00:20:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1209) installed. Otherwise, it will not work. Node.js&nbsp; is a system-wide installation. It is not like a&nbsp;&nbsp;

- [00:20:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1214) virtual environment, so you need to install it as&nbsp; I have shown you. You may get some warnings like&nbsp;&nbsp;

- [00:20:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1219) this. These are all unimportant. You see there are&nbsp; warnings. You can just ignore all of them, and it&nbsp;&nbsp;

- [00:20:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1226) is done. You see setup completed successfully. Now&nbsp; we are ready to use. Next time for updating, you&nbsp;&nbsp;

- [00:20:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1231) can use Windows update app .bat file. But since we&nbsp; just installed, let's start the application. So it&nbsp;&nbsp;

- [00:20:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1238) will give us public URL and localhost URL. Public&nbsp; URL is useful in MassedCompute. It doesn't work in&nbsp;&nbsp;

- [00:20:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1245) RunPod, but in MassedCompute it works. I will show&nbsp; both of them hopefully. This is our interface.&nbsp;&nbsp;

- [00:20:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1251) Go to New Job and Show Advanced. There is no&nbsp; preset saving and loading in the AI Toolkit yet.

- [00:20:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1259) So how you are going to use my presets?&nbsp; Enter inside the Z-Image Turbo LoRA&nbsp;&nbsp;

- [00:21:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1264) configs. According to your GPU, select&nbsp; the configuration. Since I have RTX 5090,&nbsp;&nbsp;

- [00:21:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1270) I am going to use 24 GB. You see there&nbsp; is no higher configuration because this&nbsp;&nbsp;

- [00:21:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1275) model fits into 24 GB. Quality 1 is better than&nbsp; Quality 2. Quality 2 is better than Quality 3,&nbsp;&nbsp;

- [00:21:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1282) 4, and it goes on. So let's open this Quality 1&nbsp; config. Copy it. Paste it here. And Show Simple.&nbsp;&nbsp;

- [00:21:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1289) It will update everything except the dataset. So&nbsp; you need to have your dataset from Datasets, New&nbsp;&nbsp;

- [00:21:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1298) Dataset. Give a name like My Dataset. Then upload&nbsp; your images with drag and drop here. They will be&nbsp;&nbsp;

- [00:21:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1304) uploaded. Then you can type any caption: Caption&nbsp; 1, Caption 2, anything. I will explain everything,&nbsp;&nbsp;

- [00:21:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1311) don't worry. This is just explaining you how&nbsp; it works. The dataset will be saved inside the&nbsp;&nbsp;

- [00:21:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1316) AI Toolkit, inside datasets here. You see My&nbsp; Dataset. And the captions are image file names&nbsp;&nbsp;

- [00:22:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1323) with txt. So image file name and txt. This&nbsp; is the format of the dataset system of the&nbsp;&nbsp;

- [00:22:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1330) AI Toolkit. I already have my dataset here. So you&nbsp; see this is my dataset. I will copy this, paste it&nbsp;&nbsp;

- [00:22:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1337) into datasets folder. And when I go to datasets&nbsp; and refresh this page, you see it will appear.

- [00:22:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1344) So how to prepare your training images dataset?&nbsp; Now I will explain this part extremely carefully,&nbsp;&nbsp;

- [00:22:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1351) so watch all of it. To automatically prepare your&nbsp; images, I recommend to use Ultimate Batch Image&nbsp;&nbsp;

- [00:22:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1358) Processing App. You see it is under Auxiliary&nbsp; Tools section. So let's go to this link. I&nbsp;&nbsp;

- [00:22:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1364) recommend you to check out these screenshots,&nbsp; read this post. Let's scroll down and let's&nbsp;&nbsp;

- [00:22:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1370) download the latest version. Then let's move&nbsp; it into our Q drive, right click, extract here,&nbsp;&nbsp;

- [00:22:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1376) enter inside it. First of all, we need to&nbsp; install. This is a pretty fast installation.&nbsp;&nbsp;

- [00:23:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1381) This application is very lightweight,&nbsp; but it has so many features. Okay,&nbsp;&nbsp;

- [00:23:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1385) the installation has been completed. Scroll up&nbsp; to see if there are any errors or not. Then close&nbsp;&nbsp;

- [00:23:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1391) this. Then let's start the application. Windows&nbsp; Start application run. Why is this application&nbsp;&nbsp;

- [00:23:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1397) important? Because this will allow you to&nbsp; batch preprocess your training images. You&nbsp;&nbsp;

- [00:23:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1403) can of course manually preprocess your images,&nbsp; but this makes it much easier and accurate.

- [00:23:30](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1410) So I have some sample images to demonstrate you&nbsp; the power of this tool. I will copy this path&nbsp;&nbsp;

- [00:23:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1417) and enter as an input folder. Then as an output&nbsp; folder, let's output them into my other folder as&nbsp;&nbsp;

- [00:23:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1425) Preprocess Stage 1. Then the aspect ratio. If you&nbsp; are going to generate images with 16 by 9 always,&nbsp;&nbsp;

- [00:23:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1435) you can make your aspect ratio accordingly.&nbsp; However, if you are not sure which aspect&nbsp;&nbsp;

- [00:24:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1440) ratio you are going to use, I recommend you&nbsp; to use square aspect ratio with 1328 to 1328&nbsp;&nbsp;

- [00:24:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1448) pixels. This is the base resolution of the Qwen&nbsp; image model or Qwen image edit model. This works&nbsp;&nbsp;

- [00:24:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1454) best. And with this aspect ratio and resolution,&nbsp; you can still generate any aspect ratio. All the&nbsp;&nbsp;

- [00:24:20](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1460) images I have shown you in the beginning of&nbsp; the tutorial were trained with 1328 to 1328.&nbsp;&nbsp;

- [00:24:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1467) Then there are several options. You can select&nbsp; the classes from here to zoom them in. This is&nbsp;&nbsp;

- [00:24:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1473) extremely useful when you are training a person.&nbsp; Because you want to zoom in the person. What I&nbsp;&nbsp;

- [00:24:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1479) mean by that? You see in these images, there&nbsp; are a lot of extra spaces that can be zoomed&nbsp;&nbsp;

- [00:24:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1486) in. For example, in this image, I can zoom&nbsp; in myself a lot. So you can choose this,&nbsp;&nbsp;

- [00:24:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1492) or there is a better one which is based on&nbsp; SAM2. This takes anything as a prompt. Let's&nbsp;&nbsp;

- [00:25:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1500) say "person". You can set your batch size, GPU&nbsp; IDs. These are all advanced stuff if you are&nbsp;&nbsp;

- [00:25:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1505) going to process a lot of images. So default is&nbsp; good. Let's start processing. What this is going&nbsp;&nbsp;

- [00:25:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1512) to do is it is going to zoom in the class I&nbsp; have given without cropping any part of the&nbsp;&nbsp;

- [00:25:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1518) class. So this will not make these images&nbsp; exactly as this resolution or this aspect&nbsp;&nbsp;

- [00:25:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1524) ratio. It will try to match this aspect ratio&nbsp; without cropping the any part of the subject.

- [00:25:30](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1530) So let's see what kind of images we are&nbsp; getting. We are saving them inside here.&nbsp;&nbsp;

- [00:25:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1534) You see it has generated this subfolder. This&nbsp; is important because in the second stage,&nbsp;&nbsp;

- [00:25:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1540) we are going to use this to make them exactly same&nbsp; resolution. When I enter inside this folder, you&nbsp;&nbsp;

- [00:25:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1548) can see that it has zoomed in the person. So this&nbsp; is how it works. And when zooming in, it will not&nbsp;&nbsp;

- [00:25:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1555) crop any parts of the image. And also when zooming&nbsp; in, it will try to match the aspect ratio that you&nbsp;&nbsp;

- [00:26:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1562) have given like this. Okay, the first stage has&nbsp; been completed. Now the second stage is resizing&nbsp;&nbsp;

- [00:26:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1568) them into the exact resolution. This will crop&nbsp; the subject if it is necessary. Like cropping the&nbsp;&nbsp;

- [00:26:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1574) body parts to match the exact resolution. So this&nbsp; takes the parent folder, not this folder. This is&nbsp;&nbsp;

- [00:26:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1581) not the folder, but this is the folder that I need&nbsp; to give. And I need to change the resolution that&nbsp;&nbsp;

- [00:26:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1586) I want. So this will look a subfolder named&nbsp; as exactly like this. You can have multiple&nbsp;&nbsp;

- [00:26:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1592) resolutions actually. For example, in the image&nbsp; cropper, I can add here another resolution. Let's&nbsp;&nbsp;

- [00:26:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1598) say 16:9. So this is the resolution of 16:9 for&nbsp; Qwen image model. Let's add it like 1744 to 992.&nbsp;&nbsp;

- [00:26:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1608) Let's start processing. It will process this new&nbsp; resolution as well. And I am going to see a folder&nbsp;&nbsp;

- [00:26:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1614) generated here in a minute when it is processed.&nbsp; Okay, it is started processing. Now it will try&nbsp;&nbsp;

- [00:27:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1620) to match this aspect ratio. It may not match it&nbsp; exactly. Why? Because it is not going to crop any&nbsp;&nbsp;

- [00:27:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1627) body parts. So you see this image cannot match&nbsp; that aspect ratio. This is not a suitable image&nbsp;&nbsp;

- [00:27:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1633) for that. This is almost still square. However,&nbsp; in the second tab, when I go to image resizer,&nbsp;&nbsp;

- [00:27:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1638) when I type it, you see I have given the parent&nbsp; folder. Let's wait for this one to finish. Okay,&nbsp;&nbsp;

- [00:27:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1645) it is almost finished. By the way, if you use this&nbsp; YOLO, it is faster than SAM2. So just delete this&nbsp;&nbsp;

- [00:27:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1652) and select your class from here. It supports so&nbsp; many classes to focus on them. Okay, it is done.&nbsp;&nbsp;

- [00:27:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1658) Now I am going to make the output folder as Final&nbsp; Images like this. And I will click Resize Images.&nbsp;&nbsp;

- [00:27:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1665) You can also make resize without cropping, so&nbsp; it will make padding expansion. So let's resize&nbsp;&nbsp;

- [00:27:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1672) images. I recommend cropping; it is better. Then&nbsp; let's go back to our folder Final Images. Okay,&nbsp;&nbsp;

- [00:27:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1679) in here you will see that it has cropped the body&nbsp; parts, resized it into the exact resolution like&nbsp;&nbsp;

- [00:28:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1686) this. And these are the square images. They&nbsp; are much more accurate than the other ones.

- [00:28:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1692) Now I have my images ready. However, this is not&nbsp; a very good collection of images. It is another&nbsp;&nbsp;

- [00:28:20](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1700) thing that you need to be careful of. I have used&nbsp; these images to train the models that I have shown&nbsp;&nbsp;

- [00:28:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1706) you in the beginning of the tutorial. So when we&nbsp; analyze these images, what do you see? I have full&nbsp;&nbsp;

- [00:28:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1712) body pose like this. I have half body pose. I&nbsp; have very close shot. And when you have images,&nbsp;&nbsp;

- [00:28:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1719) what matters is that it should have good&nbsp; lighting, good focus. These two are extremely&nbsp;&nbsp;

- [00:28:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1726) important. It should be very clear. All of&nbsp; these images are captured with my cheap phone,&nbsp;&nbsp;

- [00:28:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1732) so they are not taken with a professional camera.&nbsp; For example, when we look at this image, you see&nbsp;&nbsp;

- [00:28:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1737) it is not even a very high quality. This is how&nbsp; it looks. And this is a real image. This is a raw&nbsp;&nbsp;

- [00:29:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1766) image. And when we look at the AI generated image,&nbsp; as you can see, it is even higher quality than my&nbsp;&nbsp;

- [00:29:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1773) raw image. And therefore, you should add highest&nbsp; possible quality images into your training dataset&nbsp;&nbsp;

- [00:29:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1781) to get the maximum quality images. What else&nbsp; is important? You should try to have different&nbsp;&nbsp;

- [00:29:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1788) clothings so it will not memorize your clothing.&nbsp; This is super important. Try to have different&nbsp;&nbsp;

- [00:29:53](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1793) clothings, different times, different backgrounds.&nbsp; All of these will help. Whatever you repeat in&nbsp;&nbsp;

- [00:29:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1799) your training dataset, the model will memorize&nbsp; them. You don't want that. You want only yourself&nbsp;&nbsp;

- [00:30:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1806) or the subject if you are training a style, the&nbsp; style, or an object, the object, to be repeated.&nbsp;&nbsp;

- [00:30:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1812) Nothing else. I will explain them in the style&nbsp; and the item training, the product training part.&nbsp;&nbsp;

- [00:30:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1817) And one another thing is that you should add the&nbsp; emotions that you want. If you want smiling, you&nbsp;&nbsp;

- [00:30:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1824) should add it. If you want laughing, you should&nbsp; add it. So whatever the emotion you have will make&nbsp;&nbsp;

- [00:30:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1831) 100 percentage quality difference in your outputs.&nbsp; Try to have all the emotions you want. But that is&nbsp;&nbsp;

- [00:30:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1839) not all. Also try to have all the angles you want.&nbsp; If you want to generate images that looks down,&nbsp;&nbsp;

- [00:30:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1846) you should have an image that has a look down&nbsp; like this. Or from this angle, this angle.&nbsp;&nbsp;

- [00:30:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1851) Whatever angle. So do not add the angles and&nbsp; poses that you don't want after training. And&nbsp;&nbsp;

- [00:30:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1858) add the poses and the angles you want to generate&nbsp; after training. So if we summarize again: have the&nbsp;&nbsp;

- [00:31:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1867) emotions, have the poses, have the angles, have&nbsp; different backgrounds, have different clothings,&nbsp;&nbsp;

- [00:31:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1874) have highest possible quality lighting and focus.&nbsp; Do not have blurry backgrounds. Do not have&nbsp;&nbsp;

- [00:31:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1881) fuzzy backgrounds. They will impact your output&nbsp; quality. So in the AI world, whatever you give,&nbsp;&nbsp;

- [00:31:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1888) you get it. And with this medium quality&nbsp; dataset, I am able to generate amazing images.&nbsp;&nbsp;

- [00:31:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1893) If I increase the number of images, the variety&nbsp; in these images, I can get even better quality.

- [00:31:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1898) Okay, now you understand how to prepare your&nbsp; dataset. There are few tricky issues with the&nbsp;&nbsp;

- [00:31:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1904) Z-Image Turbo model training. The best quality&nbsp; for this model is 1536 pixels. So make your images&nbsp;&nbsp;

- [00:31:53](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1913) 1536 pixels if they are bigger resolution.&nbsp; Not 1328 or not 1024. 1536 pixels. Another&nbsp;&nbsp;

- [00:32:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1922) thing is that this model is extremely aspect ratio&nbsp; dependent. So if you want to generate your images&nbsp;&nbsp;

- [00:32:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1930) with a certain aspect ratio, then you should&nbsp; prepare your images with that aspect ratio. What I&nbsp;&nbsp;

- [00:32:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1937) mean by that? For example, currently my images are&nbsp; all square like this. You see like this. However,&nbsp;&nbsp;

- [00:32:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1944) if I want 16:9 aspect ratio to generate images&nbsp; after training, then I should set my aspect ratio&nbsp;&nbsp;

- [00:32:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1952) according to like this. So if I use this image,&nbsp; this aspect ratio for training instead of square&nbsp;&nbsp;

- [00:32:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1958) aspect ratio, this model will able to generate&nbsp; images better in that aspect ratio. So therefore,&nbsp;&nbsp;

- [00:32:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1965) I recommend you to prepare your images with&nbsp; your desired aspect ratio after training. So&nbsp;&nbsp;

- [00:32:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1971) you see this generation was square; therefore,&nbsp; it is much more natural and accurate compared&nbsp;&nbsp;

- [00:32:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1976) to the 16:9 aspect ratio. I had to generate a lot&nbsp; of images to get accurately looking 16:9 aspect&nbsp;&nbsp;

- [00:33:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1984) ratio images. So decide your aspect ratio,&nbsp; whichever the aspect ratio that you want to&nbsp;&nbsp;

- [00:33:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1989) generate your images after training, and based on&nbsp; that aspect ratio, prepare your training images.

- [00:33:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=1996) Okay, once the training images are ready,&nbsp; let's go back to New Job, Show Advanced,&nbsp;&nbsp;

- [00:33:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2001) copy the configuration, Show Simple. Now, training&nbsp; name is the final file names that you are going to&nbsp;&nbsp;

- [00:33:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2009) get after training. Since I have done previously a&nbsp; training, I will use this name so it will generate&nbsp;&nbsp;

- [00:33:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2014) names like this so that I can show you how to find&nbsp; the best checkpoint. And you will see that our&nbsp;&nbsp;

- [00:33:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2020) configuration is already using Version 2 adapter.&nbsp; This may get updated later because the Ostris is&nbsp;&nbsp;

- [00:33:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2028) working on adapter. And what is this? Because this&nbsp; model is turbo model, it is distilled model. Until&nbsp;&nbsp;

- [00:33:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2036) the Alibaba team publishes the main model, we are&nbsp; using distilled turbo model. So to not break the&nbsp;&nbsp;

- [00:34:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2044) distillation of the model, we are using a trick.&nbsp; This adapter model is merged with the turbo model&nbsp;&nbsp;

- [00:34:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2050) during training automatically. We don't do that.&nbsp; So that it behaves like a main model. So therefore&nbsp;&nbsp;

- [00:34:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2056) our trained LoRA is not breaking the turbo model.&nbsp; This is not the highest quality. This is not the&nbsp;&nbsp;

- [00:34:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2061) quality that we are going to get from the base&nbsp; model, but it is working. And we don't change&nbsp;&nbsp;

- [00:34:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2065) this. It will download it into Hugging Face&nbsp; cache. You don't change anything here. What&nbsp;&nbsp;

- [00:34:30](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2070) you can change here is that save every N steps.&nbsp; So this trainer doesn't work with epoch based;&nbsp;&nbsp;

- [00:34:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2077) it works with the steps based. Therefore,&nbsp; I recommend you to calculate your number of&nbsp;&nbsp;

- [00:34:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2083) steps based number of the training images. I&nbsp; have 28 images, so I recommend 200 epochs for&nbsp;&nbsp;

- [00:34:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2089) this number of images. That makes 5,600 steps. And&nbsp; if you want 10 checkpoints, make this 560. If you&nbsp;&nbsp;

- [00:34:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2096) want 8 checkpoints, make it 800 steps. So based&nbsp; on these steps, it will save those checkpoints.&nbsp;&nbsp;

- [00:35:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2103) And max steps saves to keep. So let's, if I make&nbsp; this 3, it will keep only 3, and it will delete&nbsp;&nbsp;

- [00:35:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2110) the previous ones. This is how it works. So I will&nbsp; keep all of them. And you don't change anything&nbsp;&nbsp;

- [00:35:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2115) here. They are all set. In the dataset, you select&nbsp; your training dataset. This is my dataset. And&nbsp;&nbsp;

- [00:35:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2121) you don't change anything else here from the&nbsp; configuration. And that's it. You can also have&nbsp;&nbsp;

- [00:35:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2127) samples during generation. Currently I did set&nbsp; it 250,000 steps, so they are never generated.&nbsp;&nbsp;

- [00:35:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2133) But if you want them to be generated like every&nbsp; 100 steps or maybe 200 steps, you can generate&nbsp;&nbsp;

- [00:35:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2139) them and you can see them if they are good or&nbsp; not. But I am not doing that. It is up to you.

- [00:35:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2146) Moreover, there is skip first sample, which&nbsp; generates the samples just when begin the&nbsp;&nbsp;

- [00:35:53](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2153) training. I'm not using that either, but you can&nbsp; disable this and it will generate samples. And&nbsp;&nbsp;

- [00:35:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2159) there is trigger word. I am only training with a&nbsp; trigger word right now. Since I don't provide any&nbsp;&nbsp;

- [00:36:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2165) caption in my dataset, it is trained entirely&nbsp; with this. But if you also provide captions&nbsp;&nbsp;

- [00:36:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2172) with your dataset like Test 1 caption, then&nbsp; it will append the trigger word. I think it&nbsp;&nbsp;

- [00:36:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2178) is appended into beginning. So it will become&nbsp; like "ohwx test 1" during the training. However,&nbsp;&nbsp;

- [00:36:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2183) I don't recommend the captions. And you see we&nbsp; are losing our configuration. This is annoying,&nbsp;&nbsp;

- [00:36:30](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2190) I know that. The AI Toolkit must get&nbsp; save and load configuration. Okay,&nbsp;&nbsp;

- [00:36:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2196) I need to make the file name again like this.&nbsp; Okay, and this was 700 steps. This was 5,600.&nbsp;&nbsp;

- [00:36:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2206) Okay. So I have compared all this. I have tested&nbsp; all of them for you. I have done so many grid&nbsp;&nbsp;

- [00:36:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2212) tests to find everything. I did so many trainings.&nbsp; For example, let me show you some of the trainings&nbsp;&nbsp;

- [00:36:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2219) that I have made. You see all these different&nbsp; parameters I have tested. I have tested 1024,&nbsp;&nbsp;

- [00:37:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2226) 1280, combination of the different resolutions&nbsp; like these 3. And the best yielding resolution&nbsp;&nbsp;

- [00:37:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2234) for this model is 1536. However, if&nbsp; you want to speed up your training,&nbsp;&nbsp;

- [00:37:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2239) if this becomes too slow for you, then you&nbsp; need to disable this and use like 1280 or&nbsp;&nbsp;

- [00:37:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2245) just use 1024. Or you can enable all 3.&nbsp; Too much speed comes with 1024. But the&nbsp;&nbsp;

- [00:37:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2251) best quality is with 1536 for the Z-Image Turbo&nbsp; model. And let's select our training dataset. I&nbsp;&nbsp;

- [00:37:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2259) am also not using any caption dropout. So these&nbsp; are all my settings. And then click Create Job.

- [00:37:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2266) Now this training is queued. Not automatically&nbsp; started. So you can either click from here&nbsp;&nbsp;

- [00:37:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2272) to start or you can go to Training Queue and&nbsp; click the play icon from here. And you see it&nbsp;&nbsp;

- [00:37:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2278) shows Queued, then you click start. And it will&nbsp; start the queue processing. Let's see what is&nbsp;&nbsp;

- [00:38:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2284) happening in our VRAM. Currently I'm recording&nbsp; video with my second GPU, so my initial GPU is&nbsp;&nbsp;

- [00:38:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2291) empty. I just need to close the SwarmUI; it will&nbsp; become zero. Yes. So you can see the speed. I&nbsp;&nbsp;

- [00:38:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2296) have tested the speed. It is same on Windows and&nbsp; Linux. This is surprising, but maybe it is good,&nbsp;&nbsp;

- [00:38:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2303) I don't know. Because I am not sure whether it is&nbsp; fully utilizing the GPU or not. I don't see it is&nbsp;&nbsp;

- [00:38:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2308) fully utilizing on Windows. But it is fairly fast.&nbsp; And I can speed up the training significantly with&nbsp;&nbsp;

- [00:38:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2314) dropping the resolution. So when you click this&nbsp; icon, it will show you the training window like&nbsp;&nbsp;

- [00:38:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2319) this. You don't see the training on the started&nbsp; CMD window. You will see it from here. When you&nbsp;&nbsp;

- [00:38:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2324) refresh this page, let's go to Dashboard, you&nbsp; need to click this icon to see it. Don't forget&nbsp;&nbsp;

- [00:38:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2329) that. So it will show you some of the statistics,&nbsp; and it will show you what is happening. This is&nbsp;&nbsp;

- [00:38:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2334) actually what is happening on the training. This&nbsp; is the window that you are going to follow. It&nbsp;&nbsp;

- [00:38:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2339) will first cache then unload the text encoder.&nbsp; I did set everything for you. These parameters&nbsp;&nbsp;

- [00:39:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2345) are really optimal. Let's say you have 100 images&nbsp; as a training dataset. Then set it 10,000 steps.&nbsp;&nbsp;

- [00:39:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2351) I don't know how many steps you can do until the&nbsp; model breaks, but I can say that up to 10,000&nbsp;&nbsp;

- [00:39:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2358) steps you are safe. Maybe even 20,000 steps. You&nbsp; need to test. And since we are saving checkpoints,&nbsp;&nbsp;

- [00:39:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2363) we will compare. The checkpoints will appear&nbsp; here. This is very useful because on RunPod and&nbsp;&nbsp;

- [00:39:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2369) MassedCompute, you can directly download them&nbsp; from here. They will appear here. They will be&nbsp;&nbsp;

- [00:39:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2375) saved inside the folder. So it is started. But to&nbsp; get checkpoints quickly, let me show you how they&nbsp;&nbsp;

- [00:39:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2383) will appear. So I will pause this and you see it&nbsp; says that you can resume. But you can resume from&nbsp;&nbsp;

- [00:39:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2389) the last checkpoint. Therefore if there weren't&nbsp; any checkpoints, it will start from the beginning.&nbsp;&nbsp;

- [00:39:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2395) However, if you had checkpoints, it will resume&nbsp; from the last checkpoint. This is how it works.

- [00:40:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2400) So I will modify and I will save checkpoints every&nbsp; 5 steps. So let's make this every 5 steps. Update&nbsp;&nbsp;

- [00:40:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2408) Job. Then click Play. And it will start again. So&nbsp; I will start getting checkpoints here. Therefore&nbsp;&nbsp;

- [00:40:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2414) I can show you how they are appearing. When I&nbsp; start it again, it will not cache the images and&nbsp;&nbsp;

- [00:40:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2422) text captions again since they were already&nbsp; cached. So where they are stored? When you&nbsp;&nbsp;

- [00:40:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2427) go back into your AI Toolkit installation, in&nbsp; the output, your trainings will be saved here.&nbsp;&nbsp;

- [00:40:33](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2433) When I enter inside this training, you see they&nbsp; are named with the same name as the name that&nbsp;&nbsp;

- [00:40:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2439) I have set or the name I set here. So they will&nbsp; be saved with that name. It shows the log, PID,&nbsp;&nbsp;

- [00:40:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2446) and it will save the checkpoints here. We will see&nbsp; in a moment. You can also set the checkpoints from&nbsp;&nbsp;

- [00:40:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2452) the settings. You can set the training folder&nbsp; path. So you see, this is the path where it&nbsp;&nbsp;

- [00:40:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2457) will save the checkpoints. You can change this&nbsp; and it will save the checkpoints there. And you&nbsp;&nbsp;

- [00:41:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2463) see this is the datasets folder. So you can change&nbsp; both of these and save settings. Let's go back to&nbsp;&nbsp;

- [00:41:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2468) Dashboard. Let's see our training. So we see the&nbsp; steps. It will start from the first step. Okay,&nbsp;&nbsp;

- [00:41:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2474) it started. It is doing the steps. The speed&nbsp; is 6.67 seconds for RTX 5090 with the very&nbsp;&nbsp;

- [00:41:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2482) high quality, highest quality. Okay, we got&nbsp; the first checkpoint. So it is appeared here.&nbsp;&nbsp;

- [00:41:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2487) When I click this download, it will download. So&nbsp; you can use this in RunPod or MassedCompute. And&nbsp;&nbsp;

- [00:41:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2492) when I go back to outputs, I will see the&nbsp; checkpoint here. So it is saved like this.&nbsp;&nbsp;

- [00:41:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2497) Now I need to move this into my LoRA folder&nbsp; and test it. And you see it also saved an&nbsp;&nbsp;

- [00:41:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2504) optimizer PT file. So now that I can pause and&nbsp; continue. So let's get the next checkpoint. Yes,&nbsp;&nbsp;

- [00:41:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2511) it is saved here. Now I will pause it and I will&nbsp; resume it. Let's see how it continues. Okay,&nbsp;&nbsp;

- [00:41:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2517) click play again. Now it should resume from the&nbsp; last checkpoint which was 10 steps. Let's see what&nbsp;&nbsp;

- [00:42:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2523) happens. So the speed was 6.7 seconds. I also&nbsp; shown the speeds in experiment speeds folder.&nbsp;&nbsp;

- [00:42:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2529) You can see the speeds of different resolutions:&nbsp; 1024, 1280, combination mixed, 1536. These are all&nbsp;&nbsp;

- [00:42:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2538) speeds of the RTX 4090. Not 5090. This is 5090&nbsp; speed. And this is RTX 3060 speed. So we have&nbsp;&nbsp;

- [00:42:26](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2546) the speeds. Okay, nice. So it is continuing&nbsp; from the last checkpoint which was 10 steps.

- [00:42:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2552) So this is how you can continue your training&nbsp; with AI Toolkit. These things are not specific&nbsp;&nbsp;

- [00:42:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2558) to the Z-Image Turbo model. With any model&nbsp; these are applying. But for each model,&nbsp;&nbsp;

- [00:42:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2565) you need to research a new configuration. That&nbsp; is important. If you use the default values,&nbsp;&nbsp;

- [00:42:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2570) you probably won't get the best results. Okay,&nbsp; so this is the speed. I can increase the speed&nbsp;&nbsp;

- [00:42:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2574) with reducing the resolution. And what are the&nbsp; differences between the default versus our best&nbsp;&nbsp;

- [00:43:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2581) training? I have it. So let me show you. This&nbsp; is default configuration, which the Ostris shown&nbsp;&nbsp;

- [00:43:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2589) in his tutorial, and this is our config. This is&nbsp; default; this is our config. Default, our config.&nbsp;&nbsp;

- [00:43:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2595) Default, our config. Our configuration yields much&nbsp; better results. Default, which the Ostris shown,&nbsp;&nbsp;

- [00:43:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2614) our config. You see there is a massive quality&nbsp; difference between default versus ours. And&nbsp;&nbsp;

- [00:43:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2618) these are not cherry-picked images; these are&nbsp; grid generations. Default, our config. Default,&nbsp;&nbsp;

- [00:43:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2624) our config. There is a huge difference between&nbsp; default and our config. Default, our config.&nbsp;&nbsp;

- [00:43:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2628) Default, our config. You see there is 2 persons&nbsp; because we are generating in high resolution. So&nbsp;&nbsp;

- [00:43:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2634) we need to generate just more images to get.&nbsp; Default, our config. Another prompt. Default,&nbsp;&nbsp;

- [00:43:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2639) our config. There is a massive difference.&nbsp; Default versus our config. Default,&nbsp;&nbsp;

- [00:44:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2644) our config. And these are grid images. And you&nbsp; see it even learned my broken teeth. I have a&nbsp;&nbsp;

- [00:44:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2650) broken teeth here. Maybe you noticed that. It&nbsp; learned it slightly. And this is a turbo model,&nbsp;&nbsp;

- [00:44:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2656) not like a base model. So this is pretty good,&nbsp; pretty accurate. So this is how we train.

- [00:44:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2661) After training, how you are going to test&nbsp; them? It is same as our other tests that&nbsp;&nbsp;

- [00:44:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2667) I have shown in other tutorials. So you will&nbsp; have checkpoints like this in the output folder&nbsp;&nbsp;

- [00:44:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2672) once the training finished. Move them into your&nbsp; LoRA folder. So I have them in my LoRA folder.&nbsp;&nbsp;

- [00:44:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2679) Then start your SwarmUI after put them in. Or if&nbsp; you are already running, it is fine. Go to LoRAs,&nbsp;&nbsp;

- [00:44:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2686) refresh. Then let's reset params to default.&nbsp; Let's go to presets. Select our preset again.&nbsp;&nbsp;

- [00:44:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2692) Direct apply. And go to Tools and select&nbsp; the Grid Generator. Let's say Test 1,&nbsp;&nbsp;

- [00:44:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2698) whatever the name you want. From here select LoRA.&nbsp; Type your LoRA name. My LoRA name is like this at&nbsp;&nbsp;

- [00:45:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2704) all. So it adds all the LoRAs. The last one goes&nbsp; here. So it is the last checkpoint. So they are&nbsp;&nbsp;

- [00:45:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2710) also sorted like this. Then the prompt. You can&nbsp; use any prompt you want like prompt like this.&nbsp;&nbsp;

- [00:45:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2715) To separate prompts use this character. So each&nbsp; prompt will be different. However, this is not a&nbsp;&nbsp;

- [00:45:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2721) proper prompt. So I am going to use the example&nbsp; prompt which I have provided in the zip file.&nbsp;&nbsp;

- [00:45:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2727) When you go here you will see Test Grid Prompts&nbsp; and Grid Format. Copy this. You can change this&nbsp;&nbsp;

- [00:45:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2732) according to your training. And generate grid. Now&nbsp; this will generate a grid for me based on these&nbsp;&nbsp;

- [00:45:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2739) LoRA checkpoints so I can see them. So let's go&nbsp; to here and see that in real time. Okay. So from&nbsp;&nbsp;

- [00:45:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2746) here. Okay, LoRA prompt. This is true. Sometimes&nbsp; you need to play with this to see. As the images&nbsp;&nbsp;

- [00:45:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2752) generated, they will appear. Do we have an error&nbsp; somewhere? Why did it? Okay, we have forgotten&nbsp;&nbsp;

- [00:45:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2758) reset params to default. Therefore the generation&nbsp; failed. You see because the ControlNet is open.&nbsp;&nbsp;

- [00:46:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2764) So always reset params to default. Don't forget&nbsp; that. Okay. Then let's select the preset one more&nbsp;&nbsp;

- [00:46:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2771) time. Direct apply. Let's go back to Tools and&nbsp; generate grid. Because otherwise you will get&nbsp;&nbsp;

- [00:46:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2776) error as I just had because the ControlNet&nbsp; was enabled. Now you just need to wait for&nbsp;&nbsp;

- [00:46:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2782) processing to be finished. And we will be able to&nbsp; compare the grid, the quality. So this is first.&nbsp;&nbsp;

- [00:46:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2788) As you can see on 5090 it is pretty fast. Every&nbsp; image taking like 8 seconds. I don't need to wait&nbsp;&nbsp;

- [00:46:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2794) more. But you can see that it is very undertrained&nbsp; in early steps. And it will get better trained up&nbsp;&nbsp;

- [00:46:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2800) to the last steps. We will see it. Even early&nbsp; steps there is some resemblance. I prefer this&nbsp;&nbsp;

- [00:46:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2806) over generating samples during the training.&nbsp; It's a choice. I find this better because I&nbsp;&nbsp;

- [00:46:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2812) don't lose time with the training process. And&nbsp; this is the most proper way of testing in my&nbsp;&nbsp;

- [00:46:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2818) opinion. Not using the samples generated during&nbsp; the training. Sometimes they may be inaccurate.

- [00:47:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2823) Okay, so the grid generation has been completed.&nbsp; Let's refresh. Now compare the checkpoints. 700&nbsp;&nbsp;

- [00:47:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2829) steps, 1400 steps, 2100 steps. So you see this way&nbsp; it goes. Decide which one is best for you. I can&nbsp;&nbsp;

- [00:47:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2838) say that the last one is the best. So you see this&nbsp; is very best. If you can't decide based on this,&nbsp;&nbsp;

- [00:47:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2844) what you can do is you can make this Test 2 and&nbsp; generate another grid. So this way compare until&nbsp;&nbsp;

- [00:47:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2851) you decide which one is working best. Moreover,&nbsp; trained LoRAs working with the ControlNet Union as&nbsp;&nbsp;

- [00:47:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2858) well. The only thing is that set your ControlNet&nbsp; strength to 0.6, so it is 60 percentage. And then&nbsp;&nbsp;

- [00:47:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2865) type your prompt. With just this simple prompt,&nbsp; "Photo of ohwx man wearing an amazing suit",&nbsp;&nbsp;

- [00:47:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2871) I am able to get amazing quality images with my&nbsp; trained LoRA by using this reference image as a&nbsp;&nbsp;

- [00:47:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2879) ControlNet. So it is fully working same way as&nbsp; using the base model with our trained LoRAs.

- [00:48:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2885) Now I will show you how to install and&nbsp; use Ostris AI Toolkit on RunPod. Then&nbsp;&nbsp;

- [00:48:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2890) on MassedCompute. To use on RunPod, always&nbsp; follow RunPod instructions txt file that I&nbsp;&nbsp;

- [00:48:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2897) have. Always. I have this file in all of my&nbsp; applications. For RunPod and MassedCompute,&nbsp;&nbsp;

- [00:48:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2903) always follow them. So let's open this. First&nbsp; of all, please register RunPod from this link.&nbsp;&nbsp;

- [00:48:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2908) I appreciate that. This enables me to do more&nbsp; research on RunPod. This helps me significantly&nbsp;&nbsp;

- [00:48:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2916) because these trainings are using huge amount&nbsp; of money. So you see I have spent 90 dollars on&nbsp;&nbsp;

- [00:48:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2922) a single day for Z-Image research. And then 10&nbsp; dollars. Once you are here, go to Billing and set&nbsp;&nbsp;

- [00:48:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2930) some credits. Pay with your card, whatever. Then&nbsp; go to Pods. You can also use permanent storage,&nbsp;&nbsp;

- [00:48:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2937) which I use it. I also have a dedicated tutorial&nbsp; for that. So you see we have RunPod permanent&nbsp;&nbsp;

- [00:49:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2944) network storage tutorial. But I will show on a&nbsp; single pod this time. I recommend you to limit&nbsp;&nbsp;

- [00:49:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2950) your region to the US starting from bottom. These&nbsp; are the best GPUs. For this Ostris AI Toolkit,&nbsp;&nbsp;

- [00:49:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2958) you can use RTX 4090. This is most performant&nbsp; price option. If you want more speed, you can use&nbsp;&nbsp;

- [00:49:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2965) RTX 5090. The bigger ones are useless because it&nbsp; fits into VRAM. So let's see where we have. Okay,&nbsp;&nbsp;

- [00:49:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2971) we have it here. Moreover, from additional&nbsp; filters, select 100 RAM and NVME disk. Okay,&nbsp;&nbsp;

- [00:49:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2978) we don't have it. So we need to check again. US&nbsp; NC2, NC1, MO2, MO1, MD1, KS. Okay, here. We have&nbsp;&nbsp;

- [00:49:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2990) it. Then change this template to whatever template&nbsp; the instructions file tells you. The instructions&nbsp;&nbsp;

- [00:49:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=2997) is telling this. Then you need to select this. If&nbsp; you get an error here, like when I select 5090,&nbsp;&nbsp;

- [00:50:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3003) it will tell me that you need to use this.&nbsp; This is wrong. Why? Because I am installing&nbsp;&nbsp;

- [00:50:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3009) applications into a virtual environment. I am not&nbsp; using the template environment. That is why. So&nbsp;&nbsp;

- [00:50:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3015) don't believe whatever the RunPod is telling you.&nbsp; Use the template that I write in my instructions.&nbsp;&nbsp;

- [00:50:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3024) So we are going to use this official PyTorch 2.2.0&nbsp; template. This is super fast. Then click this edit&nbsp;&nbsp;

- [00:50:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3032) template and add an port here: 8675. This is super&nbsp; important. Otherwise you won't be able to connect&nbsp;&nbsp;

- [00:50:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3041) the Ostris AI Toolkit interface. And set your&nbsp; volume disk according to your, you know, needs.&nbsp;&nbsp;

- [00:50:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3048) If you are going to get too many checkpoints,&nbsp; if you are going to train bigger model,&nbsp;&nbsp;

- [00:50:51](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3051) you need bigger. But for Z-Image Turbo model, 200&nbsp; is sufficient. And deploy on demand. Since this&nbsp;&nbsp;

- [00:50:58](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3058) is using official template, it will be super fast&nbsp; to initialize. Sometimes it doesn't show here, so&nbsp;&nbsp;

- [00:51:04](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3064) refresh to see the status. If it gets initialized&nbsp; or not. It should be very fast initialized. Okay,&nbsp;&nbsp;

- [00:51:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3071) details, telemetry, refresh. Okay, it is&nbsp; initialized. So it took like 20 or 30 seconds&nbsp;&nbsp;

- [00:51:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3078) because this template is very lightweight. Then&nbsp; click Jupyter Lab. Sometimes Jupyter Lab may also&nbsp;&nbsp;

- [00:51:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3083) not get loaded. You need to refresh. If it doesn't&nbsp; get loaded, delete the machine and get a new one.

- [00:51:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3088) First of all, verify that its GPU is working. pip&nbsp; install nvitop. Then type nvitop. And you need to&nbsp;&nbsp;

- [00:51:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3096) see your GPU like this. Otherwise just delete the&nbsp; pod and move to new one. Then upload the zip file&nbsp;&nbsp;

- [00:51:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3103) into here like this. This is important. Wait&nbsp; for upload to be completed. It is uploading in&nbsp;&nbsp;

- [00:51:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3108) the bottom as you see. Then right click and&nbsp; extract archive. Then click refresh. Okay,&nbsp;&nbsp;

- [00:51:53](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3113) it is extracted. Open the RunPod instructions read&nbsp; txt file. Copy this command. Open a new terminal.&nbsp;&nbsp;

- [00:52:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3121) Paste it and hit enter. This is it. This will&nbsp; install everything fully automatically. Including&nbsp;&nbsp;

- [00:52:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3126) the Node.js or whatever libraries. You don't need&nbsp; to do anything else. Once the installation has&nbsp;&nbsp;

- [00:52:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3132) been completed, we are going to use this to start&nbsp; the application. If you restart your pod again, if&nbsp;&nbsp;

- [00:52:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3139) you want to use again, you just need to run this&nbsp; command. But since this is first time, we just&nbsp;&nbsp;

- [00:52:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3144) need this to start once the installation has been&nbsp; completed. The installation speed totally depends&nbsp;&nbsp;

- [00:52:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3149) on the pod that you got. If it is a fast pod, if&nbsp; you are lucky enough, it will be fast. Otherwise&nbsp;&nbsp;

- [00:52:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3155) it will take time. But since we have made some&nbsp; filtering, we have selected from a certain region,&nbsp;&nbsp;

- [00:52:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3161) I can say that this pod is fast. There are&nbsp; major advantages of my installers on RunPod&nbsp;&nbsp;

- [00:52:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3167) instead of using a RunPod template. It always&nbsp; installs the latest version of the AI Toolkit.&nbsp;&nbsp;

- [00:52:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3175) It supports all of the GPUs that are available on&nbsp; RunPod. Not certain type of GPUs. So installation&nbsp;&nbsp;

- [00:53:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3182) of latest version and this GPU support makes it&nbsp; much more advantageous because you always use the&nbsp;&nbsp;

- [00:53:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3189) latest version of the application. Moreover&nbsp; the installation is fairly fast since it is&nbsp;&nbsp;

- [00:53:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3194) extremely optimized by myself. So the installation&nbsp; is getting completed. You can ignore these warning&nbsp;&nbsp;

- [00:53:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3201) messages as I have also explained in the Windows&nbsp; tutorial part. You need to watch Windows tutorial&nbsp;&nbsp;

- [00:53:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3207) part to learn it. Moreover if you don't know how&nbsp; to install and use SwarmUI and ComfyUI on RunPod I&nbsp;&nbsp;

- [00:53:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3214) have an excellent up to date tutorial. The link&nbsp; will be in the description of the video. This&nbsp;&nbsp;

- [00:53:39](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3219) tutorial. So watch it to learn how to use SwarmUI&nbsp; and ComfyUI on RunPod. I won't explain that part&nbsp;&nbsp;

- [00:53:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3223) in this video. I will only show Ostris AI Toolkit&nbsp; usage on RunPod in this tutorial. So watch this&nbsp;&nbsp;

- [00:53:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3230) tutorial to learn how to use SwarmUI and ComfyUI&nbsp; on RunPod. The link will be in the description&nbsp;&nbsp;

- [00:53:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3235) of the video. Okay installation almost completed.&nbsp; All right the installation has been completed. Now&nbsp;&nbsp;

- [00:54:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3241) we will run this starting command terminal. Copy&nbsp; paste the starting command. The starting should&nbsp;&nbsp;

- [00:54:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3247) be fairly fast. You see it also give us a network&nbsp; link like this but it is not working in RunPod. So&nbsp;&nbsp;

- [00:54:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3256) we need to connect from RunPod proxy. So go back&nbsp; to your My Pods click and click HTTP service 8675.&nbsp;&nbsp;

- [00:54:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3265) It will open the AI Toolkit. And we got the&nbsp; interface. The rest is exactly same. First&nbsp;&nbsp;

- [00:54:31](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3271) of all make your dataset. You can also upload&nbsp; your dataset into AI Toolkit Datasets folder&nbsp;&nbsp;

- [00:54:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3278) or you can click dataset my dataset like this&nbsp; create. Then click add images and you can drag&nbsp;&nbsp;

- [00:54:45](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3285) and drop the files as I have shown in the Windows&nbsp; tutorial part. It will upload them to the RunPod.&nbsp;&nbsp;

- [00:54:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3292) We will see the dataset here. Yes. You see the&nbsp; datasets. My dataset. Exactly same. The upload&nbsp;&nbsp;

- [00:54:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3299) will take some time because the RunPod is slow.&nbsp; They will appear here once processed. Okay. Let's&nbsp;&nbsp;

- [00:55:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3307) see what's happening. If it doesn't work you can&nbsp; also drag and drop them to here like this. It will&nbsp;&nbsp;

- [00:55:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3312) upload from the Jupyter Lab interface. Then you&nbsp; can refresh to get it. Yes it is uploading. So&nbsp;&nbsp;

- [00:55:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3319) let's use this way. Either way should work.&nbsp; We can just refresh. So you see the data set&nbsp;&nbsp;

- [00:55:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3325) images will appear here. Then click new job, show&nbsp; advanced. Again, same as in the Windows tutorial&nbsp;&nbsp;

- [00:55:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3332) part. Let's select our config, like this one,&nbsp; copy-paste, show simple, select your data set.&nbsp;&nbsp;

- [00:55:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3338) I'm not going to repeat the Windows tutorial part.&nbsp; Create job and click training. So that we can see&nbsp;&nbsp;

- [00:55:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3344) the training on RunPod. It should be fairly fast.&nbsp; First, it will download the necessary model,&nbsp;&nbsp;

- [00:55:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3350) then it will start the training. Let's just wait&nbsp; and see the logs. So you see, it is downloading&nbsp;&nbsp;

- [00:55:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3356) model into our workspace, fairly fast. We can see&nbsp; the speed. Okay, so the training has been started.&nbsp;&nbsp;

- [00:56:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3363) You can see the step speeds here. It will also&nbsp; show the step speed here after a while. Currently&nbsp;&nbsp;

- [00:56:09](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3369) like 8 seconds IT. You need to wait a little bit.&nbsp; It is using the GPU 100 percentage. The memory&nbsp;&nbsp;

- [00:56:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3374) usage is around 90 percentage. So RTX 4090 is very&nbsp; good on RunPod as a price performance. Therefore,&nbsp;&nbsp;

- [00:56:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3384) I recommend it. If you want faster, go with&nbsp; the RTX 5090. It's a little bit faster. Again,&nbsp;&nbsp;

- [00:56:30](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3390) as I have shown in the Windows tutorial part, you&nbsp; can look at the speeds. These four are for RTX&nbsp;&nbsp;

- [00:56:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3396) 4090. This is RTX 5090, and this is RTX 3060. So&nbsp; the speed is decent. It will take like 13 hours.&nbsp;&nbsp;

- [00:56:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3402) Maybe it will take lesser, but let's say 13 hours.&nbsp; The cost would be like $10, maybe lesser than $10,&nbsp;&nbsp;

- [00:56:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3410) 0.62 with 13, like $8. If you want faster, as&nbsp; I have shown in the tutorial, just change the&nbsp;&nbsp;

- [00:56:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3419) resolution. It will become four times faster. It&nbsp; will take four times lesser. That is the strategy,&nbsp;&nbsp;

- [00:57:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3425) but it will lower the quality. I don't recommend&nbsp; it. As I have shown in Windows tutorial part,&nbsp;&nbsp;

- [00:57:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3430) it will lower the quality significantly. Then you&nbsp; will get the checkpoints here, so you can download&nbsp;&nbsp;

- [00:57:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3435) them from here or from my pods, go back to AI&nbsp; toolkit outputs, they will appear inside here,&nbsp;&nbsp;

- [00:57:23](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3443) so you can download them from here too.&nbsp; That is it. Then you can terminate your pod,&nbsp;&nbsp;

- [00:57:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3448) stop your pod. These are the same. If you want to&nbsp; stop your pod after training has been finished,&nbsp;&nbsp;

- [00:57:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3455) we also have a command for it. So you see, this&nbsp; will stop your pod. How to do it? You need to get&nbsp;&nbsp;

- [00:57:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3461) your pod ID and paste it here. So this is seconds.&nbsp; Let's stop our pod in 20 seconds. So copy this,&nbsp;&nbsp;

- [00:57:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3469) open a new terminal, paste it. Now in 20 seconds,&nbsp; we will see that our pod has been stopped. Let's&nbsp;&nbsp;

- [00:57:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3477) see. Okay. Okay, it should be any second. I didn't&nbsp; count. We will see the command has been executed.&nbsp;&nbsp;

- [00:58:05](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3485) This way, you can sleep. Okay, it is stopped. So&nbsp; now when I refresh this page, I should see it is&nbsp;&nbsp;

- [00:58:11](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3491) stopped. Yes. So it won't spend my money.&nbsp; If you have any questions, you can ask me.

- [00:58:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3497) Now, the MassedCompute part will begin. Okay,&nbsp; now I will show the MassedCompute part. For&nbsp;&nbsp;

- [00:58:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3504) MassedCompute part, we are going to follow&nbsp; MassedCompute instructions. This is same&nbsp;&nbsp;

- [00:58:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3509) for all of my applications. Always follow the&nbsp; instructions.txt file. Please use this link&nbsp;&nbsp;

- [00:58:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3515) to register MassedCompute. I appreciate that.&nbsp; Login your account after registration, go back&nbsp;&nbsp;

- [00:58:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3520) to billing and add some credits. Once you have the&nbsp; credits, go to deploy. For Z Image Turbo version,&nbsp;&nbsp;

- [00:58:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3529) my recommended GPU is L40S. But you see, all of&nbsp; them is currently occupied, and they are hopefully&nbsp;&nbsp;

- [00:58:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3537) going to add new GPUs soon, they told me. So what&nbsp; can we use alternatively? We can use RTX 6000 ADA,&nbsp;&nbsp;

- [00:59:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3546) but they are also all full. Yes, there are no&nbsp; RTX 6000 ADA GPU. Therefore, to the cheapest one,&nbsp;&nbsp;

- [00:59:13](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3553) which would take time, we can use RTX A6000&nbsp; premium. This is the cheapest one. If you want&nbsp;&nbsp;

- [00:59:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3559) speed, you can use A100 or H100. So let's go with&nbsp; the cheapest option, RTX A6000. So let's select&nbsp;&nbsp;

- [00:59:27](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3567) the category creator, select the image SE Courses.&nbsp; So you see, currently this is $0.56 per hour.&nbsp;&nbsp;

- [00:59:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3574) We are going to apply our coupon, SE Courses,&nbsp; verify, and it's only 42 cents. Deploy. You see,&nbsp;&nbsp;

- [00:59:41](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3581) I have selected premium version. This premium&nbsp; version is the best one. It has the most RAM&nbsp;&nbsp;

- [00:59:46](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3586) memory. Therefore, I recommend you to pick this&nbsp; one if you are going to use RTX A6000. However,&nbsp;&nbsp;

- [00:59:53](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3593) my recommended GPU, as I said, for Z Image&nbsp; Turbo version, L40S or RTX Pro 6000 if they&nbsp;&nbsp;

- [01:00:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3601) are available. If they are not available, RTX&nbsp; 6000 ADA, this GPU. If none of them is available,&nbsp;&nbsp;

- [01:00:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3608) you can use A100, H100, depending on your budget,&nbsp; or RTX A6000 and the premium version. Now we need&nbsp;&nbsp;

- [01:00:16](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3616) to wait for the initialization. When you click&nbsp; the running instance, when you refresh this page,&nbsp;&nbsp;

- [01:00:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3622) you will see it. Wait for initialization to be&nbsp; completed. Meanwhile waiting for initialization,&nbsp;&nbsp;

- [01:00:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3628) click details, and you see there is ThinLinc&nbsp; client. If you haven't installed it yet,&nbsp;&nbsp;

- [01:00:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3634) we are going to use it. Download according to your&nbsp; platform. I am on Windows, so let's download this.&nbsp;&nbsp;

- [01:00:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3640) Let's start it. Yes, next, accept, select the&nbsp; options, run ThinLinc client. Once the ThinLinc&nbsp;&nbsp;

- [01:00:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3647) client started, click options, go to local&nbsp; devices. Just have clipboard synchronization&nbsp;&nbsp;

- [01:00:52](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3652) and drivers enabled. Click drivers details and&nbsp; add a folder from your computer like this one.&nbsp;&nbsp;

- [01:00:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3659) You see there is add and remove, or you can&nbsp; copy-paste the path from here. Make sure that&nbsp;&nbsp;

- [01:01:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3663) it has read and write permission. Click okay&nbsp; and click okay. Then you just need to wait for&nbsp;&nbsp;

- [01:01:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3668) initialization to be completed. Sometimes refresh&nbsp; the page to be sure. Okay, the machine has been&nbsp;&nbsp;

- [01:01:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3674) initialized. Before connecting it, I recommend you&nbsp; to put your training images, let's copy it, into&nbsp;&nbsp;

- [01:01:21](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3681) your shared folder. So my shared folder is here.&nbsp; Copy-paste them there. Moreover, also copy the&nbsp;&nbsp;

- [01:01:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3689) downloaded installation zip file into your shared&nbsp; folder. Then you are ready. Then click this IP,&nbsp;&nbsp;

- [01:01:36](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3696) it is copied. Copy-paste it here. You see there&nbsp; is username. Copy the username, copy-paste here,&nbsp;&nbsp;

- [01:01:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3702) and user password. You cannot transfer big files&nbsp; with ThinLinc client. You need to use like Google&nbsp;&nbsp;

- [01:01:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3709) Drive, OneDrive, or Hugging Face. We have Hugging&nbsp; Face upload and download notebook as well. So&nbsp;&nbsp;

- [01:01:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3715) this is only for small files, like your training&nbsp; images or like installation zip files. Remember&nbsp;&nbsp;

- [01:02:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3721) this. The big files will be very slow or will not&nbsp; work. Once you are in this screen, go to home, go&nbsp;&nbsp;

- [01:02:08](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3728) to Thin Drives, MassedCompute shared folder, wait&nbsp; for synchronization to be completed. Sometimes it&nbsp;&nbsp;

- [01:02:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3735) can take time depending on your internet. Okay.&nbsp; Then select your installation zip file, drag and&nbsp;&nbsp;

- [01:02:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3742) drop it into downloads folder. Moreover, drag&nbsp; and drop your training images as well. This is&nbsp;&nbsp;

- [01:02:29](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3749) not mandatory. We will be able to upload from the&nbsp; interface as in the Windows tutorial part, but you&nbsp;&nbsp;

- [01:02:35](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3755) can have it. Then extract the installation in the&nbsp; downloads folder. Do not run anything in ThinLinc&nbsp;&nbsp;

- [01:02:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3762) client driver, in the shared folder. Always copy&nbsp; files into downloads. Enter inside the folder,&nbsp;&nbsp;

- [01:02:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3768) double-click MassedCompute instructions, copy this&nbsp; installation command, click these three dots icon,&nbsp;&nbsp;

- [01:02:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3775) open in terminal inside this extracted folder,&nbsp; right-click and paste. This will do the entire&nbsp;&nbsp;

- [01:03:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3782) installation of the AI toolkit on MassedCompute.&nbsp; Now just wait for installation. This will be&nbsp;&nbsp;

- [01:03:07](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3787) really fast compared to the RunPod. MassedCompute&nbsp; is super fast. Then meanwhile it is installing,&nbsp;&nbsp;

- [01:03:14](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3794) copy-pasting the training files during the&nbsp; installation will give you speed up, will reduce&nbsp;&nbsp;

- [01:03:20](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3800) your timing. So that's an advantage. But you see,&nbsp; this ThinLinc client for transferring files is&nbsp;&nbsp;

- [01:03:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3808) very slow. It is really, really slow. Therefore,&nbsp; for big files, you need to use like Google Drive,&nbsp;&nbsp;

- [01:03:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3814) OneDrive, big cloud services like Hugging Face.&nbsp; Okay, the training images have been copied.&nbsp;&nbsp;

- [01:03:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3820) So while installing the AI toolkit, I will copy&nbsp; this, enter inside the AI toolkit, enter inside AI&nbsp;&nbsp;

- [01:03:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3827) toolkit, and here, make a new folder named as data&nbsp; sets because it is not automatically generated.&nbsp;&nbsp;

- [01:03:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3835) Copy-paste it here. So when we start the&nbsp; application, our data set will be ready. Still,&nbsp;&nbsp;

- [01:04:00](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3840) as in the Windows tutorial part, you can use&nbsp; the interface to upload from these data sets,&nbsp;&nbsp;

- [01:04:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3846) new data set, type your data set like test, and&nbsp; you will be able to upload from this interface&nbsp;&nbsp;

- [01:04:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3852) as well. Okay, installation is continuing. When&nbsp; you get this window, just click cancel. Moreover,&nbsp;&nbsp;

- [01:04:19](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3859) when you start Google Chrome, it may ask you&nbsp; something as login or something. Okay, it didn't&nbsp;&nbsp;

- [01:04:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3865) ask. If you get that error, just click cancel.&nbsp; So you don't need to update software installed on&nbsp;&nbsp;

- [01:04:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3872) MassedCompute. Just click cancel to all of them.&nbsp; Moreover, I won't show you how to use SwarmUI on&nbsp;&nbsp;

- [01:04:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3878) MassedCompute because we have fully up-to-date&nbsp; tutorial for MassedCompute. You see this one,&nbsp;&nbsp;

- [01:04:44](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3884) ComfyUI and SwarmUI on cloud GPUs tutorial. The&nbsp; link will be in the description of the video.&nbsp;&nbsp;

- [01:04:48](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3888) So watch this to learn that part. I will just&nbsp; show how to use AI toolkit on MassedCompute,&nbsp;&nbsp;

- [01:04:55](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3895) not the how to use SwarmUI and ComfyUI and&nbsp; do the grid generation or other stuff as I&nbsp;&nbsp;

- [01:05:01](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3901) have shown in the Windows tutorial part. The&nbsp; biggest advantage of my installer is that it&nbsp;&nbsp;

- [01:05:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3906) always installs the latest version of the AI&nbsp; toolkit trainer. Moreover, it supports all of&nbsp;&nbsp;

- [01:05:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3912) the GPUs with the latest pre-compiled drivers&nbsp; with flash attention, xformers, sage attention,&nbsp;&nbsp;

- [01:05:18](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3918) Torch version, CUDA version. Therefore, my&nbsp; installers are really better than using the&nbsp;&nbsp;

- [01:05:24](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3924) templates. So during the Node.js installation, it&nbsp; is all automatic. You may get some warnings, just&nbsp;&nbsp;

- [01:05:30](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3930) ignore them because it will work. My installer&nbsp; is fully optimized and made it so easy that you&nbsp;&nbsp;

- [01:05:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3937) just run these two lines of command. It handles&nbsp; everything, all the setup for you. Okay, so the&nbsp;&nbsp;

- [01:05:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3943) installation has been completed. You can scroll&nbsp; up to see if there are any errors or not. Then&nbsp;&nbsp;

- [01:05:49](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3949) return back to your folder, open the MassedCompute&nbsp; instructions txt file again, and copy this part.&nbsp;&nbsp;

- [01:05:57](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3957) This is for starting. Then open three dots here,&nbsp; open in terminal, copy-paste it. We always run the&nbsp;&nbsp;

- [01:06:03](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3963) commands inside installed folder. This is super&nbsp; important. So it has been started. You can either&nbsp;&nbsp;

- [01:06:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3970) use the local link like this, or if you want to&nbsp; connect from your computer, which I recommend,&nbsp;&nbsp;

- [01:06:15](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3975) open link like this. So you see this is public&nbsp; link, and now I can connect from my computer. So&nbsp;&nbsp;

- [01:06:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3982) let's see. It says, yes, it says it is not secure.&nbsp; Continue site. This is totally fine. And now,&nbsp;&nbsp;

- [01:06:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3988) yes. So you see it is running in MassedCompute,&nbsp; but I am connected from my computer. The data&nbsp;&nbsp;

- [01:06:34](https://www.youtube.com/watch?v=ezD6QO14kRc&t=3994) set will be here since I have copy-pasted it,&nbsp; or I can click copy data set. I can type GG,&nbsp;&nbsp;

- [01:06:40](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4000) create, then I can add images. I can drag and drop&nbsp; images from here to upload. However, copy-pasting&nbsp;&nbsp;

- [01:06:47](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4007) from the disk is better than here in my opinion.&nbsp; Okay, let's refresh. We don't need it. Then click&nbsp;&nbsp;

- [01:06:54](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4014) new job as in the Windows tutorial part, show&nbsp; advanced, select the configuration from the zip&nbsp;&nbsp;

- [01:06:59](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4019) file inside Z Image Turbo Lora configs. So since&nbsp; this GPU is 24 GB, copy-paste it, show simple,&nbsp;&nbsp;

- [01:07:06](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4026) give a name to your training, whatever you&nbsp; want, and then in the data set, select it.&nbsp;&nbsp;

- [01:07:12](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4032) As in the Windows tutorial part, you need to&nbsp; set your save every N steps and step count.&nbsp;&nbsp;

- [01:07:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4037) Watch the Windows tutorial part. Don't skip it.&nbsp; Then create job and then click play. So it will&nbsp;&nbsp;

- [01:07:22](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4042) first download the necessary models, then it will&nbsp; start training. Then the checkpoints will appear&nbsp;&nbsp;

- [01:07:28](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4048) here so that I will be able to download from here&nbsp; or in my machine in the AI toolkit installation,&nbsp;&nbsp;

- [01:07:37](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4057) they will be inside the output folder. So they&nbsp; will be inside here. To download from here,&nbsp;&nbsp;

- [01:07:42](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4062) I can use my notebook, my Jupyter Lab notebook,&nbsp; or you can use Google Drive, OneDrive, or you can&nbsp;&nbsp;

- [01:07:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4070) use the ThinLinc client. However, it would be&nbsp; very slow. So probably downloading from these&nbsp;&nbsp;

- [01:07:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4076) checkpoints from here will be the fastest way to&nbsp; download. Let's wait until the training begins so&nbsp;&nbsp;

- [01:08:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4082) we can see the speed. Okay, so the training has&nbsp; been started. It is like 18 seconds per IT. So&nbsp;&nbsp;

- [01:08:10](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4090) it will take 30 hours for 6,000 steps on this&nbsp; GPU. It is only 42 cents. Therefore, it would&nbsp;&nbsp;

- [01:08:17](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4097) take like $12. However, it is up to you. You can&nbsp; rent powerful GPU or you can use RunPod and 4090,&nbsp;&nbsp;

- [01:08:25](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4105) 5090, or you can reduce the training resolution&nbsp; and speed up like four times, five times. It is&nbsp;&nbsp;

- [01:08:32](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4112) totally up to you what you want to do, but this is&nbsp; how you do it. And as the checkpoints generated,&nbsp;&nbsp;

- [01:08:38](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4118) they will appear here so that you can download&nbsp; and use on your local computer right away. This&nbsp;&nbsp;

- [01:08:43](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4123) is it. I hope you have enjoyed. Don't forget&nbsp; to delete your machine once you have saved&nbsp;&nbsp;

- [01:08:50](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4130) your generated checkpoints. Otherwise, if you use&nbsp; stop, it will not stop billing on MassedCompute.&nbsp;&nbsp;

- [01:08:56](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4136) And MassedCompute team told me that they will&nbsp; get a lot of new GPUs, hopefully very soon,&nbsp;&nbsp;

- [01:09:02](https://www.youtube.com/watch?v=ezD6QO14kRc&t=4142) and maybe there will be permanent storage as well.&nbsp; We will see. Keep watching. Thank you so much.

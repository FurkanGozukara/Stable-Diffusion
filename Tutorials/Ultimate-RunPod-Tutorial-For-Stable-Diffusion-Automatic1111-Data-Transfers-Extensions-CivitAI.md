# Ultimate RunPod Tutorial For Stable Diffusion - Automatic1111 - Data Transfers, Extensions, CivitAI

## Full tutorial link > https://www.youtube.com/watch?v=QN1vdGhjcRc

[![Ultimate RunPod Tutorial For Stable Diffusion - Automatic1111 - Data Transfers, Extensions, CivitAI](https://img.youtube.com/vi/QN1vdGhjcRc/sddefault.jpg)](https://www.youtube.com/watch?v=QN1vdGhjcRc "Ultimate RunPod Tutorial For Stable Diffusion - Automatic1111 - Data Transfers, Extensions, CivitAI")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Ultimate-RunPod-Tutorial-For-Stable-Diffusion-Automatic1111-Data-Transfers-Extensions-CivitAI.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Ultimate-RunPod-Tutorial-For-Stable-Diffusion-Automatic1111-Data-Transfers-Extensions-CivitAI.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Sign up RunPod: [https://bit.ly/RunPodIO.](https://bit.ly/RunPodIO.) This is the Grand Master tutorial for running Stable Diffusion via Web UI on RunPod cloud services. If I have been of assistance to you and you would like to show your support for my work, please consider becoming a patron on ü•∞ [https://www.patreon.com/SECourses](https://www.patreon.com/SECourses)

SECourses Discord To Get Full Support ‚§µÔ∏è

[https://discord.com/servers/software-engineering-courses-secourses-772774097734074388](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388)

#RunPod discord: [https://discord.gg/pJ3P2DbUUq](https://discord.gg/pJ3P2DbUUq)

Colab Tutorial 1: [https://youtu.be/mnCY8uM7E50](https://youtu.be/mnCY8uM7E50)

Colab Tutorial 2: [https://youtu.be/kIyqAdd_i10](https://youtu.be/kIyqAdd_i10)

Automatic1111 Command Line: [https://bit.ly/StartArguments](https://bit.ly/StartArguments)

Best DreamBooth Tutorial: [https://youtu.be/Bdl-jWR3Ukc](https://youtu.be/Bdl-jWR3Ukc)

DreamBooth second tutorial: [https://youtu.be/KwxNcGhHuLY](https://youtu.be/KwxNcGhHuLY)

RunPodCTL GitHub: [https://github.com/runpod/runpodctl](https://github.com/runpod/runpodctl)

Pre-trained models repo link : [https://huggingface.co/lllyasviel/ControlNet](https://huggingface.co/lllyasviel/ControlNet)

Web UI install tutorial on PC: [https://youtu.be/AZg6vzWHOTA](https://youtu.be/AZg6vzWHOTA)

How To Use Different Models Automatic1111: [https://youtu.be/aAyvsX-EpG4](https://youtu.be/aAyvsX-EpG4)

Textual Inversion Training Tutorial: [https://youtu.be/dNOpWt-epdQ](https://youtu.be/dNOpWt-epdQ)

ControlNet Tutorial Video: [https://youtu.be/vhqqmkTBMlU](https://youtu.be/vhqqmkTBMlU)

ControlNet extension: [http://bit.ly/3IxBYc6](http://bit.ly/3IxBYc6)

ControlNet Model Files: [https://bit.ly/CTRLNETModels](https://bit.ly/CTRLNETModels)

ControlNet Native Script: [https://youtu.be/YJebdQ30UZQ](https://youtu.be/YJebdQ30UZQ)

Upgrade xformers Commands: [https://bit.ly/UPxformers](https://bit.ly/UPxformers)

Kohya GUI: [http://bit.ly/3ICvsB7](http://bit.ly/3ICvsB7)

Cloud sync: [http://bit.ly/40Zf44C](http://bit.ly/40Zf44C)

[00:00:00](https://youtu.be/QN1vdGhjcRc?t=0) Intro

[00:01:32](https://youtu.be/QN1vdGhjcRc?t=92) How to register RunPod.io and charge your credits

[00:02:34](https://youtu.be/QN1vdGhjcRc?t=154) How to deploy a pod - start a server for Stable Diffusion 1.5 Automatic1111 Web UI

[00:03:30](https://youtu.be/QN1vdGhjcRc?t=210) How to select deployment template for Stable Diffusion Web UI in RunPod

[00:04:00](https://youtu.be/QN1vdGhjcRc?t=240) Explanation of temporary disk and persistent volume

[00:04:44](https://youtu.be/QN1vdGhjcRc?t=284) Explanation of credit spending per minute for storage usage in RunPod

[00:08:10](https://youtu.be/QN1vdGhjcRc?t=490) My Pods section

[00:08:30](https://youtu.be/QN1vdGhjcRc?t=510) Connect to the started Pod

[00:08:41](https://youtu.be/QN1vdGhjcRc?t=521) Start SD 2.1 Version Web UI Pod

[00:09:25](https://youtu.be/QN1vdGhjcRc?t=565) Why pick a lesser used Pod

[00:10:53](https://youtu.be/QN1vdGhjcRc?t=653) Bidding system of RunPod.io

[00:13:11](https://youtu.be/QN1vdGhjcRc?t=791) Where and how to see scheduled maintenance

[00:13:31](https://youtu.be/QN1vdGhjcRc?t=811) Stop Pod vs Terminate (delete) Pod

[00:14:24](https://youtu.be/QN1vdGhjcRc?t=864) Where to see logs to debug and understand errors

[00:15:08](https://youtu.be/QN1vdGhjcRc?t=908) Connect your Pod via a Jupyter Lab interface

[00:15:16](https://youtu.be/QN1vdGhjcRc?t=916) How to change Automatic1111 Web UI command line arguments and restart it

[00:17:54](https://youtu.be/QN1vdGhjcRc?t=1074) First prompt in RunPod Automatic1111 Web UI

[00:18:45](https://youtu.be/QN1vdGhjcRc?t=1125) Where to see logs, find error logs, debug them

[00:19:35](https://youtu.be/QN1vdGhjcRc?t=1175) How to install DreamBooth extension of Automatic1111 Web UI

[00:20:58](https://youtu.be/QN1vdGhjcRc?t=1258) Where the generated images are saved

[00:21:10](https://youtu.be/QN1vdGhjcRc?t=1270) How to download generated images

[00:21:38](https://youtu.be/QN1vdGhjcRc?t=1298) How to update installed extensions

[00:21:55](https://youtu.be/QN1vdGhjcRc?t=1315) How to notice port error and fix it

[00:23:04](https://youtu.be/QN1vdGhjcRc?t=1384) How to install runpodctl latest version to transfer files very quickly between Pods and PC

[00:23:55](https://youtu.be/QN1vdGhjcRc?t=1435) How to download a ckpt file very fast from Hugging Face repo

[00:25:10](https://youtu.be/QN1vdGhjcRc?t=1510) Start DreamBooth training with best model and settings

[00:30:41](https://youtu.be/QN1vdGhjcRc?t=1841) How to upload your training dataset images

[00:34:15](https://youtu.be/QN1vdGhjcRc?t=2055) How to upload thousands of images (big data) from your computer to RunPod via runpodctl

[00:34:28](https://youtu.be/QN1vdGhjcRc?t=2068) How to install RunPodCTL on your Windows computer

[00:35:06](https://youtu.be/QN1vdGhjcRc?t=2106) How to send files from your PC to RunPod via runpodctl

[00:39:38](https://youtu.be/QN1vdGhjcRc?t=2378) Where to find generated checkpoints and sample images during DreamBooth training

[00:41:30](https://youtu.be/QN1vdGhjcRc?t=2490) How to delete non-empty folder

[00:41:51](https://youtu.be/QN1vdGhjcRc?t=2511) Even though xformers not selected during training, still breaks training and how to fix it

[00:42:29](https://youtu.be/QN1vdGhjcRc?t=2549) How to download a folder from RunPod to your PC via runpodctl very quickly

[00:43:09](https://youtu.be/QN1vdGhjcRc?t=2589) How to add runpodctl to environment path to use from every folder

[00:47:25](https://youtu.be/QN1vdGhjcRc?t=2845) How to continue/resume DreamBooth training

[00:48:20](https://youtu.be/QN1vdGhjcRc?t=2900) Test all training checkpoints with x/y plot to find best one

[00:52:09](https://youtu.be/QN1vdGhjcRc?t=3129) How to set correct command line arguments for SD 2.1

[00:52:55](https://youtu.be/QN1vdGhjcRc?t=3175) Where to see currently spent credits per hour

[00:54:05](https://youtu.be/QN1vdGhjcRc?t=3245) How to do DreamBooth training on SD 2.1 - 768 pixel version with best possible settings

[00:57:42](https://youtu.be/QN1vdGhjcRc?t=3462) How to generate classification images manually very fast

[01:00:26](https://youtu.be/QN1vdGhjcRc?t=3626) Why SD 1.5 is superior to 2.1

[01:04:34](https://youtu.be/QN1vdGhjcRc?t=3874) How to download custom models very fast from CivitAI

[01:08:45](https://youtu.be/QN1vdGhjcRc?t=4125) How to do Textual Inversion training with some optimal settings

[01:13:00](https://youtu.be/QN1vdGhjcRc?t=4380) Where Textual Inversion training samples and checkpoints are saved

[01:14:07](https://youtu.be/QN1vdGhjcRc?t=4447) How to use Textual Inversion check points

[01:15:55](https://youtu.be/QN1vdGhjcRc?t=4555) Move generated SD 2.1 classification images into correct folder

[01:19:26](https://youtu.be/QN1vdGhjcRc?t=4766) How to install and run ControlNet extension on RunPod IO

[01:21:11](https://youtu.be/QN1vdGhjcRc?t=4871) How to download your trained model files (ckpt) into your PC very fast via runpodctl

[01:25:00](https://youtu.be/QN1vdGhjcRc?t=5100) How to upgrade xformers to 0.0.17 for DreamBooth SD 2.1 training

[01:26:04](https://youtu.be/QN1vdGhjcRc?t=5164) How to expand runtime disk space

[01:27:21](https://youtu.be/QN1vdGhjcRc?t=5241) Best settings for SD 2.1 with xformers

[01:31:30](https://youtu.be/QN1vdGhjcRc?t=5490) What is Stable Diffusion fine tuning and how to do fine tuning with DreamBooth

[01:39:20](https://youtu.be/QN1vdGhjcRc?t=5960) Best settings quick recap for SD 2.1 for 24 GB VRAM

[01:40:34](https://youtu.be/QN1vdGhjcRc?t=6034) How to install and run Kohya GUI on RunPod

[01:44:16](https://youtu.be/QN1vdGhjcRc?t=6256) How to enable public Gradio link for Kohya GUI

[01:44:52](https://youtu.be/QN1vdGhjcRc?t=6292) How to start RunPods without GPU

[01:46:53](https://youtu.be/QN1vdGhjcRc?t=6413) Cloud snyching your Pod data / content

thumbnail freepik macrovector



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=0) Greetings everyone.

- [00:00:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1) In this video, I am going to show how to use Automatic1111 Web UI for Stable Diffusion

- [00:00:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=7) tasks on RunPod.io like you are using it on your computer.

- [00:00:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=11) I will cover many topics such as how to upload and download files quickly, how to delete

- [00:00:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=17) directories, how to install and run extensions, how to quickly download and use custom models,

- [00:00:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=23) how to do DreamBooth training on Stable Diffusion 1.5 or 2.1 versions, how to do fine tuning

- [00:00:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=30) via DreamBooth extension, how to do Textual Inversion training.

- [00:00:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=34) I will also explain how their pricing system works, how you can use bidding, how you can

- [00:00:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=39) transfer files from Pod to Pod or from Computer to Pod and vice versa, how you can install

- [00:00:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=45) custom other scripts such as famous Kohya graphical user interface.

- [00:00:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=50) I will also demonstrate how you can use new famous ControlNet on RunPod.io.

- [00:00:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=56) So why RunPod.io?

- [00:00:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=58) Because their system charges you based on per minute and they have great Discord support.

- [00:01:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=63) They are also easier to use with the tools they have.

- [00:01:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=67) But still, if you are interested in free cloud services for Stable Diffusion, I have two

- [00:01:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=72) great tutorials for Google Colab.

- [00:01:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=74) The first one is this one and the second one is this one.

- [00:01:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=78) And if you don't know how to use Automatic1111 Web UI, if you don't know what is Stable Diffusion,

- [00:01:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=83) what is Automatic1111 Web UI, I have great tutorial series for them.

- [00:01:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=87) For example, you can begin with watching video and you can check out the other videos in

- [00:01:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=91) this playlist.

- [00:01:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=92) So let's begin the Grandmaster RunPod.io tutorial by signing up a new account.

- [00:01:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=98) Click the sign up button.

- [00:01:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=99) For sign up I will use my Google account.

- [00:01:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=102) You can also enter your email and password if you wish.

- [00:01:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=105) Choose your account to sign up.

- [00:01:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=107) Click I have read and agreed RunPod Terms and Services.

- [00:01:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=111) Click Continue.

- [00:01:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=112) And yes, we are ready to start.

- [00:01:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=114) First of all, you need to charge some credits to start using the pods.

- [00:01:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=119) Click your balance from here as you can see in the right top menu, then it will show your

- [00:02:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=124) available balance.

- [00:02:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=126) From here you can pay with a card.

- [00:02:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=128) You can change the amount that you want to charge.

- [00:02:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=130) To have automatic payments you can add a card.

- [00:02:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=133) They also allow you to pay with a crypto.

- [00:02:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=136) Just click this icon.

- [00:02:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=137) They also show recent transactions, recent charges, and everything is very transparent.

- [00:02:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=143) OK, now I have logged in my account where I have my credits.

- [00:02:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=148) Now we can start using our Pods.

- [00:02:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=150) To do that, go to the browse servers tab in here and in here you will see the available

- [00:02:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=157) servers.

- [00:02:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=158) If you are going to do training, then I suggest you to get minimum 24 gigabytes VRAM having

- [00:02:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=165) server.

- [00:02:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=166) Because currently the latest officially released xformers is not working very well for training.

- [00:02:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=173) They have a nightly version that works well, but for training we won't use xformers.

- [00:03:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=180) And if you are not going to use xformers, then you should get minimum 24 gigabytes VRAM

- [00:03:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=186) having server.

- [00:03:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=187) I find that RTX A5000 is very decent GPU with a lower price.

- [00:03:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=194) As you can see, it is only 0.32 dollars per hour.

- [00:03:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=199) So I am going to deploy RTX A5000 GPU.

- [00:03:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=203) When you click the deploy icon, this interface will appear to you.

- [00:03:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=208) So in this interface, you should select your template.

- [00:03:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=211) There are many templates.

- [00:03:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=213) When you type Stable Diffusion, you see there are two very popular templates for Stable

- [00:03:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=219) Diffusion.

- [00:03:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=220) RunPod Stable Diffusion 1.5 and RunPod Stable Diffusion 2.1.

- [00:03:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=223) I will start both of them and I will start doing training both of them simultaneously.

- [00:03:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=229) So let's begin with RunPod Stable Diffusion 1.5 as a template.

- [00:03:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=234) So it will also download the official 1.5 version when it starts.

- [00:03:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=239) In here it shows us the other features.

- [00:04:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=241) They are very decent.

- [00:04:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=243) The temporary disk is the disk where the operating system will run.

- [00:04:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=248) You don't need to increase this.

- [00:04:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=250) And the persistent volume.

- [00:04:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=251) Now this is really important.

- [00:04:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=253) The persistent volume will stay remain as long as you don't delete your Pod.

- [00:04:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=260) So when you close your Pod, it will remain as it is.

- [00:04:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=263) It is like your hard drive.

- [00:04:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=264) It is persistent.

- [00:04:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=266) Everything you have generated, you have downloaded will remain there.

- [00:04:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=270) So this should be a sufficient amount of disk space based on your needs.

- [00:04:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=276) I am going to set it as 100 and when you set it, it will increase your minute credit spending.

- [00:04:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=284) So when you hover your mouse over this icon, it shows that 0.10 per gigabyte per month

- [00:04:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=292) for total disk on running Pods, 0.20 per gigabyte per month for volumes on exited Pods.

- [00:05:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=300) I know that this may be sounding confusing in the beginning, so I have prepared an example

- [00:05:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=306) for you which I will explain step by step.

- [00:05:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=309) So we have 105 gigabytes while running.

- [00:05:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=313) Why?

- [00:05:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=314) Persistent volume is 100 gigabytes and temporary disk is 5 gigabytes.

- [00:05:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=317) So while running, we are going to spend like this.

- [00:05:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=321) Let's say our Pod did run 75 minutes.

- [00:05:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=325) So 105 multiplied with 0.1 which is the per gigabyte price for per month.

- [00:05:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=333) In per month, how many days there are?

- [00:05:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=336) 30 days.

- [00:05:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=337) So we are dividing it with 30 days.

- [00:05:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=340) In a day, how many hours there are?

- [00:05:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=342) 24 hours.

- [00:05:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=343) So we are dividing it with 24 hours.

- [00:05:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=346) In an hour, how many minutes there are?

- [00:05:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=348) There are 60 minutes.

- [00:05:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=349) So this is the price of per minute running and since we are running 75 minutes, it is

- [00:05:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=356) going to take total 0.018 dollar from our credit.

- [00:06:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=362) You can also copy this.

- [00:06:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=364) Open your calculator with typing calculator in your search bar, paste it and hit enter

- [00:06:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=369) and you will get the result like this as you can see.

- [00:06:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=372) So in the below, I am giving example of Pod when it is not running.

- [00:06:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=378) When the Pod is not running, we are going to use 100 gigabytes persistent volume and

- [00:06:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=385) let's say our Pod did remain not running for two days.

- [00:06:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=390) So when Pod is not running, the price is for per gigabyte per month 0.20 dollars.

- [00:06:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=397) So since we have 100 gigabytes, 100 multiplied with 0.2, then let's delete this to not have

- [00:06:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=405) more confusion than in a month.

- [00:06:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=408) We have 30 days and we are going to use two days.

- [00:06:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=412) So this will be our spending.

- [00:06:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=414) So you can also open the calculator and copy-paste it, hit enter and you will get the price.

- [00:07:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=421) So this part is the price of one day offline for your 100 gigabytes having Pod.

- [00:07:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=429) And since it will be offline for two days, this is the credit that we are going to use.

- [00:07:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=433) The very important thing is that these credits will be deducted from your account per minute.

- [00:07:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=440) So if you keep using RunPod.io service for 10 minutes, you will be charged for 10 minutes.

- [00:07:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=446) So if it remains offline for 10 minutes, then you will be charged for 10 minutes.

- [00:07:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=451) It is not like taking your credits for per day, for per hour, or for per month.

- [00:07:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=457) It is using your credits for every minute.

- [00:07:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=460) When you hover your mouse over encrypt volume, you will see the message.

- [00:07:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=464) Encrypted volumes provide better data security, but will incur a performance penalty and cannot

- [00:07:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=469) be resized later.

- [00:07:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=470) So unless you need this, don't check this box.

- [00:07:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=474) Start Jupyter Notebook.

- [00:07:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=475) This will make your life much easier.

- [00:07:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=478) And this is the price per hour for our GPU.

- [00:08:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=482) So this price will be added these volume prices as well.

- [00:08:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=487) After you clicked deploy button, you will see an interface like this.

- [00:08:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=491) You can go to the My Pods section and you will see on demand community cloud is being

- [00:08:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=497) prepared.

- [00:08:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=498) When I click in here, you see it is showing me the messages of the Pod that is being prepared,

- [00:08:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=507) what is happening on the Pod.

- [00:08:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=508) And once it becomes ready, we will see connect button in here.

- [00:08:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=513) So it is initializing the Pod with the necessary installation and the Pod is now ready and

- [00:08:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=519) it is running.

- [00:08:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=520) Now I will start SD 2.1 version Pod simultaneously.

- [00:08:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=525) To do that I am clicking browse servers and when you open browse servers tab, you will

- [00:08:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=529) see in the right tab how much credits you are spending right now.

- [00:08:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=534) Because currently my other Pod is running, as you can see in My Pods tab.

- [00:09:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=540) So let's return back the browse servers and in here there are several options.

- [00:09:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=544) So you see there are one GPU Pods, two GPU Pods, large Pods, four GPU or x large Pods,

- [00:09:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=552) eight GPUs.

- [00:09:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=553) So if you need multiple GPUs, then you can filter them with this.

- [00:09:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=556) Also in each Pod, you will see their location, their available upload and download speeds,

- [00:09:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=562) their available disks and other things.

- [00:09:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=565) Choosing a less used Pod is better because if your previous Pod is fully used, then you

- [00:09:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=574) won't be able to get a GPU on that Pod.

- [00:09:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=577) So what happens then, then to use your existing files, you need to compose a new Pod and transfer

- [00:09:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=585) your files.

- [00:09:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=586) So availability is really important when choosing your Pod.

- [00:09:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=590) If you choose highly preferred Pod, then you will have lesser time to get it and it will

- [00:09:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=597) make things harder for you.

- [00:09:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=599) So based on this fact, you should choose your Pod.

- [00:10:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=603) So for the SD 2.1 version, I am going to pick another RTX A5000.

- [00:10:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=609) When you click more RTX A5000, it displays you other locations as well.

- [00:10:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=616) You see the upload and download speeds changes and the available space changes.

- [00:10:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=622) More available space probably means that it is being used lesser.

- [00:10:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=627) So for Canada server, it looks like it is not very much preferred this particular server.

- [00:10:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=633) So there is also Norway server.

- [00:10:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=635) You see it has great upload and download speeds.

- [00:10:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=638) It has decent hard drive space as well.

- [00:10:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=640) So it is probably also not very much used.

- [00:10:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=643) However, this is expensive than others.

- [00:10:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=646) So I think I will go with this Canada server.

- [00:10:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=650) Its speeds are also decent.

- [00:10:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=652) Click deploy.

- [00:10:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=654) There is one more thing as well that I need to explain.

- [00:10:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=657) Community cloud.

- [00:10:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=658) So what does community cloud mean that?

- [00:11:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=661) In the community cloud section, you will be able to bid for shared servers.

- [00:11:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=666) All of the servers are shared, but this is kind of that you bid and if someone overbids

- [00:11:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=671) you, they get your GPU.

- [00:11:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=674) So in here you see the prices will be lower.

- [00:11:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=677) When I click RTX A5000 select and then I click continue.

- [00:11:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=682) So you see currently this is selected.

- [00:11:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=684) RunPod Stable Diffusion 1.5.

- [00:11:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=687) I can also change it from this template.

- [00:11:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=689) Don't forget to change template.

- [00:11:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=692) When I click continue, you see now I am getting pricing summary and advanced.

- [00:11:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=696) When I click advanced, it will allow me to bid for a spot.

- [00:11:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=701) So you see the current bid is 0.198.

- [00:11:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=704) When I bid this, I will overbid the other person who has bidded lesser than this.

- [00:11:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=711) So I am going to get his GPU if there are no available other GPUs.

- [00:11:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=716) So let's say we did bid like this and we started our RunPod.

- [00:12:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=720) So someone else comes and bids 0.2 and they will get our GPU.

- [00:12:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=726) Then our pod will not have any GPU to do inference or training and our training will be also

- [00:12:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=733) halted.

- [00:12:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=734) So be careful with this.

- [00:12:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=735) If you are not going to do training, if you are only going to do image generation, then

- [00:12:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=740) you can go with this option and spend lesser.

- [00:12:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=743) The running disk cost and exited disk cost also slightly changes.

- [00:12:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=748) You can recalculate the cost.

- [00:12:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=750) So this is how you do bidding and this is how you use community cloud servers.

- [00:12:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=756) Since I am going to do training, I am going to use on demand server and I am going to

- [00:12:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=761) pick on demand server from here.

- [00:12:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=764) This Canada server.

- [00:12:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=766) Let's check again.

- [00:12:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=767) Yes, I am going to use this Canada server because it has the most available disk space.

- [00:12:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=772) Therefore, I am assuming that it is being used lesser than others.

- [00:12:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=777) Click deploy and we have selected RunPod Stable Diffusion 2.1 version.

- [00:13:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=781) Let's set our persistent volume as 100 GB and let's also deploy it so it will get deployed.

- [00:13:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=788) When I click My Pods, I will see them in here.

- [00:13:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=791) OK, when you go on My Pods, it is going to show you if there will be a maintenance or

- [00:13:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=798) not.

- [00:13:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=799) So you should be careful with this maintenance.

- [00:13:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=801) It says that it will start at this local time.

- [00:13:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=804) Therefore, I think I will delete this Pod.

- [00:13:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=807) So I will just click stop Pod and then I will delete it.

- [00:13:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=811) So when you stop your Pod, it will remain as it is.

- [00:13:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=814) However, if you click this terminate, then the Pod will be permanently deleted and you

- [00:13:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=819) won't be able to recover or access any of your data.

- [00:13:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=823) So now it is gone.

- [00:13:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=825) Let's go back to the browse servers tab and let's pick another server from here.

- [00:13:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=831) Maybe that is why it was being lesser used.

- [00:13:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=834) So I will pick this one.

- [00:13:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=836) OK, 2.1 version 100 GB.

- [00:13:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=839) Let's deploy.

- [00:14:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=840) Let's go to the My Pods and it is being deployed.

- [00:14:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=843) The first one we started is running.

- [00:14:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=846) The other one is being initialized and this is my per hour using credits right now.

- [00:14:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=852) OK, let's connect our first Pod.

- [00:14:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=854) To connect our first Pod.

- [00:14:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=856) I am clicking My Pods.

- [00:14:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=858) Let's refresh so you will see the interface as it is.

- [00:14:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=860) OK, I am clicking here.

- [00:14:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=862) It will open the interface.

- [00:14:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=864) When you click logs, it will show you the logs screen.

- [00:14:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=867) This is really important to debug the errors that you might encounter.

- [00:14:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=871) So it started with xformers with Workspace 1.5. emaonly CKPT file.

- [00:14:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=876) Actually, this is not the best CKPT file for training, so I will download the best one

- [00:14:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=883) and it is running on xformers 0.0.16.

- [00:14:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=887) This xformers is not compatible with DreamBooth training or Textual Inversion training, unfortunately,

- [00:14:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=894) so we won't use xformers during training and the other things are also displayed here.

- [00:14:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=899) When you click system logs, it will also show you the system logs.

- [00:15:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=902) When you click this refresh icon, it will refresh and when you click this X, it will

- [00:15:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=907) close it.

- [00:15:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=908) So let's click connect and I will connect it via Jupyter Lab, which will make our life

- [00:15:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=914) much easier.

- [00:15:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=915) OK, so our Jupyter has started like this.

- [00:15:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=919) The first thing that I am going to show you is how to change starting command line arguments.

- [00:15:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=925) To change them, I am zooming it for you to see easier.

- [00:15:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=928) That is webui-user.sh.

- [00:15:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=933) So this is the file where the command line arguments are provided.

- [00:15:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=938) You see it is starting with default port 3000.

- [00:15:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=941) It is starting with xformers.

- [00:15:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=943) The default CKPT is provided like this and there is a listen and enable insecure access.

- [00:15:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=950) So if you wonder what are these arguments are doing, there is a wiki page of Automatic1111

- [00:15:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=955) web UI and you can search for the commands by copying and pasting them and it will show

- [00:16:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=962) you launch gradio with 0000 as server name allowing to respond network requests.

- [00:16:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=967) Actually, I am going to also add share to be able to use it from my browser like this

- [00:16:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=974) and enable insecure extension access means that we will be able to install extensions.

- [00:16:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=979) Make sure that these commands are already enabled.

- [00:16:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=983) Otherwise, you won't be able to install extensions and I think we are ready.

- [00:16:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=988) I will also change the port to not get conflicted with any of the initial starting.

- [00:16:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=994) Just save.

- [00:16:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=995) When you save, you will see in the bottom saving completed.

- [00:16:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=997) Then go to the running terminals and kernels.

- [00:16:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1000) Shut down all of the running terminals and then go back to the file browser.

- [00:16:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1006) Make sure that you are inside Stable Diffusion web UI folder.

- [00:16:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1010) Then start the terminal.

- [00:16:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1011) When you start the terminal, it will start with the folder that you are currently in.

- [00:16:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1016) You see it is the same as the folder that we are in and in here we will use relauncher.py.

- [00:17:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1023) To do that just type python and I will copy paste the name relauncher.py hit enter and

- [00:17:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1030) it will restart our web UI with the newest set command line arguments.

- [00:17:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1035) We should be able to see them in here.

- [00:17:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1037) Yes, we are seeing dash dash port three thousand ten xformers.

- [00:17:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1041) So with this way you can also start multiple instances of web UI.

- [00:17:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1047) If you are a professional, then you can do that.

- [00:17:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1049) But if you are not, I don't suggest you to do that.

- [00:17:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1052) Now we can access it from this public URL.

- [00:17:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1055) This public URL is currently not secured by a password.

- [00:17:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1059) You can also add a password in here I think.

- [00:17:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1062) Let me show you.

- [00:17:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1063) Yes, you can also set out username and password.

- [00:17:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1066) However, if you are not giving this URL to anyone, then it should be safe.

- [00:17:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1071) As you can see, our interface is started.

- [00:17:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1074) Let's start with typing a simple prompt and see what happens.

- [00:17:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1078) OK, I have prepared my prompt.

- [00:18:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1081) I hit generate and in My Pods now you will see the GPU memory used is being increased.

- [00:18:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1087) GPU utilization will also increase as it generates the images and image is already generated.

- [00:18:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1094) Let's set the batch size as eight and batch count as one hundred.

- [00:18:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1098) And let's see how it is using our GPU.

- [00:18:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1101) So let's hit the refresh.

- [00:18:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1103) So it is showing like ten seconds ago.

- [00:18:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1105) OK, now you see the GPU utilization is one hundred percent.

- [00:18:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1109) GPU memory used is still significantly low because it is using also xformers, even though

- [00:18:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1117) we are generating images as batches with eight as batch size.

- [00:18:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1122) So in each time it will generate eight images.

- [00:18:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1125) So where are these files are being saved?

- [00:18:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1129) And how can I see if any error occurs?

- [00:18:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1132) You see in the My Pods, just click the logs and you will see all of the logs here.

- [00:18:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1138) This is really important to debug the logs.

- [00:19:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1140) And in here in the terminal window, you will see what is happening.

- [00:19:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1144) So how can you open the terminal.

- [00:19:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1145) To open the terminal, go to the running terminals and kernels.

- [00:19:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1148) And let's say I have closed the terminal.

- [00:19:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1151) I double click the terminal and it will show me the terminal as here.

- [00:19:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1156) As you can see in here.

- [00:19:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1157) This is equal to the terminal that we have on our computer when we are running it locally

- [00:19:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1163) on our computer.

- [00:19:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1164) This is the it per second.

- [00:19:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1166) However, since we are generating eight images at a time, it is actually over twenty four

- [00:19:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1171) it per second.

- [00:19:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1173) You need to multiply this with eight.

- [00:19:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1175) OK, let's hit the interrupt.

- [00:19:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1177) Now I will install the DreamBooth extension.

- [00:19:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1179) To do that go to the extension tab.

- [00:19:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1181) Go to the available hit load from.

- [00:19:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1184) Search DreamBooth, hit install.

- [00:19:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1187) Meanwhile, my two point one version terminal is also spending my time, my credit.

- [00:19:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1193) So I will just stop it.

- [00:19:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1195) So when you click stop Pod you are going to get this message, you should read it and understand

- [00:20:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1201) it.

- [00:20:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1202) OK, stopped Pod.

- [00:20:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1203) Basically what does it says that all of the things that is not saved on your workspace

- [00:20:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1209) will be lost.

- [00:20:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1211) So whatever you have in your workspace will be saved.

- [00:20:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1215) OK, let's see the status of the installation.

- [00:20:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1218) OK, it says that installed into workspace, Stable Diffusion, web ui extensions, SD DreamBooth

- [00:20:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1224) extension.

- [00:20:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1225) Now I will restart my terminal because when you first time install DreamBooth, you really

- [00:20:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1230) need to restart terminal so that it can install the necessary dependencies.

- [00:20:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1235) So I am going to do terminal stop, shut down all terminals.

- [00:20:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1239) Then I am going to Stable Diffusion Web UI folder and in here I will open a new terminal.

- [00:20:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1246) Same as before, I will type Python and relauncher.py and hit enter.

- [00:20:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1251) So the Web UI has been restarted and now we got a new link.

- [00:20:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1256) Let's copy and paste it.

- [00:20:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1258) Meanwhile, it is being loaded let's check out the generated images.

- [00:21:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1261) So they are saved in the outputs folder in the in the text to image images folder.

- [00:21:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1267) And yes, they are in here.

- [00:21:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1269) So how to download them?

- [00:21:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1270) You can download them one by one, right click and download.

- [00:21:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1273) Then it will download like this.

- [00:21:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1276) You can alternatively right click and download current folder as an archive.

- [00:21:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1280) It will first make archive and it will download all of the images like this.

- [00:21:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1285) It is a decent speed and it has downloaded all of these images.

- [00:21:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1291) 121 files so far.

- [00:21:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1292) OK, the interface has been reloaded and now we are seeing the DreamBooth extension.

- [00:21:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1298) When we go to the extension tab, check for updates.

- [00:21:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1301) We should see the latest version in here.

- [00:21:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1304) Actually, it says that it is behind.

- [00:21:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1306) So let's click apply and restart UI.

- [00:21:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1309) And once we do that, we get an error.

- [00:21:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1313) It is relaunching in two seconds.

- [00:21:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1315) OK, when relaunching, we are getting port error because the previous one was crashed.

- [00:22:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1321) So what I'm going to do is: I will shut down all of the terminals.

- [00:22:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1325) Go back to the file browser.

- [00:22:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1327) In the first installation, you may encounter such errors.

- [00:22:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1330) Go to the webui user.sh file and change the port here and then go to the terminal tab.

- [00:22:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1338) Open a new terminal like this and type Python relauncher.py.

- [00:22:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1342) it will restart and when restarting now it is showing us the DreamBooth revision and

- [00:22:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1348) the SD Web UI revision like this.

- [00:22:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1350) I will just start training.

- [00:22:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1351) OK, it has been restarted.

- [00:22:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1353) Let's open the new URL.

- [00:22:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1355) OK, currently it is selected as 1.5 pruned emaonly CKPT and in the DreamBooth tab.

- [00:22:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1362) When we are going to generate a new training model, this is only available model.

- [00:22:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1368) However, 1.5 pruned CKPT is better than emaonly for training.

- [00:22:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1373) Therefore, I am going to download this CKPT file.

- [00:22:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1376) So how am I going to download it?

- [00:22:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1378) You see there is a download button in here.

- [00:23:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1381) I am right clicking and copying link address.

- [00:23:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1384) But before doing that, let's start a new terminal.

- [00:23:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1386) To do that, I am going to right click new plus icon here.

- [00:23:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1390) It will open a new launcher.

- [00:23:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1391) Hit terminal.

- [00:23:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1393) For fast download I am going to use RunPod CTL.

- [00:23:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1397) The RunPod CTL allows us to quickly download or upload files through our Pods to Pods or

- [00:23:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1404) from Windows to Pods and vice versa.

- [00:23:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1407) There are different versions.

- [00:23:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1409) I am going to install the Linux one on my RunPod.

- [00:23:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1412) So I am selecting it like this and copying it.

- [00:23:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1415) Then in my terminal I am pasting it with control V and I am hitting enter.

- [00:23:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1421) It will install the latest RunPod CTL.

- [00:23:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1424) After this command type RunPod CTL hit enter and you should get a message like this.

- [00:23:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1430) That means that it has been successfully installed or it was already installed.

- [00:23:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1435) Now how are we going to download this pruned CKPT file.

- [00:23:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1437) To download it first enter where you want to download, which is inside models inside

- [00:24:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1445) Stable Diffusion.

- [00:24:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1446) And in here where we want to download our model file, then I am going to click this

- [00:24:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1452) plus new launcher, launch a new terminal, and in this new terminal, this is the folder

- [00:24:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1458) where we are right now.

- [00:24:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1459) Now for downloading type wget and copy this URL paste it, hit enter and it will get downloaded

- [00:24:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1469) inside this folder.

- [00:24:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1470) By the way RunPod CTL is not necessary to download this file, but we will use it to

- [00:24:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1477) send data and get data from RunPod to our computer or from computer to RunPod or from

- [00:24:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1484) RunPod to RunPod.

- [00:24:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1485) This wget is a unix command and also alternative of it is available on windows as well.

- [00:24:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1492) So with this wget command, you can quickly download files into your RunPod folders like

- [00:24:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1499) this.

- [00:25:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1500) So you see currently it is downloading with 90 megabytes per second which is pretty decent

- [00:25:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1505) speed.

- [00:25:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1506) Okay the download has been completed and now the file is located in here.

- [00:25:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1510) Then what are we going to do is hit refresh button here and now I can see the 1.5 pruned

- [00:25:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1518) CKPT as well.

- [00:25:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1519) This is the way to download models from Hugging Face or wherever they are hosted.

- [00:25:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1524) If you can get direct link of it I will show examples.

- [00:25:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1528) Don't worry.

- [00:25:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1529) So now I will start DreamBooth training with the best possible settings.

- [00:25:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1533) First let's switch to 1.5 pruned CKPT.

- [00:25:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1536) This is not necessary but I'm not being sure that it is working as expected.

- [00:25:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1540) So I am making sure I have selected the target model in here as well.

- [00:25:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1545) So it has been loaded.

- [00:25:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1547) If it doesn't get loaded.

- [00:25:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1548) You should check the terminal window.

- [00:25:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1550) It is running on here.

- [00:25:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1552) It will show what is happening and you can also check the logs window in here.

- [00:25:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1557) It will show what is happening.

- [00:25:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1559) Okay now let's give a name to our training.

- [00:26:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1561) Let's say test SD 15 and check the source point.

- [00:26:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1565) So you see it is not seeing my latest checkpoint.

- [00:26:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1567) I am clicking refresh and I am checking the latest checkpoint.

- [00:26:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1571) This is very good to teach faces.

- [00:26:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1574) 1.5 pruned CKPT the 512x model is selected and hit create model.

- [00:26:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1580) I am not changing other parameters because optimal parameters are currently selected.

- [00:26:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1586) These are more like experimental things or things that for more professional people.

- [00:26:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1591) And in the terminal you see it is downloading the necessary files right now.

- [00:26:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1596) That is why it is waiting.

- [00:26:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1597) Okay it says that checkpoint successfully extracted.

- [00:26:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1601) So the model has been generated.

- [00:26:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1602) However as you can see, the interface is frozen.

- [00:26:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1606) Unfortunately this is a problem of Gradio.

- [00:26:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1609) So what are we going to do is we will refresh reload this page and now it says no interface

- [00:26:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1614) is running.

- [00:26:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1615) It looks like the interface has been terminated unexpectedly.

- [00:27:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1621) And what do we see in the terminal in here in the system logs.

- [00:27:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1625) Okay it doesn't show anything and it doesn't show anything in here either.

- [00:27:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1629) So let's check out our terminals.

- [00:27:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1631) Terminal one which is our main terminal and yes it is not showing.

- [00:27:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1637) So what can we do.

- [00:27:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1639) We need to restart.

- [00:27:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1640) To restart I will shut down all terminals and I will follow the same procedure.

- [00:27:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1644) Open terminal.

- [00:27:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1646) However currently we are inside model Stable Diffusion so it won't work.

- [00:27:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1649) We need to move to the parent folder.

- [00:27:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1652) To moving parent folder.

- [00:27:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1653) I am closing this terminal going to the folders tab.

- [00:27:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1657) I am navigating like this opening a new terminal.

- [00:27:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1660) Python relauncher.py and in my pod current GPU memory usage is only 11 percent.

- [00:27:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1666) So it is good, which means that no other terminal or instance of Web UI is running.

- [00:27:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1672) Also there are some warning messages here.

- [00:27:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1675) I think we could ignore them.

- [00:27:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1677) Okay it has started.

- [00:27:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1678) I am opening this URL.

- [00:28:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1680) I am going DreamBooth tab and now I will select my model because I already created it and

- [00:28:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1686) it is selected.

- [00:28:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1687) Let's set up the settings.

- [00:28:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1689) Okay I won't pick this checkbox because it is usually causing me problems.

- [00:28:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1694) How many steps per image.

- [00:28:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1695) I am going to use 12 images and I am going to train up to 200 epochs.

- [00:28:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1700) I will save model for every 10 epoch.

- [00:28:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1704) Be careful with this because each save will take about five gigabyte space and with every

- [00:28:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1712) 10 epoch, it is going to make 20 saves.

- [00:28:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1715) So it is going to take all of my hard drive.

- [00:28:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1718) So I think I will make this up to 180 or 160.

- [00:28:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1722) This should be sufficient.

- [00:28:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1724) If you don't know what are these parameters, how am I setting them.

- [00:28:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1728) I have an excellent DreamBooth tutorial on my YouTube channel.

- [00:28:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1733) You should watch this definitely to learn more about DreamBooth training.

- [00:28:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1737) Okay the batch size is one.

- [00:28:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1739) Gradient accumulation steps are one class batch size which will determine how many images

- [00:29:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1744) at a time that I want to be generated for classification images not related to training.

- [00:29:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1751) I will set this as 16 because this graphic card has huge VRAM, but if we get error, I

- [00:29:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1757) will reduce it.

- [00:29:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1758) Set gradients to none when zeroing.

- [00:29:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1760) Okay correct.

- [00:29:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1761) I am going to use half learning rate.

- [00:29:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1764) I am going to use sanity prompt as photo of ohwx man by Tomer Hanuka.

- [00:29:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1770) I will explain what are these for.

- [00:29:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1773) Actually I am explaining what are these for in this tutorial with details.

- [00:29:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1777) This is for checking the over trained or not.

- [00:29:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1781) And in here I am going to use EMA.

- [00:29:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1783) This will improve my training success rate and I have 24 gigabyte VRAM.

- [00:29:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1788) I will use 8 bit adam.

- [00:29:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1790) I am going to use mixed precision and I am going to use fp16 because this bf16 is not

- [00:29:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1797) supported by all graphic cards.

- [00:29:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1798) It is supported by RTX 2000 series or 3000 series.

- [00:30:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1803) I am not sure about this card as well.

- [00:30:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1805) So fp16 is our most safe option for every cards.

- [00:30:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1809) I am not going to use xformers.

- [00:30:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1811) This is important because the current xformers is not supporting the DreamBooth training

- [00:30:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1817) or Textual Inversion training.

- [00:30:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1818) It is you see, xformers 0016.

- [00:30:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1821) I think it will become compatible with xformers 0017 when it is officially released.

- [00:30:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1828) Currently nightly version is supporting as well as far as I know.

- [00:30:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1832) Cache latents.

- [00:30:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1833) Yes it will improve speed.

- [00:30:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1835) Train UNET.

- [00:30:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1836) Okay these are the optimal settings actually, so no need to change them.

- [00:30:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1840) And in here concepts.

- [00:30:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1841) Okay first we need to upload our training data set.

- [00:30:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1844) To do that go to the Stable Diffusion web ui folder or workspace.

- [00:30:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1848) Doesn't matter I will upload them to workspace.

- [00:30:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1851) In here create new folder training data set.

- [00:30:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1855) I have named the folder like this.

- [00:30:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1857) Enter inside folder and click upload files.

- [00:31:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1860) Select the files from your computer.

- [00:31:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1863) Since I don't have many files currently I am going to use this method and you see I

- [00:31:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1868) have only nine images which are pretty close shots.

- [00:31:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1872) No same background.

- [00:31:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1873) No same clothes as you can see.

- [00:31:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1876) I am all explaining what is a good training data set in this video and they are getting

- [00:31:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1881) uploaded.

- [00:31:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1882) We could also use runpodctl.

- [00:31:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1884) However, since there isn't many files, I am using this methodology for this task and our

- [00:31:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1891) training data set is ready.

- [00:31:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1893) Okay now we need to give the path of it.

- [00:31:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1895) To give the path of it.

- [00:31:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1896) Go back to the workspace like this: right click, copy path, paste it like this and put

- [00:31:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1902) a backslash to the beginning of it and where we want regularization images to be generated.

- [00:31:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1908) I am copy pasting like this and I will type classification images.

- [00:31:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1913) Okay filewords.

- [00:31:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1915) For training faces I am not using filewords.

- [00:31:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1917) It is more likely needed to fine-tune your model with lots of tokens and lots of good

- [00:32:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1925) images.

- [00:32:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1926) If you wonder how filewords are working in this short video.

- [00:32:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1929) I am explaining how file words are actually working.

- [00:32:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1933) So I'm just skipping file words and I am going to prompts.

- [00:32:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1937) So our instance prompt will be ohwx man.

- [00:32:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1940) Ohwx is our rare token and man is our class.

- [00:32:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1944) Class prompt will be photo of man since I am teaching a face of a man.

- [00:32:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1949) Sample prompt will be simply photo of ohwx man.

- [00:32:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1953) I am not going to set negative prompt or other things.

- [00:32:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1956) How many classification regularization images we want for per training image.

- [00:32:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1962) I have nine training images and I want 50 for per image.

- [00:32:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1966) This is actually a debated topic, how many is good is not precise.

- [00:32:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1972) In the official DreamBooth paper, the authors have used 200 so you can also try with 100

- [00:32:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1978) like this as well.

- [00:32:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1979) Okay then go to the saving tab, generate a ckpt file when saving during training.

- [00:33:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1984) So we will be able to generate checkpoints for every 10 epochs and then we will be able

- [00:33:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1991) to compare them to see which one of the checkpoint is performing best, which one of the checkpoint

- [00:33:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=1999) has learned our subject best and with this way you can avoid over training.

- [00:33:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2006) And once you are ready, click save settings and hit train.

- [00:33:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2010) First it will start with generating class images.

- [00:33:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2012) In my pod I will see GPU utilization and memory usage.

- [00:33:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2015) Okay it says that exception training model no executable batch size found reached zero.

- [00:33:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2022) Why we got this error because we did set the classification images batch size pretty big.

- [00:33:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2030) If you make it like let's say six and try again.

- [00:33:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2034) And now I am seeing that it is generating six images at a time.

- [00:33:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2039) The it is pretty low actually only 12 because we need to multiply this with six and we are

- [00:34:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2047) seeing the images are being generated.

- [00:34:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2049) They will be saved in workspace, classification images directory like this: if you have previously

- [00:34:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2058) generated images on your computer, then you can alternatively upload them.

- [00:34:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2062) For uploading them I will install runpodctl on my windows.

- [00:34:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2068) To do that I am going to run this command on my windows powershell.

- [00:34:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2073) Type powershell, right click and hit enter.

- [00:34:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2077) Okay the installation has been completed, the runpodctl is now available on my command

- [00:34:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2082) prompt: let's see, runpodctl and now I am seeing it.

- [00:34:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2088) So I have previously generated 2400 images on my hard drive.

- [00:34:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2094) I am going to share this with runpodctl to download them in RunPod.

- [00:34:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2099) Alternatively, you can use upload methodology as well.

- [00:35:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2103) It also works, but for bigger files, runpodctl is better.

- [00:35:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2108) So for sharing the folder type runpodctl send and the folder path like this.

- [00:35:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2116) Getting the folder path easier, copy the folder path from here, paste it into the notepad

- [00:35:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2122) like this.

- [00:35:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2123) Put quotation mark to the beginning and end and type in your cmd.

- [00:35:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2129) I will show from beginning once again.

- [00:35:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2132) Open cmd type runpodctl send and paste the path like this and it will prepare like it.

- [00:35:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2139) It says that photo of man zip already exists because in another cmd window we used that.

- [00:35:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2146) So I need to delete this file.

- [00:35:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2149) Okay, this zip file is generated inside local disk c users and my username directory.

- [00:35:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2156) I am just going to delete it and I will run the command once again.

- [00:36:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2160) It will quickly prepare all of the files and now share link is generated I am copying this,

- [00:36:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2167) selecting it ctrl c or select it right click from here and copy, then go back to your Jupyter

- [00:36:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2174) Lab where your RunPod is running and in here I will make a new folder like this: ready

- [00:36:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2181) class.

- [00:36:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2182) I will enter inside ready class folder, then I will open a new terminal like this and I

- [00:36:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2188) will paste the command.

- [00:36:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2191) You see runpodctl receive the URL it has generated, hit enter.

- [00:36:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2196) It will connect to my computer and it will start downloading all of the files very quickly.

- [00:36:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2201) So this is how you can upload files from your computer to the remote RunPod.

- [00:36:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2208) The same thing applies to the RunPod to RunPod, so this is all vice versa.

- [00:36:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2213) RunPod to computer, RunPod to RunPod computer to RunPod.

- [00:36:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2217) You can send and receive files like this.

- [00:37:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2220) This is of course totally depends on my upload speed.

- [00:37:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2223) So when I open my task manager I see that it is using all of my available upload speed

- [00:37:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2229) like this.

- [00:37:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2230) This is pretty useful and convenient.

- [00:37:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2233) Instead of generating new classification images each time which uses your GPU time and consumes

- [00:37:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2240) your credits, you can prepare them on your computer and then quickly upload them to your

- [00:37:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2245) RunPod.

- [00:37:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2247) You can also upload them to any hosting, website, or other places that has better upload speed

- [00:37:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2253) and download them with the wget command as I have shown to download ckpt file.

- [00:37:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2261) RunPodCTL is extremely useful to upload and download files as you can see.

- [00:37:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2268) Okay 2400 photo of man.

- [00:37:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2271) The classification regularization images upload have been completed.

- [00:37:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2275) Now I see that it is uploaded as a zip here.

- [00:37:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2279) I need to extract them like oh.

- [00:38:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2281) It has automatically extracted as you can see after refresh.

- [00:38:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2285) Now they are here.

- [00:38:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2287) So what am I going to do is I will cancel training and I will give this folder.

- [00:38:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2293) So I will just skip image generation.

- [00:38:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2296) So it has been cancelled.

- [00:38:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2297) Let's give the new folder.

- [00:38:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2300) In concepts type here new folder name and click save settings and okay looks like the

- [00:38:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2307) train button is not appeared.

- [00:38:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2309) So what we need to do is we need to refresh reload.

- [00:38:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2314) Okay reloaded.

- [00:38:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2315) Go to the DreamBooth select the model, hit load settings, verify the settings are properly

- [00:38:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2321) loaded.

- [00:38:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2322) Okay, this is not being saved so you should uncheck it.

- [00:38:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2325) Okay, all settings are looking good and click train.

- [00:38:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2329) Now it won't generate any new classification regularization images because we already provided.

- [00:38:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2334) We can see that in the terminal window in here.

- [00:38:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2338) So you see it is processing the uploaded photo of man images.

- [00:39:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2342) Then it is going to cache the classification images with caching latents.

- [00:39:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2347) Okay, the training has started.

- [00:39:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2349) It has a pretty good speed as you can see.

- [00:39:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2353) It is supposed to do 180 epochs in less than 15 minutes.

- [00:39:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2357) However, this will take a little bit more time because it will generate ckpt during

- [00:39:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2362) the training.

- [00:39:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2363) We can also watch the training here.

- [00:39:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2365) However, you may get disconnected from gradio interface.

- [00:39:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2370) You can just watch the command line interface from here and know the status of the training

- [00:39:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2375) if that happens.

- [00:39:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2377) Okay, 10 epochs have been completed so it started generating the initial images as you

- [00:39:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2382) can see.

- [00:39:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2383) It also generated a checkpoint.

- [00:39:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2385) Where can we see the checkpoint?

- [00:39:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2387) Go to the workspace, go to the Stable Diffusion Web UI, go to the models folder, go to the

- [00:39:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2392) Stable Diffusion folder, and in here you will see our training name, go inside that folder

- [00:39:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2398) and now we can see the checkpoints being generated.

- [00:40:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2401) Then we will test each one of them with x/y plot and see how they are performing.

- [00:40:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2407) So if you want to see the generated samples during training, go to the models folder,

- [00:40:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2412) go to the DreamBooth folder, go to your training named folder, and in here you will see samples.

- [00:40:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2418) So these are the samples being generated during training and when you click the txt file,

- [00:40:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2424) you will see which prompt was used to generate this image.

- [00:40:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2427) When you double click the image, it will open image like this.

- [00:40:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2430) So far it is not like me at the moment.

- [00:40:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2434) When you go to the My Pods, you can see the GPU utilization and GPU memory being used.

- [00:40:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2439) The GPU memory is almost full because we are using EMA and we are not using xformers.

- [00:40:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2445) Because in the settings tab, we checked to use EMA and in the memory attention we didn't

- [00:40:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2449) use xformers.

- [00:40:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2450) And do, and these two are heavily increasing the memory usage.

- [00:40:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2455) Also, we didn't check the gradient checkpointing.

- [00:40:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2458) This also reduces the VRAM usage.

- [00:41:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2461) However, if you have sufficient amount of VRAM you shouldn't check this as well.

- [00:41:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2465) Okay, even after 130 epochs, it is still not learning even though it shows a good loss

- [00:41:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2471) rate.

- [00:41:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2472) That means that there is a bug currently with DreamBooth extension.

- [00:41:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2476) Therefore, I have cancelled the training.

- [00:41:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2478) Now I will delete the folder to open a space.

- [00:41:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2482) Right click folder.

- [00:41:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2483) Delete it.

- [00:41:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2484) It says that it is not empty so you can't delete it.

- [00:41:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2487) However, we can.

- [00:41:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2488) Now I will show you how to do it.

- [00:41:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2490) Click new, open a new terminal type rm minus r and the directory name test sd15.

- [00:41:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2499) It will iteratively delete all of the files and the folder.

- [00:41:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2502) After we refresh it is gone.

- [00:41:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2504) Now I will figure out the problem and show you the working settings and setup.

- [00:41:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2510) So I have figured out the problem and the problem was exactly as I have guessed it.

- [00:41:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2515) It was using xformers even though we didn't select use xformers.

- [00:42:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2522) In the settings, we had used memory attention default.

- [00:42:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2526) However, it was still using xformers.

- [00:42:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2529) Wo what did I do to fix this problem?

- [00:42:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2532) It is simple.

- [00:42:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2533) I have opened the Web UI user dot sh file and I have removed the dash dash xformers

- [00:42:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2541) from command line arguments.

- [00:42:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2542) I have restarted my Web UI.

- [00:42:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2545) Then I have composed a new training with the exactly same parameters and it did work very

- [00:42:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2551) well.

- [00:42:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2552) The training has been completed, so let's download the samples and check them out on

- [00:42:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2557) our computer.

- [00:42:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2558) To download the folder of samples, I will use runpodctl command.

- [00:42:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2562) So what I need to do is I will enter the samples folders.

- [00:42:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2567) So to do that, go to the models folder, go to the DreamBooth, go to the training folder

- [00:42:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2572) name so the samples are located here.

- [00:42:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2575) Open a new command terminal, write runpodctl send samples which is the folder name and

- [00:43:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2583) it will zip the samples folder and generate a receive command.

- [00:43:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2587) Copy it with ctrl c.

- [00:43:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2589) First, I need to add the path of runpodctl into my environment.

- [00:43:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2595) So the currently runpodctl exe is located inside my user folder.

- [00:43:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2601) Go to the users and your username and I will copy the runpot, yaml and runpodctl exe file.

- [00:43:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2607) Copy them.

- [00:43:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2608) Then I will make a new folder in my c drive as runpot exe.

- [00:43:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2613) Paste them here.

- [00:43:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2614) Then in the search bar search for environment, it will open, edit environment variables like

- [00:43:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2621) here and in here.

- [00:43:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2622) I am going to add a path variable for system variables, so go to the path, click edit and

- [00:43:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2629) in here click browse, select the folder where you have copy pasted which is inside c drive.

- [00:43:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2636) Runpod exe click ok, now the runpod exe is registered in my path.

- [00:44:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2642) Click ok, click ok click ok and now runpod exe should be available to call from everywhere.

- [00:44:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2649) Where I want to download.

- [00:44:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2650) I want to download the files inside my pictures, inside test samples.

- [00:44:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2656) I type cmd here.

- [00:44:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2658) So currently this is where I am.

- [00:44:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2660) Now I will copy and paste this command into my cmd window.

- [00:44:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2665) And yes, it is running as expected and the files are being copied into my folder.

- [00:44:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2673) And then they are automatically extracted with the folder name.

- [00:44:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2676) So in here we are able to see the generated sample images.

- [00:44:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2680) I can say that after 800 steps it started to resemble me and we have totally trained

- [00:44:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2688) it for 160 epochs, 3200 steps, we can see the examples here.

- [00:44:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2695) Okay, this is pretty much like me, so with good prompting I think we can get good results.

- [00:45:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2703) So let's try all of the checkpoints to see which one is working best.

- [00:45:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2707) How are we going to do that?

- [00:45:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2709) We are going to do that with text to image tab and in here we are going to use x/y/z

- [00:45:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2714) plot.

- [00:45:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2715) Okay, it didn't appear.

- [00:45:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2716) Let's refresh.

- [00:45:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2717) Oh, looks like our instance is closed so I will restart.

- [00:45:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2722) So before restarting make sure that you have closed all of the running terminals and I

- [00:45:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2727) will also close all of the open tabs.

- [00:45:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2729) Okay, all of the tabs and terminals are closed.

- [00:45:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2733) Okay, Web UI is restarted.

- [00:45:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2735) Let's open it.

- [00:45:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2736) Okay, now we can also see the checkpoints in here so you can test particularly one of

- [00:45:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2743) them.

- [00:45:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2744) But I am going to do xyz plot test.

- [00:45:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2747) But before that, let's decide our testing prompt.

- [00:45:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2751) So I am going to make my tests on 2200 step checkpoint.

- [00:45:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2758) I am going to select it from here.

- [00:46:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2760) First, let's see the raw prompt.

- [00:46:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2762) Ohwx man.

- [00:46:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2763) Okay, this is the raw prompt and it looks pretty decent.

- [00:46:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2768) This is the training data set you see.

- [00:46:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2771) It looks pretty decent, but it looks like have some memorization.

- [00:46:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2775) Actually, not exactly memorization.

- [00:46:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2778) The clothe is similar but not exactly same.

- [00:46:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2780) Okay, while doing testing, my Web UI has been killed.

- [00:46:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2784) So I have checked the terminal to see the message.

- [00:46:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2788) So you should be careful if some error happens.

- [00:46:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2791) Make sure to check the terminal to see what is happening in the behind the scenes and

- [00:46:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2796) now it is not able to restart.

- [00:46:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2799) Therefore, I will close all of the terminals and start with a different port.

- [00:46:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2806) To do that, you need to go to the terminals tab, shut down all and change the webui user.sh

- [00:46:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2813) file: change the port from here.

- [00:46:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2816) Save and restart.

- [00:46:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2817) Okay, I got a simple prompt like this: photo of ohwx man 1.2 emphasis: you can learn emphasis

- [00:47:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2825) from wiki page of Automatic1111.

- [00:47:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2829) Just pause the video and read here if you don't know.

- [00:47:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2832) And digital painting, artstation, masterpiece.

- [00:47:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2834) I don't have any negative prompts.

- [00:47:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2837) The picture is not exactly like me.

- [00:47:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2839) So now we are ready to do test and see if model is trained enough.

- [00:47:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2843) If it is not trained enough, then go to the DreamBooth tab, select the model load settings

- [00:47:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2849) and continue training.

- [00:47:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2851) It will continue training for the number of steps that you have defined in here.

- [00:47:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2856) Okay, I started continue training and it will start from this model revision which means

- [00:47:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2862) it will start from 3200 steps and it will continue to do training for number of epochs

- [00:47:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2870) that we have defined here.

- [00:47:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2872) However, my Gradio is crashed once again and I am able to see the continuing training from

- [00:47:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2879) here.

- [00:48:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2880) Now let's test the current checkpoints and see whether they are trained enough or not

- [00:48:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2885) and decide upon that to continue training or not.

- [00:48:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2888) However, since my Gradio is crashed, I have to restart the terminal because there is no

- [00:48:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2894) way to cancel the training right now.

- [00:48:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2896) Let's also have yes no way.

- [00:48:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2898) Okay, I did a restart.

- [00:48:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2900) So how are we going to test different checkpoints?

- [00:48:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2904) Prompt emphasis, and CFG values.

- [00:48:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2906) Go to the bottom, pick x/y/z plot and in here you see there are different type of parameters.

- [00:48:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2913) So first parameter will be checkpoint name.

- [00:48:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2916) When you click this icon it will paste the available checkpoints.

- [00:48:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2920) I am going to start picking from 1600 steps which means 80 epochs for me.

- [00:48:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2926) It depends on the your training dataset size and I will test the remaining as well like

- [00:48:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2932) this.

- [00:48:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2933) It is also displaying the calculated hash value.

- [00:48:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2936) Okay, as a second thing, I am going to test prompt strength.

- [00:49:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2940) To do that, I am going to use prompt s/r.

- [00:49:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2942) So I am going to give this a any keyword like prsr.

- [00:49:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2947) So the first value here will be prsr.

- [00:49:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2950) Then I will type the prompt strengths like 1.1, 1.2, 1.3 let's also try 1.0, 1.4 1.5,

- [00:49:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2960) 1.6 and 1.7 okay, as a third comparison thing, I am going to test CFG value.

- [00:49:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2968) So for CFG values, I am going to test seven, seven point five, eight, eight point five,

- [00:49:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2974) nine, nine point five and ten.

- [00:49:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2977) If you keep minus one for seeds then you won't be able to compare them very well.

- [00:49:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2982) So do not check this checkbox so it will use same seed for all of the comparisons and then

- [00:49:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2988) when you click generate it will process all of them.

- [00:49:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2992) You can see the process in the command line interface.

- [00:49:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=2996) Now meanwhile this is running I will start my 2.1 version RunPod as well.

- [00:50:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3002) Okay, it says that there is no available GPU for this RunPod right now so I can start it

- [00:50:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3009) without a GPU and transfer my files with runpodctl.

- [00:50:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3014) However, I do not have any files on it so I will just delete it because I didn't even

- [00:50:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3020) start it yet and I will start a new one.

- [00:50:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3022) Okay, I am going to use this one.

- [00:50:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3026) Select the template from here.

- [00:50:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3027) I will pick Stable Diffusion 2.1 version: I will start with 100 gigabytes, deploy my

- [00:50:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3034) pods, it is being initialized and my other Pod is currently working with this kind of

- [00:50:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3040) i/t.

- [00:50:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3041) By the way, xformers is still not enabled right now, so if you enable it, this will

- [00:50:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3046) become even faster.

- [00:50:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3047) But for training, make sure that you have disabled it.

- [00:50:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3050) And images are being generated in here.

- [00:50:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3052) We will download all of them and check all of them later.

- [00:50:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3056) Okay, 2.1 version is being generated and getting ready.

- [00:51:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3061) Okay, 2.1 is now ready.

- [00:51:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3063) Just click connect.

- [00:51:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3065) Connect to the Jupyter.

- [00:51:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3066) Okay, it says that it cannot connect yet so it is probably still not ready.

- [00:51:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3070) Let's wait.

- [00:51:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3071) Try again.

- [00:51:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3073) Okay, let's refresh the page.

- [00:51:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3074) Maybe the URL is incorrect.

- [00:51:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3077) Yes, after the refresh I think it is fixed or it is just started.

- [00:51:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3081) So just be patient a little bit.

- [00:51:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3083) It is getting loaded and yes, 2.1 version is started.

- [00:51:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3087) It is exactly same as the previous one.

- [00:51:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3091) We are editing the command line arguments here.

- [00:51:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3093) I will add dash dash share so I can use it as I want.

- [00:51:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3097) And I will also remove xformers because it is preventing training.

- [00:51:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3102) I will set the port as 3001.

- [00:51:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3105) Save it.

- [00:51:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3106) Then there is no open terminals.

- [00:51:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3109) Let's open a new launcher terminal python relauncher.py Our comparison on SD 1.5 trained

- [00:51:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3117) models are continuing.

- [00:51:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3118) Okay, 2.1 RunPod is ready.

- [00:52:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3122) Let's start it.

- [00:52:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3123) Okay, currently selected model is 2.1 version.

- [00:52:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3126) Let's test it.

- [00:52:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3127) Okay, I have written my prompt the the output resolution is 768 and 768.

- [00:52:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3134) Looks like we got a problem.

- [00:52:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3137) It says that a tensor with all NaNs was produced in Unet.

- [00:52:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3141) So we need to add no half command to the command line because with this graphic card, otherwise

- [00:52:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3148) it won't work.

- [00:52:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3149) So let's go back to the RunPod.

- [00:52:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3151) Open the webui dash user dash sh.

- [00:52:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3154) So for SD 2.1 version, make sure that you are using these command line arguments.

- [00:52:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3161) These may be necessary for some of the custom models as well.

- [00:52:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3164) So check the messages that you see in here.

- [00:52:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3167) This message should be available also in the terminal window.

- [00:52:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3171) Yes, you can also see the error in here as well.

- [00:52:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3175) So I will close the terminal and restart it.

- [00:52:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3178) Currently I am spending 0.669 dollars per hour.

- [00:53:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3183) My mode of the RunPods are running right now.

- [00:53:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3186) Okay, it looks like I have mistyped the dash dash precision.

- [00:53:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3192) So it says that argument precision expected one argument.

- [00:53:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3195) I will just fix it quickly.

- [00:53:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3197) To fix it, I am opening the file and I am setting dash dash precision as full, saving

- [00:53:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3204) it and restarting.

- [00:53:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3206) Make sure that you only have one active running terminal, otherwise other terminals will also

- [00:53:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3212) consume your VRAM memory.

- [00:53:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3215) You can also see the VRAM memory usage in your My Pods tab and you can see the logs

- [00:53:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3221) from here.

- [00:53:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3222) This is really important to debug the errors.

- [00:53:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3224) Okay, it is started with these command line arguments exactly like this.

- [00:53:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3229) Let's open the Gradio window.

- [00:53:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3231) Okay, let's hit generate with our written prompt and it is getting generated.

- [00:53:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3237) And we got our tank image.

- [00:54:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3240) Now I will install the extension same exactly as I have did.

- [00:54:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3244) Okay, 2.1 version is ready with DreamBooth now.

- [00:54:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3247) Go to the DreamBooth tab, make a new model I will name as test select the source checkpoint.

- [00:54:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3253) Uncheck 512 model.

- [00:54:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3254) Hit create.

- [00:54:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3255) When the first time you click hit create it is downloading the necessary files same as

- [00:54:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3259) before because this is a new RunPod so they are not connected.

- [00:54:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3263) This is a fresh installation and checkpoint successfully extracted so it is ready.

- [00:54:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3269) Okay, we didn't get any error so we can continue.

- [00:54:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3272) So for 2.1 version usually you need more epochs so I will set this as 300.

- [00:54:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3278) However, now it will also use more space.

- [00:54:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3282) Due to more epochs so I need to reduce save model frequency.

- [00:54:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3287) I think I will save it for every 20 epochs.

- [00:54:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3290) Batch size one, gradient accumulation one, class batch size will be four.

- [00:54:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3295) I am not going to set gradient checkpointing.

- [00:54:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3298) You can also leave it as default learning rate.

- [00:55:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3301) This would make it learn faster, however, it may also not learn very well or it may

- [00:55:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3307) get over trained quickly.

- [00:55:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3309) So I will make this as one.

- [00:55:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3310) But you can also leave it as default.

- [00:55:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3313) So the other things are same.

- [00:55:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3314) Now with 2.1 version, I don't know if 24 gigabytes will be enough without xformers when we use

- [00:55:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3320) EMA so I will test it.

- [00:55:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3323) Okay, it says let's make it like this.

- [00:55:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3326) Actually, we should click performance wizard so it will set the optimal ones for us.

- [00:55:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3332) Okay, okay, I am leaving the settings like this.

- [00:55:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3335) Let's also set the memory attention as default and let's see if it will work.

- [00:55:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3339) By the way, we also need to re-upload our training images and these training images

- [00:55:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3344) have to be 768 pixels because this model is 768 pixels model.

- [00:55:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3352) So to upload them I am following just the same things.

- [00:55:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3356) Here my 768 pixel images.

- [00:55:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3359) I'm just going to use drag and drop but you can use runpodctl as well as just I have displayed.

- [00:56:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3366) Okay they are ready.

- [00:56:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3367) So I am right clicking copy path, paste it, adding a backslash to the beginning.

- [00:56:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3372) Copy this and let's say class 786.

- [00:56:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3377) All other settings are same.

- [00:56:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3379) Ohwx man, photo of man, photo of ohwx man and I will use only 12 images because I want

- [00:56:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3388) training to start quickly but you should use bigger number.

- [00:56:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3392) I am checking generate ckpt during the checkpoints, click save settings, and hit train.

- [00:56:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3399) So it will start with generating class images.

- [00:56:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3402) So for each image we are generating 12.

- [00:56:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3404) Okay, we got an error.

- [00:56:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3406) Therefore, we need to decrease the class batch size.

- [00:56:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3409) Let's hit train again.

- [00:56:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3410) Okay, looks like our Gradio is killed, therefore it has to be restarted.

- [00:56:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3415) You may get these errors.

- [00:56:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3416) Okay, during restart, it is throwing error because port is still being in used.

- [00:57:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3421) So I am going to close the terminal, change the port and restart myself manually.

- [00:57:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3427) Okay, restart has been completed.

- [00:57:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3429) Let's go to the DreamBooth, select model load settings, just quickly verify settings.

- [00:57:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3434) I am unchecking this because it is usually problematic.

- [00:57:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3437) Class batch size is two and let's hit train.

- [00:57:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3441) You can also generate classification images from text to image directly yourself.

- [00:57:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3445) Cut the generated images and put them into a new folder.

- [00:57:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3448) Okay, we got error once again.

- [00:57:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3450) This is a memory error actually.

- [00:57:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3452) When we check the command line interface, we can see the memory error.

- [00:57:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3457) So looks like our only option is class batch size one.

- [00:57:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3460) Let's click train.

- [00:57:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3461) Okay, it is working.

- [00:57:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3462) However, this will be very slow.

- [00:57:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3464) So what am I going to do is?

- [00:57:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3465) I will enable xformers, manually generate from text to image and use them as classification

- [00:57:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3471) images which will save our time significantly.

- [00:57:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3475) So follow me how am I doing.

- [00:57:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3477) First, I will just terminate the terminal from here.

- [00:58:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3480) I will add dash dash xformers, change the port and restart python relauncher.py I would

- [00:58:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3488) also clear text to images tab so you can directly use it so I will just rename it.

- [00:58:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3494) It will generate a new folder for me and new app is started with xformers.

- [00:58:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3499) Let's open it!

- [00:58:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3500) So our class prompt is photo of man.

- [00:58:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3503) I am typing photo of man.

- [00:58:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3505) I am going to set the sampling steps as 30 which is a decent enough and I am leaving

- [00:58:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3510) all other options are same and I will use batch size as eight and how many images total

- [00:58:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3517) do you need?

- [00:58:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3518) Let's say for per training image 50 images since I have nine images, I am going to generate

- [00:58:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3524) 480 images.

- [00:58:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3526) Therefore I need to set this minimum 57 and then hit generate and let's see if we will

- [00:58:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3533) get out of memory error.

- [00:58:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3535) And you see from text to image tab we are not getting out of memory error even when

- [00:59:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3541) the batch size is eight.

- [00:59:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3543) So it will very quickly generate all of these images for us much faster than using the classification

- [00:59:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3551) images that is being generated in the DreamBooth.

- [00:59:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3555) If you wonder why it is generating images like this or why we are using these kind of

- [00:59:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3559) images, in this video I am explaining all of them so we are keeping the underlying contextual

- [00:59:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3565) data of the model.

- [00:59:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3567) You could also use more beautiful images in your classification training data set.

- [00:59:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3572) However, it would break your model conceptual meaning so your model would become more biased

- [00:59:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3580) to the images that you have used.

- [00:59:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3582) Also, your face would be biased to the images that you use.

- [00:59:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3586) With this methodology, we are using the underlying contextual knowledge of the model and we are

- [00:59:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3593) trying to keep it as much as possible.

- [00:59:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3595) However, this is up to you.

- [00:59:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3598) So if you use all handsome images, all full colored, professional real images, then your

- [01:00:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3606) model would become more biased to them.

- [01:00:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3608) This is how custom models are usually made.

- [01:00:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3612) They are being cooked to those kind of images.

- [01:00:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3615) So whatever you type, you are getting beautiful images because all of the other underlying

- [01:00:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3620) conceptual data of the model is lost during the training.

- [01:00:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3625) Actually, according to the ControlNet developer, SD 2.1 version is inferior to the SD 1.5 due

- [01:00:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3635) to the used CLIP.

- [01:00:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3636) You can read this with pausing the video right now.

- [01:00:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3639) Okay, looks like our 1.5 version experiment has ended.

- [01:00:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3644) Let's go to the outputs and in here there are text to image grids and you see there

- [01:00:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3651) is a grid file.

- [01:00:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3653) 35 megabytes.

- [01:00:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3654) Let's open it.

- [01:00:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3655) Actually I will download this and there is also 228 megabytes.

- [01:01:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3660) So for downloading let's use the runpodctl.

- [01:01:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3664) I am going to open a new command line in here.

- [01:01:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3667) Runpodctl, send text to image grids.

- [01:01:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3671) Hit enter and it will generate download link for us.

- [01:01:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3675) Go to the folder where you want to download.

- [01:01:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3677) I will download inside in here, type cmd, copy paste the link like this.

- [01:01:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3682) So it is going to download 265 megabyte grid output.

- [01:01:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3687) This is much faster than downloading from the Jupyter notebook.

- [01:01:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3691) Okay, the grid images are downloaded.

- [01:01:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3694) And in here this is the newest grid image that is generated.

- [01:01:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3699) It is over 200 megabytes, it is over 35 000 pixels and now we are able to compare different

- [01:01:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3707) checkpoints with different prompt emphasis and with different CFG scale.

- [01:01:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3713) So this is for CFG scale 7.

- [01:01:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3715) These are the checkpoints and these are the prompt emphasis.

- [01:02:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3720) Let's find the best one that we like and that is similar to us.

- [01:02:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3725) You see these faces are not like me but in here I am seeing faces like me.

- [01:02:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3732) So with prompt strength 1.4 in these checkpoints I am starting to get similar face like to

- [01:02:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3739) me.

- [01:02:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3740) I think this one is very similar to me.

- [01:02:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3742) So with prompt strength 1.4 for CFG scale 7 and for checkpoint 3000 steps.

- [01:02:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3750) Yeah I like it.

- [01:02:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3751) So you should also compare for yourself.

- [01:02:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3754) And after prompt strength 1.4 the image becomes very very bad.

- [01:02:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3759) So let's also look at the other CFG scales and checkpoints.

- [01:02:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3764) Okay now I will show you slowly what is happening from CFG scale 10 to 7 and this is the prompt

- [01:02:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3771) strength 1.4.

- [01:02:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3773) This is how the images are changing.

- [01:02:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3775) This would of course depend on your training data set, how it is trained and I can see

- [01:03:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3781) that they are not very good at all because we also didn't use any negative prompts.

- [01:03:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3788) Our aim here is finding the sweet spot of prompt strength and the checkpoint and the

- [01:03:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3796) CFG possibly.

- [01:03:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3798) Okay I think this model is still not trained enough.

- [01:03:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3802) Because with only 1.4 strength and in the 3200 steps, it is providing the best.

- [01:03:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3811) So therefore I will train this model even further with more steps and then do another

- [01:03:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3818) experiment.

- [01:03:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3819) However, currently we could use 1.4 strength with checkpoint 3200.

- [01:03:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3825) I suggest you to test no half and precision full training for SD 1.5 version as well without

- [01:03:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3834) xformers and compare whether it is learning better or not.

- [01:04:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3840) Because of the used graphic card this could be making a difference and you can test use

- [01:04:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3846) 8bit adam or not.

- [01:04:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3848) You can test mixed precision no versus fp16 and bf16 so these all things could improve

- [01:04:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3856) your training success rate.

- [01:04:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3858) You should experiment with them and currently I do not have time to test all of them.

- [01:04:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3864) I am showing the some of the settings that are widely used but you should also experiment

- [01:04:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3870) with them.

- [01:04:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3871) Like options like this or like this or like this or like this.

- [01:04:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3876) Now I will show you how to download custom models from CivitAI .com and use them in your

- [01:04:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3883) RunPod io.

- [01:04:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3884) So I am going to show example of Protogen x3.4.

- [01:04:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3889) Right click download latest copy link, go to your RunPod io interface, Jupyter interface

- [01:04:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3897) and in here go to the folder where the model files are downloaded.

- [01:05:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3902) So in this folder which is model Stable Diffusion where you are supposed to put your model files,

- [01:05:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3909) open a new launcher, open launcher, type wget, paste the link and hit enter and it will start

- [01:05:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3916) downloading the model file.

- [01:05:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3918) So you see 5.6 gigabytes and you see there are no more space left on my hard drive.

- [01:05:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3926) What I need to do is I will delete the some of the models.

- [01:05:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3931) So I am going to delete some of the training checkpoints.

- [01:05:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3934) They are located inside models, inside Stable Diffusion, inside my training folder and in

- [01:05:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3941) here I am going to remove delete some of them.

- [01:05:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3943) You can also do a directory delete right, click and delete.

- [01:05:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3947) You can also select them and hit delete button on your keyboard.

- [01:05:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3951) Okay, I think we got now sufficient space so I will just rerun the prompt.

- [01:05:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3956) So to open back the latest executed command I just hit up arrow and hit enter and now

- [01:06:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3962) it will start downloading.

- [01:06:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3963) Currently it will be downloaded in this folder where we had opened this terminal.

- [01:06:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3970) Let's go back to there.

- [01:06:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3971) Models Stable Diffusion and now this file is being downloaded with the name of 4048.

- [01:06:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3979) Then I will rename it.

- [01:06:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3981) Meanwhile, 2.1 version classification regularization images are still being generated.

- [01:06:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3986) We can see the process in the terminal of it.

- [01:06:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3990) You see it has generated over 160 images so far.

- [01:06:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3994) Okay, it is downloading the custom model file with 50 megabytes per second.

- [01:06:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=3999) You can also upload those files from your computer or you can download from Hugging

- [01:06:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4005) Face as I have shown you already.

- [01:06:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4008) So this is how you can download files fast on your Pod.

- [01:06:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4012) Okay, the file has been downloaded and saved as 4048.

- [01:06:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4017) I will rename right click, rename and let's say protogen x34 it is renamed.

- [01:07:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4025) Then let's go back to our Stable Diffusion interface.

- [01:07:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4028) Click, refresh folder.

- [01:07:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4030) It is not appearing because the model file extension is not correct.

- [01:07:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4034) Right Click.

- [01:07:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4035) And when renaming, add dot ckpt to end of it like this and then refresh again.

- [01:07:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4043) Okay, now we see the model here.

- [01:07:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4045) Let's test it.

- [01:07:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4046) Okay, it didn't load even though I have selected.

- [01:07:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4049) Let's look at the command line interface.

- [01:07:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4051) Okay, it says that we should add disable safe unpickle because we have downloaded it like

- [01:07:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4058) that.

- [01:07:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4059) So I will add this to the command line arguments and restart like this.

- [01:07:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4064) Let's also change the port.

- [01:07:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4066) Just close all of the terminals.

- [01:07:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4067) Okay, restart has been completed with disable safe unpickle.

- [01:07:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4071) Let's open the interface.

- [01:07:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4073) Okay, let's try with protogen.

- [01:07:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4075) Okay, we got error once again because when we download it, it is downloading safetensors

- [01:08:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4082) not ckpt.

- [01:08:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4083) Therefore, we have to rename it once again into safe tensors .safetensors like this and

- [01:08:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4091) try again.

- [01:08:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4092) Let's hit refresh.

- [01:08:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4093) Now there is safetensors.

- [01:08:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4095) Okay, it is loaded.

- [01:08:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4096) Let's test it and protogen is working as expected.

- [01:08:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4100) You see of awesome, intricate, fantastic, castle, in a forest and this is what I got.

- [01:08:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4105) Let's run again.

- [01:08:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4106) And yes, this is definitely protogen.

- [01:08:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4108) Let me run it on 1.5 version official as well.

- [01:08:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4112) Okay, 1.5 version is loaded and this is the result on 1.5 version official.

- [01:08:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4118) So this is how you can use custom models on RunPod io.

- [01:08:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4123) 2.1 image generation is still going on.

- [01:08:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4125) Now I will show you how to do Textual Inversion training.

- [01:08:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4129) To do that, let's go to the train tab.

- [01:08:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4132) By the way before doing that, let's go to the settings and in here in training, move

- [01:08:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4136) VAE and CLIP to RAM when training if possible.

- [01:09:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4140) You can pick this option to reduce VRAM usage.

- [01:09:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4143) You can also turn on pin memory for data loader.

- [01:09:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4146) Makes training slightly faster, but it can increase memory usage.

- [01:09:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4149) You can also pick this depending on your machine's RAM memory.

- [01:09:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4153) However, since we have 24 gigabytes, I am not going to pick them.

- [01:09:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4157) So let's give a name as test initialization text is none.

- [01:09:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4161) Number of vectors is two.

- [01:09:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4164) You can watch my excellent how to do Stable Diffusion Textual Inversion video.

- [01:09:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4170) I am explaining in great details in this video and you can learn many of the things related

- [01:09:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4177) to the Textual Inversion from this video.

- [01:09:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4180) Hit create embedding and it is already created.

- [01:09:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4183) Let's go to the train tab, pick the embedding.

- [01:09:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4186) We also need to set dataset directory.

- [01:09:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4189) So our data set directory is like this.

- [01:09:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4192) We don't need classification images for Textual Inversion training.

- [01:09:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4196) You can reduce the learning rate or leave it as default.

- [01:10:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4200) You can test it.

- [01:10:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4201) Okay, we need a style file word for Textual Inversion.

- [01:10:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4206) When you watch this video, you will understand it better.

- [01:10:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4210) So this text file is located inside Stable Diffusion, inside Textual Inversion templates.

- [01:10:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4216) In here, i'm going to edit the none as as [name].

- [01:10:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4220) You need this otherwise it won't work.

- [01:10:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4222) This is the name of the Textual Inversion.

- [01:10:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4224) This is basically going to use the unique tokens that it generates so i'm going to pick

- [01:10:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4230) none from here.

- [01:10:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4232) My width and height are 512 pixels.

- [01:10:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4235) Max number of steps.

- [01:10:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4237) You can leave it as this because it will generate pretty small files, but since we are already

- [01:10:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4242) using a lot of space, I will delete my older checkpoints from DreamBooth, Stable Diffusion

- [01:10:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4248) Web UI inside models inside Stable Diffusion and inside test2 folder.

- [01:10:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4254) Okay for selecting hit left shift key, select first, then go to the very bottom while pressing

- [01:11:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4260) shift key hit here it will select all of them.

- [01:11:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4264) Then while hitting control button left control, unpick the ones that you don't want to delete

- [01:11:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4270) right, click and hit delete.

- [01:11:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4272) It will delete all these files and open a space for me.

- [01:11:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4276) Okay, now we are ready.

- [01:11:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4277) I want to check checkpoints for every 10 epochs.

- [01:11:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4283) How many training images I have.

- [01:11:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4285) I have nine training images.

- [01:11:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4286) Therefore, one epochs means nine steps.

- [01:11:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4290) Five epochs means 45 steps.

- [01:11:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4293) So for every five epoch I am going to make save.

- [01:11:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4296) I don't need this and I will pick deterministic.

- [01:11:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4300) This is the best option and we are ready.

- [01:11:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4303) Just click hit train embedding.

- [01:11:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4305) Okay, it has started training.

- [01:11:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4308) By the way currently xformers is enabled.

- [01:11:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4311) Therefore, I will disable it and restart again because there is a bug as I have just shown

- [01:11:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4318) and it is preventing good training.

- [01:12:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4321) Also in settings this is unchecked.

- [01:12:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4324) Use cross attention optimizations but still it could be using it due to a bug.

- [01:12:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4330) So best thing is just disabling the xformers and restarting the training.

- [01:12:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4336) However, looks like learning right now I think.

- [01:12:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4339) So probably there is no bug for this one unlike the DreamBooth.

- [01:12:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4344) The loss rate is also pretty low and it is pretty fast.

- [01:12:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4348) Okay, it already started learning my face.

- [01:12:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4352) Not very good but there is a resemblance as you can see and it is really really fast the

- [01:12:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4358) number of steps it is taking really really fast.

- [01:12:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4361) This is how fast it is you see.

- [01:12:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4364) Training Textual Inversion epochs, training speed, the i/t per second and it is learning.

- [01:12:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4372) However, which one will be best is needs to be checked from text to image tab from x/y

- [01:13:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4380) plot and as you can see it is learning.

- [01:13:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4383) So all these samples are being saved inside.

- [01:13:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4387) Let's go to the Stable Diffusion Web UI folder inside here, textual inversion, inside here

- [01:13:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4393) you will see the training date and inside here the name of the Textual Inversion training

- [01:13:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4397) inside here images and these are the images named with the epoch number.

- [01:13:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4404) You can check them like this, or you can download them and check all of them.

- [01:13:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4409) Okay, 2700 steps looks a little bit decent.

- [01:13:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4414) It is actually equal to 300 epochs.

- [01:13:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4418) Maybe it may get better over time or we may need to use more vector count, but since I

- [01:13:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4424) am just trying to explain, I will use this and show you how you can use this checkpoint

- [01:13:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4431) in your queries in your text to image tab.

- [01:13:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4434) First I will cancel the training.

- [01:13:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4435) This one also looks like a decent one.

- [01:13:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4439) Hit interrupt: yeah.

- [01:14:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4441) 3240 also looking decent so it may get even better over time as we do more training, but

- [01:14:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4448) I don't have too much time.

- [01:14:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4450) Okay, so to be able to use these embeddings first, we need to copy the generated pt file

- [01:14:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4456) which is the checkpoint.

- [01:14:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4458) To do that, go to the Textual Inversion inside your main folder, go to the date that you

- [01:14:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4463) did training, go to the training name, go to the embeddings, and in here you will see

- [01:14:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4468) the dot pt files.

- [01:14:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4470) Pick the checkpoints that you want to test right, click, copy, then go back to the main

- [01:14:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4476) installation folder and in here you will see embeddings folder and paste them there like

- [01:14:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4482) this so it is pasted now here.

- [01:14:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4484) So to activate this Textual Inversion, we are going to type it like this.

- [01:14:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4490) By the way, there is one very important thing when you do training, it will train based

- [01:14:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4496) on the model selected here.

- [01:14:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4497) Therefore this will be most compatible with this selected model and just hit generate

- [01:15:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4504) and you see our face is generated trained subject.

- [01:15:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4507) Now we can try stylizing.

- [01:15:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4509) Okay, I did a simple test awesome, intricate, 3d artstation, cinematic lightning and generated

- [01:15:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4516) batch size as eight and these are the generated images.

- [01:15:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4520) So with better prompting it should be possible to get better results.

- [01:15:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4525) You can do same training on protogen or any other custom model as well, just check it

- [01:15:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4531) from here, make a new embedding and do training.

- [01:15:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4535) The Textual Inversion training works pretty decent on custom models as well.

- [01:15:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4540) However, custom models are not working very well with DreamBooth training.

- [01:15:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4544) Okay, so our image generation for classification data set for SD 2.1 is completed.

- [01:15:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4552) Now we will put them into the correct folder so all of the images are now generated inside

- [01:15:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4559) this folder.

- [01:16:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4560) How am I gonna do that?

- [01:16:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4561) I will right click cut, then I will go to the workspace, right, click paste and then

- [01:16:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4567) I will rename as class 768 version 2 like this.

- [01:16:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4574) Then I will go to the DreamBooth tab, I will open my test, load settings, go to the settings

- [01:16:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4581) and in here I will set the concept the classification data set directory as class 768 version 2

- [01:16:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4590) and now I have 50 images for per instance.

- [01:16:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4594) Okay, everything else is same.

- [01:16:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4596) Just save settings and hit train and let's see if we will get out of memory error or

- [01:16:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4601) not.

- [01:16:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4602) So it is preprocessing class images.

- [01:16:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4604) We can see the command line interface okay, uh, so it looks like the Gradio is killed

- [01:16:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4611) or our web app.

- [01:16:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4612) Therefore, we need to restart it.

- [01:16:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4615) By the way, we also need to disable xformers, otherwise it won't work for training.

- [01:16:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4619) So I am disabling xformers, saving, closing all of the terminals and starting a new instance

- [01:17:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4626) of the web ui.

- [01:17:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4628) Okay, restart is done.

- [01:17:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4629) You see these are the command line arguments that I have used to start 2.1 version Web

- [01:17:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4636) UI let's open it.

- [01:17:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4638) Go to the DreamBooth select model, click load settings.

- [01:17:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4642) Just verify settings quickly if they are correct or not.

- [01:17:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4645) Okay, all looking good and let's click train to see how it works.

- [01:17:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4650) Okay, preprocessing class.

- [01:17:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4652) Let's also see the cmd window from here.

- [01:17:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4655) Okay, you see it says nothing to generate because we already have sufficient number

- [01:17:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4660) of classification images in our folder 456 and we need 450 images.

- [01:17:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4667) So it is caching right now.

- [01:17:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4669) Okay, after caching it is killed once again and trying to relaunch.

- [01:17:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4675) Okay, we got out of memory error so we need to enable some more of the memory optimization

- [01:18:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4683) and I already unchecked the EMA.

- [01:18:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4687) Therefore, looks like we need some more optimization.

- [01:18:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4690) So I will pick fp16, but we are not using mixed precision so it is probably being ignored.

- [01:18:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4697) What else we can do for more optimization?

- [01:18:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4701) Gradient checkpointing yes, we can do this and let's save settings, load settings, and

- [01:18:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4708) hit train once again.

- [01:18:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4710) Okay, looks like I had to refresh load settings.

- [01:18:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4714) Hit train okay, yeah, it says that change in precision detected.

- [01:18:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4719) Please restart Web UI entirely to use new precision.

- [01:18:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4723) All right, so we will restart it.

- [01:18:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4726) Okay.

- [01:18:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4727) Restart is done.

- [01:18:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4728) Let's go to DreamBooth select model load settings and now gradient checkpointing enabled.

- [01:18:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4734) Use 8-bit adam fp16, memory attention default, cache latents and let's see if we will get

- [01:19:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4742) any error or not.

- [01:19:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4743) Okay, training started this time.

- [01:19:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4745) I hope we don't get any error during preview generation because it also uses GPU and we

- [01:19:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4751) can see our GPU is being used 95 percent already.

- [01:19:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4756) You can also see other utilization parameters here volume, container, and this is my other

- [01:19:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4761) running pod and this is how much I have spent and how much I am spending.

- [01:19:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4766) So now I will show you how to install ControlNet on SD 1.5 version.

- [01:19:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4773) If you don't know what is control net and how to install and use it.

- [01:19:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4777) I already have a great tutorial on my channel.

- [01:19:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4780) So this is the extension that we are going to install.

- [01:19:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4782) Copy the extension URL.

- [01:19:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4785) You can also find this in the description.

- [01:19:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4787) Go to the extension tabs, go to the install from URL, copy paste it, and click install.

- [01:19:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4793) Then once it is installed, go to the installed tab, apply and restart UI.

- [01:19:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4798) After we clicked it and unfortunately the Gradio is died again.

- [01:20:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4801) So I will relaunch it and since I am not going to do any training, I am enabling xformers

- [01:20:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4807) once again because it will speed up my image generation.

- [01:20:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4811) Okay, after restart, go to the text to image tab and in the bottom you should see ControlNet

- [01:20:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4816) like this.

- [01:20:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4817) Now we need to download ControlNet model which is hosted on Hugging Face in here.

- [01:20:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4824) Go to the files and versions and just download which model that you want to use.

- [01:20:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4829) Because each model files are like five gigabytes.

- [01:20:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4832) I'm going to show scribble as an example.

- [01:20:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4835) All others are same, exactly same and when you watch this video you will learn more about

- [01:20:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4840) them.

- [01:20:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4841) Okay right.

- [01:20:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4843) Click the download button, copy link path, go to your RunPod.

- [01:20:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4846) So these files will be put inside another folder.

- [01:20:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4850) Go to the extensions, go to the sd Web UI control net, go to the models.

- [01:20:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4855) We are going to put them inside here.

- [01:20:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4858) So in here I will open new launcher, open terminal wget and copy paste the link and

- [01:21:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4865) you see it has started downloading file from Hugging Face with an incredible speed.

- [01:21:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4870) Meanwhile I will show something else how you can download your trained models into your

- [01:21:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4875) computer.

- [01:21:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4877) So to download your trained DreamBooth model, go to the models, go to the Stable Diffusion,

- [01:21:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4883) go to the training and let's say you want to download this ckpt.

- [01:21:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4887) You can right click and download.

- [01:21:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4890) Or you can use runpodctl as we already shown multiple times.

- [01:21:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4894) But let's just show once again, runpodctl send the checkpoint file full name, not the

- [01:21:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4901) directory and it generated the download command like this: go to the download folder where

- [01:21:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4907) you want to download.

- [01:21:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4908) So let's say I want to download here.

- [01:21:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4910) Open cmd, right!

- [01:21:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4911) click, paste and hit enter and that model file will be downloaded into your computer

- [01:21:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4917) with a great speed like this as you can see.

- [01:22:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4920) It is downloading with 70 megabits per second and my maximum internet is 100 megabits per

- [01:22:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4926) second.

- [01:22:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4927) So this will of course totally depend on how other users are currently using the Pot network.

- [01:22:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4934) Okay, meanwhile ControlNet file is downloaded and saved in the folder.

- [01:22:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4939) Let's verify it.

- [01:22:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4940) Go to the extensions sd web ui control net inside models.

- [01:22:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4944) I see the pth file.

- [01:22:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4946) Let's go back to the ControlNet and in here.

- [01:22:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4949) When we refresh models we should see it.

- [01:22:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4953) Yes it is here and there is also pre-processor, then upload your file into this canvas that

- [01:22:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4960) you want to use.

- [01:22:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4961) I will do a scribble.

- [01:22:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4963) I am going to use this file.

- [01:22:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4966) Let's set the canvas with and height like this, also set your target resolution.

- [01:22:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4970) I will use the native resolution of the provided image which is 866 and 684.

- [01:22:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4978) Then type your prompt here and you can use the any model from here.

- [01:23:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4983) Let's use Protogen model so my prompt is dragon, awesome, intricate, cinematic, artstation.

- [01:23:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4988) Let's type some negative low,bad, worse.

- [01:23:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4991) Hit generate.

- [01:23:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4992) Okay, we didn't get the output because we didn't enable the ControlNet.

- [01:23:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4996) Don't forget that.

- [01:23:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=4998) And don't forget the check scribble mode, invert colors and now it is the map it it

- [01:23:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5005) generated and this is the output we got.

- [01:23:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5008) So you can play with different prompts and different models and generate different images.

- [01:23:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5015) It works pretty fast and pretty correct.

- [01:23:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5018) Just watch this video to learn more.

- [01:23:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5019) Actually, I have another control net video as well which is based on the native released

- [01:23:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5025) scripts from the official author.

- [01:23:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5027) You can also watch this video to learn even more about ControlNet.

- [01:23:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5031) Our SD 2.1 version training is going on.

- [01:23:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5035) However, it looks like there are some problems because generated image is not correct.

- [01:24:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5040) Okay, I have done a lot of research and looks like there is no way to do SD 2.1 version

- [01:24:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5047) 768 pixels training with DreamBooth without using xformers.

- [01:24:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5055) I wanted to avoid xformers during training because it reduces the quality of the training.

- [01:24:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5061) However, 24 gigabytes VRAM is just not enough.

- [01:24:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5064) So we need to downgrade the xformers version to 0.0.14 I already have an excellent tutorial

- [01:24:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5073) video for that for windows installation, so now I will show it on unix on RunPod.

- [01:24:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5080) Alternatively, you can go to the browse servers and in here you can deploy a RunPod with 48

- [01:24:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5089) gigabytes VRAM or 40 gigabytes VRAM.

- [01:24:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5092) It is up to you, but they cost more.

- [01:24:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5095) Therefore, we will just downgrade the xformers version.

- [01:25:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5100) Now, follow me very carefully to learn how to downgrade xformers on RunPod io.

- [01:25:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5107) First close all of the running kernels and terminals.

- [01:25:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5111) Then inside python 3.10 folder, start a new terminal.

- [01:25:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5116) First, we are going to run this command.

- [01:25:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5119) Pip Uninstall torch torchvision.

- [01:25:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5122) Paste it and hit yes and hit yes.

- [01:25:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5125) Okay, it is uninstalled.

- [01:25:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5126) Then we are going to run pip Uninstall torch audio.

- [01:25:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5131) Paste it.

- [01:25:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5132) Okay, it is done.

- [01:25:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5133) Then we are going to use pip Uninstall xformers.

- [01:25:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5136) Hit yes and it is done.

- [01:25:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5139) You know?

- [01:25:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5140) Currently I am inside workspace venv lib python 3.10.

- [01:25:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5144) The folder where you are currently located makes huge difference.

- [01:25:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5149) Make sure that you are inside the same folder.

- [01:25:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5151) You can also apply this to SD 1.5 version as well.

- [01:25:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5156) It is just same thing.

- [01:25:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5157) Then we are going to install torch vision.

- [01:25:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5159) Just copy this and paste it and hit enter.

- [01:26:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5162) Okay, I got error.

- [01:26:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5164) It says that there is no space left on the device because currently we started with five

- [01:26:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5171) gigabyte space for runtime.

- [01:26:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5174) Therefore, I will stop the pod like this.

- [01:26:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5177) I will edit the disk space from.

- [01:26:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5181) Click here.

- [01:26:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5182) More actions.

- [01:26:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5183) Click edit pod and in here in increase the container disk size.

- [01:26:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5187) Save it, run it, start it, and reconnect to Jupyter lab.

- [01:26:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5192) Enter inside the same folder venv lib, python 3.10 open terminal and make sure that you

- [01:26:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5201) run all of the commands once again to be sure.

- [01:26:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5204) Pip uninstall hit yes! if they are installed once again and pip uninstall torch audio,

- [01:26:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5212) then pip uninstall xformers.

- [01:26:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5214) Okay, it is done, then we will install this one.

- [01:26:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5218) As you can see, I have changed it because this is the one that is working.

- [01:27:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5222) Copy paste and hit.

- [01:27:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5223) Enter and it is going to install.

- [01:27:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5226) So once the full version of 0.0.17 is released, it will work with DreamBooth.

- [01:27:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5231) Currently this is a development version as you can see and it is installed.

- [01:27:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5236) Now we are ready to run our web UI as usual and it should support DreamBooth training

- [01:27:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5242) with xformers.

- [01:27:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5243) Before starting, I am going to edit xformers command line arguments minus minus xformers

- [01:27:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5249) and I am going to add back the full precision minus minus no half and minus minus precision

- [01:27:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5257) full and minus minus no half vae.

- [01:27:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5261) Save it, run on a different port, shut down all of the terminals start a new terminal,

- [01:27:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5267) relaunch the Web UI like this.

- [01:27:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5269) Okay, so our application is now starting with 0.0.17.dev 448 version for xformers and these

- [01:27:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5279) are the torch, torch vision, diffusers, and other versions.

- [01:28:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5283) Okay, it is started now.

- [01:28:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5284) Time to test whether it is working correctly or not for SD 2.1 DreamBooth training: okay,

- [01:28:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5292) I am loading my model, load settings and in here.

- [01:28:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5296) Let me show you quickly the latest settings.

- [01:28:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5299) So let's make the amount of time to pause between epochs zero.

- [01:28:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5303) I will save for every 20 epochs.

- [01:28:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5306) I am unchecking gradient checkpointing.

- [01:28:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5308) I will make learning rate as default.

- [01:28:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5310) Actually, let's try it.

- [01:28:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5312) Okay photo of ohwx man by tomer hanuka for sanity prompt and in advanced tab: now this

- [01:28:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5318) is important.

- [01:28:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5319) I will use EMA and in the mixed position, I am going to use fp16.

- [01:28:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5324) Some cards also supports bf16, but to be sure use fp16.

- [01:28:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5329) And when you hover your mouse it also says you that required when using xformers and

- [01:28:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5335) in here I am going to use xformers.

- [01:28:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5336) This is important.

- [01:28:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5337) Cache latents: okay, then go to the concepts tab.

- [01:29:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5342) They are set.

- [01:29:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5343) Everything is looking good and in saving, generate a ckpt file when saving during training

- [01:29:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5349) and hit train.

- [01:29:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5350) By the way, we should have clicked save settings before, but I think it is automatically saved.

- [01:29:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5356) If it doesn't work right away, just click save settings then hit train.

- [01:29:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5360) Okay, let's watch the terminal.

- [01:29:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5362) I hope that we won't get any more.

- [01:29:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5364) Uh, out of memory error.

- [01:29:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5366) Okay, it is killed so I will test one more time.

- [01:29:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5370) Refresh the Gradio, DreamBooth select model load settings.

- [01:29:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5375) Now this time I will set gradient checkpointing because it looks like necessary.

- [01:29:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5380) Fp16 use EMA and yes, everything is same and let's try again with save settings.

- [01:29:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5387) Train: okay, we got another error so this time I won't use EMA.

- [01:29:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5391) Refresh the interface DreamBooth, model load settings uncheck gradient checkpointing and

- [01:29:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5398) uncheck use EMA.

- [01:29:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5399) This is significantly increasing the VRAM usage.

- [01:30:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5402) Save settings hit train okay.

- [01:30:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5404) Finally, the training has started and now time to wait and see how well it is learning

- [01:30:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5410) and training.

- [01:30:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5412) The Gradio is still responsive.

- [01:30:13](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5413) That is very good and it is using this much of GPU memory so you see how much GPU memory

- [01:30:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5420) usage the EMA is increasing when we check the EMA option.

- [01:30:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5427) Meanwhile, SD 2.1 version training continues.

- [01:30:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5429) I will explain what is fine tuning with DreamBooth.

- [01:30:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5434) Okay, before I show how to do fine tuning.

- [01:30:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5437) We got an error during the SD 2.1 version training at the 400 steps which means when

- [01:30:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5444) it is generating a ckpt from the 20th epoch checkpoint.

- [01:30:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5449) Therefore, I will restart the training with one change one parameter, change load settings,

- [01:30:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5456) and go to the settings tab and enable gradient checkpointing.

- [01:31:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5461) The rest is same like this so it should just work fine this time I think.

- [01:31:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5467) Save settings hit train okay, this time we didn't get any error.

- [01:31:11](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5471) During SD 2.1 version training, we got sample yes, somewhat similar.

- [01:31:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5477) This is the first one at the 20th epoch and we got our sanity prompt as well.

- [01:31:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5481) This is the loss rate which is very erratic as you can see and this is the VRAM usage

- [01:31:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5487) like this.

- [01:31:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5488) Now I can start showing you fine tuning.

- [01:31:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5490) I have opened my 1.5 version RunPod so what is the difference of fine tuning.

- [01:31:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5498) In the fine tuning we are not going to use classification images and we are going to

- [01:31:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5504) use file words.

- [01:31:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5505) Fine tuning is basically using a lot of good images with proper captions and not using

- [01:31:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5513) any classification images.

- [01:31:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5514) The rest is same.

- [01:31:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5516) So every one of the keywords, every one of the tokens in the captions of the images will

- [01:32:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5522) be trained and they will become like the images that you use for fine tuning.

- [01:32:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5529) First of all, we need to process image files and add captions to them.

- [01:32:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5535) So go to the training tab, go to the preprocess images, set the source directory.

- [01:32:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5540) I don't have a data set for fine tuning a good data set you need a lot of images you

- [01:32:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5544) need so I will use my own pictures that I used for training and set a destination like

- [01:32:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5552) training captioned and in here use BLIP for caption and if those images are not 512 and

- [01:32:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5561) 512 pixels.

- [01:32:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5562) If you are going to fine tune SD 2.1 version with 768 pixels then you need to change these

- [01:32:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5569) resolution as well.

- [01:32:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5570) You can also crop them with autofocal point crop but manually cropping them and preparing

- [01:32:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5577) them is better and then click preprocess.

- [01:33:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5580) When the first time you run it.

- [01:33:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5581) It will download the BLIP model from internet.

- [01:33:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5584) Okay, preprocessing has been completed now.

- [01:33:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5587) Training captioned folder is generated.

- [01:33:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5590) Now you see there are txt files named same as the image file.

- [01:33:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5596) When you open them, you will see this captioning.

- [01:33:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5599) So what does this mean.

- [01:33:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5601) In the fine tuning all of these words, these tokens will be improved by the image they

- [01:33:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5610) are same named.

- [01:33:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5612) So all of these words will be improved towards this image.

- [01:33:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5617) This is what is fine tuning.

- [01:33:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5619) Let's say you want to improve castle images, then you should have good castle images and

- [01:33:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5624) inside their description, you should have castle word.

- [01:33:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5628) And if you want to associate those pictures with other words such as beautiful, intricate,

- [01:33:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5633) high quality, then you should also put them.

- [01:33:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5636) So put here whatever the words that you want to improve in your model with related to the

- [01:34:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5643) picture they are associated with, and then once you prepared good captions and images

- [01:34:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5649) inside your folder, copy the path of the new folder, go back to your DreamBooth tab and

- [01:34:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5655) make this setup like this in concepts, workspace, training captioned data directory.

- [01:34:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5661) Now this is important.

- [01:34:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5663) In the prompt just type [filewords] and nothing else.

- [01:34:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5668) This means that whenever it is training that particular image, it will load whatever is

- [01:34:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5676) written inside here and replace instance prompt with it.

- [01:34:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5680) That's it.

- [01:34:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5681) So this will be equal to this prompt for this particular image that is going to train.

- [01:34:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5689) In class prompt we are not using any classifications or class prompt.

- [01:34:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5693) In the sample prompt, you can use the [filewords] to see what kind of images it is generating

- [01:34:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5699) and make sure that class images per instance is zero.

- [01:35:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5703) Because we don't want to try to keep the previous context of the model, we want its underlying

- [01:35:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5710) context, latent space to be improved.

- [01:35:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5714) And that's it everything else is same.

- [01:35:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5716) So for fine tuning you need a lot of good images, good quality images with good captions.

- [01:35:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5723) Those captions will be improved.

- [01:35:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5725) It will also improve the Unet of the model so it will become overall better and overall

- [01:35:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5730) cooked we can say.

- [01:35:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5733) Because if you show less number of images than it was trained on, it will lose a lot

- [01:35:38](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5738) of the contextual knowledge it has.

- [01:35:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5742) Therefore, these cooked custom models are not good to train your faces on them because

- [01:35:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5747) they don't have as much as information as these 1.5 pruned ckpt have.

- [01:35:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5752) For example, this model was trained on 5 billion images as far as I know of.

- [01:35:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5759) However, those custom models may be trained on 1000 images, one maybe 10 000 images.

- [01:36:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5766) So their Unet has become like those 10 000 images instead of being trained on 5 billion

- [01:36:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5774) images.

- [01:36:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5775) That is why they are so good, but they have much lesser knowledge in their underlying

- [01:36:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5781) context in their latent space.

- [01:36:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5783) So this is basically fine tuning how it is done.

- [01:36:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5787) If you want to be exactly same as Stable Diffusion training that the official training.

- [01:36:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5793) You can also remove text encoder training with setting this parameter as zero.

- [01:36:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5800) So with this way the tokens won't be improved.

- [01:36:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5804) Only Unet will be improved.

- [01:36:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5806) However, you don't want that for fine tuning.

- [01:36:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5809) This is more like using hundreds thousands of images and training from scratch your model.

- [01:36:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5817) So you should keep it perhaps like one and train Unet as well.

- [01:37:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5821) So you will train both text encoder and the Unet and improve all of those keywords together.

- [01:37:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5829) Hopefully I will make another very technical video about how training works, what is Unet,

- [01:37:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5836) what is text encoder, how they are being changed during training, and it will explain a lot

- [01:37:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5842) of the questions that are not very well answered in the community.

- [01:37:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5847) So stay subscribed.

- [01:37:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5849) Open notifications to not miss it.

- [01:37:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5851) So let's check out our 2.1 version training.

- [01:37:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5854) Okay, our sanity prompt already looks like lost its stylizing ability and the sample

- [01:37:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5861) is not also looking very good.

- [01:37:43](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5863) Uh, however, I have seen that it was learning so let's open the directory.

- [01:37:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5867) Okay, inside DreamBooth, inside samples, let's look at each one of the sample.

- [01:37:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5873) So this is the 20 epoch.

- [01:37:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5874) Yes, it has a resemblance.

- [01:37:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5876) It is not very good.

- [01:37:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5877) This is the 40 epoch.

- [01:37:59](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5879) Very minor resemblance.

- [01:38:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5881) Let's check out the sanity prompt.

- [01:38:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5883) The sanity prompt is much better.

- [01:38:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5885) So this is somewhat similar to me, but stylized in Tomer Hanuka style.

- [01:38:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5890) So the sanity prompt of the 60 epoch is not good at all.

- [01:38:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5894) It lost its stylizing.

- [01:38:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5897) The sample is also not very related, but this is SD 2.1 so it is harder to train and obtain

- [01:38:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5903) good images.

- [01:38:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5904) So you see this is the 80 epoch.

- [01:38:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5906) This is almost as like me.

- [01:38:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5908) Let me show you for comparison.

- [01:38:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5911) With 80 epoch 2.1 version, it is started to learning my face very well.

- [01:38:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5917) Let's check out the sanity prompt.

- [01:38:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5919) However, sanity prompt also lost its ability to stylize so our learning rate could be very

- [01:38:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5926) high.

- [01:38:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5927) Perhaps we should try half of it.

- [01:38:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5929) Based on your training data set the learning rate may change, number of steps, number of

- [01:38:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5935) epochs that you need to do training may change.

- [01:38:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5938) So it is up to you to do multiple trainings and compare how well they are working with

- [01:39:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5945) x/y/z plots as I have shown.

- [01:39:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5947) However, the training is working very well.

- [01:39:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5950) It is learning the subject very well so we managed to make it work very well for SD 2.1

- [01:39:17](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5957) version 768 a model.

- [01:39:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5961) Let me show you the parameters once again.

- [01:39:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5964) So I will slowly scroll down and you will be able to see all of the settings.

- [01:39:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5970) This totally depends on your learning rate and how many number of training images you

- [01:39:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5975) use.

- [01:39:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5976) You should also save multiple checkpoints during training and compare them: batch size

- [01:39:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5981) one and gradient accumulation one.

- [01:39:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5982) If you increase this, it will increase significantly your VRAM usage.

- [01:39:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5987) Also, we can't say bigger batch size is better.

- [01:39:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5990) It's a debated topic.

- [01:39:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5992) Mini batches versus full batches.

- [01:39:54](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5994) These two are checked.

- [01:39:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5995) Otherwise, we are getting VRAM error on 24 gigabyte.

- [01:39:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=5998) This is my current learning rate.

- [01:40:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6001) This may be fast, so you may try half of it or even lower.

- [01:40:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6005) This is the resolution.

- [01:40:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6007) This is the sanity prompt to see how well it stylized.

- [01:40:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6010) So don't check EMA because you will get error VRAM error even when using xformers.

- [01:40:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6016) Use 8-bit adam, use fp16 to be sure that it is supported on your graphic card.

- [01:40:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6022) Use xformers, cache latents, train Unet, train text encoder and these other things are just

- [01:40:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6029) default.

- [01:40:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6030) Okay, now I will show you how to install and run Kohya Lora training Kohya GUI on RunPod.

- [01:40:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6037) To do that we are going to use Kohya ss linux branch.

- [01:40:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6041) To do that we are going to use kohya ss linux fork of the official repository of kohya ss.

- [01:40:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6048) This is modified to run on linux.

- [01:40:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6051) So first of all, we are going to clone the repository into our RunPod.

- [01:40:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6056) So this is my 1.5 RunPod.

- [01:40:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6058) I am inside workspace.

- [01:41:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6060) I have closed everything.

- [01:41:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6062) Open a new terminal, copy paste the git clone command.

- [01:41:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6065) It will clone into the kohya ss linux folder, then move into the kohya ss linux, type cd

- [01:41:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6072) ko type tab.

- [01:41:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6074) Hit enter and now I am inside kohya ss linux.

- [01:41:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6078) Then we will generate virtual environment folder with this command.

- [01:41:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6083) Copy it, hit enter inside this folder.

- [01:41:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6086) Okay, it is generated.

- [01:41:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6088) Let's also move it in here.

- [01:41:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6090) Now we will run the next command which is for activating and entering inside that virtual

- [01:41:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6096) folder.

- [01:41:37](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6097) Actually source venv command: copy paste it.

- [01:41:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6100) Hit.

- [01:41:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6101) Enter now you see venv here.

- [01:41:44](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6104) That means that currently actually we are running on the newly generated virtual environment

- [01:41:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6110) folder.

- [01:41:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6111) Next, we are going to install requirements.

- [01:41:53](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6113) This is only one time necessary.

- [01:41:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6116) The requirements file is located inside here and currently we are also inside that folder

- [01:42:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6121) so it should work.

- [01:42:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6122) The requirements installation may take some time.

- [01:42:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6126) These installations will not affect your other installations because everything being installed

- [01:42:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6132) here will be only installed inside this folder.

- [01:42:16](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6136) Okay, we got an error that says no space left on the drive so I will just.

- [01:42:21](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6141) I will just close the RunPod with stop pod and I will increase the container disk size

- [01:42:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6146) to 10 gigabytes.

- [01:42:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6148) To do that, click here, edit pod and run it once again.

- [01:42:31](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6151) Start then click connect.

- [01:42:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6153) Connect to Jupyter lab.

- [01:42:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6155) Okay, it is still being getting launched so be patient.

- [01:42:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6160) Okay notebook started once again so I will just delete the venv folder rm -r, venv.

- [01:42:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6169) So I will start from beginning.

- [01:42:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6171) Python minus m, venv venv then source command activate then install command.

- [01:42:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6178) It will install the requirements.

- [01:43:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6180) Okay, all requirements have been installed.

- [01:43:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6183) As author here noted, it requires python 3.10 and it doesn't work on 3.11 since the RunPod

- [01:43:12](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6192) runs on 3.10.9 for Stable Diffusion, it is just fine.

- [01:43:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6198) Then we will set accelerate config.

- [01:43:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6200) I am copying this pasting in here.

- [01:43:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6203) We are still inside that venv folder.

- [01:43:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6207) So now it will ask us bunch of questions.

- [01:43:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6209) Select this machine hit, enter select, no distributed hit enter type no to this question,

- [01:43:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6216) then type no to this question as well.

- [01:43:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6219) And type no to this question as well.

- [01:43:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6222) And type all for this question.

- [01:43:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6225) And do you wish to use fp16 or bf16?

- [01:43:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6229) select fp16.

- [01:43:51](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6231) It will speed up your training and also use lesser VRAM.

- [01:43:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6236) Okay and everything is ready.

- [01:43:58](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6238) Then we are currently activated with source command so we don't need to run this again.

- [01:44:03](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6243) We will just run this command and it should start our GUI.

- [01:44:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6248) Okay, it is running on localhost so therefore we need to run it on shared link.

- [01:44:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6255) To enable public Gradio link as we are using in Web UI.

- [01:44:19](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6259) Open the kohyagui.py go to the interface launch tab here and add this comma Share true, save

- [01:44:28](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6268) it and start it once again.

- [01:44:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6270) So new terminal open first.

- [01:44:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6273) Activate the venv like this and just run this command and now it has given us a Gradio link.

- [01:44:40](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6280) When we run it, the famous Kohya GUI is loaded and ready to do training.

- [01:44:46](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6286) The training with it is another topic and I won't cover it in this.

- [01:44:50](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6290) Now I will stop my running RunPods and when I stop at them nothing will happen.

- [01:44:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6295) They will just remain as they are.

- [01:44:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6297) I can also start them without any GPU.

- [01:45:00](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6300) So from here you can select zero and you can start your RunPod to backup your data to download

- [01:45:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6307) your data without using any GPUs.

- [01:45:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6309) So when you run them on CPU the disk cost plus it uses 0.16 dollars per hour.

- [01:45:18](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6318) So it is still costing something.

- [01:45:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6320) I think it is costing half of the original GPU price.

- [01:45:24](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6324) However, sometimes you may not get a GPU.

- [01:45:27](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6327) Sometimes all of the GPUs may be full on the RunPod so you will be have to run it without

- [01:45:33](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6333) a GPU.

- [01:45:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6335) So this is how you start it without using any GPU and there is also terminate.

- [01:45:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6341) When you hit terminate it will delete your RunPod permanently.

- [01:45:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6345) I already said this but I am saying it again.

- [01:45:49](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6349) So do not hit terminate button unless you are 100 sure because it will delete everything

- [01:45:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6355) on this RunPod and until you terminate and delete your RunPod it will continue using

- [01:46:02](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6362) your credits.

- [01:46:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6364) Currently I have two RunPods not running and it is using 0.056 dollars per hour.

- [01:46:14](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6374) So this is the cost of keeping these two RunPods on my account.

- [01:46:20](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6380) And when I delete them you will see this will get decreased.

- [01:46:23](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6383) Let's delete first one with terminate pod.

- [01:46:26](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6386) Okay and now this should get decreased.

- [01:46:29](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6389) Let's go to the my pods.

- [01:46:30](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6390) Let's refresh.

- [01:46:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6392) Okay now you see currently it is decreasing.

- [01:46:35](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6395) Zero point zero point twenty eight dollars per hour.

- [01:46:39](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6399) This is charged per minute by the way, not per hour and I will also delete this and it

- [01:46:45](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6405) will become zero.

- [01:46:47](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6407) And now my credits are remaining as they are until I start another pod.

- [01:46:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6412) There is one final thing that I want to show you cloud sync button here.

- [01:46:57](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6417) So with cloud sync you can synchronize your data in your server to these cloud services

- [01:47:04](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6424) and there is a great tutorial on the RunPod blog.

- [01:47:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6428) I will share this link into the description as well so you can read here and set up your

- [01:47:15](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6435) cloud storage and set a synchronization with your run pod and everything generated in your

- [01:47:22](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6442) RunPod will be synchronized with your cloud.

- [01:47:25](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6445) Also you can use the runpodctl that I have shown multiple times to download your data

- [01:47:32](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6452) to upload your data.

- [01:47:34](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6454) It is up to you that how you want to use it.

- [01:47:36](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6456) I think I have covered everything that I have mentioned in the beginning.

- [01:47:41](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6461) I hope you have enjoyed.

- [01:47:42](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6462) Please like, subscribe and leave a comment to do this tutorial also join our Discord

- [01:47:48](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6468) channel, ask any questions that you can't solve.

- [01:47:52](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6472) Also, please support us on Patreon.

- [01:47:55](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6475) It is really important.

- [01:47:56](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6476) The Patreon link and the Discord link will be in the comments and description.

- [01:48:01](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6481) All of the links we have used in this video will be in the description.

- [01:48:05](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6485) You can also find our Patreon page on our about tab of our youtube page youtube channel.

- [01:48:06](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6486) We have so far 26 patrons.

- [01:48:07](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6487) I thank them a lot thank them very much.

- [01:48:08](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6488) I hope you also become a Patreon.

- [01:48:09](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6489) Hopefully see you in another awesome video!

- [01:48:10](https://www.youtube.com/watch?v=QN1vdGhjcRc&t=6490) Thank you so much.

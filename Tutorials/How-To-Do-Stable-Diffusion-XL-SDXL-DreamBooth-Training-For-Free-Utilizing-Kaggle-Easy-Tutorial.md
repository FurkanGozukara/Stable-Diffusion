# How To Do Stable Diffusion XL (SDXL) DreamBooth Training For Free - Utilizing Kaggle - Easy Tutorial

## Full tutorial link > https://www.youtube.com/watch?v=16-b1AjvyBE

[![How To Do Stable Diffusion XL (SDXL) DreamBooth Training For Free - Utilizing Kaggle - Easy Tutorial](https://img.youtube.com/vi/16-b1AjvyBE/sddefault.jpg)](https://www.youtube.com/watch?v=16-b1AjvyBE "How To Do Stable Diffusion XL (SDXL) DreamBooth Training For Free - Utilizing Kaggle - Easy Tutorial")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Do-Stable-Diffusion-XL-SDXL-DreamBooth-Training-For-Free-Utilizing-Kaggle-Easy-Tutorial.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Do-Stable-Diffusion-XL-SDXL-DreamBooth-Training-For-Free-Utilizing-Kaggle-Easy-Tutorial.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


üåü Master Stable Diffusion XL Training on Kaggle for Free! üåü Welcome to this comprehensive tutorial where I'll be guiding you through the exciting world of setting up and training Stable Diffusion XL (SDXL) with Kohya on a free Kaggle account. This video is your one-stop resource for learning everything from initiating a Kaggle session with dual T4 GPUs to fine-tuning your SDXL model for optimal performance.

#Kaggle #StableDiffusion #SDXL

Notebook ‚§µÔ∏è

[https://www.patreon.com/posts/kohya-sdxl-lora-88397937](https://www.patreon.com/posts/kohya-sdxl-lora-88397937)

Tutorial GitHub Readme File ‚§µÔ∏è

[https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Full-Stable-Diffusion-XL-SDXL-DreamBooth-Training-Tutorial-On-Kaggle.md](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Full-Stable-Diffusion-XL-SDXL-DreamBooth-Training-Tutorial-On-Kaggle.md)

[00:00:00](https://youtu.be/16-b1AjvyBE?t=0) Introduction To The Kaggle Free SDXL DreamBooth Training Tutorial

[00:02:01](https://youtu.be/16-b1AjvyBE?t=121) How to register Kaggle account and login

[00:02:26](https://youtu.be/16-b1AjvyBE?t=146) Where to and how to download Kaggle training notebook for Kohya GUI

[00:02:47](https://youtu.be/16-b1AjvyBE?t=167) How to import / load downloaded Kaggle Kohya GUI training notebook

[00:03:08](https://youtu.be/16-b1AjvyBE?t=188) How to enable GPUs and Internet on your Kaggle session

[00:03:52](https://youtu.be/16-b1AjvyBE?t=232) How to start your Kaggle session / cloud machine

[00:04:02](https://youtu.be/16-b1AjvyBE?t=242) How to see your Kaggle given free hardware features

[00:04:18](https://youtu.be/16-b1AjvyBE?t=258) How to install Kohya GUI on a Kaggle notebook

[00:04:46](https://youtu.be/16-b1AjvyBE?t=286) How to know when the Kohya GUI installation has been completed on a Kaggle notebook

[00:05:00](https://youtu.be/16-b1AjvyBE?t=300) How to download regularization images before starting training

[00:05:22](https://youtu.be/16-b1AjvyBE?t=322) Introduction to the classification dataset that I prepared

[00:06:35](https://youtu.be/16-b1AjvyBE?t=395) How to setup and enter your token to use Kohya Web UI on Kaggle

[00:08:20](https://youtu.be/16-b1AjvyBE?t=500) How to load pre-prepared configuration json file on Kohya GUI

[00:08:48](https://youtu.be/16-b1AjvyBE?t=528) How to do Dataset Preparation after configuration loaded

[00:08:59](https://youtu.be/16-b1AjvyBE?t=539) How to upload your training dataset to your Kaggle session

[00:09:12](https://youtu.be/16-b1AjvyBE?t=552) Properties of my training images dataset

[00:09:22](https://youtu.be/16-b1AjvyBE?t=562) What kind of training dataset is good and why

[00:10:06](https://youtu.be/16-b1AjvyBE?t=606) How to upload any data to Kaggle and use it on your notebook

[00:10:20](https://youtu.be/16-b1AjvyBE?t=620) How to use previously composed Kaggle dataset in your new Kaggle session

[00:10:34](https://youtu.be/16-b1AjvyBE?t=634) How to get path of session included dataset

[00:10:44](https://youtu.be/16-b1AjvyBE?t=644) Why do I train with 100 repeating and 1 epoch

[00:10:54](https://youtu.be/16-b1AjvyBE?t=654) Explanation of 1 epoch and how to calculate epochs

[00:11:23](https://youtu.be/16-b1AjvyBE?t=683) How to set path of regularization images

[00:11:33](https://youtu.be/16-b1AjvyBE?t=693) How to set instance prompt and why we set it to a rare token

[00:11:46](https://youtu.be/16-b1AjvyBE?t=706) How to set destination directory and model output into temp disk space

[00:12:29](https://youtu.be/16-b1AjvyBE?t=749) How to set Kaggle temporary models folder path

[00:13:07](https://youtu.be/16-b1AjvyBE?t=787) How many GB temporary space do Kaggle provides us for free

[00:13:23](https://youtu.be/16-b1AjvyBE?t=803) Which parameters you need to set on Kohya GUI before starting training

[00:13:33](https://youtu.be/16-b1AjvyBE?t=813) How to calculate the N number of save every N steps parameter to save checkpoints

[00:13:45](https://youtu.be/16-b1AjvyBE?t=825) How to calculate total number of steps that your Kohya Stable Diffusion going to take

[00:14:10](https://youtu.be/16-b1AjvyBE?t=850) If I want to take 5 checkpoints what number of steps I need calculation

[00:14:33](https://youtu.be/16-b1AjvyBE?t=873) How to download saved configuration json file

[00:14:43](https://youtu.be/16-b1AjvyBE?t=883) Click start training and training starts

[00:14:55](https://youtu.be/16-b1AjvyBE?t=895) Can we combine both GPU VRAM and use as a single VRAM

[00:15:05](https://youtu.be/16-b1AjvyBE?t=905) How we are setting the base model that it will do training

[00:15:55](https://youtu.be/16-b1AjvyBE?t=955) The SDXL full DreamBooth training speed we get on a free Kaggle notebook

[00:16:51](https://youtu.be/16-b1AjvyBE?t=1011) Can you close your browser or computer during training

[00:17:54](https://youtu.be/16-b1AjvyBE?t=1074) Can we download models during training

[00:18:26](https://youtu.be/16-b1AjvyBE?t=1106) Training has been completed

[00:18:57](https://youtu.be/16-b1AjvyBE?t=1137) How to prevent last checkpoint to be saved 2 times

[00:19:30](https://youtu.be/16-b1AjvyBE?t=1170) How to download generated checkpoints / model files

[00:21:11](https://youtu.be/16-b1AjvyBE?t=1271) How you will know the download status when downloading from Kaggle working directory

[00:22:03](https://youtu.be/16-b1AjvyBE?t=1323) How to upload generated checkpoints / model files into Hugging Face for blazing fast upload and download

[00:25:02](https://youtu.be/16-b1AjvyBE?t=1502) Where to find Hugging Face uploaded models after upload has been completed

[00:26:54](https://youtu.be/16-b1AjvyBE?t=1614) Explanation of why generated last 2 checkpoints are duplicate

[00:27:27](https://youtu.be/16-b1AjvyBE?t=1647) Hugging Face upload started and the amazing speed of the upload

[00:27:49](https://youtu.be/16-b1AjvyBE?t=1669) All uploads have been completed now how to download them

[00:29:02](https://youtu.be/16-b1AjvyBE?t=1742) Download speed from Hugging Face repository

[00:29:17](https://youtu.be/16-b1AjvyBE?t=1757) How to terminate your Kaggle session

[00:29:36](https://youtu.be/16-b1AjvyBE?t=1776) Where to see how much GPU time you have left for free on Kaggle for that week

[00:29:46](https://youtu.be/16-b1AjvyBE?t=1786) How to make a fresh installation of Automatic1111 SD Web UI

[00:31:05](https://youtu.be/16-b1AjvyBE?t=1865) How to download Hugging Face uploaded models with wget very fast

[00:31:57](https://youtu.be/16-b1AjvyBE?t=1917) Which settings to set on a freshly installed Automatic1111 Web UI, e.g. VAE quick selection

[00:32:07](https://youtu.be/16-b1AjvyBE?t=1927) How to install after detailer (adetailer) extension to improve faces automatically

[00:32:51](https://youtu.be/16-b1AjvyBE?t=1971) Why you should add --no-half-vae to your command line arguments

[00:33:05](https://youtu.be/16-b1AjvyBE?t=1985) How to start / restart Automatic1111 Web UI

[00:33:37](https://youtu.be/16-b1AjvyBE?t=2017) How switch to the development branch of Automatic1111 Web UI to use latest version

[00:34:24](https://youtu.be/16-b1AjvyBE?t=2064) Where to download amazing prompts list for DreamBooth trained models

[00:35:07](https://youtu.be/16-b1AjvyBE?t=2107) How to use PNG info to quickly load prompts

[00:35:52](https://youtu.be/16-b1AjvyBE?t=2152) How to do x/y/z checkpoint comparison to find the best checkpoint of your SDXL DreamBooth training

[00:38:09](https://youtu.be/16-b1AjvyBE?t=2289) How to make SDXL work faster on weak GPUs

[00:38:37](https://youtu.be/16-b1AjvyBE?t=2317) How to analyze results of x/y/z checkpoint comparison to decide best checkpoint

[00:42:06](https://youtu.be/16-b1AjvyBE?t=2526) How to obtain better images

[00:42:20](https://youtu.be/16-b1AjvyBE?t=2540) How to install TensorRT and use it to generate images very fast with same quality

[00:44:41](https://youtu.be/16-b1AjvyBE?t=2681) How to use amazing prompt list as a list txt file



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=16-b1AjvyBE&t=0) In this tutorial video, I will guide you through&nbsp; setting up your Stable Diffusion XL (SDXL) Kohya&nbsp;&nbsp;

- [00:00:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=6) training notebook on a free Kaggle account. Here&nbsp; is what you will learn: How to select the correct&nbsp;&nbsp;

- [00:00:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=11) Kaggle notebook settings and start your session.&nbsp; Steps to install and initiate the Kohya graphical&nbsp;&nbsp;

- [00:00:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=17) user interface Stable Diffusion trainer. Setting&nbsp; best parameters and configurations for SDXL&nbsp;&nbsp;

- [00:00:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=23) training with Kohya on a free Kaggle notebook,&nbsp; utilizing dual T4 GPUs simultaneously. Simply load&nbsp;&nbsp;

- [00:00:30](https://www.youtube.com/watch?v=16-b1AjvyBE&t=30) my pre-shared configuration and click prepare data&nbsp; set. Adding new data to your Kaggle account as a&nbsp;&nbsp;

- [00:00:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=36) data set for use in your session, like training&nbsp; images. The types of training images to use in&nbsp;&nbsp;

- [00:00:42](https://www.youtube.com/watch?v=16-b1AjvyBE&t=42) your data set. A new training approach, instead&nbsp; of epochs, use a higher repetition count and save&nbsp;&nbsp;

- [00:00:48](https://www.youtube.com/watch?v=16-b1AjvyBE&t=48) checkpoints based on step count. How to calculate&nbsp; checkpoint saves every N steps. Estimating the&nbsp;&nbsp;

- [00:00:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=54) total number of steps your training will take.&nbsp; Downloading saved checkpoints or files directly&nbsp;&nbsp;

- [00:00:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=58) from the Kaggle working directory. Uploading&nbsp; generated checkpoints to Hugging Face from Kaggle&nbsp;&nbsp;

- [00:01:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=64) or from other cloud services such as Google Colab,&nbsp; RunPod, and AWS. Quickly downloading checkpoints&nbsp;&nbsp;

- [00:01:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=70) from Hugging Face using a browser or wget.&nbsp; Switching your Automatic1111 Stable Diffusion&nbsp;&nbsp;

- [00:01:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=77) web UI to the development branch. Finding and&nbsp; using amazing prompt list PNGs. Installing and&nbsp;&nbsp;

- [00:01:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=83) effectively using the after-detailer extension&nbsp; for automatic face inpainting to enhance image&nbsp;&nbsp;

- [00:01:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=89) quality, including specific face improvements.&nbsp; Comparing checkpoints by using X/Y/Z comparison&nbsp;&nbsp;

- [00:01:35](https://www.youtube.com/watch?v=16-b1AjvyBE&t=95) to identify the best trained model. Correct&nbsp; Automatic1111 command line arguments for&nbsp;&nbsp;

- [00:01:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=101) using SDXL on low-end graphic cards for image&nbsp; generation. Installing TensorRT for faster image&nbsp;&nbsp;

- [00:01:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=107) generation and improved quality. As usual, I have&nbsp; prepared an amazing GitHub Readme file for this&nbsp;&nbsp;

- [00:01:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=114) tutorial. Follow this tutorial while this file is&nbsp; open. I will update this file if it be necessary.&nbsp;&nbsp;

- [00:02:01](https://www.youtube.com/watch?v=16-b1AjvyBE&t=121) We will begin with logging in into our Kaggle&nbsp; account. If you don't have a Kaggle account,&nbsp;&nbsp;

- [00:02:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=126) register it from here. It is for free. After that&nbsp; login and make sure that your phone number is&nbsp;&nbsp;

- [00:02:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=134) verified. Otherwise, you won't be able to use GPUs&nbsp; that Kaggle provides us for every week, 30 hours.&nbsp;&nbsp;

- [00:02:21](https://www.youtube.com/watch?v=16-b1AjvyBE&t=141) And it is amazing. So this is my Kaggle account.&nbsp; I am logged in right now. So as a next step,&nbsp;&nbsp;

- [00:02:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=147) go to this link to download the notebook file&nbsp; that we are going to use in this tutorial. You can&nbsp;&nbsp;

- [00:02:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=152) download it from here, version 9. Alternatively,&nbsp; which is even better way, go to the very bottom&nbsp;&nbsp;

- [00:02:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=159) of the post. And in here, you will see the&nbsp; attachment here. Downloading from this attachment&nbsp;&nbsp;

- [00:02:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=165) is usually better. So we have downloaded our&nbsp; notebook file, then click create icon here,&nbsp;&nbsp;

- [00:02:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=170) click new notebook, then go to the file here&nbsp; and click import notebook. Click browse files,&nbsp;&nbsp;

- [00:02:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=176) select the downloaded notebook from your downloads&nbsp; or wherever you have downloaded and click import.&nbsp;&nbsp;

- [00:03:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=182) Then the notebook will be imported. Click X&nbsp; to close it. So this will be your notebook.&nbsp;&nbsp;

- [00:03:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=187) Before starting, you need to make sure that your&nbsp; accelerator is selected GPU T4 X2. This is super&nbsp;&nbsp;

- [00:03:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=195) important. Turn on GPU as you have seen right&nbsp; now. Then you can also select persistence. If&nbsp;&nbsp;

- [00:03:21](https://www.youtube.com/watch?v=16-b1AjvyBE&t=201) you select files only, it will try to recover&nbsp; files, but this will make it work very slow,&nbsp;&nbsp;

- [00:03:28](https://www.youtube.com/watch?v=16-b1AjvyBE&t=208) extremely slow. I don't suggest it. So when&nbsp; you are going to do training, you should be&nbsp;&nbsp;

- [00:03:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=214) available until training completes. Then once&nbsp; the training completed, you should upload your&nbsp;&nbsp;

- [00:03:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=219) models into the Hugging Face or download them&nbsp; into your computer. Uploading to Hugging Face,&nbsp;&nbsp;

- [00:03:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=224) which is I suggest you to do. Then make sure that&nbsp; Internet on is selected. Once you have made those&nbsp;&nbsp;

- [00:03:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=232) changes, you need to click this button. It will&nbsp; start the session. Once the session started,&nbsp;&nbsp;

- [00:03:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=238) you will see your hardware when you click here.&nbsp; Recently, Kaggle did a huge upgrade to the RAM&nbsp;&nbsp;

- [00:04:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=245) they provide for free accounts. Now it is 29&nbsp; gigabytes and it is amazing. And we still get&nbsp;&nbsp;

- [00:04:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=250) 2 dual GPU T4 with 15 gigabyte VRAM having each&nbsp; GPU. They are amazing. Then all you need to do&nbsp;&nbsp;

- [00:04:19](https://www.youtube.com/watch?v=16-b1AjvyBE&t=259) is click this cell. Once this cell is selected you&nbsp; can click this icon or this icon. Let's click this&nbsp;&nbsp;

- [00:04:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=266) icon. Wait until this cancel run disappears.&nbsp; So currently it will execute this cell and&nbsp;&nbsp;

- [00:04:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=274) install everything automatically for you. This&nbsp; installation may take a while. So patiently wait.&nbsp;&nbsp;

- [00:04:40](https://www.youtube.com/watch?v=16-b1AjvyBE&t=280) While installing you will see the installation&nbsp; messages like this. Just wait at the end here.&nbsp;&nbsp;

- [00:04:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=287) Once the setup has been completed, you see there&nbsp; is no cancel run anymore, there is no executing&nbsp;&nbsp;

- [00:04:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=293) cell and you will see setup finished here. After&nbsp; that, whether you are training a woman or whether&nbsp;&nbsp;

- [00:04:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=299) you are training a man, you can execute this cell&nbsp; to automatically download them and extract them.&nbsp;&nbsp;

- [00:05:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=307) These are the latest regularization images that&nbsp; I have prepared for you guys. Since I'm going to&nbsp;&nbsp;

- [00:05:13](https://www.youtube.com/watch?v=16-b1AjvyBE&t=313) train myself, it is going to a man data set. So&nbsp; I click this cell. It will download and extract&nbsp;&nbsp;

- [00:05:19](https://www.youtube.com/watch?v=16-b1AjvyBE&t=319) all the man data set automatically for me. This&nbsp; data set is prepared by me by spending days,&nbsp;&nbsp;

- [00:05:25](https://www.youtube.com/watch?v=16-b1AjvyBE&t=325) literally days, and I am providing all of them&nbsp; to you. So when I enter inside the 1024 folder,&nbsp;&nbsp;

- [00:05:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=333) 1024 pixels folder, you see they are even sorted&nbsp; by the face quality. How did I calculate the face&nbsp;&nbsp;

- [00:05:40](https://www.youtube.com/watch?v=16-b1AjvyBE&t=340) quality? I used the very best algorithm available&nbsp; to rank the faces among different images based on&nbsp;&nbsp;

- [00:05:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=349) the sharpness and focus of the face. You see&nbsp; in each image, the face is extremely clear,&nbsp;&nbsp;

- [00:05:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=356) very high quality. And the reason why I did this&nbsp; is and sort them with a specific naming pattern,&nbsp;&nbsp;

- [00:06:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=362) as you are seeing, because the Kohya script will&nbsp; use the very first images that you need to use&nbsp;&nbsp;

- [00:06:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=370) during your training, which I will explain how&nbsp; many will be used. So using these regularization&nbsp;&nbsp;

- [00:06:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=375) images, classification images will improve our&nbsp; training significantly. This is the very best&nbsp;&nbsp;

- [00:06:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=382) regularization / classification images data set&nbsp; that you can find. It is manually prepared by&nbsp;&nbsp;

- [00:06:28](https://www.youtube.com/watch?v=16-b1AjvyBE&t=388) me. So the extraction has been completed as you&nbsp; are seeing right now, our classification images&nbsp;&nbsp;

- [00:06:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=393) are ready. Then as a next step, we are going to&nbsp; do a something special thing to run the GUI on&nbsp;&nbsp;

- [00:06:40](https://www.youtube.com/watch?v=16-b1AjvyBE&t=400) the Kaggle notebook. Unfortunately, the Kaggle&nbsp; is not allowing to use public Gradio sharing&nbsp;&nbsp;

- [00:06:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=407) anymore. Therefore, we are going to use a specific&nbsp; way. So first, click the link that you will see&nbsp;&nbsp;

- [00:06:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=414) on your screen, read the description and the&nbsp; steps. Get your authentication token, copy it,&nbsp;&nbsp;

- [00:07:01](https://www.youtube.com/watch?v=16-b1AjvyBE&t=421) then paste your authentication token where you&nbsp; will see your token here, then execute the cell.&nbsp;&nbsp;

- [00:07:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=427) Whenever you start your GUI, you need to execute&nbsp; this cell. So it will give you a link here that&nbsp;&nbsp;

- [00:07:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=434) you will see on your screen. Open it and just&nbsp; wait before clicking visit site. Then we will&nbsp;&nbsp;

- [00:07:21](https://www.youtube.com/watch?v=16-b1AjvyBE&t=441) execute this link. This will also download the&nbsp; very best as the SDXL DreamBooth configuration&nbsp;&nbsp;

- [00:07:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=447) automatically for you, which is curated for&nbsp; Kaggle. With this configuration, we will be able&nbsp;&nbsp;

- [00:07:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=453) to do full fine tuning, full DreamBooth training&nbsp; of Stable Diffusion XL, SDXL for free on Kaggle,&nbsp;&nbsp;

- [00:07:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=461) which is amazing. If you had used the paid&nbsp; services, you would get much lesser quality and&nbsp;&nbsp;

- [00:07:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=467) you would pay huge amount of money. However, I am&nbsp; bringing all of these to you for free so that you&nbsp;&nbsp;

- [00:07:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=473) can use that. I have made over 100 full trainings&nbsp; to find the best hyper parameters for Kohya to do&nbsp;&nbsp;

- [00:08:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=482) Stable Diffusion XL, SDXL DreamBooth training. So&nbsp; you will have all of it. After this cell executed,&nbsp;&nbsp;

- [00:08:08](https://www.youtube.com/watch?v=16-b1AjvyBE&t=488) you will get this screen, then go to the other&nbsp; link that we have opened and click the visit site.&nbsp;&nbsp;

- [00:08:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=495) And now you see, we have loaded our Kohya GUI, as&nbsp; you are seeing right now, then we will begin with&nbsp;&nbsp;

- [00:08:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=502) loading the configuration file. So click here,&nbsp; return back to your notebook. And when you go to&nbsp;&nbsp;

- [00:08:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=509) the output folder and refresh it by clicking here,&nbsp; you should see the configuration. Yes, we see the&nbsp;&nbsp;

- [00:08:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=516) configuration. Kaggle_SDXL_DreamBooth_Best.json.&nbsp; Click this here to copy file path, then paste it&nbsp;&nbsp;

- [00:08:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=523) here. Click load. It will load the very best&nbsp; configuration for you. All you need to do is&nbsp;&nbsp;

- [00:08:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=529) just data set preparation, nothing else. So to&nbsp; be able to use your training images, you need to&nbsp;&nbsp;

- [00:08:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=536) first generate a data set in the Kaggle. So click&nbsp; this icon here. It will allow you to upload files,&nbsp;&nbsp;

- [00:09:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=543) click browse files, go to your training images,&nbsp; wherever they are. My training images are in&nbsp;&nbsp;

- [00:09:08](https://www.youtube.com/watch?v=16-b1AjvyBE&t=548) here and this is my training images data set.&nbsp; They are all 1024 pixels exactly. This is not a&nbsp;&nbsp;

- [00:09:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=557) very good data set. Why? Because I have repeating&nbsp; backgrounds and I have repeating clothing. This is&nbsp;&nbsp;

- [00:09:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=562) a decent data set, but not a good data set. I have&nbsp; different distances as you are seeing right now,&nbsp;&nbsp;

- [00:09:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=567) close shot, mid shot, and I have different angles.&nbsp; I don't have different emotions. If you want to&nbsp;&nbsp;

- [00:09:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=572) have different emotions in the output, you can&nbsp; also add them. So this is my medium quality data&nbsp;&nbsp;

- [00:09:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=578) set. Hopefully I will make a much better and&nbsp; bigger tutorial. I will explain all of them.&nbsp;&nbsp;

- [00:09:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=583) So stay subscribed. So I select all of them with&nbsp; control A and open. I have to enter a data set&nbsp;&nbsp;

- [00:09:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=590) title. When entering a data set title here,&nbsp; make sure that you use English characters and&nbsp;&nbsp;

- [00:09:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=594) no spaces. My_train_images, whatever the name you&nbsp; want to give. This is private. So no one else will&nbsp;&nbsp;

- [00:10:01](https://www.youtube.com/watch?v=16-b1AjvyBE&t=601) see them. Click create. They will get uploaded&nbsp; into my Kaggle data sets. If you want to use&nbsp;&nbsp;

- [00:10:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=607) anything with a Kaggle notebook, you should make&nbsp; a data set first. Whether they are models, whether&nbsp;&nbsp;

- [00:10:12](https://www.youtube.com/watch?v=16-b1AjvyBE&t=612) they are images, whatever they are, or whether&nbsp; they are a configuration file. And now you see,&nbsp;&nbsp;

- [00:10:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=617) I have my data set here. If I do training again,&nbsp; I don't need to re-upload. When you click add data&nbsp;&nbsp;

- [00:10:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=623) set and when you click your data sets here,&nbsp; you will see it. And when you click this plus&nbsp;&nbsp;

- [00:10:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=629) icon and they will get added into your running&nbsp; notebook session. So my data set is added now.&nbsp;&nbsp;

- [00:10:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=634) I click copy file path and I paste it here into&nbsp; training images. I will train up to 100 repeating.&nbsp;&nbsp;

- [00:10:42](https://www.youtube.com/watch?v=16-b1AjvyBE&t=642) And since this is a dual GPU, it will be total&nbsp; 200 epochs. Now the epoch calculation is really,&nbsp;&nbsp;

- [00:10:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=650) really confusing at the beginning. Hard to&nbsp; understand. One epoch means that all of your&nbsp;&nbsp;

- [00:10:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=656) training images are one time trained. Since we are&nbsp; going to do training with dual GPU at one step,&nbsp;&nbsp;

- [00:11:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=663) we will train two images. Therefore, with 100&nbsp; repeating, we will actually do 200 epochs. You&nbsp;&nbsp;

- [00:11:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=670) don't need to think about it a lot because I will&nbsp; also show you how to get checkpoints and compare&nbsp;&nbsp;

- [00:11:16](https://www.youtube.com/watch?v=16-b1AjvyBE&t=676) them. So you will find the best checkpoint.&nbsp; Regularization images. They are also here as&nbsp;&nbsp;

- [00:11:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=682) you are seeing right now. So copy directory and&nbsp; put it here like this. Regularization images&nbsp;&nbsp;

- [00:11:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=687) repeat 1. Instance prompt. it will be a rare&nbsp; token ohwx and the class prompt will be man.&nbsp;&nbsp;

- [00:11:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=694) I have other tutorials. If you want to learn&nbsp; more about instance prompt and class prompt,&nbsp;&nbsp;

- [00:11:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=699) you can watch them. They are all linked in the&nbsp; GitHub Readme file, as you are seeing right now.&nbsp;&nbsp;

- [00:11:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=705) So destination directory, this will be inside&nbsp; in our working directory in outputs like this.&nbsp;&nbsp;

- [00:11:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=713) So everything will be saved here. Click prepare&nbsp; training data, copy info to folders tab. And now&nbsp;&nbsp;

- [00:11:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=719) you see they are all ready. You can give any model&nbsp; output name. I will use My_DB_Kaggle and you can&nbsp;&nbsp;

- [00:12:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=725) see they are all copied here. Now we will be using&nbsp; more output folder size as you are seeing right&nbsp;&nbsp;

- [00:12:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=731) now. The outputs arrived here after I clicked&nbsp; refresh. However, since each checkpoint will be&nbsp;&nbsp;

- [00:12:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=738) about 7 gigabytes, we don't have sufficient output&nbsp; folder space. So what we are going to do is we&nbsp;&nbsp;

- [00:12:25](https://www.youtube.com/watch?v=16-b1AjvyBE&t=745) are going to save them into the Kaggle temporary&nbsp; models folder. So copy the path from here, go back&nbsp;&nbsp;

- [00:12:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=753) to your Kohya GUI, go back to folders and change&nbsp; the output folders model path. Make it how you&nbsp;&nbsp;

- [00:12:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=761) should make it unique to make it like Kaggle temp&nbsp; models. Because this directory has been generated&nbsp;&nbsp;

- [00:12:46](https://www.youtube.com/watch?v=16-b1AjvyBE&t=766) automatically. So go back to here and change it&nbsp; to this. This is really important. If you give&nbsp;&nbsp;

- [00:12:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=772) another name, it may not work because the models&nbsp; folder may not be automatically generated by&nbsp;&nbsp;

- [00:12:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=778) the Kohya in the second time. So use this models&nbsp; folder. So the model files, the checkpoints will&nbsp;&nbsp;

- [00:13:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=783) be saved into the temporary space of the Kaggle,&nbsp; and Kaggle provides us about 50 gigabyte temporary&nbsp;&nbsp;

- [00:13:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=790) space available. You see from here, which makes&nbsp; roughly we can take like seven checkpoints, but&nbsp;&nbsp;

- [00:13:16](https://www.youtube.com/watch?v=16-b1AjvyBE&t=796) we will stop at taking 6 checkpoints to be sure.&nbsp; Okay. Now the parameters. There is one parameter&nbsp;&nbsp;

- [00:13:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=803) that you need to set, which is when you go to&nbsp; the advanced tab, save every N steps. Now you&nbsp;&nbsp;

- [00:13:30](https://www.youtube.com/watch?v=16-b1AjvyBE&t=810) need to calculate this yourself. For calculating&nbsp; it easily click print training command here, and&nbsp;&nbsp;

- [00:13:37](https://www.youtube.com/watch?v=16-b1AjvyBE&t=817) it will display how many training steps that it is&nbsp; going to take. Since I have 13 images, it is going&nbsp;&nbsp;

- [00:13:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=823) to take 13 multiplied with repeating 100, 1300&nbsp; divided to 1 because the batch size is 1, divided&nbsp;&nbsp;

- [00:13:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=832) to 1 because the gradient accumulation steps are&nbsp; 1 and multiplied with 1 because we are going to do&nbsp;&nbsp;

- [00:13:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=838) training with only 1 epoch and multiplied with 2&nbsp; because we are also using regularization images.&nbsp;&nbsp;

- [00:14:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=844) So the total training will take 2,600 steps&nbsp; and we will do total 200 epochs training. If&nbsp;&nbsp;

- [00:14:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=851) I want to take 5 checkpoints, you just need to&nbsp; divide this into 5. So 2,600 divided to 5, 520&nbsp;&nbsp;

- [00:14:19](https://www.youtube.com/watch?v=16-b1AjvyBE&t=859) steps. This is the step count that I need to get&nbsp; checkpoints. So 520 steps. With every 520 steps,&nbsp;&nbsp;

- [00:14:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=867) I will get a checkpoint and I will download all&nbsp; of them. And after that, you can save your json&nbsp;&nbsp;

- [00:14:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=872) if you want to use it later. Then you can download&nbsp; it from here if you wish and we are ready. Then&nbsp;&nbsp;

- [00:14:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=878) click start training and you don't need to do&nbsp; anything else. This training will start. First&nbsp;&nbsp;

- [00:14:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=884) it will cache all of the images that we are going&nbsp; to use, including the regularization images. The&nbsp;&nbsp;

- [00:14:51](https://www.youtube.com/watch?v=16-b1AjvyBE&t=891) caching will take some time. It will also display&nbsp; you everything here. You see, it is going to fully&nbsp;&nbsp;

- [00:14:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=896) load models into both of the GPUs. So it is not&nbsp; like we can combine the VRAM of the both GPU and&nbsp;&nbsp;

- [00:15:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=903) it will download the SDXL base model and it will&nbsp; download the SDXL 32 precision VAE as well. So&nbsp;&nbsp;

- [00:15:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=911) our models will have the best SDXL VAE already&nbsp; embedded. The download speed of Kaggle is just&nbsp;&nbsp;

- [00:15:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=918) amazing. As you are seeing right now, then it is&nbsp; going to load the models into the VRAM after they&nbsp;&nbsp;

- [00:15:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=924) are downloaded. You see additional VAE is loaded.&nbsp; I have prepared everything for you. So it is just&nbsp;&nbsp;

- [00:15:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=931) super easy for you. You don't need to do anything.&nbsp; First, it will cache latents, then it will start&nbsp;&nbsp;

- [00:15:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=936) training. The training for 2600 steps is taking&nbsp; about 3.5 hours. When the caching included, it is&nbsp;&nbsp;

- [00:15:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=945) going to take like 4 hours, which is amazing. Why?&nbsp; I will explain in a moment once the caching is&nbsp;&nbsp;

- [00:15:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=952) completed. So the training has been started. You&nbsp; see, currently we are getting 5.08 seconds IT and&nbsp;&nbsp;

- [00:16:00](https://www.youtube.com/watch?v=16-b1AjvyBE&t=960) you may say this is slow. No, this is actually&nbsp; a great speed. Why? Because currently we are&nbsp;&nbsp;

- [00:16:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=967) utilizing dual GPU. Therefore, this is actively&nbsp; 2.5 seconds per IT and on my RTX 3090 Ti GPU,&nbsp;&nbsp;

- [00:16:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=978) I am getting like 1.6 second IT. So we are almost&nbsp; getting a free RTX 3090 Ti GPU from Kaggle for&nbsp;&nbsp;

- [00:16:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=989) free every week, 30 hours. This is amazing speed.&nbsp; So the total training is going to take like 3&nbsp;&nbsp;

- [00:16:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=996) hours and 32 minutes plus 7 minutes are passed. So&nbsp; it is about 4 hours in total for training. So just&nbsp;&nbsp;

- [00:16:46](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1006) wait and we will download all of the models after&nbsp; the training has been completed. You cannot close&nbsp;&nbsp;

- [00:16:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1012) your browser while the training is happening.&nbsp; This is a limitation of free Kaggle. Therefore,&nbsp;&nbsp;

- [00:16:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1018) your computer and browser has to be open during&nbsp; the entire training session. Currently, we are&nbsp;&nbsp;

- [00:17:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1024) using 32.4 gigabytes on our temporary disk. After&nbsp; checkpoints are generated, we will use more. So&nbsp;&nbsp;

- [00:17:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1034) we will compare once the first checkpoint has been&nbsp; generated. The first checkpoint will be generated&nbsp;&nbsp;

- [00:17:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1040) after exactly 520 steps because we did set it like&nbsp; that and currently we are at the 108th step. So&nbsp;&nbsp;

- [00:17:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1049) the first checkpoint has been generated. You see&nbsp; exactly at the 20% steps because we have divided&nbsp;&nbsp;

- [00:17:37](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1057) the number of steps that are required to 5. So we&nbsp; got our first checkpoint. This is its saved name&nbsp;&nbsp;

- [00:17:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1065) and you see the disk usage is now 38.9 gigabytes&nbsp; and the training is continuing successfully. We&nbsp;&nbsp;

- [00:17:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1073) just need to wait. Unfortunately, there is no way&nbsp; to download this model before canceling or waiting&nbsp;&nbsp;

- [00:18:01](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1081) the training to finish. Therefore, we have to wait&nbsp; until the training has been completed to download&nbsp;&nbsp;

- [00:18:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1086) this saved checkpoint since it is saved in the&nbsp; temporary folder. We are going to use the Hugging&nbsp;&nbsp;

- [00:18:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1094) Face repository upload method, which will be super&nbsp; fast for uploading. And when you are downloading,&nbsp;&nbsp;

- [00:18:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1100) it will be also super fast. I will show in a&nbsp; moment after the training has been completed.&nbsp;&nbsp;

- [00:18:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1106) All right, the training has been completed.&nbsp; It took 3 hours and 44 minutes. However, we&nbsp;&nbsp;

- [00:18:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1113) have an issue. You see, currently we are using 77&nbsp; gigabytes of temporary memory and they are giving&nbsp;&nbsp;

- [00:18:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1119) us only 73 gigabytes of hard drive. Therefore, we&nbsp; need to reduce the number of saved checkpoints.&nbsp;&nbsp;

- [00:18:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1127) We saved 5 checkpoints. However, since it was&nbsp; exactly as the 20% of the steps, it also saved&nbsp;&nbsp;

- [00:18:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1136) the last step 2 times. So how to prevent it?&nbsp; Instead of using the exactly divided step number,&nbsp;&nbsp;

- [00:19:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1143) increase this by 1 step. So make it 521 steps. So&nbsp; you will not get the last step saved checkpoint.&nbsp;&nbsp;

- [00:19:12](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1152) You will get the end of the checkpoint that the&nbsp; model generates. Therefore, remember when you are&nbsp;&nbsp;

- [00:19:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1157) watching this tutorial, make the step count 1 more&nbsp; than the division of the 5. All right. So how are&nbsp;&nbsp;

- [00:19:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1166) we going to download the generated models right&nbsp; now? There are two ways to download them. The&nbsp;&nbsp;

- [00:19:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1172) first way is moving them into the output directory&nbsp; and downloading from there. To do that, we need to&nbsp;&nbsp;

- [00:19:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1179) first cancel run, which is the running instance&nbsp; of the Kohya GUI. So I will cancel the run. Okay,&nbsp;&nbsp;

- [00:19:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1185) now I can execute the other cells. The first&nbsp; cell that we will execute is this cell. This&nbsp;&nbsp;

- [00:19:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1192) cell will list the directory of the temporary&nbsp; models folder where we have saved our models.&nbsp;&nbsp;

- [00:19:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1198) And these are the models that have been saved as&nbsp; you are seeing right now. So we can download them&nbsp;&nbsp;

- [00:20:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1203) one by one. Let's say we want to download the&nbsp; first checkpoint, which is this one. Copy its&nbsp;&nbsp;

- [00:20:09](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1209) name. Change the name here like this. Execute&nbsp; this cell. After you executed this cell, this&nbsp;&nbsp;

- [00:20:16](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1216) model will be also copied into the Kaggle working&nbsp; directory. We will see it in a moment after this&nbsp;&nbsp;

- [00:20:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1222) cell execution has been completed. The temporary&nbsp; disk space of the Kaggle is really really slow&nbsp;&nbsp;

- [00:20:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1229) compared to the output folder's hard drive space.&nbsp; Actually, there was once a bug which made it much&nbsp;&nbsp;

- [00:20:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1236) more slower than the output. By the way, it looks&nbsp; like it is also counting the output folder in this&nbsp;&nbsp;

- [00:20:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1243) total disk space utilization. Okay, it is almost&nbsp; completed. Yes, it is completed. Now refresh here&nbsp;&nbsp;

- [00:20:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1250) and you see the safetensor file is also here.&nbsp; So you can click these three dots and click&nbsp;&nbsp;

- [00:20:55](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1255) download. When you do this, watch the address bar&nbsp; of your browser. If you start multiple downloads,&nbsp;&nbsp;

- [00:21:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1262) it will ask you to allow multiple downloads from&nbsp; Kaggle.com and it will not display the download&nbsp;&nbsp;

- [00:21:08](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1268) status. So how you will know the download status?&nbsp; You need to open your task manager, go to the&nbsp;&nbsp;

- [00:21:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1274) performance and check out your ethernet. So you&nbsp; see currently it is downloading with 200 megabits&nbsp;&nbsp;

- [00:21:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1280) per second. Once the download is completed, I will&nbsp; see an immediate download from my browser. So it&nbsp;&nbsp;

- [00:21:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1287) will be immediately saved into the downloads&nbsp; folder. But I am not suggesting to do this&nbsp;&nbsp;

- [00:21:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1292) methodology. Because you have to move every file&nbsp; one by one and you will not see the progress of&nbsp;&nbsp;

- [00:21:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1298) download. For example, if I want to also download&nbsp; the second checkpoint, I have to first remove this&nbsp;&nbsp;

- [00:21:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1305) first checkpoint from the output folder by using&nbsp; this. This will delete this model from here. So&nbsp;&nbsp;

- [00:21:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1312) I will be able to repeat the first process and&nbsp; move the second model into the output folder. So&nbsp;&nbsp;

- [00:21:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1319) what I suggest, I suggest you to do Hugging Face&nbsp; upload methodology. To do that, you need to have&nbsp;&nbsp;

- [00:22:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1324) a Hugging Face account. The join link is here. You&nbsp; can click this join and register. Currently I will&nbsp;&nbsp;

- [00:22:12](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1332) also register to show you. So this is the account&nbsp; that I am going to use for registering. I written&nbsp;&nbsp;

- [00:22:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1338) a password, click next. It will ask you username&nbsp; and other stuff. So let's make this account as&nbsp;&nbsp;

- [00:22:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1344) video tutorials. Let's say my username. Okay.&nbsp; Other things are not important. I have read,&nbsp;&nbsp;

- [00:22:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1352) create account. Okay. It is first asking me human&nbsp; verification. This may be an interesting issue&nbsp;&nbsp;

- [00:22:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1359) for you. So let's make it like this. Okay. It&nbsp; was success and we got our account. We need to&nbsp;&nbsp;

- [00:22:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1365) verify our email. So let's verify it. Okay. It is&nbsp; verified. So then you need to go to the new model.&nbsp;&nbsp;

- [00:22:51](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1371) This is important. Click new model, give a model&nbsp; name, my checkpoints, whatever the model name you&nbsp;&nbsp;

- [00:22:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1378) want. You can make it private or public. I will&nbsp; make it private. So no one else will be able to&nbsp;&nbsp;

- [00:23:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1383) see or download it. So this will be my username&nbsp; and model folder. Click here to copy it, return&nbsp;&nbsp;

- [00:23:09](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1389) back to your Kaggle notebook, change the repo ID&nbsp; from here. The folder path is this folder where I&nbsp;&nbsp;

- [00:23:16](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1396) have generated and saved the models. So you don't&nbsp; need to change it. Then click this icon first. It&nbsp;&nbsp;

- [00:23:21](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1401) will ask you to enter your token. So how will you&nbsp; generate the token? When you go back to our GitHub&nbsp;&nbsp;

- [00:23:28](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1408) readme file, you see there is a tokens link, right&nbsp; click and open it in browser. Alternatively, you&nbsp;&nbsp;

- [00:23:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1413) can click here and you can go to settings. In the&nbsp; settings you will have access tokens. Click here,&nbsp;&nbsp;

- [00:23:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1419) click new token, make sure that you have selected&nbsp; write. This is super important. And let's say&nbsp;&nbsp;

- [00:23:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1424) upload. Any name you can give, generate token,&nbsp; copy the token from here, go back to your Kaggle,&nbsp;&nbsp;

- [00:23:51](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1431) paste it, click login. And you see token is valid&nbsp; permission write. This is super important. Then&nbsp;&nbsp;

- [00:23:57](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1437) set the repo ID, as I said from here and click&nbsp; this play icon. So this will upload all of the&nbsp;&nbsp;

- [00:24:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1445) models into the Hugging Face repository that&nbsp; you have made permanently. And then later you&nbsp;&nbsp;

- [00:24:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1451) can download them as you wish whenever you want&nbsp; with ultra fast speed. I thank a lot the Kaggle&nbsp;&nbsp;

- [00:24:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1458) and Hugging Face from here. They are hugely&nbsp; contributing to the machine learning, to the&nbsp;&nbsp;

- [00:24:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1464) AI space. Their importance are significant. So&nbsp; I thank them a lot. I suggest you to also follow&nbsp;&nbsp;

- [00:24:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1471) this strategy to upload. In the first run it&nbsp; may take a while because it is first calculating&nbsp;&nbsp;

- [00:24:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1478) the hashes of the models. Then it will start&nbsp; uploading. You see our model download is also&nbsp;&nbsp;

- [00:24:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1483) just completed after downloading. And now when I&nbsp; check my Ethernet, you see the speed is dropped&nbsp;&nbsp;

- [00:24:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1490) like this, the internet usage speed. So as I said,&nbsp; you can move each file one by one and download&nbsp;&nbsp;

- [00:24:57](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1497) them. Alternatively, you can upload all of them&nbsp; to the Hugging Face. Let's just wait a little bit.&nbsp;&nbsp;

- [00:25:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1502) So after you upload those files into the Hugging&nbsp; Face, where they will appear. When you go to the&nbsp;&nbsp;

- [00:25:08](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1508) profile, go to your model's checkpoints here. Go&nbsp; to files and versions, they will be here. And this&nbsp;&nbsp;

- [00:25:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1514) will be only visible to you because it is set to&nbsp; private. No one else will be able to access them.&nbsp;&nbsp;

- [00:25:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1520) Let's just wait a little bit more. Okay. Meanwhile&nbsp; waiting it, the below is for LoRA training. I will&nbsp;&nbsp;

- [00:25:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1526) search for better configuration for LoRA training,&nbsp; but I don't suggest you to do LoRA training. SDXL&nbsp;&nbsp;

- [00:25:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1533) DreamBooth is much more stronger and better&nbsp; than the LoRA. So if you really need LoRAs,&nbsp;&nbsp;

- [00:25:40](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1540) then you can use the Kohya GUI version to extract&nbsp; LoRAs out of the fully trained checkpoints,&nbsp;&nbsp;

- [00:25:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1547) fully trained models. And they are much better&nbsp; quality than the LoRA training itself. Hopefully&nbsp;&nbsp;

- [00:25:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1553) I will make a video about that too. You can use&nbsp; your own computer to extract them. You don't&nbsp;&nbsp;

- [00:25:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1559) need VRAM actually for doing that. So it will&nbsp; be hopefully a topic of another video. I will&nbsp;&nbsp;

- [00:26:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1565) search for the best LoRA extraction settings and&nbsp; share them with you. I will also search for best&nbsp;&nbsp;

- [00:26:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1571) LoRA training configuration as well. But this&nbsp; is the configuration I have at the moment when&nbsp;&nbsp;

- [00:26:16](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1576) you download this notebook, you will have that.&nbsp; So on our channel, I suggest you to watch these&nbsp;&nbsp;

- [00:26:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1583) 2 tutorials as well if you wish to learn more&nbsp; about using the Kaggle, using the Automatic1111&nbsp;&nbsp;

- [00:26:30](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1590) Web UI on a Kaggle and watch this tutorial to&nbsp; learn more about LoRA training if you prefer.&nbsp;&nbsp;

- [00:26:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1596) Hopefully new tutorials are coming too. So please&nbsp; subscribe to our channel. You won't regret it&nbsp;&nbsp;

- [00:26:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1601) believe me. The upload still didn't start. I think&nbsp; it is taking time to calculate hash all of the&nbsp;&nbsp;

- [00:26:48](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1608) models. We can see the CPU usage and the RAM usage&nbsp; because it is working right now. So from these&nbsp;&nbsp;

- [00:26:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1614) uploaded models, actually this final file, you&nbsp; see it is named like this, is equal to 2600 steps&nbsp;&nbsp;

- [00:27:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1623) model. So these 2 model checkpoints are actually&nbsp; duplicate. As I have explained to prevent that, we&nbsp;&nbsp;

- [00:27:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1631) need to make minimum number of steps to generate&nbsp; checkpoint is 1 plus of the division. So calculate&nbsp;&nbsp;

- [00:27:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1640) the number of steps, multiply it with 5 and add&nbsp; 1 step. So the upload has been started. You see&nbsp;&nbsp;

- [00:27:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1646) the upload speed. It is huge. Currently, it is&nbsp; uploading 5 models and the total upload speed&nbsp;&nbsp;

- [00:27:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1653) is like 100 megabytes per second. So it is equal&nbsp; to 800 megabits per second. You see the speed. It&nbsp;&nbsp;

- [00:27:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1661) is huge. Once these uploads have been completed,&nbsp; we will download them from the Hugging Face as we&nbsp;&nbsp;

- [00:27:46](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1666) wish. So all of the uploads have been completed.&nbsp; You see it took total like 5 minutes and not more&nbsp;&nbsp;

- [00:27:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1673) than that to upload all of the models. So you see&nbsp; we got the link here where the uploads have been&nbsp;&nbsp;

- [00:27:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1679) completed. Let's refresh our files and versions&nbsp; and you see all of the files are here. We already&nbsp;&nbsp;

- [00:28:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1686) have downloaded this checkpoint. Now I will&nbsp; download the other ones too. So click this icon&nbsp;&nbsp;

- [00:28:13](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1693) and it will ask you where to download. So I will&nbsp; download them here. Let's download all of them.&nbsp;&nbsp;

- [00:28:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1698) Why I am downloading all models because I will do&nbsp; a checkpoint comparison. So instead of these 2600&nbsp;&nbsp;

- [00:28:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1706) steps, I am going to download this file. This&nbsp; is the which one was the latest. So if we look&nbsp;&nbsp;

- [00:28:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1714) at the checkpoints, yeah, the last checkpoint is&nbsp; My_DB_Kaggle.safetensors. So that is the one we&nbsp;&nbsp;

- [00:28:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1721) are going to download, which is this one. This&nbsp; is the last checkpoint. This one is equal to&nbsp;&nbsp;

- [00:28:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1725) 2600 steps. So this model that contains one step&nbsp; shouldn't have been generated. I will tell this to&nbsp;&nbsp;

- [00:28:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1732) the developer for fixing and our last checkpoint&nbsp; is named like this. So let's also download it. All&nbsp;&nbsp;

- [00:28:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1738) the files are getting downloaded as you are seeing&nbsp; right now. Let's see the download speed. You see&nbsp;&nbsp;

- [00:29:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1743) it is 430 megabits per second and my maximum&nbsp; download speed is 500 megabits. So it is almost&nbsp;&nbsp;

- [00:29:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1750) maximum. Okay, now we are completely done with the&nbsp; Kaggle. So we don't need anything else from here.&nbsp;&nbsp;

- [00:29:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1757) Then you can terminate your session by clicking&nbsp; here and start using your models. Now I will show&nbsp;&nbsp;

- [00:29:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1764) how to do a checkpoint comparison to find the best&nbsp; checkpoint among all of the same checkpoints. So&nbsp;&nbsp;

- [00:29:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1771) let's terminate this and I still have over 19&nbsp; hours this week. When I hover my mouse here,&nbsp;&nbsp;

- [00:29:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1778) you see it shows when my quota will be reset. So&nbsp; all of the downloads have been completed. I am&nbsp;&nbsp;

- [00:29:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1785) going to do a fresh installation of Automatic1111&nbsp; UI. Let's go to our automatic installer list. In&nbsp;&nbsp;

- [00:29:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1792) here we have automatic windows installer which&nbsp; is automatic installer for SDXL. So let's open&nbsp;&nbsp;

- [00:29:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1798) this link and we have automatic installer bat&nbsp; file here. Let's download it. Where should we&nbsp;&nbsp;

- [00:30:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1805) install? I will install it into my F drive.&nbsp; Let's say test. Let's enter inside test and&nbsp;&nbsp;

- [00:30:12](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1812) let's double click. More info around anyway.&nbsp; It is cloning the Automatic1111 Web UI. This&nbsp;&nbsp;

- [00:30:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1818) will install everything automatically for you.&nbsp; It skipped the download SDXL.py file because it&nbsp;&nbsp;

- [00:30:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1824) doesn't exist. We didn't download it. I will move&nbsp; my models into this folder. So they were inside my&nbsp;&nbsp;

- [00:30:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1831) downloads folder. Let's refresh and let's cut all&nbsp; of the downloaded files. This is from yesterday,&nbsp;&nbsp;

- [00:30:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1838) not today. And let's move them into the models&nbsp; folder. If you don't have a GPU having computer,&nbsp;&nbsp;

- [00:30:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1845) then you can follow my how to use Kaggle for&nbsp; Automatic1111 Web UI tutorial and you can upload&nbsp;&nbsp;

- [00:30:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1853) these models to your Kaggle with just wget into&nbsp; the models folder and use them. So it is very&nbsp;&nbsp;

- [00:31:00](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1860) easy to upload them once you have them on your&nbsp; Hugging Face account. If you want to use these&nbsp;&nbsp;

- [00:31:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1866) with wget command, all you need to do is right:&nbsp; click copy link address, then entering inside the&nbsp;&nbsp;

- [00:31:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1874) models folder. Wget this link, remove this part&nbsp; and that's it. However, for this to work, you need&nbsp;&nbsp;

- [00:31:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1880) to make this public. So when you are downloading&nbsp; into your Kaggle or Google Cloud or RunPod, make&nbsp;&nbsp;

- [00:31:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1886) it public temporarily, then make it private again&nbsp; and it will allow you to quickly download models.&nbsp;&nbsp;

- [00:31:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1893) All right, automatic installer is installing. Our&nbsp; models are here. These models have the embedded&nbsp;&nbsp;

- [00:31:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1899) VAE the best VAE so we don't need a secondary VAE&nbsp; for this to work. Okay, the installation has been&nbsp;&nbsp;

- [00:31:46](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1906) completed. The Stable Diffusion Automatic1111&nbsp; Web UI automatically started. We can see the&nbsp;&nbsp;

- [00:31:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1912) checkpoints here. There are several things that&nbsp; I do. First of all, go to the settings tab,&nbsp;&nbsp;

- [00:31:57](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1917) in here go to the user interface, in here&nbsp; make VAE from here like this. Apply settings&nbsp;&nbsp;

- [00:32:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1924) and then go to the extensions click available,&nbsp; load from. Select after. Search for after and&nbsp;&nbsp;

- [00:32:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1931) install After Detailer. You see this extension,&nbsp; click install and you can watch the status from&nbsp;&nbsp;

- [00:32:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1937) here. So you see my automatic installer installed&nbsp; everything for me. What you need for this to work,&nbsp;&nbsp;

- [00:32:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1943) you need to have Python installed. You see my&nbsp; default Python is 3.10.11 and plus to that, you&nbsp;&nbsp;

- [00:32:30](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1950) need to have Git installed. When you type git, you&nbsp; should get a message like this git. All right the&nbsp;&nbsp;

- [00:32:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1956) web UI is getting reloaded. It is installing the&nbsp; necessary requirements. Everything is installed.&nbsp;&nbsp;

- [00:32:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1963) After this go to installed tab apply and restart&nbsp; the UI so you will have the newly installed&nbsp;&nbsp;

- [00:32:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1969) extension. We also should add --no-half-vae to our&nbsp; web UI. So it is here: I am editing webui-user.bat&nbsp;&nbsp;

- [00:33:01](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1981) file so let's add no-half-vae and after that&nbsp; I will restart the web UI. So let's go back to&nbsp;&nbsp;

- [00:33:09](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1989) Web UI and start again. This is how you start the&nbsp; Automatic1111 Web UI. I am starting with xFormers&nbsp;&nbsp;

- [00:33:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=1994) and no-half-vae. After detailer is initialized.&nbsp; I will make this none so it will use the embedded&nbsp;&nbsp;

- [00:33:21](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2001) VAE. I prefer to use DPM++ 2M SDE Karras. This is&nbsp; really important as a sampling method and first&nbsp;&nbsp;

- [00:33:30](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2010) we need to decide which checkpoint is best.&nbsp; But before start there is one more thing that&nbsp;&nbsp;

- [00:33:35](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2015) I will do. There haven't been any significant&nbsp; updates to the Automatic1111 Web UI for weeks,&nbsp;&nbsp;

- [00:33:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2024) actually for months. When we go to the development&nbsp; branch in the Web UI GitHub repository, we will&nbsp;&nbsp;

- [00:33:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2030) see that it is 367 commits ahead. Therefore, I&nbsp; will update the Web UI branch to the development&nbsp;&nbsp;

- [00:34:01](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2041) branch. So how will we do that? Let's close this.&nbsp; Let's go back to our installation, start a cmd&nbsp;&nbsp;

- [00:34:08](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2048) like this and do git checkout dev. Now we are at&nbsp; the development branch. Let's also update it. Git&nbsp;&nbsp;

- [00:34:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2055) pull and now we are at the latest version of the&nbsp; development branch. Then let's restart the Web UI&nbsp;&nbsp;

- [00:34:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2062) like this and I will use the amazing prompts that&nbsp; I have found after a lot of research to do x/y/z&nbsp;&nbsp;

- [00:34:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2071) checkpoint comparison testing. The prompts are in&nbsp; this post. Let's click it from here. You see it&nbsp;&nbsp;

- [00:34:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2078) is under suggested resources in the GitHub Readme&nbsp; file. This Readme file will be in the description&nbsp;&nbsp;

- [00:34:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2083) of the video and you see there is version 1&nbsp; prompt list.pdf or you can also download the&nbsp;&nbsp;

- [00:34:48](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2088) images and use the png info. Actually, let's&nbsp; do that. So these are the images. They are&nbsp;&nbsp;

- [00:34:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2094) getting downloaded. Let's open, extract and the&nbsp; images are here. So now I can use png info. You&nbsp;&nbsp;

- [00:35:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2102) can alternatively also download the pdf file and&nbsp; use that. So the prompt images are here. I have&nbsp;&nbsp;

- [00:35:08](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2108) gone to the PNG info tab. Now I will just drag and&nbsp; drop the image that I want to use as a checkpoint&nbsp;&nbsp;

- [00:35:16](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2116) comparison testing. You see the prompt images&nbsp; are here. Which one we should use? Maybe yeah,&nbsp;&nbsp;

- [00:35:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2123) let's let's use this one perhaps. This is a good&nbsp; one. Let's see the image. It is a decent image.&nbsp;&nbsp;

- [00:35:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2129) By the way with the very best configuration&nbsp; that I have on Patreon right now, I can get&nbsp;&nbsp;

- [00:35:35](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2135) even better than this image. This image has been&nbsp; generated without Text Encoder. Unfortunately,&nbsp;&nbsp;

- [00:35:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2141) the Kaggle performance is not as good as you are&nbsp; doing it in your computer with 24 gigabyte GPU or&nbsp;&nbsp;

- [00:35:48](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2148) on RunPod. But still, we will see the performance&nbsp; of the Kaggle training. I will use sampling steps&nbsp;&nbsp;

- [00:35:55](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2155) 20. You can also use 40. It will be a little&nbsp; bit better, but for this demonstration let's&nbsp;&nbsp;

- [00:36:00](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2160) use 20. You see this is the rare token that we did&nbsp; training ohwx man. If you are training with woman,&nbsp;&nbsp;

- [00:36:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2167) you need to change this woman or whatever the&nbsp; rare token and the class token you have chosen.&nbsp;&nbsp;

- [00:36:13](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2173) Don't forget that. Width and height has to be 1024&nbsp; to 1024. Or if you have done the training with a&nbsp;&nbsp;

- [00:36:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2180) different resolution then you should use it. Let's&nbsp; make the batch count 9. Let's make this random&nbsp;&nbsp;

- [00:36:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2186) seed. Let's uncheck this VAE. Because we have used&nbsp; the best VAE. Now these models have the best VAE&nbsp;&nbsp;

- [00:36:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2194) automatically. You don't need any additional VAE.&nbsp; Let's enable after detailer. You see the prompt&nbsp;&nbsp;

- [00:36:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2199) is also here. Let's make the detection mask only&nbsp; the top k largest 1 so it will only inpaint my&nbsp;&nbsp;

- [00:36:47](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2207) face. If there are multiple persons in the image&nbsp; they won't get inpainted. And I will also change&nbsp;&nbsp;

- [00:36:53](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2213) the in painting denoising strength to 0.5 it is&nbsp; already like that. You don't need to change any&nbsp;&nbsp;

- [00:36:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2219) other options if you are not sure. The default are&nbsp; good. Photo of ohwx man is the prompt. Let's make&nbsp;&nbsp;

- [00:37:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2226) the x/y/z plot. So this is how we are going to do&nbsp; checkpoint comparison. We go to the very bottom.&nbsp;&nbsp;

- [00:37:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2231) We select the x/y/z plot from here. We select&nbsp; the checkpoint name from here. It will list the&nbsp;&nbsp;

- [00:37:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2237) checkpoints. I will start from the least training&nbsp; steps to the latest training steps. By the way,&nbsp;&nbsp;

- [00:37:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2243) 2600 and the very last one are same. I also&nbsp; compared them. So I will select the 2600 or&nbsp;&nbsp;

- [00:37:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2251) maybe let's select the last one. It shouldn't&nbsp; matter. And let's also make the grid margins&nbsp;&nbsp;

- [00:37:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2256) 50. All right. So this is it. Now we are ready to&nbsp; do testing. At every checkpoint it will generate 9&nbsp;&nbsp;

- [00:37:43](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2263) images with these prompts and it will also do face&nbsp; inpainting to improve the face quality. Cfg scale&nbsp;&nbsp;

- [00:37:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2270) is 7 then let's generate. Okay, the generation has&nbsp; started. With this way we will compare the outputs&nbsp;&nbsp;

- [00:37:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2278) of the each checkpoint. Then we will decide which&nbsp; one of the checkpoint is looking best. All right,&nbsp;&nbsp;

- [00:38:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2283) we got the images. There is one more thing that&nbsp; I want to mention. If your GPU is not good then&nbsp;&nbsp;

- [00:38:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2290) you should edit webui-user.bat file and add here&nbsp; like --medvram. If it is still working very slow&nbsp;&nbsp;

- [00:38:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2298) or not even working then you can add lowvram. This&nbsp; will make the application work slower but it will&nbsp;&nbsp;

- [00:38:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2306) work. So try --medvram first and if still fails,&nbsp; add --lowvram. Don't forget that. But I don't&nbsp;&nbsp;

- [00:38:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2314) need them to add right now. Okay, so we click this&nbsp; icon. It will open the outputs folder like this.&nbsp;&nbsp;

- [00:38:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2321) Let's go to the text to image grids and in here at&nbsp; the very bottom we will find the very last grid.&nbsp;&nbsp;

- [00:38:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2330) Okay. So we got the images. Let's look at them.&nbsp; Here we see the images. The first checkpoint is&nbsp;&nbsp;

- [00:38:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2338) looking very bad actually. Let me also open one of&nbsp; the images from the training data set so we will&nbsp;&nbsp;

- [00:39:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2345) have a better comparison. Let's go to the pictures&nbsp; where my training images were okay here here. For&nbsp;&nbsp;

- [00:39:13](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2353) example. Let's use this one. Okay, now we will&nbsp; have a better idea. You see the first checkpoint&nbsp;&nbsp;

- [00:39:19](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2359) is not good, then let's look at the second&nbsp; checkpoint. By the way, I am using paint.net so&nbsp;&nbsp;

- [00:39:25](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2365) this is a free image editor. The second checkpoint&nbsp; is also not looking good. Let's look at the third&nbsp;&nbsp;

- [00:39:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2371) checkpoint. The third checkpoint is very decent.&nbsp; You see you can get very good images by generating&nbsp;&nbsp;

- [00:39:39](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2379) more images. As you can see the realism is&nbsp; really good. So not all the images will be&nbsp;&nbsp;

- [00:39:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2384) super good. Because we are doing a free training.&nbsp; We don't have a 24 gigabytes but very decent and&nbsp;&nbsp;

- [00:39:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2392) my data set is not good as I said. If you improve&nbsp; your data set you will get better results. I am&nbsp;&nbsp;

- [00:39:58](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2398) using this at best medium quality data set as&nbsp; I said. So that you can get a better data set&nbsp;&nbsp;

- [00:40:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2404) than this and collect better images. Also some&nbsp; images will look according to your other images,&nbsp;&nbsp;

- [00:40:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2410) not the very best looking one. So improve your&nbsp; data set to get better quality images. Okay,&nbsp;&nbsp;

- [00:40:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2415) this is the third checkpoint. 2080 steps. Actually&nbsp; it is being effectively 4060 steps because the&nbsp;&nbsp;

- [00:40:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2422) batch size is 2. Yeah, we can see the results. The&nbsp; head of the the shape type of the head is broken&nbsp;&nbsp;

- [00:40:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2429) for some reason and this is the last checkpoint.&nbsp; Yeah, the head is broken. I think it is a little&nbsp;&nbsp;

- [00:40:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2436) bit over trained. So among these I think the best&nbsp; looking one is the third checkpoint. Maybe if we&nbsp;&nbsp;

- [00:40:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2444) had a checkpoint between these two it would be&nbsp; better. So you can do multiple trainings and&nbsp;&nbsp;

- [00:40:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2449) aim different checkpoints to see which number of&nbsp; steps are best. I think it can be between these&nbsp;&nbsp;

- [00:40:55](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2455) two on these settings. But you can also do more&nbsp; checkpoint comparison test with more images not&nbsp;&nbsp;

- [00:41:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2463) with just single prompt. So let's select another&nbsp; prompt from our downloaded prompts. Let's see&nbsp;&nbsp;

- [00:41:09](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2469) which one should we try. Okay let's try this&nbsp; prompt so I will copy the positive prompt and&nbsp;&nbsp;

- [00:41:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2477) I will copy the negative prompt. The rest will be&nbsp; same. So let's hit, generate and see the results.&nbsp;&nbsp;

- [00:41:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2482) Okay, the second test has been completed as well.&nbsp; Let's open the image file and let's look at the&nbsp;&nbsp;

- [00:41:28](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2488) each checkpoint. Okay let's see: first, second,&nbsp; third checkpoint, fourth one and the fifth one&nbsp;&nbsp;

- [00:41:38](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2498) is here. Yeah the fifth one has face is really&nbsp; broken for some reason. Some of them are looking&nbsp;&nbsp;

- [00:41:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2504) good though. I think the third one is still&nbsp; looking the best. Probably from third checkpoint,&nbsp;&nbsp;

- [00:41:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2510) we can get really good images, but I would say&nbsp; that something between third and fourth would&nbsp;&nbsp;

- [00:41:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2516) be better if we had more frequent checkpoints.&nbsp; So perhaps we could reduce the number of steps&nbsp;&nbsp;

- [00:42:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2523) and have more frequent checkpoints. So to get good&nbsp; images that we would like, what can we do? We need&nbsp;&nbsp;

- [00:42:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2530) to generate a lot of images and find the very best&nbsp; ones. And we need to generate fast. For generating&nbsp;&nbsp;

- [00:42:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2537) fast we need TensorRT. For TensorRT I have this&nbsp; auto installer in this post. Let's download the&nbsp;&nbsp;

- [00:42:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2544) TensorRT installer this bat file. I also have&nbsp; a full tutorial here so you can also watch this&nbsp;&nbsp;

- [00:42:31](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2551) tutorial to manually install yourself and learn&nbsp; everything about it. Let's move this into our&nbsp;&nbsp;

- [00:42:37](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2557) repository. So I will quickly install it into my&nbsp; Stable Diffusion Web UI. Just double click. More&nbsp;&nbsp;

- [00:42:45](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2565) info, run anyway. It will install the extension&nbsp; and also the necessary cuDNN library for me&nbsp;&nbsp;

- [00:42:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2572) automatically. Then I will generate the TensorRT&nbsp; model quickly. Okay, download has been completed.&nbsp;&nbsp;

- [00:42:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2579) Let's restart the Web UI. I am in the development&nbsp; branch. That is really important. Okay, TensorRT&nbsp;&nbsp;

- [00:43:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2586) installed and started. Let's enable the U-NET&nbsp; from user interface. U-NET. From here sd_unet&nbsp;&nbsp;

- [00:43:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2594) apply and reload UI. Since I think that the third&nbsp; checkpoint which is 1560 steps is best, I will&nbsp;&nbsp;

- [00:43:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2603) generate a TensorRT for that one. To do that&nbsp; first, I will select the model from here as you&nbsp;&nbsp;

- [00:43:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2609) are seeing right now, once the model is loaded, I&nbsp; will use 1024 batch size 1, but I will change the&nbsp;&nbsp;

- [00:43:37](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2617) optimal prompt token count to 225. So if the&nbsp; prompt is long, it will not cause any errors.&nbsp;&nbsp;

- [00:43:46](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2626) Let's export engine. It will export the engine&nbsp; and do everything for me automatically. Let's&nbsp;&nbsp;

- [00:43:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2632) see if there is any error. Okay, we have an error&nbsp; at somewhere. It says self mean match size match&nbsp;&nbsp;

- [00:44:00](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2640) size self not batch size. Assertion error okay,&nbsp; maybe we don't need to use static shapes since we&nbsp;&nbsp;

- [00:44:07](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2647) are changing the prompt token count. Yeah, let's&nbsp; make it like this: export engine. Yeah, you see,&nbsp;&nbsp;

- [00:44:14](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2654) after I enabled the advanced settings, make the&nbsp; mean prompt token count 75 optimal 75 and max&nbsp;&nbsp;

- [00:44:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2662) 225. Now it is starting. This is really important.&nbsp; Watch this full tutorial to learn more about it.&nbsp;&nbsp;

- [00:44:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2669) The tutorial link is here. The automatic installer&nbsp; is here. Okay, so the TensorRT file has been&nbsp;&nbsp;

- [00:44:35](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2675) generated and saved into disk. Now we can generate&nbsp; images very fast and I am going to use the amazing&nbsp;&nbsp;

- [00:44:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2684) prompt list as a txt file from this post. Let's&nbsp; download it. Let's open all of the prompts like&nbsp;&nbsp;

- [00:44:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2692) this. If you have a different rare token, just&nbsp; use notepad++ and replace all of them as you wish&nbsp;&nbsp;

- [00:44:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2699) for. Okay, let's copy it. Let's go here and&nbsp; let's select and from the very bottom select&nbsp;&nbsp;

- [00:45:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2706) prompts from file or text box. You can upload or&nbsp; copy them. Let's upload the downloaded file like&nbsp;&nbsp;

- [00:45:12](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2712) this. All right and let's enable after detailer.&nbsp; Photo of ohwx man. For non-realistic prompts this&nbsp;&nbsp;

- [00:45:20](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2720) may override the style, but for realistic prompts&nbsp; this will work very well. And for inpainting I&nbsp;&nbsp;

- [00:45:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2727) made it 50% so this is being equal to 50 percent.&nbsp; Let's change the height and width. Batch count 1.&nbsp;&nbsp;

- [00:45:36](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2736) Let's select the best sampling method. All right,&nbsp; everything is looking good. Then from SD_UNET I&nbsp;&nbsp;

- [00:45:42](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2742) will select the newly generated TensorRT file&nbsp; and I will also delete the older generated&nbsp;&nbsp;

- [00:45:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2750) images so we will see the new generated images and&nbsp; let's hit generate and see the speed. All right,&nbsp;&nbsp;

- [00:45:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2756) let's open the command line interface to see the&nbsp; speed. Meanwhile I am generating. Uh okay we got&nbsp;&nbsp;

- [00:46:03](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2763) an error which is let's see. Maybe it didn't&nbsp; see them as a single line. So let's try with a&nbsp;&nbsp;

- [00:46:12](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2772) single line first and verify the TensorRT is&nbsp; working or not. Okay, let's generate. Yeah,&nbsp;&nbsp;

- [00:46:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2778) we have a problem. Multi-head attention, forward&nbsp; name error. It is still trying to use all of the&nbsp;&nbsp;

- [00:46:25](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2785) prompts for some reason. That is weird. All right,&nbsp; let's restart the Web UI. Sometimes there might be&nbsp;&nbsp;

- [00:46:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2792) some errors, it is not a very important issue.&nbsp; You will also get these errors. You can ignore&nbsp;&nbsp;

- [00:46:37](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2797) them. Okay, accurate model are selected. Let's&nbsp; make the resolution. Let's try quickly. Okay,&nbsp;&nbsp;

- [00:46:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2804) the image is getting generated. The speed is very&nbsp; very decent. Now let's enable After Detailer and&nbsp;&nbsp;

- [00:46:52](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2812) change the everything to accurate settings. All&nbsp; right. Okay, let's try one more time with After&nbsp;&nbsp;

- [00:46:59](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2819) Detailer enabled. Okay. Okay the speed is huge as&nbsp; you are seeing right now. It is really fast even&nbsp;&nbsp;

- [00:47:06](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2826) though I am recording a video. Okay, face improved&nbsp; but I can see the clothing over training. This is&nbsp;&nbsp;

- [00:47:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2835) like my shirt in my training images. So you really&nbsp; need to improve your training data set if you want&nbsp;&nbsp;

- [00:47:21](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2841) the very best quality. Okay, it is looking decent.&nbsp; If you want to use high resolution fix then you&nbsp;&nbsp;

- [00:47:27](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2847) need to increase the resolution of the TensorRT&nbsp; that you have generated. Now time to try the&nbsp;&nbsp;

- [00:47:34](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2854) prompts from file or textbox. Now let's upload&nbsp; all of them, insert prompts at the start or end&nbsp;&nbsp;

- [00:47:42](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2862) it says. So let's try like this: let's delete&nbsp; the original image. Original prompt. Okay now&nbsp;&nbsp;

- [00:47:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2869) it started generating all of the images. For some&nbsp; reason, probably due to a bug in the Automatic1111&nbsp;&nbsp;

- [00:47:56](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2876) Web UI it wasn't working. Now it will generate&nbsp; all of the images very quickly and very amazingly.&nbsp;&nbsp;

- [00:48:04](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2884) With this strategy, you can get perfect images&nbsp; from different styles and use the very best&nbsp;&nbsp;

- [00:48:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2891) ones. So you see in that image there were multiple&nbsp; faces but it only changed the single face. Okay,&nbsp;&nbsp;

- [00:48:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2897) you see this face is also getting improved like&nbsp; this, but the quality is not at the 24 gigabyte&nbsp;&nbsp;

- [00:48:24](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2904) training level with BF16. On Kaggle, we are using&nbsp; FP16 and I think BF16 is working better than FP16&nbsp;&nbsp;

- [00:48:32](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2912) for some reason. I don't know, probably due to&nbsp; the precision of the weights, but the results are&nbsp;&nbsp;

- [00:48:37](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2917) really really good. You cannot get these results&nbsp; with Stable Diffusion 1.5 based models training.&nbsp;&nbsp;

- [00:48:44](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2924) Of course not all the images will be best so&nbsp; you can generate multiple images and find the&nbsp;&nbsp;

- [00:48:50](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2930) very best ones. You see very very decent image.&nbsp; You can even do high resolution fix by making&nbsp;&nbsp;

- [00:48:57](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2937) a TensorRT for it. So each image generation is&nbsp; taking like 2 seconds to with the After Detailer&nbsp;&nbsp;

- [00:49:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2945) like five seconds. It is taking like 5 seconds. I&nbsp; also have a tutorial for how to use Automatic1111&nbsp;&nbsp;

- [00:49:11](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2951) Web UI on a Kaggle. So by watching this: how&nbsp; to use Stable Diffusion SDXL ControlNet LoRAs&nbsp;&nbsp;

- [00:49:17](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2957) for free without a GPU on Kaggle, you can watch&nbsp; this tutorial. If you don't have a strong GPU,&nbsp;&nbsp;

- [00:49:22](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2962) strong computer, watch this tutorial to learn how&nbsp; to use Automatic1111 Web UI on a Kaggle with super&nbsp;&nbsp;

- [00:49:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2969) fast speed. Believe me, it's really working very&nbsp; well with the GPU that Kaggle provides. So you can&nbsp;&nbsp;

- [00:49:35](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2975) do everything that we are doing on our computer&nbsp; on Kaggle for free and we are getting very good&nbsp;&nbsp;

- [00:49:41](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2981) images as well as this one you are seeing right&nbsp; now. Results are decent, I like them and all of&nbsp;&nbsp;

- [00:49:48](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2988) these are made with a free Kaggle account. We&nbsp; didn't spend any time you see. This is decent.&nbsp;&nbsp;

- [00:49:54](https://www.youtube.com/watch?v=16-b1AjvyBE&t=2994) Okay, there is another one as you are seeing right&nbsp; now. Very decent. The model is performing decent.&nbsp;&nbsp;

- [00:50:00](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3000) I think for free these are really really good&nbsp; and you can try different prompts, improve your&nbsp;&nbsp;

- [00:50:05](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3005) training data set, change the number of steps that&nbsp; you did training to get the very best results.&nbsp;&nbsp;

- [00:50:10](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3010) If you decide to use paid Google Colab, Kaggle&nbsp; or RunPod and have 24 gigabyte having GPU, our&nbsp;&nbsp;

- [00:50:18](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3018) very best settings are shared here. These settings&nbsp; found after 100+ full trainings. I just recently&nbsp;&nbsp;

- [00:50:26](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3026) updated them yesterday so you can download the 24&nbsp; gigabyte Text Encoder json. It is the very best&nbsp;&nbsp;

- [00:50:33](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3033) version and do your training and get even much&nbsp; higher quality results and accurate images. But&nbsp;&nbsp;

- [00:50:42](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3042) with even SDXL DreamBooth training on a Kaggle,&nbsp; we are able to obtain amazing quality images like&nbsp;&nbsp;

- [00:50:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3049) this one. This is all for today. You will find all&nbsp; of the links and instructions that you need on the&nbsp;&nbsp;

- [00:50:55](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3055) GitHub Readme file. I hope you have enjoyed.&nbsp; Please join our Discord channel and ask me any&nbsp;&nbsp;

- [00:51:02](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3062) questions that you have or reply to this video.&nbsp; Our Discord channel is really really important.&nbsp;&nbsp;

- [00:51:09](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3069) You see, we have Discord online here. When you&nbsp; click this link you will get to this page. Join&nbsp;&nbsp;

- [00:51:15](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3075) our server. We have over 5500 members. Majority of&nbsp; them related to Stable Diffusion, AI, Generative&nbsp;&nbsp;

- [00:51:23](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3083) AI. I am working on even more amazing tutorials.&nbsp; You can also purchase our Udemy course, you&nbsp;&nbsp;

- [00:51:29](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3089) can follow me on LinkedIn, you can follow me on&nbsp; Twitter, on Deviantart, on CivitAI or Medium. You&nbsp;&nbsp;

- [00:51:35](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3095) can support me with Patreon or Buy Me A Coffee. I&nbsp; appreciate that very much. On our channel you will&nbsp;&nbsp;

- [00:51:42](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3102) find amazing videos. Click the playlist and you&nbsp; will find the playlists that I have. So I suggest&nbsp;&nbsp;

- [00:51:49](https://www.youtube.com/watch?v=16-b1AjvyBE&t=3109) you to watch the playlists that we have. Hopefully&nbsp; see you in another amazing tutorial video.

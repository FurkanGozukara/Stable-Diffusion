# FLUX: The First Ever Open Source txt2img Model Truly Beats Midjourney & Others - FLUX is Awaited SD3

## Full tutorial link > https://www.youtube.com/watch?v=bupRePUOA18

[![FLUX: The First Ever Open Source txt2img Model Truly Beats Midjourney & Others - FLUX is Awaited SD3](https://img.youtube.com/vi/bupRePUOA18/sddefault.jpg)](https://www.youtube.com/watch?v=bupRePUOA18 "FLUX: The First Ever Open Source txt2img Model Truly Beats Midjourney & Others - FLUX is Awaited SD3")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/FLUX-The-First-Ever-Open-Source-txt2img-Model-Truly-Beats-Midjourney-and-Others-FLUX-is-Awaited-SD3.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/FLUX-The-First-Ever-Open-Source-txt2img-Model-Truly-Beats-Midjourney-and-Others-FLUX-is-Awaited-SD3.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


FLUX is the first time every an open source txt2img is able to truly surpass and produce better  quality and better prompt following images than #Midjourney, Adobe Firefly, Leonardo Ai, Playground Ai, Stable Diffusion, SDXL, SD3 and Dall E3. #FLUX is developed Black Forest Labs and its team is mainly composed by the original authors of #StableDiffusion and its quality is mind blowing. When I say these words I am not exaggerating you will see that after watching the tutorial. In this tutorial I will show you how to very easily download and use FLUX models on your PC and also on Cloud services Massed Compute, RunPod and a free Kaggle account.

üîó FLUX Instructions Post (public no need login) ‚§µÔ∏è

‚ñ∂Ô∏è [https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-106135985](https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-106135985)

üîó FLUX Models 1-Click Robust Auto Downloader Scripts ‚§µÔ∏è

‚ñ∂Ô∏è [https://www.patreon.com/posts/auto-downloader-scripts-click-to-download-109289967](https://www.patreon.com/posts/auto-downloader-scripts-click-to-download-109289967)

üîó Main Windows SwarmUI Tutorial (Watch To Learn How to Use) ‚§µÔ∏è

‚ñ∂Ô∏è [https://youtu.be/HKX8_F1Er_w](https://youtu.be/HKX8_F1Er_w)

üîó Cloud SwarmUI Tutorial (Massed Compute - RunPod - Kaggle) ‚§µÔ∏è

‚ñ∂Ô∏è [https://youtu.be/XFUZof6Skkw](https://youtu.be/XFUZof6Skkw)

üîó SECourses Discord Channel to Get Full Support ‚§µÔ∏è

‚ñ∂Ô∏è [https://discord.com/servers/software-engineering-courses-secourses-772774097734074388](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388)

üîó SECourses Reddit ‚§µÔ∏è

‚ñ∂Ô∏è [https://www.reddit.com/r/SECourses/](https://www.reddit.com/r/SECourses/)

üîó SECourses GitHub ‚§µÔ∏è

‚ñ∂Ô∏è [https://github.com/FurkanGozukara/Stable-Diffusion](https://github.com/FurkanGozukara/Stable-Diffusion)

Video Chapters

[00:00:00](https://youtu.be/bupRePUOA18?t=0) Introduction to the truly SOTA txt2img model FLUX which is Open Source

[00:05:01](https://youtu.be/bupRePUOA18?t=301) How we are going to¬†install FLUX model into our SwarmUI and use it

[00:05:33](https://youtu.be/bupRePUOA18?t=333) How to accurately download FLUX models manually

[00:05:54](https://youtu.be/bupRePUOA18?t=354) How to download FP16 and optimized FP8 FLUX models automatically 1-click

[00:06:45](https://youtu.be/bupRePUOA18?t=405) Which precision and type of FLUX models are best for your case and what is the difference

[00:07:56](https://youtu.be/bupRePUOA18?t=476) Which folder you need to put FLUX models accurately

[00:08:07](https://youtu.be/bupRePUOA18?t=487) How to update your SwarmUI to latest version for FLUX support

[00:08:58](https://youtu.be/bupRePUOA18?t=538) How to use FLUX models after SwarmUI started

[00:09:44](https://youtu.be/bupRePUOA18?t=584) How to use CFG scale for FLUX model

[00:10:23](https://youtu.be/bupRePUOA18?t=623) How to see what is happening that moment in the server debug logs

[00:10:49](https://youtu.be/bupRePUOA18?t=649) Turbo model image generation speed on RTX 3090 Ti GPU

[00:10:59](https://youtu.be/bupRePUOA18?t=659) Somes turbo model may generate blurry images

[00:11:30](https://youtu.be/bupRePUOA18?t=690) How to generate images with development model

[00:11:53](https://youtu.be/bupRePUOA18?t=713) How to use FLUX model in FP16 instead of default FP8 precision on SwarmUI

[00:12:31](https://youtu.be/bupRePUOA18?t=751) What are the difference between development and turbo model of FLUX models

[00:13:05](https://youtu.be/bupRePUOA18?t=785) Generating native 1536x1536 and testing high res capability of FLUX and how much VRAM it uses

[00:13:41](https://youtu.be/bupRePUOA18?t=821) Image generation speed of 1536x1536 resolution FLUX image on RTX 3090 Ti GPU with SwarmUI

[00:13:56](https://youtu.be/bupRePUOA18?t=836) How to check if you are using any shared VRAM - this slows down generation speed significantly

[00:14:35](https://youtu.be/bupRePUOA18?t=875) How to use SwarmUI and FLUX on cloud services - no PC or GPU is required

[00:14:48](https://youtu.be/bupRePUOA18?t=888) How to use pre-installed SwarmUI on amazing Massed Compute 48 GB GPU for 31 cents per hour with FLUX dev FP16 model

[00:16:05](https://youtu.be/bupRePUOA18?t=965) How to download FLUX models on Massed Compute instance

[00:17:15](https://youtu.be/bupRePUOA18?t=1035) FLUX models downloading speed of Massed Compute

[00:18:19](https://youtu.be/bupRePUOA18?t=1099) How much time it takes on Massed Compute download all very best FP16 FLUX and T5 models

[00:18:52](https://youtu.be/bupRePUOA18?t=1132) How to first update and start SwarmUI on Massed Compute with 1-click

[00:19:33](https://youtu.be/bupRePUOA18?t=1173) How to use Massed Compute started SwarmUI on your PC's browser with ngrok - you can use even on your phone this way

[00:21:08](https://youtu.be/bupRePUOA18?t=1268) Comparing Midjourney image to open source FLUX with same prompt

[00:22:02](https://youtu.be/bupRePUOA18?t=1322) How to set DType to FP16 to generate better quality images on Massed Compute with FLUX

[00:22:12](https://youtu.be/bupRePUOA18?t=1332) Comparing FLUX generated image with the Midjourney generated image for same prompt

[00:23:00](https://youtu.be/bupRePUOA18?t=1380) How to install SwarmUI and download FLUX models on RunPod to use

[00:25:01](https://youtu.be/bupRePUOA18?t=1501) Step speed and VRAM of Turbo model vs Dev model of FLUX

[00:26:04](https://youtu.be/bupRePUOA18?t=1564) How to download FLUX models on RunPod after SwarmUI installed

[00:26:55](https://youtu.be/bupRePUOA18?t=1615) How to start SwarmUI after you restart your pod or turn off and on your pod

[00:27:42](https://youtu.be/bupRePUOA18?t=1662) If CFG scale panel of SwarmUI is not visible properly how to fix it

[00:27:54](https://youtu.be/bupRePUOA18?t=1674) Comparing FLUX quality with very best models of Stable Diffusion XL (SDXL) via popular CivitAI image

[00:29:20](https://youtu.be/bupRePUOA18?t=1760) FLUX image generation speed on L40S GPU - FP16 precision

[00:29:43](https://youtu.be/bupRePUOA18?t=1783) Comparing FLUX image vs CivitAI popular SDXL image

[00:30:05](https://youtu.be/bupRePUOA18?t=1805) Does increasing step count improves image quality significantly

[00:30:33](https://youtu.be/bupRePUOA18?t=1833) How to generate bigger resolution 1536x1536 pixel image

[00:30:45](https://youtu.be/bupRePUOA18?t=1845) How to install nvitop and check how much VRAM 1536px resolution and FP16 DType uses

[00:31:25](https://youtu.be/bupRePUOA18?t=1885) How much speed drop happened when increase image resolution from 1024px to 1536px

[00:31:42](https://youtu.be/bupRePUOA18?t=1902) How to use SwarmUI and FLUX models on a free Kaggle account same as on your local PC

[00:32:29](https://youtu.be/bupRePUOA18?t=1949) How to join SECourses discord channel and contact with me for any help and discuss AI



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=bupRePUOA18&t=0) Greetings, everyone. In today's video, I am going to show you how to download, install and use the

- [00:00:07](https://www.youtube.com/watch?v=bupRePUOA18&t=7) FLUX in details by using the SwarmUI. SwarmUI is a very advanced and also very powerful GUI that

- [00:00:17](https://www.youtube.com/watch?v=bupRePUOA18&t=17) will allow you to use the FLUX model as easily as using it on Automatic1111 Web UI. Probably

- [00:00:24](https://www.youtube.com/watch?v=bupRePUOA18&t=24) it will take a lot of time for Automatic1111 Web UI to bring support to the FLUX models. So if you

- [00:00:31](https://www.youtube.com/watch?v=bupRePUOA18&t=31) want to use it as easily as Automatic1111 Web UI, SwarmUI and this tutorial is the best one

- [00:00:38](https://www.youtube.com/watch?v=bupRePUOA18&t=38) that you can find. I have prepared very detailed instructions and also 1-click models downloader

- [00:00:45](https://www.youtube.com/watch?v=bupRePUOA18&t=45) that supports FP8 version of the model. Thus you will save over 20 GB storage and bandwidth.

- [00:00:53](https://www.youtube.com/watch?v=bupRePUOA18&t=53) FLUX model works as low as 6 GB VRAM having GPUs. However, it will be a little bit slower,

- [00:01:01](https://www.youtube.com/watch?v=bupRePUOA18&t=61) but don't worry because I will show how to use it on cloud services as well. FLUX model is the

- [00:01:08](https://www.youtube.com/watch?v=bupRePUOA18&t=68) currently state of the art model according to the ELO score, even better than Midjourney,

- [00:01:12](https://www.youtube.com/watch?v=bupRePUOA18&t=72) and it is developed by the Black Forest Labs. So if you have a lower VRAM having GPU, I will

- [00:01:19](https://www.youtube.com/watch?v=bupRePUOA18&t=79) show you how to use this amazing model on Massed Compute with amazingly cheap price 31 cents per

- [00:01:26](https://www.youtube.com/watch?v=bupRePUOA18&t=86) hour on a very powerful 48 GB A6000 GPU. It works blazing fast. If you are a RunPod fan, I will show

- [00:01:33](https://www.youtube.com/watch?v=bupRePUOA18&t=93) you how to install latest version of SwarmUI and use the FLUX on RunPod as well. You will be amazed

- [00:01:40](https://www.youtube.com/watch?v=bupRePUOA18&t=100) by the quality of the FLUX model, how well it follows your prompts, how amazing anatomy and

- [00:01:48](https://www.youtube.com/watch?v=bupRePUOA18&t=108) text it can generate. I will make a comparison with the Midjourney and you will be surprised

- [00:01:53](https://www.youtube.com/watch?v=bupRePUOA18&t=113) that how FLUX model beaten the Midjourney in terms of prompt following and quality. Moreover,

- [00:02:00](https://www.youtube.com/watch?v=bupRePUOA18&t=120) I will show some of the technical details that no others will show you like using this model with

- [00:02:06](https://www.youtube.com/watch?v=bupRePUOA18&t=126) FP16 precision. The FP16 precision is not enabled by default, even if you have a high VRAM GPU,

- [00:02:14](https://www.youtube.com/watch?v=bupRePUOA18&t=134) but on the cloud services, you will be able to use FP16 and get better quality images. Also,

- [00:02:21](https://www.youtube.com/watch?v=bupRePUOA18&t=141) I will show you FLUX guidance scale. The CFG scale of the FLUX is different than the CFG of the SDXL

- [00:02:29](https://www.youtube.com/watch?v=bupRePUOA18&t=149) or other Stable Diffusion models. Furthermore, I have done a very extensive comparison for both

- [00:02:36](https://www.youtube.com/watch?v=bupRePUOA18&t=156) development model, turbo model and FP16 version. So you will be able to compare any combination

- [00:02:44](https://www.youtube.com/watch?v=bupRePUOA18&t=164) with any other combination and see how different images they generate. Finally, I have updated

- [00:02:52](https://www.youtube.com/watch?v=bupRePUOA18&t=172) our SwarmUI Kaggle notebook, free account Kaggle notebook. And on this notebook, you will be able

- [00:02:58](https://www.youtube.com/watch?v=bupRePUOA18&t=178) to use the FLUX model as you are using it on your PC. So if you don't have a powerful GPU and if you

- [00:03:05](https://www.youtube.com/watch?v=bupRePUOA18&t=185) don't want to pay any cloud services, you will be able to use FLUX model on a free Kaggle account.

- [00:03:11](https://www.youtube.com/watch?v=bupRePUOA18&t=191) As usual, I have prepared a very detailed post. This is a public post. You can see the content

- [00:03:18](https://www.youtube.com/watch?v=bupRePUOA18&t=198) and download the content of this post without even having a Patreon account. If you have watched my

- [00:03:24](https://www.youtube.com/watch?v=bupRePUOA18&t=204) previous master SwarmUI tutorial, you already know this post. I have updated it. In this tutorial, I

- [00:03:32](https://www.youtube.com/watch?v=bupRePUOA18&t=212) will not show how to install and use SwarmUI from scratch like I did. So if you haven't watched it

- [00:03:38](https://www.youtube.com/watch?v=bupRePUOA18&t=218) previously, please watch this 70 chapters video. Click this link. So in this amazing tutorial,

- [00:03:45](https://www.youtube.com/watch?v=bupRePUOA18&t=225) click here to see all of the chapters. You see there are 70 chapters fully written by me. It has

- [00:03:53](https://www.youtube.com/watch?v=bupRePUOA18&t=233) manually written fully accurate subtitles, captions. So watch this tutorial to learn

- [00:04:00](https://www.youtube.com/watch?v=bupRePUOA18&t=240) how to install and use the SwarmUI on your Windows PC. And if you want to install and

- [00:04:06](https://www.youtube.com/watch?v=bupRePUOA18&t=246) use on cloud services such as Massed Compute, RunPod and Kaggle, I have another tutorial. So

- [00:04:12](https://www.youtube.com/watch?v=bupRePUOA18&t=252) first you watch this Windows tutorial, then you watch this cloud tutorial. This cloud tutorial is

- [00:04:17](https://www.youtube.com/watch?v=bupRePUOA18&t=257) also perfectly chaptered. So look at the chapters to learn how to install. So in this tutorial,

- [00:04:23](https://www.youtube.com/watch?v=bupRePUOA18&t=263) I am going to show you the newest FLUX models installation and how to use them. And also I

- [00:04:31](https://www.youtube.com/watch?v=bupRePUOA18&t=271) will give a lot of information regarding the precision of the models. By default,

- [00:04:36](https://www.youtube.com/watch?v=bupRePUOA18&t=276) the published models by the Black Forest Labs are FP16. However, when we use them in SwarmUI,

- [00:04:44](https://www.youtube.com/watch?v=bupRePUOA18&t=284) they are by default used with FP8 version. Also, I have prepared amazing comparison imgsli. I have

- [00:04:53](https://www.youtube.com/watch?v=bupRePUOA18&t=293) rented a very powerful GPU and compared every one of the cases like you are seeing. So you can

- [00:05:00](https://www.youtube.com/watch?v=bupRePUOA18&t=300) check this link as well. So how we are going to install FLUX model into our SwarmUI and use it on

- [00:05:07](https://www.youtube.com/watch?v=bupRePUOA18&t=307) our computer, I will also show how to use that on RunPod also on Massed Compute as well. Moreover,

- [00:05:14](https://www.youtube.com/watch?v=bupRePUOA18&t=314) our Kaggle notebook is updated. And now you can use the FLUX model on a free Kaggle account. So

- [00:05:21](https://www.youtube.com/watch?v=bupRePUOA18&t=321) if you don't have a powerful GPU, you can use the FLUX model on a Kaggle account. All the

- [00:05:26](https://www.youtube.com/watch?v=bupRePUOA18&t=326) instructions are written on the Kaggle notebook as well. So you need to start downloading the FLUX

- [00:05:31](https://www.youtube.com/watch?v=bupRePUOA18&t=331) models. They are not automatically downloaded. The download instructions are posted on the Discord

- [00:05:37](https://www.youtube.com/watch?v=bupRePUOA18&t=337) channel of the SwarmUI. However, I also have attached it to this post. So click this link.

- [00:05:44](https://www.youtube.com/watch?v=bupRePUOA18&t=344) It will download these instructions. This is from the Discord channel of the SwarmUI. Follow the

- [00:05:51](https://www.youtube.com/watch?v=bupRePUOA18&t=351) instructions from here. Alternatively, as usual, I have prepared one click model downloaders,

- [00:05:57](https://www.youtube.com/watch?v=bupRePUOA18&t=357) which I am going to use. So the model downloaders are posted in this link. Click here. In this post,

- [00:06:04](https://www.youtube.com/watch?v=bupRePUOA18&t=364) you can read the descriptions. And also in the very bottom, you are going to find FLUX

- [00:06:09](https://www.youtube.com/watch?v=bupRePUOA18&t=369) models auto downloaders zip file. Let's click and download it, then cut it and

- [00:06:14](https://www.youtube.com/watch?v=bupRePUOA18&t=374) move into your SwarmUI installation folder. I did a fresh installation yesterday. So for

- [00:06:20](https://www.youtube.com/watch?v=bupRePUOA18&t=380) SwarmUI installation, if you remember, we just ran the install windows dot bat file,

- [00:06:24](https://www.youtube.com/watch?v=bupRePUOA18&t=384) which is the official file from the SwarmUI GitHub repository. So paste it into same folder. You see,

- [00:06:31](https://www.youtube.com/watch?v=bupRePUOA18&t=391) this is my SwarmUI installation. And this is the installer files. Extract here. Click yes, because

- [00:06:37](https://www.youtube.com/watch?v=bupRePUOA18&t=397) I have Massed Compute and then double click windows start, download dot bat file. It will ask

- [00:06:43](https://www.youtube.com/watch?v=bupRePUOA18&t=403) you all of the options. Now, which options do you need? If you don't have a bandwidth problem, you

- [00:06:49](https://www.youtube.com/watch?v=bupRePUOA18&t=409) can download the FP16 versions. Don't worry, the SwarmUI will run them at the FP8 version. However,

- [00:06:56](https://www.youtube.com/watch?v=bupRePUOA18&t=416) if you are not going to use FP16 version, which you cannot use unless you have more than 24 GB,

- [00:07:03](https://www.youtube.com/watch?v=bupRePUOA18&t=423) you can download the FP8 versions, which will save your space. So how you're going to download,

- [00:07:10](https://www.youtube.com/watch?v=bupRePUOA18&t=430) just select the option that you want to download. Now there are two options you see 4 steps version

- [00:07:16](https://www.youtube.com/watch?v=bupRePUOA18&t=436) and 20 steps development version. If you don't have a 24 GB GPU, like RTX 3090 or 4090, the 20

- [00:07:24](https://www.youtube.com/watch?v=bupRePUOA18&t=444) steps version will work slower, the development version. So you need schnell version, which I

- [00:07:30](https://www.youtube.com/watch?v=bupRePUOA18&t=450) call turbo model for 4 steps. It is up to you. I'm going to download both of them to show you.

- [00:07:35](https://www.youtube.com/watch?v=bupRePUOA18&t=455) So I will select option 3 and it will start downloading them automatically. Since I already

- [00:07:41](https://www.youtube.com/watch?v=bupRePUOA18&t=461) have downloaded them, you see, it shows me that successfully downloaded both of the files because

- [00:07:46](https://www.youtube.com/watch?v=bupRePUOA18&t=466) I had downloaded them. This downloader script has resume capability, retry capability, and if fully

- [00:07:54](https://www.youtube.com/watch?v=bupRePUOA18&t=474) downloaded, it will skip the downloading. So once you have downloaded the files,

- [00:07:58](https://www.youtube.com/watch?v=bupRePUOA18&t=478) let me show you the files, inside models, inside unet. They are here. All you need to do is first

- [00:08:04](https://www.youtube.com/watch?v=bupRePUOA18&t=484) update your SwarmUI. This is super important. So for updating, update windows dot bat file. It will

- [00:08:09](https://www.youtube.com/watch?v=bupRePUOA18&t=489) automatically update to the latest version. Then it will automatically close and then we will start

- [00:08:14](https://www.youtube.com/watch?v=bupRePUOA18&t=494) the SwarmUI as usual. Everything explained in the original 90 minute video. So I'm just launching

- [00:08:20](https://www.youtube.com/watch?v=bupRePUOA18&t=500) it. And in the downloader script, you will see one another option, which is T5 text encoder,

- [00:08:25](https://www.youtube.com/watch?v=bupRePUOA18&t=505) FP16 version. Automatically SwarmUI will download and use FP8 version. However, if you have 24 GB,

- [00:08:33](https://www.youtube.com/watch?v=bupRePUOA18&t=513) you can use the FP16 version as well, which I am going to use. So I will select it and I

- [00:08:39](https://www.youtube.com/watch?v=bupRePUOA18&t=519) will download the FP16 version because I have 24 GB. And this makes some improvements to the

- [00:08:47](https://www.youtube.com/watch?v=bupRePUOA18&t=527) original version. It doesn't much, but it's a little bit. Actually, this is going to take time.

- [00:08:52](https://www.youtube.com/watch?v=bupRePUOA18&t=532) So I will just skip it for now. I will show that on the cloud computers. Okay. So the SwarmUI has

- [00:08:59](https://www.youtube.com/watch?v=bupRePUOA18&t=539) started. And when we go to the models tab and we refresh, we will see the both turbo version

- [00:09:06](https://www.youtube.com/watch?v=bupRePUOA18&t=546) and the development version. The development version is better than the turbo version. I have

- [00:09:11](https://www.youtube.com/watch?v=bupRePUOA18&t=551) compared both of them. Now, how are we going to use these models? According to your GPU,

- [00:09:16](https://www.youtube.com/watch?v=bupRePUOA18&t=556) select the model that you want. I am going to first start with the FLUX turbo model. Let's

- [00:09:22](https://www.youtube.com/watch?v=bupRePUOA18&t=562) type a prompt super amazing car. Are we done? No. First of all, you need to set the CFG scale to 1.

- [00:09:29](https://www.youtube.com/watch?v=bupRePUOA18&t=569) Because FLUX works with only CFG scale 1, and you need to set the steps count 4 to get the

- [00:09:34](https://www.youtube.com/watch?v=bupRePUOA18&t=574) advantage of the turbo model. And if you're wondering, are there CFG scale for the FLUX

- [00:09:40](https://www.youtube.com/watch?v=bupRePUOA18&t=580) model? Yes, there is CFG scale for FLUX model. However, it doesn't exist on the turbo model.

- [00:09:46](https://www.youtube.com/watch?v=bupRePUOA18&t=586) When I select the development model, you will see under sampling, there is FLUX guidance scale here,

- [00:09:52](https://www.youtube.com/watch?v=bupRePUOA18&t=592) so you can enable this and use it. For now, we are going to use turbo model. So let's make the

- [00:09:58](https://www.youtube.com/watch?v=bupRePUOA18&t=598) first example with turbo model. So let's generate amazing car. All we did was setting the step count

- [00:10:05](https://www.youtube.com/watch?v=bupRePUOA18&t=605) 4 and CFG scale 1. So the CFG scale and the CFG scale of the FLUX model is different. This

- [00:10:13](https://www.youtube.com/watch?v=bupRePUOA18&t=613) is FLUX guidance scale, not exactly as CFG scale. The negative prompt currently is not working with

- [00:10:19](https://www.youtube.com/watch?v=bupRePUOA18&t=619) the FLUX model because we have to use CFG scale 1. And let's go to the server and in the logs,

- [00:10:26](https://www.youtube.com/watch?v=bupRePUOA18&t=626) let's see what is happening in the debug. So first it will load the model into the VRAM. Then it will

- [00:10:34](https://www.youtube.com/watch?v=bupRePUOA18&t=634) start generating. Okay. The first image generated with seven seconds. Let's see it. So this is

- [00:10:39](https://www.youtube.com/watch?v=bupRePUOA18&t=639) the image we got. Let's generate another one to see the real speed because initially it will be

- [00:10:45](https://www.youtube.com/watch?v=bupRePUOA18&t=645) initializing. Yes. The image is getting generated in total seven seconds on RTX 3090. And this is

- [00:10:53](https://www.youtube.com/watch?v=bupRePUOA18&t=653) the result we got. Unfortunately, it doesn't look very good right now. As you are seeing,

- [00:10:58](https://www.youtube.com/watch?v=bupRePUOA18&t=658) there is some blurriness, even though we are using CFG scale 1, which is the accurate and we are

- [00:11:03](https://www.youtube.com/watch?v=bupRePUOA18&t=663) using 4 steps, but not every image will be like that. Let's generate another one to see

- [00:11:08](https://www.youtube.com/watch?v=bupRePUOA18&t=668) if this is the case. Okay. You see this image is accurate. So with turbo model, you will be

- [00:11:14](https://www.youtube.com/watch?v=bupRePUOA18&t=674) sacrificing some of the quality unfortunately. However, with the development model you won't.

- [00:11:20](https://www.youtube.com/watch?v=bupRePUOA18&t=680) Okay, this one is pretty good. So you see turbo model is some like a luck. You need to generate

- [00:11:27](https://www.youtube.com/watch?v=bupRePUOA18&t=687) lots of images. It is really fast. It is almost instant. Let's generate this image with the also

- [00:11:33](https://www.youtube.com/watch?v=bupRePUOA18&t=693) development model so reuse parameters. And when I select the development model, I need to make the

- [00:11:38](https://www.youtube.com/watch?v=bupRePUOA18&t=698) step count 20 and generate. Even if you have 10 GB or 8 GB GPU, it will still work. However, it will

- [00:11:46](https://www.youtube.com/watch?v=bupRePUOA18&t=706) be much more slower than on my computer because it will be have to do a lot of optimization. And

- [00:11:53](https://www.youtube.com/watch?v=bupRePUOA18&t=713) how you can use FP16 version of this model? To use that you need to enable this advanced options and

- [00:12:02](https://www.youtube.com/watch?v=bupRePUOA18&t=722) under advanced sampling that you need to select preferred DType and default 16 bit. Otherwise,

- [00:12:08](https://www.youtube.com/watch?v=bupRePUOA18&t=728) when it is set to the automatic, it will be using FP8 weights. Okay. We are not going to do that

- [00:12:14](https://www.youtube.com/watch?v=bupRePUOA18&t=734) because it requires more than 24 GB. I will show that on the cloud part of this tutorial, we are

- [00:12:20](https://www.youtube.com/watch?v=bupRePUOA18&t=740) getting our image and yes, this is the image that the development model generates. So what is the

- [00:12:27](https://www.youtube.com/watch?v=bupRePUOA18&t=747) difference between the development model and the turbo model? The development model and turbo model

- [00:12:33](https://www.youtube.com/watch?v=bupRePUOA18&t=753) are both distilled models, not the full model. Full model is only available with API. The turbo

- [00:12:39](https://www.youtube.com/watch?v=bupRePUOA18&t=759) model distilled in time-step. So with 4 steps, you generate an image. The development model is

- [00:12:45](https://www.youtube.com/watch?v=bupRePUOA18&t=765) distilled with guidance. So it is weaker than the full model, which is only available with API, not

- [00:12:51](https://www.youtube.com/watch?v=bupRePUOA18&t=771) available to use on our computer. So then the rest is same. You know, you can generate any images you

- [00:12:57](https://www.youtube.com/watch?v=bupRePUOA18&t=777) want. This model supports up to two megapixels. So it is like up to 1536 to 1536. It really generates

- [00:13:04](https://www.youtube.com/watch?v=bupRePUOA18&t=784) good images. Let's generate 1536 to see on our computer. And if you are wondering how much VRAM

- [00:13:10](https://www.youtube.com/watch?v=bupRePUOA18&t=790) using right now. By the way, this VRAM usage will depend on your GPU. With 3090 currently my system

- [00:13:17](https://www.youtube.com/watch?v=bupRePUOA18&t=797) is using 20.5 GB VRAM. So the model is using around 19 GB, 18.5 GB VRAM on 3090 GPU. As I said,

- [00:13:28](https://www.youtube.com/watch?v=bupRePUOA18&t=808) if you have a lower VRAM machine, SwarmUI will do a lot of optimizations and reduce the VRAM usage

- [00:13:35](https://www.youtube.com/watch?v=bupRePUOA18&t=815) and it will work. However, it will be much slower. So in the server, in the debug, we can see current

- [00:13:40](https://www.youtube.com/watch?v=bupRePUOA18&t=820) speed. So currently it is taking around 3.9 second / it to generate this over 2 megapixel image.

- [00:13:49](https://www.youtube.com/watch?v=bupRePUOA18&t=829) Actually this is 2.25 megapixel, 1536 to 1536, but it is working pretty amazing. Let's see if we are

- [00:13:56](https://www.youtube.com/watch?v=bupRePUOA18&t=836) using any shared VRAM. We shouldn't be. Let's go to the performance. And you see, I'm not using any

- [00:14:02](https://www.youtube.com/watch?v=bupRePUOA18&t=842) significant shared VRAM. If you use significant shared VRAM, then it will become much more slower.

- [00:14:08](https://www.youtube.com/watch?v=bupRePUOA18&t=848) The SwarmUI does some CPU offloading and some other optimizations and we are getting the image.

- [00:14:14](https://www.youtube.com/watch?v=bupRePUOA18&t=854) And this prompt is very, very simplistic. We are going to see the results of advanced

- [00:14:20](https://www.youtube.com/watch?v=bupRePUOA18&t=860) prompts in the cloud part of this tutorial. And this is the image we got. It is looking pretty,

- [00:14:26](https://www.youtube.com/watch?v=bupRePUOA18&t=866) pretty amazing. All right, now let's begin the cloud part because many people will be

- [00:14:30](https://www.youtube.com/watch?v=bupRePUOA18&t=870) needed to use cloud services to get a faster speed. As I have shown in this cloud tutorial,

- [00:14:37](https://www.youtube.com/watch?v=bupRePUOA18&t=877) you will start your cloud services as usual. I also have added some additional information

- [00:14:43](https://www.youtube.com/watch?v=bupRePUOA18&t=883) to the bottom of the post. You should read here once more time. We also have now how to use the

- [00:14:51](https://www.youtube.com/watch?v=bupRePUOA18&t=891) started SwarmUI on Massed Compute to use on your computer. Now I will show you how to proceed. I

- [00:14:58](https://www.youtube.com/watch?v=bupRePUOA18&t=898) will begin with the Massed Compute. So the Massed Compute already has the SwarmUI installed. I am

- [00:15:05](https://www.youtube.com/watch?v=bupRePUOA18&t=905) just going to start the machine with our coupon. First of all, we select the creator category,

- [00:15:10](https://www.youtube.com/watch?v=bupRePUOA18&t=910) SECourses and our watch the full tutorial if you don't know how to use Massed Compute, I will just

- [00:15:15](https://www.youtube.com/watch?v=bupRePUOA18&t=915) start the machine. Then I will copy my downloaded downloader files into the my synchronization

- [00:15:22](https://www.youtube.com/watch?v=bupRePUOA18&t=922) folder as I have shown in the main tutorial. Okay. I have copied. Now all I need to do is just wait

- [00:15:29](https://www.youtube.com/watch?v=bupRePUOA18&t=929) for initialization. You see with Massed Compute with our coupon, it is only 31 cents per hour. And

- [00:15:34](https://www.youtube.com/watch?v=bupRePUOA18&t=934) we are using staggering 48 GB VRAM having machine with RTX A6000. This works super fast. You will

- [00:15:42](https://www.youtube.com/watch?v=bupRePUOA18&t=942) see it. All right. The Massed Compute instance started. Let's connect quickly as usual as shown

- [00:15:47](https://www.youtube.com/watch?v=bupRePUOA18&t=947) in the main cloud tutorial. So I am going to skip a lot of parts of the main cloud tutorial. There

- [00:15:54](https://www.youtube.com/watch?v=bupRePUOA18&t=954) is one additional thing that I'm going to show in this tutorial, which is connecting to the SwarmUI

- [00:15:59](https://www.youtube.com/watch?v=bupRePUOA18&t=959) with the ngrok to connect from my own computer. Okay. The Massed Compute instance started. So

- [00:16:05](https://www.youtube.com/watch?v=bupRePUOA18&t=965) I'm going to first download the FLUX models. To do that I am going to use the downloader

- [00:16:09](https://www.youtube.com/watch?v=bupRePUOA18&t=969) files from the Patreon. You can also follow the instructions here. The links are also in

- [00:16:15](https://www.youtube.com/watch?v=bupRePUOA18&t=975) the Patreon post that is the public one and don't let manually into the accurate folders. However,

- [00:16:21](https://www.youtube.com/watch?v=bupRePUOA18&t=981) using this installers will make your life easier, of course, as usual. So just copy paste the files

- [00:16:27](https://www.youtube.com/watch?v=bupRePUOA18&t=987) into the desktop first, then open the download instructions file, copy this command from here,

- [00:16:34](https://www.youtube.com/watch?v=bupRePUOA18&t=994) copy, and then three dots, open terminal, paste, and you will get these downloading options. So

- [00:16:41](https://www.youtube.com/watch?v=bupRePUOA18&t=1001) which files I'm going to download, I'm going to download FP16 versions because I have 48 GB and

- [00:16:48](https://www.youtube.com/watch?v=bupRePUOA18&t=1008) I am going to get a better quality. So let's download the FP16 version with option 4. Then

- [00:16:55](https://www.youtube.com/watch?v=bupRePUOA18&t=1015) I am going to start another instance. I'm going to download at the same time, paste it again,

- [00:17:00](https://www.youtube.com/watch?v=bupRePUOA18&t=1020) and I'm going to download option 5. Then also I'm going to download the best T5 text encoder

- [00:17:07](https://www.youtube.com/watch?v=bupRePUOA18&t=1027) with option 8. So I am downloading 3 files at the same time. Let's see the speed of the Massed

- [00:17:14](https://www.youtube.com/watch?v=bupRePUOA18&t=1034) Compute. This is running on a cloud, not on my machine. And we will see the speed. Okay. So

- [00:17:20](https://www.youtube.com/watch?v=bupRePUOA18&t=1040) there is 200 megabytes and 350 megabytes over 600 megabytes. And also this one is going to download,

- [00:17:28](https://www.youtube.com/watch?v=bupRePUOA18&t=1048) but it didn't start yet. Okay. It's starting. Yes. Okay. So when we sum all of the download speed,

- [00:17:35](https://www.youtube.com/watch?v=bupRePUOA18&t=1055) you see this is 300 megabytes per second. This is 100 megabytes and this is about 100

- [00:17:40](https://www.youtube.com/watch?v=bupRePUOA18&t=1060) megabytes. So over 500 megabytes per second download speed, which is just amazing. When

- [00:17:46](https://www.youtube.com/watch?v=bupRePUOA18&t=1066) you don't want FP16 version of the T5, you won't be able to use it as an FP8 version because it

- [00:17:53](https://www.youtube.com/watch?v=bupRePUOA18&t=1073) is automatically using the whatever the precision of the T5 text encoder with the SwarmUI. However,

- [00:18:01](https://www.youtube.com/watch?v=bupRePUOA18&t=1081) even though we are downloading the FP16 version of the FLUX models, you see 23.8 GB. The FP8 version

- [00:18:09](https://www.youtube.com/watch?v=bupRePUOA18&t=1089) was around 11 GB. You can still set the DType to FP8, which is default. So generate with lower

- [00:18:16](https://www.youtube.com/watch?v=bupRePUOA18&t=1096) VRAM. So keep in mind that if you don't want the FP16 version of T5, it will use more VRAM,

- [00:18:22](https://www.youtube.com/watch?v=bupRePUOA18&t=1102) but with FP16 version of the FLUX models, you will be still using them with FP8 by default, and you

- [00:18:29](https://www.youtube.com/watch?v=bupRePUOA18&t=1109) will be able to also use them with FP16 version as well. Okay downloads are almost completed. Yes,

- [00:18:35](https://www.youtube.com/watch?v=bupRePUOA18&t=1115) this is completed. And the last one is also almost completed. So downloading all of the

- [00:18:40](https://www.youtube.com/watch?v=bupRePUOA18&t=1120) files took lesser than 4 minutes in total time. We downloaded over 50 GB. So let's go to desktop with

- [00:18:47](https://www.youtube.com/watch?v=bupRePUOA18&t=1127) Control+Alt+d. Before starting the SwarmUI. It is pre-installed. First you need to update it. So

- [00:18:53](https://www.youtube.com/watch?v=bupRePUOA18&t=1133) this is the SwarmUI updater. This one you see when I hover my mouse, it says run stable

- [00:18:58](https://www.youtube.com/watch?v=bupRePUOA18&t=1138) SwarmUI update. It still says Stable SwarmUI, but this is using the SwarmUI latest version,

- [00:19:04](https://www.youtube.com/watch?v=bupRePUOA18&t=1144) not the Stable SwarmUI. Now it is developed as a new GitHub repository and it's updating from the

- [00:19:11](https://www.youtube.com/watch?v=bupRePUOA18&t=1151) latest GitHub repository, not from the older Stable SwarmUI. And it is started. So you see,

- [00:19:17](https://www.youtube.com/watch?v=bupRePUOA18&t=1157) we are using SwarmUI version 0.9.1.1, which is the latest version right now. It also shows the last

- [00:19:24](https://www.youtube.com/watch?v=bupRePUOA18&t=1164) update date. And then we go to the models and they are all here. However, as I said, I am going to

- [00:19:30](https://www.youtube.com/watch?v=bupRePUOA18&t=1170) use this with ngrok on my computer. So let's close this, close this as well. And we are going to use

- [00:19:36](https://www.youtube.com/watch?v=bupRePUOA18&t=1176) the instructions from here. First of all, we need to install the ngrok. So let's start a CMD window

- [00:19:43](https://www.youtube.com/watch?v=bupRePUOA18&t=1183) from here, paste it. Then we need to get a token from here. You need to log in your ngrok account.

- [00:19:49](https://www.youtube.com/watch?v=bupRePUOA18&t=1189) Let's copy it. Then let's open a notepad file, paste the token here. Then let's get this. So it

- [00:19:57](https://www.youtube.com/watch?v=bupRePUOA18&t=1197) will become like this: ngrok authtoken. Okay. And then we will just paste this. Okay. And it is saved.

- [00:20:06](https://www.youtube.com/watch?v=bupRePUOA18&t=1206) Then all we need to do is run this. This will give us a public URL. Okay. It didn't copy. Sometimes

- [00:20:12](https://www.youtube.com/watch?v=bupRePUOA18&t=1212) it may happen. Copy again and then paste it. And yes, we got the public URL right now. After that,

- [00:20:19](https://www.youtube.com/watch?v=bupRePUOA18&t=1219) we need to start the Stable SwarmUI. I'm going to just run the Stable SwarmUI now because we

- [00:20:24](https://www.youtube.com/watch?v=bupRePUOA18&t=1224) already have updated. Okay. SwarmUI started, not Stable SwarmUI. I am still saying Stable SwarmUI,

- [00:20:29](https://www.youtube.com/watch?v=bupRePUOA18&t=1229) but this is now SwarmUI. Then I need to copy this link. This is the public ngrok link and paste it

- [00:20:35](https://www.youtube.com/watch?v=bupRePUOA18&t=1235) into my own computer browser. Then click visit site. Remember the order is matter. So first you

- [00:20:42](https://www.youtube.com/watch?v=bupRePUOA18&t=1242) start the ngrok, but do not click the visit site then start the SwarmUI. Then click the visit site. And

- [00:20:48](https://www.youtube.com/watch?v=bupRePUOA18&t=1248) you see now this is running on Massed Compute. So let's go to the models. We also have other

- [00:20:54](https://www.youtube.com/watch?v=bupRePUOA18&t=1254) models on Massed Compute right away installed for you. So you can use all of them. I'm going to use

- [00:20:59](https://www.youtube.com/watch?v=bupRePUOA18&t=1259) the development branch. This will run by default on FP8 precision, not FP16. So let's generate an

- [00:21:08](https://www.youtube.com/watch?v=bupRePUOA18&t=1268) image. Don't forget to set this CFG scale to 1. And let's use some prompts from the Midjourney as

- [00:21:13](https://www.youtube.com/watch?v=bupRePUOA18&t=1273) a comparison. So this is the prompt. This is a hard prompt. Let's copy paste it. And we are set.

- [00:21:19](https://www.youtube.com/watch?v=bupRePUOA18&t=1279) Let's generate. First time it will load the model. Let's go to the server, logs and debug. So you

- [00:21:25](https://www.youtube.com/watch?v=bupRePUOA18&t=1285) can see what is happening here. This will run the FLUX model on FP8 precision, but the text encoder

- [00:21:34](https://www.youtube.com/watch?v=bupRePUOA18&t=1294) will be running on FP16 precision. So I click the display advanced options. And then I am also going

- [00:21:41](https://www.youtube.com/watch?v=bupRePUOA18&t=1301) to change the advanced sampling type from here. I will show after this is generated. And are there

- [00:21:47](https://www.youtube.com/watch?v=bupRePUOA18&t=1307) any difference between FP16 and FP8? Yes, there is difference. As I said, look at this imgsli and

- [00:21:53](https://www.youtube.com/watch?v=bupRePUOA18&t=1313) you will notice the differences. FP16 works better, but it uses more VRAM. Okay. We got

- [00:21:59](https://www.youtube.com/watch?v=bupRePUOA18&t=1319) an image. There is a robot. So I am going to make the preferred DType into the default 16 bits. And

- [00:22:07](https://www.youtube.com/watch?v=bupRePUOA18&t=1327) let's say a war robot. Okay. Let's see. And you can see that the hands are amazing. It's a perfect

- [00:22:13](https://www.youtube.com/watch?v=bupRePUOA18&t=1333) quality hands. And I can say that this is actually better than the Midjourney. The Midjourney image

- [00:22:22](https://www.youtube.com/watch?v=bupRePUOA18&t=1342) doesn't have the accurate robot doing okay hands, you see, but the FLUX model generated an image

- [00:22:30](https://www.youtube.com/watch?v=bupRePUOA18&t=1350) more accurate than the Midjourney. This is just amazing. And we can use this locally without using

- [00:22:35](https://www.youtube.com/watch?v=bupRePUOA18&t=1355) any third party services. Now it is reloading the model in FP16 precision. You can always watch the

- [00:22:44](https://www.youtube.com/watch?v=bupRePUOA18&t=1364) logs from server logs and view debug. So this is how you can use the very best FLUX

- [00:22:50](https://www.youtube.com/watch?v=bupRePUOA18&t=1370) model on Massed Compute. It is running on Massed Compute, but I am using it on my PC. As I said,

- [00:22:56](https://www.youtube.com/watch?v=bupRePUOA18&t=1376) watch the main tutorial to learn more about how to use on Massed Compute. Okay. So now I am going

- [00:23:01](https://www.youtube.com/watch?v=bupRePUOA18&t=1381) to show this on RunPod. All the instructions are written in this post. So let's go to the RunPod

- [00:23:07](https://www.youtube.com/watch?v=bupRePUOA18&t=1387) from this link. Let's log in and let's go to the pods deploy. I'm going to deploy on a secure

- [00:23:12](https://www.youtube.com/watch?v=bupRePUOA18&t=1392) cloud for faster right now. I need speed. I'm going to select this one and I am going to deploy

- [00:23:18](https://www.youtube.com/watch?v=bupRePUOA18&t=1398) it on L40S GPU. Now as a template, I suggest you to use this Torch template, which is Torch 2.1.

- [00:23:27](https://www.youtube.com/watch?v=bupRePUOA18&t=1407) This is working very, very well. Then you need to edit the template add the port of the SwarmUI,

- [00:23:34](https://www.youtube.com/watch?v=bupRePUOA18&t=1414) which is 7801. Let's make the volume disc like 100 GB and set overrides and deploy on demand and go

- [00:23:43](https://www.youtube.com/watch?v=bupRePUOA18&t=1423) to my pods. The installation is so easy. Everything is written here. We just need to install Linux.sh

- [00:23:48](https://www.youtube.com/watch?v=bupRePUOA18&t=1428) file. This is a public post as I said. Let's just wait for machine to start. The installation

- [00:23:54](https://www.youtube.com/watch?v=bupRePUOA18&t=1434) is shown in the main tutorial. You need to first install. Then you need to download the models. On

- [00:24:00](https://www.youtube.com/watch?v=bupRePUOA18&t=1440) Massed Compute you don't need to install. It is pre-installed. So let's quickly remember,

- [00:24:05](https://www.youtube.com/watch?v=bupRePUOA18&t=1445) let's upload the file, make sure that it has the accurate naming. Then all we need to do is

- [00:24:10](https://www.youtube.com/watch?v=bupRePUOA18&t=1450) just run this command open terminal. It should be very fast on this pod. It's an expensive

- [00:24:15](https://www.youtube.com/watch?v=bupRePUOA18&t=1455) pod. By the way, you don't need this pod. You can run this on RTX 3090 pod as well. You just

- [00:24:22](https://www.youtube.com/watch?v=bupRePUOA18&t=1462) need to use the FP8 precision, not FP16, and it will work perfect. And by default SwarmUI uses

- [00:24:28](https://www.youtube.com/watch?v=bupRePUOA18&t=1468) FP8 precision. So you don't need to worry about anything. Okay. The installation process will

- [00:24:34](https://www.youtube.com/watch?v=bupRePUOA18&t=1474) star now. I will connect from 7801 port. This is super important because there is no share for

- [00:24:41](https://www.youtube.com/watch?v=bupRePUOA18&t=1481) SwarmUI like Gradio. Agree. Customize, modern dark. Just yes. ComfyUI local. I'm not going

- [00:24:48](https://www.youtube.com/watch?v=bupRePUOA18&t=1488) to download anything and install now. These installers install the latest version of the

- [00:24:53](https://www.youtube.com/watch?v=bupRePUOA18&t=1493) SwarmUI from the official new repository. So you don't need to update or anything else. It will

- [00:24:59](https://www.youtube.com/watch?v=bupRePUOA18&t=1499) just install the latest version. By the way, when you use the turbo model or the development model,

- [00:25:06](https://www.youtube.com/watch?v=bupRePUOA18&t=1506) they use the same amount of VRAM and they have the same step speed. So what matters is that

- [00:25:12](https://www.youtube.com/watch?v=bupRePUOA18&t=1512) with the turbo model, you only need to execute 4 steps compared to the 20 steps. So it is taking

- [00:25:21](https://www.youtube.com/watch?v=bupRePUOA18&t=1521) 5 times lower duration than the development step. The turbo model is the schnell model. I am

- [00:25:29](https://www.youtube.com/watch?v=bupRePUOA18&t=1529) not able to spell it accurately. This is a time step distilled model. So if you have lower than

- [00:25:36](https://www.youtube.com/watch?v=bupRePUOA18&t=1536) 20 GB GPU on your computer, you can use this to generate images in the reasonable times. You can

- [00:25:44](https://www.youtube.com/watch?v=bupRePUOA18&t=1544) still use this development model, but it will take 5 times more duration than the turbo model. It

- [00:25:51](https://www.youtube.com/watch?v=bupRePUOA18&t=1551) is up to you. It is your choice. With SwarmUI as low as 6 GB GPU, you can generate images

- [00:25:57](https://www.youtube.com/watch?v=bupRePUOA18&t=1557) on FLUX models with the amazing accuracy and amazing quality. All right. The SwarmUI started

- [00:26:03](https://www.youtube.com/watch?v=bupRePUOA18&t=1563) on the RunPod. We can start installing the model. So let's upload our downloaded files, which are

- [00:26:10](https://www.youtube.com/watch?v=bupRePUOA18&t=1570) here. Let's just upload them into here. Then open the RunPod instructions txt file. Just copy this, open

- [00:26:17](https://www.youtube.com/watch?v=bupRePUOA18&t=1577) a new terminal like this paste and hit enter. And which options you want to download, it will ask

- [00:26:22](https://www.youtube.com/watch?v=bupRePUOA18&t=1582) you let's download the option 5. And then let's also download the option, which option, option 8.

- [00:26:30](https://www.youtube.com/watch?v=bupRePUOA18&t=1590) So we will have the best text encoder FP16. And we are also going to have the development branch FP16

- [00:26:37](https://www.youtube.com/watch?v=bupRePUOA18&t=1597) version. As I said, you can pick any of them. You can run them on any pod GPU. It will work

- [00:26:44](https://www.youtube.com/watch?v=bupRePUOA18&t=1604) accordingly. And backends are still loading. Sometimes you may get this error on RunPod. If

- [00:26:49](https://www.youtube.com/watch?v=bupRePUOA18&t=1609) this happens, you need to restart your pod and run it again. So after you turn off your pod or

- [00:26:56](https://www.youtube.com/watch?v=bupRePUOA18&t=1616) restarted your pod to restart the SwarmUI again, you just need to execute this command. If this

- [00:27:02](https://www.youtube.com/watch?v=bupRePUOA18&t=1622) loading doesn't get fixed, I will do a restart. This is the RunPod downloading speed. It is 170

- [00:27:09](https://www.youtube.com/watch?v=bupRePUOA18&t=1629) megabytes per second. Very decent. And there is also 150 megabytes per second. I am doing the

- [00:27:15](https://www.youtube.com/watch?v=bupRePUOA18&t=1635) downloads of two models at the same time, which is FP16 T5 and the FP16 development FLUX model.

- [00:27:23](https://www.youtube.com/watch?v=bupRePUOA18&t=1643) Okay both of the models are downloaded. You can see the status from here. Also the backend loading

- [00:27:28](https://www.youtube.com/watch?v=bupRePUOA18&t=1648) fixed automatically. So let's go to the models and refresh the models folder. It is getting

- [00:27:35](https://www.youtube.com/watch?v=bupRePUOA18&t=1655) refreshed right now. Okay. FLUX development model appeared. We select it. Don't forget to

- [00:27:40](https://www.youtube.com/watch?v=bupRePUOA18&t=1660) set the CFG scale. Currently it is not visible. So I need to, okay. Now it is visible. You see from

- [00:27:46](https://www.youtube.com/watch?v=bupRePUOA18&t=1666) clicking here to here, it can be fixed and CFG scale 1, and we are ready to use this amazing

- [00:27:52](https://www.youtube.com/watch?v=bupRePUOA18&t=1672) model on RunPod. So this time I am going to make a comparison with the CivitAI image from one of the

- [00:27:58](https://www.youtube.com/watch?v=bupRePUOA18&t=1678) Stable Diffusion models. Let's copy this prompt. There are also a lot of LoRAs and other stuff,

- [00:28:04](https://www.youtube.com/watch?v=bupRePUOA18&t=1684) and let's paste it into our prompt and let's generate our first image. This will be by

- [00:28:11](https://www.youtube.com/watch?v=bupRePUOA18&t=1691) default FP8, because we didn't change the DType from advanced. So click advanced. Don't forget

- [00:28:19](https://www.youtube.com/watch?v=bupRePUOA18&t=1699) that. If you are using over 24 GB GPU with RunPod or Massed Compute, then in the advanced sampling,

- [00:28:27](https://www.youtube.com/watch?v=bupRePUOA18&t=1707) we need to set the preferred DType. So I'm just going to cancel this operation, interrupt

- [00:28:31](https://www.youtube.com/watch?v=bupRePUOA18&t=1711) current session. Select the DType and let's say default 16 bit and generate. On ComfyUI people

- [00:28:38](https://www.youtube.com/watch?v=bupRePUOA18&t=1718) says that since they are using default, they think that it is using FP16. However not. When you don't

- [00:28:44](https://www.youtube.com/watch?v=bupRePUOA18&t=1724) explicitly define it is using automatic, which is FP8, not FP16. SwarmUI developer added these

- [00:28:51](https://www.youtube.com/watch?v=bupRePUOA18&t=1731) options after I have talked with him. So with ComfyUI, you need to same, you need to have FP16

- [00:28:58](https://www.youtube.com/watch?v=bupRePUOA18&t=1738) option added. Otherwise it will use FP8. Because otherwise it wouldn't work. The file itself is

- [00:29:05](https://www.youtube.com/watch?v=bupRePUOA18&t=1745) 24 GB in FP16 precision. So if you are using it with FP16 precision, it would require minimum 24

- [00:29:13](https://www.youtube.com/watch?v=bupRePUOA18&t=1753) GB to just load the weights into the VRAM. Okay. The generation starting. Let's go to the logs to

- [00:29:18](https://www.youtube.com/watch?v=bupRePUOA18&t=1758) see the speed. Okay. Let's go to debug and you see it is 2 it / second. This is just mind blowing

- [00:29:25](https://www.youtube.com/watch?v=bupRePUOA18&t=1765) speed. And we are using FP16 T5 text encoder. So with L40S we get an amazing speed. So this is the

- [00:29:34](https://www.youtube.com/watch?v=bupRePUOA18&t=1774) image we got. This is the first generation, not a cherry pick, which likely happened here. This

- [00:29:38](https://www.youtube.com/watch?v=bupRePUOA18&t=1778) is a very good image. And this is also a very good image, but let's say inside egg shell, warm.

- [00:29:45](https://www.youtube.com/watch?v=bupRePUOA18&t=1785) Yes. You see this is much more accurate than the Stable Diffusion CivitAI generated image. It says

- [00:29:53](https://www.youtube.com/watch?v=bupRePUOA18&t=1793) that it is inside eggshell, but in the CivitAI in the Stable Diffusion, it is not inside eggshell,

- [00:29:59](https://www.youtube.com/watch?v=bupRePUOA18&t=1799) but in the generated image of the FLUX, it is inside eggshell. So if we increase the step count,

- [00:30:06](https://www.youtube.com/watch?v=bupRePUOA18&t=1806) does it matter? Let's also test this. So reuse the parameters and let's make the step count 40,

- [00:30:13](https://www.youtube.com/watch?v=bupRePUOA18&t=1813) because we have a powerful GPU and I wonder if it will make any difference. And we got

- [00:30:18](https://www.youtube.com/watch?v=bupRePUOA18&t=1818) a different image. They both looking amazing. So the 40 steps didn't bring very much improvement,

- [00:30:26](https://www.youtube.com/watch?v=bupRePUOA18&t=1826) but I think it is a little bit better. So it is up to you. You can generate these 40 steps as

- [00:30:32](https://www.youtube.com/watch?v=bupRePUOA18&t=1832) well. Let's also generate a bigger resolution. Let's make this custom and 1536 to 1536 and

- [00:30:40](https://www.youtube.com/watch?v=bupRePUOA18&t=1840) generate. When we increase the resolution it will use more VRAM of course. And if you

- [00:30:44](https://www.youtube.com/watch?v=bupRePUOA18&t=1844) wonder how much VRAM it is using, let's install nvitop. pip install nvitop and nvitop and it is

- [00:30:52](https://www.youtube.com/watch?v=bupRePUOA18&t=1852) using 34 GB VRAM right now with these settings. However, this will give you an amazing quality.

- [00:31:01](https://www.youtube.com/watch?v=bupRePUOA18&t=1861) You can generate your YouTube thumbnails. You can generate whatever things that you want. By the way,

- [00:31:06](https://www.youtube.com/watch?v=bupRePUOA18&t=1866) this development is for non-commercial use. So if you're a company or something, you may pay

- [00:31:13](https://www.youtube.com/watch?v=bupRePUOA18&t=1873) attention to that. The Turbo is allowing you to use for commercial purposes as well. Okay. The

- [00:31:19](https://www.youtube.com/watch?v=bupRePUOA18&t=1879) image is getting generated right now. We can see the progress here. The IT, of course dropped when

- [00:31:25](https://www.youtube.com/watch?v=bupRePUOA18&t=1885) we increased the resolution, it dropped to the 1.34 seconds IT and the image is here. This is

- [00:31:32](https://www.youtube.com/watch?v=bupRePUOA18&t=1892) 1536 to 1536 native generation, not upscaled. The hands looks perfect. The image looks perfect. It's

- [00:31:40](https://www.youtube.com/watch?v=bupRePUOA18&t=1900) just amazing. As a last step, you can use this amazing model on Kaggle as well, a free Kaggle

- [00:31:47](https://www.youtube.com/watch?v=bupRePUOA18&t=1907) notebook as well. I have prepared the necessary cell on our notebook. You should use Turbo model

- [00:31:54](https://www.youtube.com/watch?v=bupRePUOA18&t=1914) on Kaggle. Otherwise it will be very slow. With Turbo model it takes around 100, 120 seconds to

- [00:32:01](https://www.youtube.com/watch?v=bupRePUOA18&t=1921) generate an image and it will work really, really good. Just follow the instructions in our Kaggle

- [00:32:07](https://www.youtube.com/watch?v=bupRePUOA18&t=1927) notebook and you can use it 30 hours every week for free on Kaggle, generate as many as images you

- [00:32:15](https://www.youtube.com/watch?v=bupRePUOA18&t=1935) want. It is just amazing. And the tutorial of the Kaggle is still valid. So all of these tutorials

- [00:32:23](https://www.youtube.com/watch?v=bupRePUOA18&t=1943) that I have shown in Windows tutorial main, Cloud tutorial main and free Kaggle account tutorial,

- [00:32:28](https://www.youtube.com/watch?v=bupRePUOA18&t=1948) all is valid. Just watch them first. If you don't know how to use SwarmUI, then watch this tutorial

- [00:32:33](https://www.youtube.com/watch?v=bupRePUOA18&t=1953) and you will know everything. Thank you very much for watching. Please like subscribe. Also,

- [00:32:39](https://www.youtube.com/watch?v=bupRePUOA18&t=1959) we have a Discord channel. When you click this link, you will see our discord channel. We have

- [00:32:43](https://www.youtube.com/watch?v=bupRePUOA18&t=1963) over 7,000 members join and chat with me. I reply every one of your messages. We also have a GitHub

- [00:32:50](https://www.youtube.com/watch?v=bupRePUOA18&t=1970) repository. It is here. If you fork it, star it and watch it and also sponsor. I appreciate that.

- [00:32:55](https://www.youtube.com/watch?v=bupRePUOA18&t=1975) You can find the link here. And finally, we also have our own unique subreddit SECourses. If you

- [00:33:03](https://www.youtube.com/watch?v=bupRePUOA18&t=1983) subscribe, follow our subreddit. I appreciate that. We only have 46 members right now,

- [00:33:09](https://www.youtube.com/watch?v=bupRePUOA18&t=1989) but hopefully it will get better. So hopefully see you in another amazing tutorial later.

# Blazing Fast & Ultra Cheap FLUX LoRA Training on Massed Compute & RunPod Tutorial - No GPU Required!

## Full tutorial link > https://www.youtube.com/watch?v=-uhL2nW7Ddw

[![Blazing Fast & Ultra Cheap FLUX LoRA Training on Massed Compute & RunPod Tutorial - No GPU Required!](https://img.youtube.com/vi/-uhL2nW7Ddw/sddefault.jpg)](https://www.youtube.com/watch?v=-uhL2nW7Ddw "Blazing Fast & Ultra Cheap FLUX LoRA Training on Massed Compute & RunPod Tutorial - No GPU Required!")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Blazing-Fast-and-Ultra-Cheap-FLUX-LoRA-Training-on-Massed-Compute-and-RunPod-Tutorial-No-GPU-Required.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Blazing-Fast-and-Ultra-Cheap-FLUX-LoRA-Training-on-Massed-Compute-and-RunPod-Tutorial-No-GPU-Required.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Unlock the power of FLUX LoRA training, even if you're short on GPUs or looking to boost speed and scale! This comprehensive guide takes you from novice to expert, showing you how to use Kohya GUI for creating top-notch FLUX LoRAs in the cloud. We'll cover everything: maximizing quality, optimizing speed, and finding the best deals. With our exclusive Massed Compute discount, you can rent 4x RTX A6000 GPUs for just $1.25 per hour, supercharging your training process. Learn how to leverage RunPod for both cost-effective computing and permanent storage. We'll also dive into lightning-fast uploads of your training checkpoints to Hugging Face, seamless downloads, and integrating LoRAs with popular tools like SwarmUI and Forge Web UI. Get ready to master the art of efficient, high-quality AI model training!

üîó Full Instructions and Links Written Post (the one used in the tutorial) ‚§µÔ∏è

‚ñ∂Ô∏è [https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-110879657](https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-110879657)

[00:00:00](https://youtu.be/-uhL2nW7Ddw?t=0) Introduction to FLUX Training on Cloud Services (Massed Compute and RunPod)

[00:00:45](https://youtu.be/-uhL2nW7Ddw?t=45) Overview of Platform Differences and Why Massed Compute is Preferred for FLUX Training

[00:02:01](https://youtu.be/-uhL2nW7Ddw?t=121) Using FLUX, Kohya GUI, and Using 4x GPUs for Fast Training

[00:03:08](https://youtu.be/-uhL2nW7Ddw?t=188) Exploring Massed Compute Coupons and Discounts: How to Save on GPU Costs

[00:05:35](https://youtu.be/-uhL2nW7Ddw?t=335) Detailed Setup for Training FLUX on Massed Compute: Account Creation, Billing, and Deploying Instances

[00:06:59](https://youtu.be/-uhL2nW7Ddw?t=419) Deploying Multiple GPUs on Massed Compute for Faster Training

[00:08:53](https://youtu.be/-uhL2nW7Ddw?t=533) Setting Up ThinLinc Client for File Transfers Between Local Machine and Cloud

[00:09:04](https://youtu.be/-uhL2nW7Ddw?t=544) Troubleshooting ThinLinc File Transfer Issues on Massed Compute

[00:09:25](https://youtu.be/-uhL2nW7Ddw?t=565) Preparing to Install Kohya GUI and Download Necessary Models on Massed Compute

[00:10:02](https://youtu.be/-uhL2nW7Ddw?t=602) Upgrading to the Latest Version of Kohya for FLUX Training

[00:11:02](https://youtu.be/-uhL2nW7Ddw?t=662) Downloading FLUX Training Models and Preparing the Dataset

[00:11:53](https://youtu.be/-uhL2nW7Ddw?t=713) Checking VRAM Usage with nvitop: Real-Time Monitoring During FLUX Training

[00:13:33](https://youtu.be/-uhL2nW7Ddw?t=813) Speed Optimization Tips: Disabling T5 Attention Mask for Faster Training

[00:17:44](https://youtu.be/-uhL2nW7Ddw?t=1064) Understanding the Trade-offs: Applying T5 Attention Mask vs. Training Speed

[00:18:40](https://youtu.be/-uhL2nW7Ddw?t=1120) Setting Up Multi-GPU Training for FLUX on Massed Compute

[00:18:52](https://youtu.be/-uhL2nW7Ddw?t=1132) Adjusting Epochs and Learning Rate for Multi-GPU Training

[00:22:24](https://youtu.be/-uhL2nW7Ddw?t=1344) Achieving Near-Linear Speed Gain with 4x GPUs on Massed Compute

[00:24:34](https://youtu.be/-uhL2nW7Ddw?t=1474) Uploading FLUX LoRAs to Hugging Face for Easy Access and Sharing

[00:24:56](https://youtu.be/-uhL2nW7Ddw?t=1496) Using SwarmUI on Your Local Machine via Cloudflare for Image Generation

[00:26:04](https://youtu.be/-uhL2nW7Ddw?t=1564) Moving Models to the Correct Folders in SwarmUI for FLUX Image Generation

[00:27:07](https://youtu.be/-uhL2nW7Ddw?t=1627) Setting Up and Running Grid Generation to Compare Different Checkpoints

[00:30:43](https://youtu.be/-uhL2nW7Ddw?t=1843) Downloading and Managing LoRAs and Models on Hugging Face

[00:33:35](https://youtu.be/-uhL2nW7Ddw?t=2015) Generating Images with FLUX on SwarmUI and Finding the Best Checkpoints

[00:38:22](https://youtu.be/-uhL2nW7Ddw?t=2302) Advanced Configurations in SwarmUI for Optimized Image Generation

[00:39:25](https://youtu.be/-uhL2nW7Ddw?t=2365) How to Use Forge Web UI with FLUX Models on Massed Compute

[00:39:33](https://youtu.be/-uhL2nW7Ddw?t=2373) Setting Up and Configuring Forge Web UI for FLUX on Massed Compute

[00:40:03](https://youtu.be/-uhL2nW7Ddw?t=2403) Moving Models and LoRAs to Forge Web UI for Image Generation

[00:41:15](https://youtu.be/-uhL2nW7Ddw?t=2475) Generating Images with LoRAs on Forge Web UI

[00:44:38](https://youtu.be/-uhL2nW7Ddw?t=2678) Transition to RunPod: Setting Up FLUX Training and Using SwarmUI/Forge Web UI

[00:45:13](https://youtu.be/-uhL2nW7Ddw?t=2713) RunPod Network Volume Storage: Setup and Integration with FLUX Training

[00:45:49](https://youtu.be/-uhL2nW7Ddw?t=2749) Differences Between Massed Compute and RunPod: Speed, Cost, and Hardware

[00:47:19](https://youtu.be/-uhL2nW7Ddw?t=2839) Deploying Instances on RunPod and Setting Up JupyterLab

[00:48:05](https://youtu.be/-uhL2nW7Ddw?t=2885) Installing Kohya GUI and Downloading Models for FLUX Training on RunPod

[00:48:48](https://youtu.be/-uhL2nW7Ddw?t=2928) Preparing Datasets and Starting FLUX Training on RunPod

[00:51:55](https://youtu.be/-uhL2nW7Ddw?t=3115) Monitoring VRAM and Training Speed on RunPod‚Äôs A40 GPUs

[00:56:42](https://youtu.be/-uhL2nW7Ddw?t=3402) Optimizing Training Speed by Disabling T5 Attention Mask on RunPod

[00:58:20](https://youtu.be/-uhL2nW7Ddw?t=3500) Comparing GPU Performance Across Platforms: A6000 vs A40 in FLUX Training

[00:58:38](https://youtu.be/-uhL2nW7Ddw?t=3518) Setting Up Multi-GPU Training on RunPod for Faster FLUX Training

[00:58:58](https://youtu.be/-uhL2nW7Ddw?t=3538) Adjusting Learning Rate and Epochs for Multi-GPU Training on RunPod

[01:03:41](https://youtu.be/-uhL2nW7Ddw?t=3821) Achieving Near-Linear Speed Gain with Multi-GPU FLUX Training on RunPod

[01:05:46](https://youtu.be/-uhL2nW7Ddw?t=3946) Completing FLUX Training on RunPod and Preparing Models for Use

[01:05:52](https://youtu.be/-uhL2nW7Ddw?t=3952) Managing Multiple Checkpoints: Best Practices for FLUX Training

[01:06:04](https://youtu.be/-uhL2nW7Ddw?t=3964) Using SwarmUI on RunPod for Image Generation with FLUX LoRAs

[01:08:18](https://youtu.be/-uhL2nW7Ddw?t=4098) Setting Up Multiple Backends on SwarmUI for Multi-GPU Image Generation

[01:10:50](https://youtu.be/-uhL2nW7Ddw?t=4250) Generating Images and Comparing Checkpoints on SwarmUI on RunPod

[01:11:55](https://youtu.be/-uhL2nW7Ddw?t=4315) Uploading FLUX LoRAs to Hugging Face from RunPod for Easy Access

[01:12:08](https://youtu.be/-uhL2nW7Ddw?t=4328) Advanced Download Techniques: Using Hugging Face CLI for Batch Downloads

[01:15:16](https://youtu.be/-uhL2nW7Ddw?t=4516) Fast Download and Upload of Models and LoRAs on Hugging Face

[01:17:14](https://youtu.be/-uhL2nW7Ddw?t=4634) Using Forge Web UI on RunPod for Image Generation with FLUX LoRAs

[01:18:01](https://youtu.be/-uhL2nW7Ddw?t=4681) Troubleshooting Installation Issues with Forge Web UI on RunPod

[01:23:25](https://youtu.be/-uhL2nW7Ddw?t=5005) Generating Images on Forge Web UI with FLUX Models and LoRAs

[01:24:20](https://youtu.be/-uhL2nW7Ddw?t=5060) Conclusion and Upcoming Research on Fine-Tuning FLUX with CLIP Large Models



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=0) Greetings, everyone. Today I am going to show&nbsp; you how you can train FLUX and use FLUX on&nbsp;&nbsp;

- [00:00:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=7) cloud services if you don't have a powerful&nbsp; GPU or if you want to speed up your training.&nbsp;&nbsp;

- [00:00:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=12) With Massed Compute and also RunPod, you will&nbsp; be able to use the Kohya GUI and train amazing&nbsp;&nbsp;

- [00:00:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=19) FLUX models in under 1 hour by only using&nbsp; $1.25 per hour by using 4x GPU. 4x GPU is&nbsp;&nbsp;

- [00:00:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=28) not mandatory. You can also use 1x GPU, but I&nbsp; will show you how you can properly use multiple&nbsp;&nbsp;

- [00:00:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=36) GPUs to speed up your training. Not only that, I&nbsp; will show how you can start SwarmUI in RunPod or&nbsp;&nbsp;

- [00:00:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=41) in Massed Compute and use it on your computer,&nbsp; generate images very fast, do grid generation,&nbsp;&nbsp;

- [00:00:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=47) and compare your checkpoints very fast to decide&nbsp; the best checkpoint, both on Massed Compute and&nbsp;&nbsp;

- [00:00:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=55) RunPod. So I am going to show everything on both&nbsp; platforms. I will show how to rent multiple GPUs&nbsp;&nbsp;

- [00:01:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=60) and do training on multiple GPUs or on a single&nbsp; GPU. But this is not all. I am also going to show&nbsp;&nbsp;

- [00:01:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=66) you how to upload and download your checkpoints,&nbsp; your training models very fast to Hugging Face,&nbsp;&nbsp;

- [00:01:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=74) uploading 12GB these LoRA files to Hugging Face&nbsp; took only 2 minutes with my amazing scripts.&nbsp;&nbsp;

- [00:01:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=81) Downloading them doesn't take much longer as&nbsp; well. So if you want to learn how to train&nbsp;&nbsp;

- [00:01:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=86) FLUX and use FLUX privately on cloud providers,&nbsp; this is the tutorial that you need. Moreover,&nbsp;&nbsp;

- [00:01:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=92) I will show how to install and use Forge Web UI's&nbsp; latest version as well. So either by using the&nbsp;&nbsp;

- [00:01:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=99) amazing SwarmUI or by using the Forge UI, you will&nbsp; be able to use your generated LoRA checkpoints&nbsp;&nbsp;

- [00:01:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=107) very fast and very efficiently on both RunPod and&nbsp; Massed Compute platforms. But please, before&nbsp;&nbsp;

- [00:01:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=114) watching this tutorial, make sure you have watched&nbsp; the main FLUX LoRA training Windows tutorial&nbsp;&nbsp;

- [00:02:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=121) because I have covered all of the details there.&nbsp; There will be fewer details in this tutorial. So&nbsp;&nbsp;

- [00:02:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=127) make sure to watch that one, then watch this&nbsp; one to learn everything perfectly. As usual,&nbsp;&nbsp;

- [00:02:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=132) I have prepared very detailed post, instructions&nbsp; where you will find all of the information and&nbsp;&nbsp;

- [00:02:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=139) the links that you need. I will begin by showing&nbsp; how to train and use on Massed Compute. However,&nbsp;&nbsp;

- [00:02:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=147) there is one requirement, both for Massed&nbsp; Compute and for RunPod, which is watching&nbsp;&nbsp;

- [00:02:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=152) this Windows tutorial, because I am not going&nbsp; to repeat everything that I have shown in this&nbsp;&nbsp;

- [00:02:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=157) tutorial. This tutorial has 74 video chapters.&nbsp; It is prepared very well. So please watch the&nbsp;&nbsp;

- [00:02:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=164) Windows tutorial to learn how to use Kohya in&nbsp; general, then watch this tutorial to learn how to&nbsp;&nbsp;

- [00:02:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=169) train and use FLUX on cloud services. So our latest&nbsp; configuration and the installers are shared in&nbsp;&nbsp;

- [00:02:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=177) version 21. When you are watching this tutorial,&nbsp; it may be a higher version. Usually, I will put it&nbsp;&nbsp;

- [00:03:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=183) at the very top and also in the attachments. Click&nbsp; this link to download it, extract it anywhere you&nbsp;&nbsp;

- [00:03:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=188) want. You can extract it even into your downloads.&nbsp; Let's extract it here, enter inside the extracted&nbsp;&nbsp;

- [00:03:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=194) folder, and you will see Massed Compute and RunPod&nbsp; instructions. I will begin with Massed Compute,&nbsp;&nbsp;

- [00:03:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=199) as I said, then next will be RunPod. So if you&nbsp; are interested in RunPod, you can just look at the&nbsp;&nbsp;

- [00:03:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=205) description of the video and jump to the RunPod&nbsp; section. However, I prefer Massed Compute because&nbsp;&nbsp;

- [00:03:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=210) of the several things that it has. So it is up&nbsp; to you to use either of them. So we will open&nbsp;&nbsp;

- [00:03:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=214) the Massed Compute FLUX instructions TXT file. All&nbsp; the steps that we are going to need are documented&nbsp;&nbsp;

- [00:03:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=221) here. First of all, you need to have a Massed&nbsp; Compute account. If you use this link to register,&nbsp;&nbsp;

- [00:03:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=225) I appreciate that. Let's use this link. Since I&nbsp; already have registered, it is already logged in.&nbsp;&nbsp;

- [00:03:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=231) Register and log in. Then you need to set up some&nbsp; billing. If you get some errors during this stage,&nbsp;&nbsp;

- [00:03:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=237) you can click here and chat with the support,&nbsp; but it is so straightforward. Probably you won't&nbsp;&nbsp;

- [00:04:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=243) need it. It also supports crypto payment as well.&nbsp; Then we go to the deploy here, and we are going to&nbsp;&nbsp;

- [00:04:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=249) deploy our cloud machine. So everything will run&nbsp; on a cloud, and it will not use our computer. We&nbsp;&nbsp;

- [00:04:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=255) are going to rent any number of GPUs that we want.&nbsp; In this tutorial, I am also going to show you&nbsp;&nbsp;

- [00:04:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=261) multiple GPU training to speed up the training. So&nbsp; I am going to rent 4 GPUs, and then I'm going to&nbsp;&nbsp;

- [00:04:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=267) select creators. This is super important. Select&nbsp; SECourses. This is our special image where Kohya,&nbsp;&nbsp;

- [00:04:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=274) SwarmUI, Forge Web UI, and a lot of things are&nbsp; installed. We have a special coupon. You see&nbsp;&nbsp;

- [00:04:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=279) currently it is $2.5 per hour, but I am going&nbsp; to enter our coupon, and it will become $1.25&nbsp;&nbsp;

- [00:04:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=287) per hour for an amazing system, which has 192GB&nbsp; RAM and 1024GB storage, because we are renting 4&nbsp;&nbsp;

- [00:04:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=298) GPUs. You don't have to rent 4 GPUs. You can also&nbsp; rent 1 GPU and train on that. When you rent 1 GPU,&nbsp;&nbsp;

- [00:05:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=303) it becomes 31 cents per hour for RTX A6000 GPU.&nbsp; This GPU has 48GB VRAM. This is just an amazing&nbsp;&nbsp;

- [00:05:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=311) price. This is also not a spot instance, so it is&nbsp; permanently assigned to you until you terminate&nbsp;&nbsp;

- [00:05:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=317) the machine. But since I'm going to show you how&nbsp; to do training on 4 GPUs at the same time to speed&nbsp;&nbsp;

- [00:05:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=322) up training, I am going to rent 4 GPUs. Everything&nbsp; is the same. When you rent 1 GPU, 2 GPUs,&nbsp;&nbsp;

- [00:05:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=328) 4 GPUs, or 8 GPUs, it doesn't matter. Everything&nbsp; is the same. Just the configuration changes,&nbsp;&nbsp;

- [00:05:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=332) which I am going to explain. So after that,&nbsp; click deploy. You see currently I also have&nbsp;&nbsp;

- [00:05:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=336) another instance running with 8 GPUs. The coupon&nbsp; will not work with 8 GPUs. This is a special given&nbsp;&nbsp;

- [00:05:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=342) coupon for me by Massed Compute, but our coupon&nbsp; is valid up to 4 GPUs at the same time. So you&nbsp;&nbsp;

- [00:05:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=348) can also rent 2x, 3x, or 4 GPUs running at the&nbsp; same time with the same price. Just wait until&nbsp;&nbsp;

- [00:05:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=355) initialization is completed. For connecting to&nbsp; the remote machine I am going to use ThinLinc&nbsp;&nbsp;

- [00:06:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=361) client. Click here, download and install it.&nbsp; It is just so straightforward. Then open the&nbsp;&nbsp;

- [00:06:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=366) ThinLinc client like this. Before starting to use&nbsp; it, click options and go to the local devices,&nbsp;&nbsp;

- [00:06:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=373) uncheck all and click drives. Details. Add a folder&nbsp; on your computer where it will be shared. You can&nbsp;&nbsp;

- [00:06:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=380) set it to read and write, or read-only, or not&nbsp; exported. I am setting it to read and write so&nbsp;&nbsp;

- [00:06:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=384) I can transfer files. This synchronization doesn't&nbsp; work well for big files. So if you have big files,&nbsp;&nbsp;

- [00:06:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=390) don't use this. Use your cloud storage like&nbsp; OneDrive, Hugging Face, or Google Drive,&nbsp;&nbsp;

- [00:06:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=396) but for small files like transferring the&nbsp; scripts, installers, or your training images,&nbsp;&nbsp;

- [00:06:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=402) if they are not very big, it works very well.&nbsp; And don't worry, I am going to show you how&nbsp;&nbsp;

- [00:06:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=406) you can save on the cloud, on Hugging Face, your&nbsp; generated model checkpoints so that you can later&nbsp;&nbsp;

- [00:06:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=412) use them very easily. By the way, one thing about&nbsp; the ThinLinc client is that it has Windows, Mac,&nbsp;&nbsp;

- [00:06:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=419) and Linux versions. So install according to your&nbsp; operating system. Don't Forget that. The machine&nbsp;&nbsp;

- [00:07:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=425) has started. You see the status is running. So we&nbsp; are going to connect. Click here. So it is copied,&nbsp;&nbsp;

- [00:07:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=431) copy-paste it here. You see, you don't type HTTP or&nbsp; the port. This is just it. You use the Ubuntu as&nbsp;&nbsp;

- [00:07:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=438) Ubuntu. This is important. And copy the password,&nbsp; and just paste it and connect. There is also end

- [00:07:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=444) existing session. When you check it, it will&nbsp; close all of the applications on the server.&nbsp;&nbsp;

- [00:07:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=449) So be careful and continue. Machine starting.&nbsp; Click start. Don't wait. And the machine has&nbsp;&nbsp;

- [00:07:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=454) started. You will see several things here. You&nbsp; will notice, for example, you can see that we&nbsp;&nbsp;

- [00:07:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=459) have 881GB free hard drive. We have 189GB RAM and&nbsp; currently using only 4% of the CPU. You can also&nbsp;&nbsp;

- [00:07:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=469) right-click here. This is terminal. New window.&nbsp; This is really important to understand. Then&nbsp;&nbsp;

- [00:07:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=474) type nvitop like this, and you can see the GPU&nbsp; status. You should see as many GPUs as you have&nbsp;&nbsp;

- [00:08:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=481) started. I have currently 4 GPUs. So this machine&nbsp; is currently started and working very well. You&nbsp;&nbsp;

- [00:08:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=486) will notice that we have run updaters for SwarmUI,&nbsp; for OneTrainer, for Kohya, for SD Forge, and for&nbsp;&nbsp;

- [00:08:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=492) Automatic1111 Web UI. Then we also have Pinokio AI&nbsp; installed here. We have JupyterLab installed here,&nbsp;&nbsp;

- [00:08:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=498) and the starting buttons for these applications&nbsp; are also located here. So these are for updates,&nbsp;&nbsp;

- [00:08:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=504) and these are for starting. So how are we going&nbsp; to move our files here to use them? First of all,&nbsp;&nbsp;

- [00:08:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=510) I am going to copy the downloaded zip file and&nbsp; move it back into my synchronization folder,&nbsp;&nbsp;

- [00:08:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=515) which is Massed Compute here. I will paste it&nbsp; here. Then I will extract it. Right-click and&nbsp;&nbsp;

- [00:08:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=521) extract this zip file so you can extract it on&nbsp; any machine without needing any third party. Then&nbsp;&nbsp;

- [00:08:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=527) enter inside home, and in here you will see thin&nbsp; drives. This is the synchronization drive with&nbsp;&nbsp;

- [00:08:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=533) your computer. You can also log in to your Patreon&nbsp; account and download the zip file on this machine&nbsp;&nbsp;

- [00:08:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=538) as well. Just wait a little bit. It will fetch the&nbsp; file names. As I said, for transferring big files,&nbsp;&nbsp;

- [00:09:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=544) this is not good, but for transferring small&nbsp; files, yes, it works. And we have the zip file&nbsp;&nbsp;

- [00:09:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=549) here. Kohya GUI FLUX installer. Please copy&nbsp; this into your downloads folder or desktop.&nbsp;&nbsp;

- [00:09:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=555) Doesn't matter. Don't use anything inside the&nbsp; synchronization drive. Otherwise, you will get&nbsp;&nbsp;

- [00:09:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=560) permission-related errors, and you will see the&nbsp; copying status here. You see it is copying from&nbsp;&nbsp;

- [00:09:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=565) my computer to the downloads folder. Just wait for&nbsp; this copy operation to be completed. As you copy&nbsp;&nbsp;

- [00:09:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=572) more files, it will take longer, and this also&nbsp; depends on your network speed, of course. Okay.&nbsp;&nbsp;

- [00:09:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=578) You see the copied all the files to downloads.&nbsp; Then let's move to the downloads folder. Let's&nbsp;&nbsp;

- [00:09:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=583) enter inside the folder. First of all, we are&nbsp; going to upgrade Kohya to the latest version,&nbsp;&nbsp;

- [00:09:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=588) but we didn't use the upgrader icon here, which&nbsp; is you see Kohya update. Why? Because currently,&nbsp;&nbsp;

- [00:09:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=596) the FLUX training is not available in the main&nbsp; branch. Therefore, we are going to switch to the&nbsp;&nbsp;

- [00:10:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=602) accurate branch and use it. Therefore, I have&nbsp; Massed_Compute_Kohya_FLUX_Instructions.txt,&nbsp;&nbsp;

- [00:10:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=607) which we had opened. So open it inside the Massed&nbsp; Compute and copy this command. Just copy it,&nbsp;&nbsp;

- [00:10:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=614) right-click, copy or Ctrl+C and start a new&nbsp; terminal, new window, and paste it. You see it&nbsp;&nbsp;

- [00:10:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=620) gave me an error. Why? Because this terminal is&nbsp; not in the accurate folder. So what you need to&nbsp;&nbsp;

- [00:10:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=625) do is go back to the folder where you have copied&nbsp; files, home, downloads here, and in here, click&nbsp;&nbsp;

- [00:10:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=631) this three dots icon and start a new terminal. So&nbsp; it will start the terminal in the accurate folder,&nbsp;&nbsp;

- [00:10:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=637) right-click and paste, and hit enter. And this&nbsp; time, it will work. So this is going to upgrade&nbsp;&nbsp;

- [00:10:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=642) my Kohya to the latest version with accurate&nbsp; libraries and the accurate branch for the FLUX&nbsp;&nbsp;

- [00:10:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=648) training. But if you are going to train SD 1.5&nbsp; or SDXL, you can just use the run update Kohya&nbsp;&nbsp;

- [00:10:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=654) and start using it. So meanwhile doing this, let's&nbsp; also download the necessary FLUX training models.&nbsp;&nbsp;

- [00:11:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=662) To do that, in the instructions, we have Massed&nbsp; Compute download models command here. So copy&nbsp;&nbsp;

- [00:11:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=668) this command, go back to the folder and start&nbsp; a new terminal here and paste it. This will&nbsp;&nbsp;

- [00:11:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=674) download the necessary models into your downloads&nbsp; model. If you copy something from your computer,&nbsp;&nbsp;

- [00:11:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=679) sometimes it may require several times copy-paste&nbsp; because there is a problem with ThinLinc client.&nbsp;&nbsp;

- [00:11:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=685) It may not sometimes copy the thing that you&nbsp; copied on your computer. So pay attention to&nbsp;&nbsp;

- [00:11:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=690) that. But when you copy something inside the&nbsp; Massed Compute, it always works. So this will&nbsp;&nbsp;

- [00:11:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=695) download the necessary models into the downloads&nbsp; folder. Here you see it started downloading. And&nbsp;&nbsp;

- [00:11:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=700) meanwhile, the other script is installing and&nbsp; upgrading Kohya to the latest version. So at this&nbsp;&nbsp;

- [00:11:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=707) point, just patiently wait for Kohya to start&nbsp; and the download to be completed. Alright, so&nbsp;&nbsp;

- [00:11:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=713) the files are downloaded, and also the Kohya has&nbsp; started. You can see running on local URL. Also,&nbsp;&nbsp;

- [00:12:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=720) it is automatically opened because I set it&nbsp; to. I will first start with a single GPU because&nbsp;&nbsp;

- [00:12:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=726) many of you may like to train on a single GPU.&nbsp; Then I will show how to train on multiple GPUs.&nbsp;&nbsp;

- [00:12:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=732) So on our Patreon post, we have the configuration&nbsp; for every config. The very best one is rank 1,&nbsp;&nbsp;

- [00:12:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=738) obviously, so I'm going to start training with&nbsp; it. To start training with it, go to the LoRA&nbsp;&nbsp;

- [00:12:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=743) tab. This is super important. Don't load into&nbsp; the DreamBooth tab, otherwise your config will&nbsp;&nbsp;

- [00:12:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=747) get corrupted. Configuration. Then click this icon&nbsp; to load it. This is running on a remote machine,&nbsp;&nbsp;

- [00:12:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=753) not mine. You can notice the ThinLinc client here.&nbsp; So once you click here, it will let you pick the&nbsp;&nbsp;

- [00:12:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=759) item. So go to the above folder. Since we copied&nbsp; into the downloads, let's enter inside downloads,&nbsp;&nbsp;

- [00:12:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=765) enter inside the folder, and we have the best&nbsp; configurations here. I'm going to load it. So it&nbsp;&nbsp;

- [00:12:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=771) has loaded everything for me. This is by default&nbsp; set for Massed Compute. You see FLUX 1 dev,&nbsp;&nbsp;

- [00:12:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=777) safetensors. This already exists there. The output name and everything. Everything is the same&nbsp;&nbsp;

- [00:13:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=783) as on Windows. If you have watched the tutorial,&nbsp; as I said, you will know by now. So I will also&nbsp;&nbsp;

- [00:13:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=788) quickly prepare my dataset to show you as well.&nbsp; My training dataset is here. I will copy it into&nbsp;&nbsp;

- [00:13:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=794) the Massed Compute drive. Since it is not big, it&nbsp; will work very well. You see, this is the dataset,&nbsp;&nbsp;

- [00:13:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=800) 11 megabytes. Then it will appear in here. Let's&nbsp; refresh this folder. You can hit F5 to refresh&nbsp;&nbsp;

- [00:13:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=807) it. Wait for a new file to be updated. Then you&nbsp; see my dataset has arrived here. So I'm going to&nbsp;&nbsp;

- [00:13:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=813) set my dataset. ohwx, man. I will do 1 repeating. So output&nbsp; where you want to save it. Let's click here. You&nbsp;&nbsp;

- [00:13:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=821) can save it anywhere. Not in thindrive, though&nbsp; it is important. Let's save it into downloads.&nbsp;&nbsp;

- [00:13:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=826) And let's say FLUX train like this. Prepare&nbsp; dataset. I explain in detail what these are doing&nbsp;&nbsp;

- [00:13:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=833) in the Windows tutorial. So watch it and copy&nbsp; info to respective fields. However, I am going&nbsp;&nbsp;

- [00:13:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=838) to make my model checkpoints output directly to&nbsp; the SwarmUI LoRA folder so I will be able to use&nbsp;&nbsp;

- [00:14:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=845) them. You can also use Forge Web UI. I will show&nbsp; that too. So you see the output directory for the&nbsp;&nbsp;

- [00:14:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=851) training model. I am going to click here, go to&nbsp; the apps, and inside here you see Stable SwarmUI.&nbsp;&nbsp;

- [00:14:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=856) This latest SwarmUI, not Stable SwarmUI. Go to&nbsp; the models, select LoRA, and that's it. So they&nbsp;&nbsp;

- [00:14:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=862) will be saved inside here. Let's delete the logs.&nbsp; I don't need them. And we don't use regularization&nbsp;&nbsp;

- [00:14:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=868) images, and we are ready. So you can save&nbsp; your config, and before starting training,&nbsp;&nbsp;

- [00:14:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=874) you can click print training command to see&nbsp; whether there are any errors or not. And it says&nbsp;&nbsp;

- [00:14:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=879) that yes, training images are failing for some&nbsp; reason. Let's see. Maybe we didn't copy properly.

- [00:14:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=885) Dataset preparation. Parameters. No, it should&nbsp; be somewhere around here. Yes. The image folder is&nbsp;&nbsp;

- [00:14:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=891) supposed to be here. Maybe there was some error&nbsp; when preparing. Yes. Probably it failed to read&nbsp;&nbsp;

- [00:14:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=899) my ThinLinc drive because I didn't copy it. So&nbsp; if you encounter that error, don't get confused.&nbsp;&nbsp;

- [00:15:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=906) So what we need to do is first move our training&nbsp; files to the downloads folder, then prepare the&nbsp;&nbsp;

- [00:15:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=912) training data. So let's move it to the downloads&nbsp; folder. I'm not going to delete this part of&nbsp;&nbsp;

- [00:15:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=917) the tutorial because you may also encounter this&nbsp; error. Okay. So we are going to reset, re-prepare.&nbsp;&nbsp;

- [00:15:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=923) To re-prepare it, oh, I didn't give the downloads&nbsp; folder first, so that was my mistake. Maybe it&nbsp;&nbsp;

- [00:15:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=930) will work with ThinLinc drive too. Okay. Let's&nbsp; try from the ThinLinc drive first, then we can&nbsp;&nbsp;

- [00:15:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=935) try from actually let's go with the safe place so&nbsp; go to the downloads. Yeah. This is my training&nbsp;&nbsp;

- [00:15:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=940) images. Prepare training data. After that verify&nbsp; it from here. Yes. It says done copying for the&nbsp;&nbsp;

- [00:15:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=946) respective fields. Okay. It is set. Then I'm going&nbsp; to set the output folder again. So from here,&nbsp;&nbsp;

- [00:15:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=952) let's go to the apps, SwarmUI, models, and LoRA&nbsp; and delete the logs and save again and click the&nbsp;&nbsp;

- [00:16:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=960) print training command. And yes, it shows the&nbsp; setup. So first I will show as a single GPU,&nbsp;&nbsp;

- [00:16:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=968) then as a multiple GPU, as I said, let's just&nbsp; click start training. The configurations may get&nbsp;&nbsp;

- [00:16:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=973) updated when you're watching this. It may become&nbsp; better because I'm currently searching for better.&nbsp;&nbsp;

- [00:16:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=978) By the way, it shows that I have 11 images, which&nbsp; is wrong. Why? Because we didn't wait for copying&nbsp;&nbsp;

- [00:16:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=986) files to the downloads. And when I was preparing&nbsp; the dataset, it wasn't full. We can see that. Yes.&nbsp;&nbsp;

- [00:16:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=992) Now all files are here. So I'm going to manually&nbsp; move them. So copy them and go to the downloads&nbsp;&nbsp;

- [00:16:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=998) FLUX train, image. ohwx man, you see it lacking. So&nbsp; I will just paste it. So make sure that all of the&nbsp;&nbsp;

- [00:16:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1005) files are fully copied. Otherwise, it will be also&nbsp; corrupted and you will get an error. Always wait&nbsp;&nbsp;

- [00:16:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1012) for full copy. Yes. Now it should work. So let's&nbsp; just click start training again. I'm not going&nbsp;&nbsp;

- [00:16:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1017) to delete any of these parts because these parts&nbsp; are likely the parts that you may also encounter&nbsp;&nbsp;

- [00:17:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1023) problems. And so you will know what is the reason&nbsp; for the problem. And it is getting ready. Okay.&nbsp;&nbsp;

- [00:17:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1029) Now let's just wait for the training to start,&nbsp; and let's return back to nvitop, where we will&nbsp;&nbsp;

- [00:17:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1036) monitor the VRAM usage. So it is loading the model&nbsp; right now. So the training has started. Wait until&nbsp;&nbsp;

- [00:17:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1042) you get like 100 steps to see the final speed&nbsp; because in the beginning, it is not displaying&nbsp;&nbsp;

- [00:17:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1049) the accurate speed because it is displaying average speed. So I wait like 100 steps to get the full&nbsp;&nbsp;

- [00:17:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1055) speed of the training. Okay. It has been 50 steps,&nbsp; and it has gone as low as 8.5 seconds / it. If you find&nbsp;&nbsp;

- [00:17:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1064) this is still very slow, what you can do is stop&nbsp; training and disable apply T5 attention mask. This&nbsp;&nbsp;

- [00:17:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1071) will speed up training hugely with the trade-off&nbsp; of some quality degradation. Alternatively,&nbsp;&nbsp;

- [00:17:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1077) what you can do? In the Massed Compute deploy&nbsp; you can select a more powerful GPU like L40S. This&nbsp;&nbsp;

- [00:18:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1085) is almost equal to, maybe a little bit more&nbsp; powerful than RTX 4090. So go with L40S GPU,&nbsp;&nbsp;

- [00:18:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1093) and you will get much better speed compared&nbsp; to this one. However, it will cost you more,&nbsp;&nbsp;

- [00:18:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1098) and we don't have a coupon for that. Okay. Without&nbsp; applying T5 attention mask, you see the speed is&nbsp;&nbsp;

- [00:18:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1104) hugely improved now, 4.43 seconds per it. It is&nbsp; almost double speed, and with this way, it will&nbsp;&nbsp;

- [00:18:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1111) take less than 3.5 hours duration for 3000 steps,&nbsp; which is amazing. So you can disable this with a&nbsp;&nbsp;

- [00:18:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1120) little bit of trade-off of quality and get a huge&nbsp; speed, or you can enable it and just wait. And now&nbsp;&nbsp;

- [00:18:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1126) it is time to start training with 4 GPUs at the&nbsp; same time. So I will stop the training. We have&nbsp;&nbsp;

- [00:18:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1132) a configuration for 4x GPU training, so you can&nbsp; just use it if you want. Just load it and use it.&nbsp;&nbsp;

- [00:18:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1139) It is inside the configurations. Let me show you.&nbsp; You see, 4x GPU batch size 1, and 4x GPU

- [00:19:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1145) batch size 2. Batch size 2 slightly improves the&nbsp; training speed, but quality will be lower. But for&nbsp;&nbsp;

- [00:19:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1152) people who want to learn how to set up themselves,&nbsp; I'm going to show that. So what we need to do is&nbsp;&nbsp;

- [00:19:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1157) we are going to set the accelerate, what we need&nbsp; to set is the number of processes 2. All right,&nbsp;&nbsp;

- [00:19:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1162) this is a hack to the flow of the video. Because&nbsp; I just figured out something, when you are setting&nbsp;&nbsp;

- [00:19:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1170) multiple GPU training, make sure that the number&nbsp; of processes equals the number of GPUs you have.&nbsp;&nbsp;

- [00:19:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1178) When you set it that way, you are going to get&nbsp; almost exactly the same number of epochs. You see,&nbsp;&nbsp;

- [00:19:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1184) currently, I am training for 60 epochs on&nbsp; 4 GPUs. Therefore, a total of 240 epochs,&nbsp;&nbsp;

- [00:19:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1192) and I am getting 240 epochs. Currently, I am doing&nbsp; training for a client, and I have figured it out.&nbsp;&nbsp;

- [00:19:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1198) There is not much speed difference. However,&nbsp; what is the benefit of this? With this way,&nbsp;&nbsp;

- [00:20:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1204) you can set the save every epochs accurately. So&nbsp; I am going to save every 20 epochs a checkpoint,&nbsp;&nbsp;

- [00:20:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1212) and it will work as expected. So set this number&nbsp; of processes equal to the number of GPUs you have.&nbsp;&nbsp;

- [00:20:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1220) If you are training on 8 GPUs, set it to 8.&nbsp; If you are training on 6, set it to 6. If you&nbsp;&nbsp;

- [00:20:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1223) are training on 4, set it to 4. So this is the&nbsp; logic. This is mandatory for multi-GPU and set&nbsp;&nbsp;

- [00:20:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1231) the GPU ID. So we have 4 GPUs, therefore 0, 1,&nbsp; 2, 3. So I'm going to train on all of the 4 GPUs&nbsp;&nbsp;

- [00:20:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1239) from the accelerated part you don't need to set&nbsp; anything else. So what else changes? When you set&nbsp;&nbsp;

- [00:20:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1244) the number of GPUs from there? You need to reduce&nbsp; your epoch. So you need to divide 200 by 4, and&nbsp;&nbsp;

- [00:20:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1252) it becomes 50. It is still the same. You can save&nbsp; every n epochs like this, like 25 or like 20,&nbsp;&nbsp;

- [00:20:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1259) whatever you wish. And we will compare them later.&nbsp; I will show that, don't worry. And one other thing&nbsp;&nbsp;

- [00:21:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1264) changes, which is the learning rate changes.&nbsp; You need to calculate the new learning rate.&nbsp;&nbsp;

- [00:21:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1271) How? So there is not a single formula for that,&nbsp; but the formula is usually it is equal to like this:&nbsp;&nbsp;

- [00:21:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1278) new LR is equal to the number of GPUs batch&nbsp; size divided by 2 and old LR. So what does&nbsp;&nbsp;

- [00:21:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1287) this mean? I'm going to show you in a moment.&nbsp; This is one of the suggested ways. So our new&nbsp;&nbsp;

- [00:21:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1292) LR will become our initial learning rate was this.&nbsp; So it will become multiplied by 4, multiplied by 1&nbsp;&nbsp;

- [00:21:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1299) because batch size 1, and divided by 2. So it will&nbsp; become like this. There is not an exact formula,&nbsp;&nbsp;

- [00:21:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1306) as I said. You can just load the configuration&nbsp; file, but you can also use this. If we had 8 GPUs,&nbsp;&nbsp;

- [00:21:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1311) it would become this, or if the batch size were&nbsp; 2, it would become like this. You see, this is the&nbsp;&nbsp;

- [00:21:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1317) logic. So whatever the learning rate at my best&nbsp; configuration, you can set your new learning rate&nbsp;&nbsp;

- [00:22:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1323) like this. So let's change the learning rate to&nbsp; the new value here. And also we have a learning&nbsp;&nbsp;

- [00:22:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1330) rate here. We can also use the configuration&nbsp; directly, and you can set a new name. Let's&nbsp;&nbsp;

- [00:22:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1336) say like this, 4x GPU train. Okay. This will be&nbsp; the output name. Change to this and save. And let's&nbsp;&nbsp;

- [00:22:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1344) see the new speed. By the way, if you apply this,&nbsp; it will become slower again. So it is up to you.&nbsp;&nbsp;

- [00:22:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1350) If you don't want to get quality loss, you can&nbsp; apply it, but if you need speed, you cannot apply&nbsp;&nbsp;

- [00:22:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1355) it. So let's see the speed without applying it.&nbsp; This will slightly reduce the quality but hugely&nbsp;&nbsp;

- [00:22:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1361) improve the speed. It is totally up to you.&nbsp; It is a trade-off. If you want the best speed,&nbsp;&nbsp;

- [00:22:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1365) don't apply it. If you don't want the best speed,&nbsp; but the best quality, apply it. Okay. So what do&nbsp;&nbsp;

- [00:22:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1370) we see now on the screen? When you pay attention,&nbsp; you will see that it is doing 750 steps instead of&nbsp;&nbsp;

- [00:22:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1377) 3000 steps because it divided the task into all 4&nbsp; GPUs. Therefore, now at one step, we are actually&nbsp;&nbsp;

- [00:23:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1386) doing 4 steps. So you see the speed is 4.85&nbsp; seconds per it. This speed gain is almost linear.&nbsp;&nbsp;

- [00:23:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1395) We almost got a speed-up of 4x. This is amazing.&nbsp; With SDXL, and last time I tested, this wasn't&nbsp;&nbsp;

- [00:23:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1402) the case. But with FLUX, we are almost getting a&nbsp; linear speed increase. This is just mind-blowing.&nbsp;&nbsp;

- [00:23:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1408) So you can just boot up 8 GPUs and you will get&nbsp; 8 times the speed with a minimal amount of loss&nbsp;&nbsp;

- [00:23:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1415) of quality. It will be almost the same quality.&nbsp; I will let this training be completed. It will&nbsp;&nbsp;

- [00:23:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1421) take a total of like 1 hour to train 3000 steps on&nbsp; FLUX AI. This is just amazing. And it will cost me&nbsp;&nbsp;

- [00:23:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1428) how much money? It will cost me only $1.25 per&nbsp; hour for training. So this is just amazing. This&nbsp;&nbsp;

- [00:23:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1437) is the most affordable, best quality training&nbsp; right now with a very high-speed training. So&nbsp;&nbsp;

- [00:24:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1443) instead of the other services, you can use Massed&nbsp; Compute, our coupon, and train very fast with the&nbsp;&nbsp;

- [00:24:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1449) maximum possible quality. My configurations&nbsp; will get hopefully updated to better versions.&nbsp;&nbsp;

- [00:24:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1454) I am testing the impact of training the text&nbsp; encoder clip large training. So the quality&nbsp;&nbsp;

- [00:24:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1461) will likely get better. After this training has&nbsp; been completed, I will also show how to use it on&nbsp;&nbsp;

- [00:24:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1468) SwarmUI and on Forge Web UI in Massed Compute. So&nbsp; let's just wait now. Alright. So the training has&nbsp;&nbsp;

- [00:24:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1474) been completed. Now I will show how you can use&nbsp; these generated LoRAs on Massed Compute and also&nbsp;&nbsp;

- [00:24:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1482) upload to Hugging Face to download later anywhere&nbsp; and use anywhere, like on your computer or in any&nbsp;&nbsp;

- [00:24:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1489) other cloud service provider. I am going to use&nbsp; SwarmUI, and we already have SwarmUI in our image.&nbsp;&nbsp;

- [00:24:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1496) So first run this to update it to the latest&nbsp; version. You see it is updating. As you see,&nbsp;&nbsp;

- [00:25:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1501) SwarmUI started with the most updated version.&nbsp; However, I am going to access it from my computer&nbsp;&nbsp;

- [00:25:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1508) browser to have more fluent usage instead&nbsp; of using it inside the ThinLinc client, you can&nbsp;&nbsp;

- [00:25:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1514) also use it inside the ThinLinc client, but it is&nbsp; better to use it on my computer. So in our post,&nbsp;&nbsp;

- [00:25:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1520) as you scroll down, you will see how to use it&nbsp; on SwarmUI. So you can watch the main tutorial.&nbsp;&nbsp;

- [00:25:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1527) I suggest that. Also, I have SwarmUI cloud&nbsp; tutorial. I suggest that. So you should watch&nbsp;&nbsp;

- [00:25:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1531) these tutorials to fully learn how to use it.&nbsp; However, I will show how to use it quickly,&nbsp;&nbsp;

- [00:25:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1536) but I want to use it on my computer. So copy this&nbsp; command. This is going to install Cloudflared,&nbsp;&nbsp;

- [00:25:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1542) and we are going to access it from Cloudflared.&nbsp; So close this terminal, start a new terminal,&nbsp;&nbsp;

- [00:25:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1547) right-click, and new window, paste the copied&nbsp; command. Okay. Looks like it didn't copy.&nbsp;&nbsp;

- [00:25:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1553) Sometimes this may happen. So right-click,&nbsp; new window, return back here, copy again.&nbsp;&nbsp;

- [00:25:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1559) Sometimes this happens with the ThinLinc client,&nbsp; paste it, hit enter. It will install the necessary&nbsp;&nbsp;

- [00:26:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1564) package. Okay. It is installed. Then copy this.&nbsp; This is going to generate a public URL that I can&nbsp;&nbsp;

- [00:26:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1570) use on my computer. Paste it. Okay. It didn't&nbsp; copy again. I hate when this happens. However,&nbsp;&nbsp;

- [00:26:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1576) there is no solution as far as I know.&nbsp; Okay. Paste again. Okay. This time it works,&nbsp;&nbsp;

- [00:26:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1581) and you see it started on localhost and also&nbsp; on a public URL. So open the public URL.&nbsp;&nbsp;

- [00:26:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1588) It will load. Okay. Then copy this link. Go&nbsp; back to your browser. Okay. You see currently&nbsp;&nbsp;

- [00:26:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1594) it is showing an error because the Adblock Plus is&nbsp; preventing it. So I will just refresh. And yes,&nbsp;&nbsp;

- [00:26:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1601) now I can use the SwarmUI that is running inside&nbsp; Massed Compute on my computer. So I prefer 30&nbsp;&nbsp;

- [00:26:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1608) steps. I have shown it in the Windows tutorial&nbsp; like this. Since this is a big GPU, I'm going&nbsp;&nbsp;

- [00:26:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1613) to also change the precision. So I enabled the&nbsp; advanced options in the sampling. I select the&nbsp;&nbsp;

- [00:27:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1620) UniPC and then I select my base model. So you see&nbsp; the models are not here. So let's move each one of&nbsp;&nbsp;

- [00:27:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1627) the files to the accurate folder. So cut this, go&nbsp; to the home apps inside the stable SwarmUI inside&nbsp;&nbsp;

- [00:27:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1635) models inside unet. This is where we put the dev&nbsp; model. Then inside clip, we are going to move&nbsp;&nbsp;

- [00:27:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1643) the T5 XXL, which is... Let's go to the downloads&nbsp; again. And clip is this one. Let's move, cut it,&nbsp;&nbsp;

- [00:27:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1652) move to the... Move back to clip, paste it. Yes,&nbsp; this may be a little bit of a task. I know you can&nbsp;&nbsp;

- [00:27:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1657) also use the downloader that I have. Then we are&nbsp; going to move the VAE file, cut it, go to the&nbsp;&nbsp;

- [00:27:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1662) home apps inside the SwarmUI. This is a one-time&nbsp; thing that you need to do. And you learn again,&nbsp;&nbsp;

- [00:27:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1669) models VAE go into the here, ea.safetensors, then&nbsp; go to the downloads. It will take just a minute.&nbsp;&nbsp;

- [00:27:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1677) Cut. This is the T5 XXL. Go back to home, go back&nbsp; to apps inside stable SwarmUI inside models. And&nbsp;&nbsp;

- [00:28:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1685) this goes into the clip here and paste it. I could&nbsp; paste both clip large and T5 XXL at the same time.&nbsp;&nbsp;

- [00:28:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1694) Then return back to your Swarm UI, refresh the&nbsp; models, and you see FLUX dev appeared. And now I&nbsp;&nbsp;

- [00:28:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1700) can set also FLUX guidance scale. I prefer 4. And&nbsp; in the advanced sampling, you can change this to&nbsp;&nbsp;

- [00:28:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1708) 16-bit because this is a big GPU. So currently it&nbsp; will generate an image with a single GPU. However,&nbsp;&nbsp;

- [00:28:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1714) if you have rented multiple GPUs, go to the&nbsp; server, go to the backends. We are going to&nbsp;&nbsp;

- [00:28:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1719) add several backends. Also, edit this and add&nbsp; --fast. It is making it faster for newer GPUs.&nbsp;&nbsp;

- [00:28:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1726) So how are we going to edit? ComfyUI self-starting&nbsp; edit, copy this paste here, copy this paste here,&nbsp;&nbsp;

- [00:28:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1733) set the GPU ID 1, save. Let's add another one&nbsp; and another one. So copy this paste, paste,&nbsp;&nbsp;

- [00:29:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1740) copy this paste, paste, set the GPU ID 2, save,&nbsp; and set the GPU ID 3, save. So it is going to&nbsp;&nbsp;

- [00:29:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1748) let me use all of the GPUs with a queue system.&nbsp; First of all, let's generate an image with the&nbsp;&nbsp;

- [00:29:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1754) FLUX dev, and I have amazing prompts to test the&nbsp; checkpoints. So the test prompts are inside here.&nbsp;&nbsp;

- [00:29:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1761) Let's open the test prompts. I have eyeglasses, so&nbsp; I am preparing the eyeglasses, for example, here.&nbsp;&nbsp;

- [00:29:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1767) And let's use this one, and let's copy-paste it&nbsp; here, and let's generate an image. So currently,&nbsp;&nbsp;

- [00:29:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1774) it will not apply my LoRA, but I want to see&nbsp; the model generation, and it is going to use&nbsp;&nbsp;

- [00:29:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1780) segmentation. So what does this segmentation mean?&nbsp; It will auto-mask the face of the generated image,&nbsp;&nbsp;

- [00:29:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1786) then with 0.7 denoise, it will inpaint it. So this&nbsp; is how you can use the SwarmUI that is running on&nbsp;&nbsp;

- [00:29:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1794) Massed Compute on your computer. Actually, I&nbsp; have shown this in the main Windows tutorial.&nbsp;&nbsp;

- [00:30:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1800) So after this, all I need to do is apply the LoRA&nbsp; from here, and which checkpoint I should apply.&nbsp;&nbsp;

- [00:30:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1807) Let's refresh this. You see there are LoRAs, and&nbsp; it saved once every 20 epochs. However, I see&nbsp;&nbsp;

- [00:30:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1815) that it only trained up to 100 epochs for some&nbsp; reason. Let's return back to... Oh, by the way,&nbsp;&nbsp;

- [00:30:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1822) the T5 XXL model needs a certain naming, therefore&nbsp; it re-downloaded it, and the name has to be like&nbsp;&nbsp;

- [00:30:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1829) this. Therefore, it has re-downloaded it. So&nbsp; we need to rename this to this file name. Yeah,&nbsp;&nbsp;

- [00:30:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1835) that is an error we had. You can also do that. So&nbsp; the LoRAs we have are 5. Let's check out the logs,&nbsp;&nbsp;

- [00:30:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1843) the reason for this. Okay, so it trained up to&nbsp; 94 epochs. It was supposed to fully train it,&nbsp;&nbsp;

- [00:30:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1850) but for some reason, only 94 epochs. Okay, this&nbsp; is the image that it generates without our LoRA.&nbsp;&nbsp;

- [00:30:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1858) Let's use the 80 epoch LoRA. This should be a&nbsp; pretty good one, and I suggest to use FP16 T5 XXL&nbsp;&nbsp;

- [00:31:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1866) instead of the FP8, which it downloads by default.&nbsp; I explain all of this in the main tutorials,&nbsp;&nbsp;

- [00:31:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1873) so you really should watch them, and you can go to&nbsp; the server and logs to see what is happening. So&nbsp;&nbsp;

- [00:31:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1879) it is generating the image right now with 1.25&nbsp; it per second, then it will inpaint the face,&nbsp;&nbsp;

- [00:31:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1885) and the image is generated with amazing quality.&nbsp; So how to find the best checkpoint. So go to the&nbsp;&nbsp;

- [00:31:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1892) tools, go to the grid generator, and in the first&nbsp; tab select LoRA. Search for LoRAs, fill all,&nbsp;&nbsp;

- [00:31:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1899) delete this "none" one, and then in the second,&nbsp; we are going to use a prompt like this, and I&nbsp;&nbsp;

- [00:31:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1905) am going to use test prompts without eyeglasses.&nbsp; This is formatted. There are no eyeglasses here,&nbsp;&nbsp;

- [00:31:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1910) so you can use this. I have the eyeglasses, so I&nbsp; am going to use grid formatted eyeglasses. For grid&nbsp;&nbsp;

- [00:31:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1916) formatting this is the separator. Just copy this,&nbsp; paste here, and give a name like test 1 here,&nbsp;&nbsp;

- [00:32:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1923) save the grid config like test 1, and generate&nbsp; grid. This time it will generate images on all of&nbsp;&nbsp;

- [00:32:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1930) the GPUs at the same time, so it will be much&nbsp; faster. Let's make this run, and meanwhile,&nbsp;&nbsp;

- [00:32:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1936) I will show you how you can upload your models to&nbsp; Hugging Face. So, for uploading models to Hugging&nbsp;&nbsp;

- [00:32:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1943) Face, I have an amazing tutorial here. So go&nbsp; to this link in the attachments, you will see&nbsp;&nbsp;

- [00:32:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1948) the version 6. This is the newest update. I just&nbsp; updated it. Move it back into your Massed Compute&nbsp;&nbsp;

- [00:32:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1956) synchronization folder, wherever you have it. It&nbsp; is here. Go back to your Massed Compute ThinLinc&nbsp;&nbsp;

- [00:32:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1962) folder from... Let's go to the new window.&nbsp; Let's go to the Thin Drives, Mass Compute,&nbsp;&nbsp;

- [00:32:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1968) and let's move the file into the downloads&nbsp; here. Then Ctrl+Alt+D to minimize everything.&nbsp;&nbsp;

- [00:32:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1976) Start the run JupyterLab interface. You need&nbsp; to have a Hugging Face account to upload there.&nbsp;&nbsp;

- [00:33:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1982) I already have a Hugging Face account. You can&nbsp; follow me here too. It is free. Hugging Face is&nbsp;&nbsp;

- [00:33:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1988) just amazing. I congratulate them. I thank them.&nbsp; They are amazing. Let's go to the access tokens.&nbsp;&nbsp;

- [00:33:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=1994) I'm going to generate a new temporary. Let's say&nbsp; delete later and make it "write" and create a token.&nbsp;&nbsp;

- [00:33:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2001) Copy the token. This is important. Then you see&nbsp; the JupyterLab interface started in the ThinLinc&nbsp;&nbsp;

- [00:33:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2008) client. So in this interface, go to the downloads&nbsp; and double-click this notebook file. First of all,&nbsp;&nbsp;

- [00:33:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2015) we need to install. This is mandatory. Just&nbsp; click this cell. It will install everything to&nbsp;&nbsp;

- [00:33:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2020) the latest version. Wait until this cell execution&nbsp; ends. After that, copy-paste your token here like&nbsp;&nbsp;

- [00:33:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2028) this. Play this cell once. This is just one time&nbsp; necessary, and you can set the upload folder and&nbsp;&nbsp;

- [00:33:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2035) upload everything, which I'm going to show right&nbsp; now. So let's go to our page. Let's click here,&nbsp;&nbsp;

- [00:34:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2041) new model, make a model, then give any name.&nbsp; Let's say video tutorial Massed Compute, any&nbsp;&nbsp;

- [00:34:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2049) name. You can make it private so no one else will&nbsp; be able to access it. Then copy. This is the path,&nbsp;&nbsp;

- [00:34:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2055) and I am going to use this one. You see, very fast&nbsp; new upload. There is also a single file upload and&nbsp;&nbsp;

- [00:34:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2062) other ones. This will upload everything very fast&nbsp; to the repository. Okay, after we set the target&nbsp;&nbsp;

- [00:34:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2068) repository and make sure that it is model type,&nbsp; this is important. I updated the notebook file to&nbsp;&nbsp;

- [00:34:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2073) have by default model. It was dataset and verified&nbsp; the local folder path. Just click the play icon,&nbsp;&nbsp;

- [00:34:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2081) and it will start massive upload with massive&nbsp; speed. It is just amazing. We will see that&nbsp;&nbsp;

- [00:34:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2087) it will be completed within like 1 minute&nbsp; or 2 minutes for 12GB of files. Let's just&nbsp;&nbsp;

- [00:34:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2094) wait. We will also be able to see the progress&nbsp; here. It runs the upload in multi-threading,&nbsp;&nbsp;

- [00:35:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2100) and it is just mind-blowingly fast compared to&nbsp; the previous upload strategies that we have. I&nbsp;&nbsp;

- [00:35:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2107) just updated this file today to be perfect. So&nbsp; the upload has been completed. It took like 2&nbsp;&nbsp;

- [00:35:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2113) minutes. You can see the logs here. Then when I&nbsp; open my repository, I will be able to see it. But&nbsp;&nbsp;

- [00:35:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2121) this is in the ThinLinc client, so I can't see&nbsp; it. I need to open it on my computer. And when&nbsp;&nbsp;

- [00:35:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2127) I open it and check the files, yes, all the&nbsp; LoRAs arrived here. It took like 1 minute or&nbsp;&nbsp;

- [00:35:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2134) mostly 2 minutes to upload all the files. So how&nbsp; can you download them again in another instance&nbsp;&nbsp;

- [00:35:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2141) of Massed Compute or on your computer? On your&nbsp; computer, you can just click this to download to&nbsp;&nbsp;

- [00:35:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2146) your computer. But let's say you started another&nbsp; Massed Compute instance and you want to download&nbsp;&nbsp;

- [00:35:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2152) all of them. So for downloading all of them&nbsp; very fast, again, you install the requirements,&nbsp;&nbsp;

- [00:35:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2157) set your Hugging Face token, and in this cell, we&nbsp; have an amazing download script. So first, let's&nbsp;&nbsp;

- [00:36:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2163) copy the path again from here and just delete this&nbsp; part like this. Paste it. Make sure that it is&nbsp;&nbsp;

- [00:36:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2171) accurately copy-pasted, and it is like this. Then&nbsp; wherever you want to download, let's download it&nbsp;&nbsp;

- [00:36:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2176) into home/ubuntu/apps/models/stable_diffusion. You&nbsp; can download it to any folder and just click play,&nbsp;&nbsp;

- [00:36:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2182) and it is going to download everything into&nbsp; there. We can see it. You see it started&nbsp;&nbsp;

- [00:36:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2188) multi-download. It is really, really fast.&nbsp; We will see it completed in a few minutes.&nbsp;&nbsp;

- [00:36:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2193) And the download completed. It didn't update these&nbsp; messages, but once you see the download completed,&nbsp;&nbsp;

- [00:36:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2199) it means that it is completed. We can also&nbsp; verify that. So where did we download them? So&nbsp;&nbsp;

- [00:36:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2207) home/apps/stable_diffusion/web_ui/inside/models/inside/stable_diffusion.&nbsp;&nbsp;

- [00:36:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2212) Yes, all the files are downloaded. This is how you&nbsp; can upload and download very fast by using Hugging&nbsp;&nbsp;

- [00:36:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2219) Face with my specially made Jupyter notebook file.&nbsp; Let's return back to our tools, grid generator,&nbsp;&nbsp;

- [00:37:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2227) load grid config, and load config from here. It&nbsp; has already been completed. Let's open the grid&nbsp;&nbsp;

- [00:37:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2233) so all the images will appear here. Currently, we&nbsp; will see the comparison of all the checkpoints. It&nbsp;&nbsp;

- [00:37:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2243) is taking some time to load on my computer because&nbsp; I have a limited internet connection. Also,&nbsp;&nbsp;

- [00:37:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2248) I can say auto-scale to see everything in the&nbsp; viewport from here, you see, and the images&nbsp;&nbsp;

- [00:37:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2253) are getting loaded. This is the 20 checkpoint. It&nbsp; is under-trained. I can see that clearly. This is&nbsp;&nbsp;

- [00:37:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2259) decent. This is the 40 checkpoint. This is the 80&nbsp; checkpoint, which is really, really good. So with&nbsp;&nbsp;

- [00:37:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2265) this way, you can compare the checkpoints&nbsp; and decide which checkpoint is the best&nbsp;&nbsp;

- [00:37:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2270) one. Probably 80 will be the best, maybe the&nbsp; last one. The last checkpoint may be better,&nbsp;&nbsp;

- [00:37:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2276) so all I need to do is just wait for generation&nbsp; to be completed. Probably not completed. Let's go&nbsp;&nbsp;

- [00:38:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2282) to the server logs, go to the debug, and we can&nbsp; see... Yes, it is still generating. We can see&nbsp;&nbsp;

- [00:38:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2288) the progress here. Okay, it says that very fast,&nbsp; and we are in painting faces as well. Okay. Yes,&nbsp;&nbsp;

- [00:38:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2295) this 80 epoch is really good, so it is up to you&nbsp; to decide which epoch you want. I am working on a&nbsp;&nbsp;

- [00:38:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2302) better workflow, better configuration. Hopefully,&nbsp; I will update the configurations once I have them&nbsp;&nbsp;

- [00:38:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2309) next week. Hopefully I am going to fully research&nbsp; the fine-tuning and fine-tuning will be many times&nbsp;&nbsp;

- [00:38:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2316) better hopefully. If you also use a better data&nbsp; set you are going to get better results than me,&nbsp;&nbsp;

- [00:38:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2321) especially with the expressions. This model was&nbsp; trained within 1 hour, actually less than 1 hour.&nbsp;&nbsp;

- [00:38:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2328) So the grid generation has been completed. It&nbsp; generated 195 images, each one was 48 steps and it&nbsp;&nbsp;

- [00:38:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2338) took only around 22 minutes. If your grid doesn't&nbsp; show everything just refresh the page and it will&nbsp;&nbsp;

- [00:39:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2346) show everything. Then decide the best checkpoint&nbsp; that you want: 20, 40, 60, 80 and the last one.&nbsp;&nbsp;

- [00:39:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2354) So it is up to you, it is personal to decide which&nbsp; one you like most and you can also generate more&nbsp;&nbsp;

- [00:39:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2359) frequent checkpoints and decide the very best one.&nbsp; As a last step, I am going to show you how you can&nbsp;&nbsp;

- [00:39:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2365) use the Forge Web UI on the Massed Compute. So we&nbsp; already have a Forge and Forge updater. First run&nbsp;&nbsp;

- [00:39:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2373) SD Forge update so you will get the very latest&nbsp; version of the Forge. So it started updating&nbsp;&nbsp;

- [00:39:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2379) everything. Then it will start the Forge both&nbsp; locally and also on the Gradio live share. We&nbsp;&nbsp;

- [00:39:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2385) are going to use with Gradio live share. So this&nbsp; is the latest Forge. You see currently my model is&nbsp;&nbsp;

- [00:39:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2391) not available yet, so I will go to the apps where&nbsp; I have the models. You can cut also or copy paste,&nbsp;&nbsp;

- [00:39:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2397) it doesn't matter, both work. So inside the unet we have the FLUX model. Let's copy it or let's&nbsp;&nbsp;

- [00:40:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2403) just move it to the Forge Web UI. It's inside&nbsp; apps, inside the sd web Forge web ui, inside&nbsp;&nbsp;

- [00:40:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2411) models and we put the model inside here, you see.&nbsp; Then we need to put the LoRAs here. Actually we&nbsp;&nbsp;

- [00:40:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2419) need to put all the models here first. So let's go&nbsp; to the apps and stable SwarmUI models and inside&nbsp;&nbsp;

- [00:40:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2428) clip we have clip large and T5 fp16. So let's&nbsp; copy both and it allows me to copy selection from&nbsp;&nbsp;

- [00:40:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2436) here. Let's go to the apps and let's go to the web&nbsp; Forge models and stable diffusion and select and&nbsp;&nbsp;

- [00:40:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2446) it will copy there. It's pretty fast. And as a last&nbsp; thing we need to copy the VAE file. I also have an&nbsp;&nbsp;

- [00:40:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2452) automatic downloader for the models if you want to&nbsp; just download but it will take time to redownload.&nbsp;&nbsp;

- [00:40:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2459) Inside VAE right click and copy or move to. Let's&nbsp; use move to, it is easier. SwarmUI apps Forge Web&nbsp;&nbsp;

- [00:41:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2467) UI models and VAE and that's it. And let's just&nbsp; copy actually this just moved there. Then click&nbsp;&nbsp;

- [00:41:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2475) refresh icon here and FLUX dev appeared. We are&nbsp; going to select VAE and we need to select the FLUX&nbsp;&nbsp;

- [00:41:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2482) from here. So the other things will also appear.&nbsp; Click here actually we need to re-refresh VAE text&nbsp;&nbsp;

- [00:41:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2487) encoder. Okay I think I was remembering the text&nbsp; encoder path inaccurately. So let's move to apps&nbsp;&nbsp;

- [00:41:36](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2496) Forge Web UI inside models. Yeah text encoder has&nbsp; a separate folder. So inside stable diffusion I&nbsp;&nbsp;

- [00:41:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2503) will move the text encoder. So clip large and&nbsp; the T5 right click and move to. So just models&nbsp;&nbsp;

- [00:41:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2510) and text encoder. Okay select then let's refresh&nbsp; and then yes. So select all these 3 and you don't&nbsp;&nbsp;

- [00:41:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2518) need to do nothing else. Go back to here first&nbsp; let's generate an image that we will generate our&nbsp;&nbsp;

- [00:42:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2524) LoRA. By the way this is running locally so let's&nbsp; connect from the Gradio live share, it will be&nbsp;&nbsp;

- [00:42:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2530) easier to use. So let's open the Gradio, copy the&nbsp; link, move back to my own browser. So the Forge&nbsp;&nbsp;

- [00:42:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2537) Web UI is loading. Okay so we have the prompts.&nbsp; Let's go to the folder we had. Let's go to the&nbsp;&nbsp;

- [00:42:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2545) prompts and let's open our prompts here. For&nbsp; example let's copy this one. I'm going to remove&nbsp;&nbsp;

- [00:42:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2552) segment because there is no segmentation here.&nbsp; Okay let's use this one. I don't change anything&nbsp;&nbsp;

- [00:42:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2558) else. I just make the Distilled CFG Scale 4 and&nbsp; generate. Now Forge is not as good as SwarmUI. It&nbsp;&nbsp;

- [00:42:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2566) is good with some quantized models but if you are&nbsp; using on a high VRAM machine it is not as fast as&nbsp;&nbsp;

- [00:42:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2573) the SwarmUI if you ask my opinion, especially when&nbsp; you use LoRA. With default generation it is fast,&nbsp;&nbsp;

- [00:43:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2580) not as bad. By the way we should also close the&nbsp; SwarmUI but I didn't close it and it doesn't have&nbsp;&nbsp;

- [00:43:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2588) automatic queue system for multiple generations.&nbsp; Okay so it is here and the image generated.&nbsp;&nbsp;

- [00:43:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2595) Actually let's go back to the SwarmUI and instead&nbsp; of closing its CMD I will just disable the back&nbsp;&nbsp;

- [00:43:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2601) end. So this will free up the RAM. Okay now how&nbsp; we are going to use the LoRA. Go to the LoRA&nbsp;&nbsp;

- [00:43:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2607) and refresh. Currently we don't have any LoRA so&nbsp; we need to move the LoRA files as well. So let's&nbsp;&nbsp;

- [00:43:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2613) go back to the apps SwarmUI inside the models&nbsp; inside LoRA just select everything right click and&nbsp;&nbsp;

- [00:43:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2622) move to. This move to is very useful. Go to the&nbsp; Forge models and LoRA and select. So it will move&nbsp;&nbsp;

- [00:43:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2631) every file immediately because it is move like cut&nbsp; and paste. Refresh the folder and LoRAs appeared.&nbsp;&nbsp;

- [00:43:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2637) For example let's use this LoRA and let's go back&nbsp; to generation and generate. Yes it's patched to&nbsp;&nbsp;

- [00:44:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2643) LoRA accurately and now it is generating the&nbsp; image. So this is how you can use the Forge&nbsp;&nbsp;

- [00:44:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2649) Web UI with your trained LoRAs. The Forge web UI&nbsp; is like Automatic1111 web UI. I assume that you&nbsp;&nbsp;

- [00:44:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2658) already know it and the image generated. Where it&nbsp; is generated? It is generated on our computer and&nbsp;&nbsp;

- [00:44:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2665) yes it is here. Currently it is not face inpainted&nbsp; but you can use the extensions and everything. So&nbsp;&nbsp;

- [00:44:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2672) this is it. I hope you have enjoyed. Now I am&nbsp; going to move to the RunPod tutorial part. Okay&nbsp;&nbsp;

- [00:44:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2678) now I will start showing how to do the same&nbsp; training on RunPod. I am assuming that you&nbsp;&nbsp;

- [00:44:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2684) might have skipped the Massed Compute part. So we&nbsp; download the zip file. If you haven't downloaded&nbsp;&nbsp;

- [00:44:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2690) yet it will be also in the attachments. Please&nbsp; also read this post very carefully always and&nbsp;&nbsp;

- [00:44:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2695) watch the Windows tutorial. Don't skip it. Enter&nbsp; inside the zip file extraction. You can extract&nbsp;&nbsp;

- [00:45:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2701) it with WinRAR or just Windows itself. Just right&nbsp; click and extract and you will see RunPod install&nbsp;&nbsp;

- [00:45:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2707) instructions. This is very important. Just double&nbsp; click it. It will give you all the instructions.&nbsp;&nbsp;

- [00:45:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2713) Please register with my link if you haven't&nbsp; registered yet. It is here. Then login. I assume&nbsp;&nbsp;

- [00:45:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2718) that you have registered. Sign up is free. Then&nbsp; you need to set up your billing at your billing&nbsp;&nbsp;

- [00:45:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2722) information. Then go to the Pods. Okay in here go&nbsp; to the deploy. You can use either community cloud&nbsp;&nbsp;

- [00:45:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2728) or secure cloud. You can also use network volume&nbsp; storage. I have a full tutorial for network volume&nbsp;&nbsp;

- [00:45:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2733) storage as well. If you are wondering it you&nbsp; can watch it. Network volume storage link will&nbsp;&nbsp;

- [00:45:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2738) be here. I'm going to update the zip file and the&nbsp; instructions txt file so you can just double click&nbsp;&nbsp;

- [00:45:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2743) and watch it. Then the selections here matters.&nbsp; You can pick any GPU that you want. We have a&nbsp;&nbsp;

- [00:45:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2749) configuration for each GPU but my suggestion&nbsp; for you would be like this. You can rent 4x A40&nbsp;&nbsp;

- [00:45:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2757) GPU. It is a very cheap one you see and it has&nbsp; 48 gigabyte VRAM. So it is pretty decent price.&nbsp;&nbsp;

- [00:46:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2764) It is not as good as Massed Compute but it is&nbsp; decent. And let's also see its training speed.&nbsp;&nbsp;

- [00:46:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2769) So I'm going to rent 4 GPU. You don't have to rent&nbsp; 4 GPU. You can even rent one RTX 3090 or one A4000&nbsp;&nbsp;

- [00:46:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2778) and you can train but I don't suggest them. Pick&nbsp; at least 40 gigabyte to get the maximum quality,&nbsp;&nbsp;

- [00:46:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2785) not the maximum speed but maximum quality. And the&nbsp; template selection matters. I train on Python 2.1&nbsp;&nbsp;

- [00:46:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2792) template. If you train on other templates it may&nbsp; not work. I cannot guarantee that. So select this&nbsp;&nbsp;

- [00:46:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2799) template to not have any issues. How you select&nbsp; it? Click here change template type PyTorch and&nbsp;&nbsp;

- [00:46:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2804) select the 2.1 version from here. You see it is&nbsp; CUDA 11.8 and then edit template. This is also&nbsp;&nbsp;

- [00:46:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2810) super important. Edit the template add port 7801.&nbsp; This is for SwarmUI. Make the volume disk bigger&nbsp;&nbsp;

- [00:46:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2817) because we are going to save checkpoints and&nbsp; download models like at least 200 gigabytes to&nbsp;&nbsp;

- [00:47:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2822) not have any issues. And you can set the container&nbsp; disk to 30 gigabytes to not have any issues as&nbsp;&nbsp;

- [00:47:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2827) well. I'm going to show both SwarmUI and Forge&nbsp; Web UI and how to use it after training with Kohya&nbsp;&nbsp;

- [00:47:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2832) GUI. So set the overrides and we are ready. Then&nbsp; click deploy on demand. After that go to the my&nbsp;&nbsp;

- [00:47:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2839) pods. So we have started 4x A40 GPU as I said. You&nbsp; can rent multiple more GPUs, more powerful GPUs.&nbsp;&nbsp;

- [00:47:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2847) You can also rent 1 GPU. All of them would&nbsp; work however the speed will change according&nbsp;&nbsp;

- [00:47:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2852) to the GPU that you have. This is an affordable&nbsp; configuration. It is only $1.4 per hour. It was&nbsp;&nbsp;

- [00:47:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2860) $1.25 on Massed Compute and I wonder the speed&nbsp; difference between two GPUs. So we are going&nbsp;&nbsp;

- [00:47:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2866) to see that. Okay wait until the connect button&nbsp; appears and it appeared. Click connect and click&nbsp;&nbsp;

- [00:47:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2871) the JupyterLab port 8888. Wait for this interface&nbsp; to load. If it doesn't load refresh this page&nbsp;&nbsp;

- [00:47:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2877) and click connect button again and the JupyterLab&nbsp; interface loaded. So go here and click this icon.&nbsp;&nbsp;

- [00:48:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2885) Go to your extracted folder and load everything.&nbsp; Okay just select everything. It is not a big file&nbsp;&nbsp;

- [00:48:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2891) so you will be able to upload all of them very&nbsp; quickly like this. Then in here find the RunPod&nbsp;&nbsp;

- [00:48:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2897) install instructions. First of all we are going to&nbsp; install Kohya GUI proper latest version. Copy this&nbsp;&nbsp;

- [00:48:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2904) part. Copy it Ctrl+C. Open a new terminal like&nbsp; here and paste it and hit enter and just wait.&nbsp;&nbsp;

- [00:48:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2910) Then meanwhile it is installing the Kohya first&nbsp; part you can go here. You see the models that we&nbsp;&nbsp;

- [00:48:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2917) are going to use. Copy them. Open a new terminal&nbsp; and paste it. So meanwhile it is installing Kohya&nbsp;&nbsp;

- [00:48:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2923) it will also download the necessary models to&nbsp; save your time. Meanwhile you can also upload&nbsp;&nbsp;

- [00:48:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2928) your training images. So click here to upload your&nbsp; training images. I suggest you to upload as a zip&nbsp;&nbsp;

- [00:48:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2934) file. So I will just right click my images here,&nbsp; zip them like this. Then click here. You cannot&nbsp;&nbsp;

- [00:49:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2940) upload folders from there. You can also use&nbsp; RunPodCTL. I also have a tutorial for that.&nbsp;&nbsp;

- [00:49:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2945) Go to the folder where your files are. Here they&nbsp; are here. Just upload it. In the bottom of screen&nbsp;&nbsp;

- [00:49:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2950) you will see uploading. So you need to wait here&nbsp; to be uploaded. Uploading from here is slower than&nbsp;&nbsp;

- [00:49:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2956) the RunPod CTL or you can upload files to the&nbsp; Hugging Face and directly download from there&nbsp;&nbsp;

- [00:49:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2960) with wget. The download speed of the RunPod&nbsp; is very poor compared to the Massed Compute.&nbsp;&nbsp;

- [00:49:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2966) That is also one another reason that I pick&nbsp; Massed Compute over RunPod. You see it is&nbsp;&nbsp;

- [00:49:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2971) only downloading with like 15 megabytes. It&nbsp; was like 150 megabytes on Massed Compute. The&nbsp;&nbsp;

- [00:49:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2977) installation speed is also slow. The Kohya was&nbsp; already installed. We just upgraded it on the&nbsp;&nbsp;

- [00:49:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2982) Massed Compute. We also need to install SwarmUI&nbsp; and Forge Web UI on the RunPod and they are both&nbsp;&nbsp;

- [00:49:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2988) installed in the Massed Compute. So since this is&nbsp; very slow pod I'm going to just terminate this.&nbsp;&nbsp;

- [00:49:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=2994) All of the downloads what I'm going to do is first&nbsp; refresh here. We need to delete already downloaded&nbsp;&nbsp;

- [00:50:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3000) files. Open a new terminal rm -r. You can also&nbsp; fully wait. Flux1. Yes you need to delete these older&nbsp;&nbsp;

- [00:50:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3008) files because they are now corrupted if you don't&nbsp; wait proper download they will get corrupted. Okay&nbsp;&nbsp;

- [00:50:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3013) so let's see if we have other ones. Okay there's&nbsp; T5 too. Okay and do we have any other one? Download

- [00:50:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3020) started. So if your files get corrupted you need&nbsp; to delete them like this and re-download. Okay so&nbsp;&nbsp;

- [00:50:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3025) what I'm going to do is this one. This is a good&nbsp; alternative. Start download separately. Copy this.&nbsp;&nbsp;

- [00:50:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3032) Open a new terminal and start it. Then let's also&nbsp; copy this. Open a new terminal and start it. Make&nbsp;&nbsp;

- [00:50:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3039) sure that all downloads are fully completed.&nbsp; Copy this and start a new terminal and download&nbsp;&nbsp;

- [00:50:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3045) it. Okay the final one is here. Copy this. Open a&nbsp; new terminal and start it. Okay so it is going to&nbsp;&nbsp;

- [00:50:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3053) download every file separately and with this way&nbsp; we get a better speed. Also you see when you start&nbsp;&nbsp;

- [00:50:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3059) a download second time it may get a speed boost.&nbsp; I don't know why this happens but this time it is&nbsp;&nbsp;

- [00:51:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3065) 60 megabytes per second instead of 15 megabytes.&nbsp; Okay nice. So we are downloading with a decent&nbsp;&nbsp;

- [00:51:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3073) speed now and the files are downloaded. The Kohya&nbsp; is getting installed right now. My images are also&nbsp;&nbsp;

- [00:51:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3080) uploaded you see here. I will right click and&nbsp; I will say extract archive. So they will be&nbsp;&nbsp;

- [00:51:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3085) extracted into here like this and we are going&nbsp; to use prepare dataset feature of the Kohya to&nbsp;&nbsp;

- [00:51:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3091) prepare our dataset. The installation on RunPod is&nbsp; really taking huge time. Still downloading model&nbsp;&nbsp;

- [00:51:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3097) and the installation is at this part. Still I have&nbsp; to wait it fully. Then we are going to execute the&nbsp;&nbsp;

- [00:51:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3103) second part. Okay the first part installation&nbsp; of the Kohya has been completed. It took more&nbsp;&nbsp;

- [00:51:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3109) than 20 minutes on this pod. It may be faster&nbsp; on some other pods. So now we are going to run&nbsp;&nbsp;

- [00:51:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3115) this second command. This is super important.&nbsp; Don't forget that. You need to run it on a new&nbsp;&nbsp;

- [00:52:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3121) terminal. So it is going to terminate running&nbsp; instance, update libraries and start again. So&nbsp;&nbsp;

- [00:52:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3128) this is mandatory. Don't forget it. Why I am doing&nbsp; two steps? Because I am upgrading scripts. I am&nbsp;&nbsp;

- [00:52:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3134) adding new stuff. So therefore this is mandatory&nbsp; to do and once FLUX becomes in the main repository&nbsp;&nbsp;

- [00:52:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3142) merged into the main branch master branch I&nbsp; am going to update my scripts. Don't you need to&nbsp;&nbsp;

- [00:52:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3147) worry about them. Just use the scripts as I show.&nbsp; So now it is starting the Kohya GUI. You see we&nbsp;&nbsp;

- [00:52:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3153) have 4 GPUs and how did I know the first part was&nbsp; completed? You see we had running on local URL.&nbsp;&nbsp;

- [00:52:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3161) So once you see this you will know that the first&nbsp; part has been completed. The installation of the&nbsp;&nbsp;

- [00:52:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3167) first part and the second part is now getting&nbsp; completed. The Kohya is starting. Usually the&nbsp;&nbsp;

- [00:52:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3173) hard drives of the RunPod are being very slow for&nbsp; me. That is another reason why I picked the Massed&nbsp;&nbsp;

- [00:52:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3179) Compute. Unless you rent a very powerful pod the&nbsp; hard drives will be slower. But the negative side&nbsp;&nbsp;

- [00:53:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3184) of the Massed Compute is that you don't have a&nbsp; permanent storage there but on RunPod you have&nbsp;&nbsp;

- [00:53:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3189) that. So that is the main advantage of RunPod. So&nbsp; the Kohya started. We can access it Gradio Live.&nbsp;&nbsp;

- [00:53:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3196) You could also access it by setting a port here&nbsp; 7861 because it starts this port by default but&nbsp;&nbsp;

- [00:53:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3205) accessing from the Gradio Live is also perfectly&nbsp; fine and safe. Okay so the interface has started.&nbsp;&nbsp;

- [00:53:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3212) It is same as using on Windows but I will show&nbsp; you how to set it up on the RunPod. First of&nbsp;&nbsp;

- [00:53:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3217) all this is the LoRA training therefore we are&nbsp; going to use LoRA tab. If you load the config&nbsp;&nbsp;

- [00:53:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3222) in the DreamBooth tab it will corrupt it. So go&nbsp; to the LoRA and select the config according to&nbsp;&nbsp;

- [00:53:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3228) your GPU. So let's see the configs are uploaded.&nbsp; No because it doesn't upload the folder. So click&nbsp;&nbsp;

- [00:53:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3235) here go back to your downloads folder and we have&nbsp; the best configurations here. I am going to start&nbsp;&nbsp;

- [00:54:00](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3240) with rank 1 file which is the best one. You see&nbsp; rank 1. So how we are going to give its path?&nbsp;&nbsp;

- [00:54:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3246) Right click and copy path then go to configuration&nbsp; put a backslash. Always put a backslash to the&nbsp;&nbsp;

- [00:54:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3253) beginning in RunPod like this. So this is the path&nbsp; then click this icon. It will load everything. If&nbsp;&nbsp;

- [00:54:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3260) it doesn't load click this icon. It will refresh.&nbsp; So you see everything is loaded. Now what we need&nbsp;&nbsp;

- [00:54:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3266) to change is we need to set the model path as&nbsp; a beginning. So our model is set here you see&nbsp;&nbsp;

- [00:54:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3272) this one. Right click copy path put a backslash&nbsp; here paste and we are set. We also need to set&nbsp;&nbsp;

- [00:54:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3278) our training images which I am going to show right&nbsp; now. So go to the dataset preparation. Type your&nbsp;&nbsp;

- [00:54:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3284) instance prompt and class prompt. I explain&nbsp; everything in the Windows tutorial. We use&nbsp;&nbsp;

- [00:54:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3289) repeating 1 because we don't use regularization&nbsp; images. Where I set my training images? They are&nbsp;&nbsp;

- [00:54:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3295) inside here. You can open each one of them to&nbsp; verify they are uploaded accurately. Then right&nbsp;&nbsp;

- [00:54:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3299) click copy path put it here like this. You see I&nbsp; put a backslash. It is one repeating. Destination&nbsp;&nbsp;

- [00:55:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3305) where I want to set my training images? Let's&nbsp; say workspace train folders like this and click&nbsp;&nbsp;

- [00:55:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3313) prepare training data. Check the CMD window and&nbsp; see that done creating. Then click copy info to&nbsp;&nbsp;

- [00:55:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3319) respective fields and we are set for this part.&nbsp; Which file name you want to give? Let's say test&nbsp;&nbsp;

- [00:55:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3325) one. So the output name will be test one. Then&nbsp; we also need to set the other file paths which&nbsp;&nbsp;

- [00:55:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3332) are let me show you. VAE path. So for VAE path this&nbsp; is the path. So copy path and put a backslash and&nbsp;&nbsp;

- [00:55:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3339) paste it. You can also do this. So I copy this&nbsp; paste it like this you see. Copy this paste it&nbsp;&nbsp;

- [00:55:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3345) like this because I have downloaded the files with&nbsp; the same names and everything is set. Currently&nbsp;&nbsp;

- [00:55:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3349) apply T5 attention mask is selected. This improves&nbsp; quality but reduces speed. So let's see the single&nbsp;&nbsp;

- [00:55:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3355) GPU speed first because you may be training with&nbsp; single GPU. Let's save and click start training.&nbsp;&nbsp;

- [00:56:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3362) You can also rent RTX 4090 and use a lower VRAM&nbsp; configuration like rank 3 and it will be faster&nbsp;&nbsp;

- [00:56:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3371) than the training on A40. The quality difference&nbsp; is minimum with rank 1 and rank 2. We are training&nbsp;&nbsp;

- [00:56:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3377) in 16-bit with the other ranks we are training in&nbsp; 8-bit. The very low ones this starting from rank&nbsp;&nbsp;

- [00:56:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3384) 5 we are using a single layer so it is getting&nbsp; lower quality but the difference is not very big.&nbsp;&nbsp;

- [00:56:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3391) I explain everything in details in the Patreon&nbsp; post. So read the post very carefully. So you&nbsp;&nbsp;

- [00:56:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3397) see it is loading the model files. It is going to&nbsp; start training. To monitor the VRAM usage I will&nbsp;&nbsp;

- [00:56:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3402) open a new terminal. I will install pip install&nbsp; nvitop like this. Then I will type nvitop like&nbsp;&nbsp;

- [00:56:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3410) this to start it. nvitop and it is started. We&nbsp; can see the VRAM usages of the GPUs right now. So&nbsp;&nbsp;

- [00:56:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3416) it is starting on a single GPU on the first one&nbsp; right now and we can monitor the status of the&nbsp;&nbsp;

- [00:57:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3423) training here. So you can verify the folders are&nbsp; they accurate the captions everything. I explained&nbsp;&nbsp;

- [00:57:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3430) all of this in details in the Windows tutorial.&nbsp; That is why you should watch it. The initial model&nbsp;&nbsp;

- [00:57:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3435) loading on RunPod is also always slower. You see&nbsp; this is how fast it loads. It is going to load&nbsp;&nbsp;

- [00:57:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3441) like 28 gigabytes and this is the speed very very&nbsp; slow. That is why I also prefer Massed Compute but&nbsp;&nbsp;

- [00:57:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3448) it is up to you. You can rent a much more powerful&nbsp; pod on RunPod and get much better speeds. Okay so&nbsp;&nbsp;

- [00:57:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3454) the training has started. Initially the speed that&nbsp; it displays will not be very accurate. Wait until&nbsp;&nbsp;

- [00:57:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3463) at least 100 steps to get the more accurate speed&nbsp; of the per step. So currently it is 10.30 seconds&nbsp;&nbsp;

- [00:57:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3472) per it. So let's just wait a little bit to see&nbsp; the accurate speed. Okay it went down to like 10&nbsp;&nbsp;

- [00:57:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3479) seconds per it and it is still very slow. So how&nbsp; you can speed it up? You can stop training and&nbsp;&nbsp;

- [00:58:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3486) disable apply T5 attention mask. This will hugely&nbsp; speed up the training with a little bit of quality&nbsp;&nbsp;

- [00:58:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3493) loss. So it is it's trade-off. Let's see the new&nbsp; speed. So with apply T5 attention mask is off we&nbsp;&nbsp;

- [00:58:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3500) are getting over 100% speed up. It is now 4.85&nbsp; seconds per it. It is slower than RTX A6000 on&nbsp;&nbsp;

- [00:58:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3512) Massed Compute but this is a decent speed and can&nbsp; you further speed it up? Yes that is what we are&nbsp;&nbsp;

- [00:58:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3518) going to do now with multi GPU training. So you&nbsp; can directly load up the 4x GPU batch size 1 or&nbsp;&nbsp;

- [00:58:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3526) batch size 2. I suggest batch size 1 because&nbsp; it is better quality and use it. However for those&nbsp;&nbsp;

- [00:58:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3532) who wants to set up themselves I am going to&nbsp; show that right now. So stop training. Go to the&nbsp;&nbsp;

- [00:58:58](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3538) accelerate tab here and set number of processes&nbsp; 2. Alright this is a hack to the flow of the&nbsp;&nbsp;

- [00:59:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3545) video because I just figured out something. When&nbsp; you are setting multiple GPU training make sure&nbsp;&nbsp;

- [00:59:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3553) that number of processes equals to the number of&nbsp; GPUs you have. When you set it that way you are&nbsp;&nbsp;

- [00:59:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3560) going to get almost exactly same number of epochs.&nbsp; You see currently I am training for 60 epochs on&nbsp;&nbsp;

- [00:59:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3568) 4 GPU therefore total 240 epochs and I am getting&nbsp; 240 epochs. Currently I am doing a training for a&nbsp;&nbsp;

- [00:59:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3577) client and I have figured out there is not much&nbsp; speed difference however what is the benefit of&nbsp;&nbsp;

- [00:59:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3584) this? With this way you can set the save every n&nbsp; epochs accurately. So I am going to save every 20&nbsp;&nbsp;

- [00:59:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3591) epochs a checkpoint and it will work as expected.&nbsp; So set this number of processes equal to the&nbsp;&nbsp;

- [00:59:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3599) number of GPUs you have. If you are training on 8&nbsp; GPU set it 8, if you are training on 6 set it 6,&nbsp;&nbsp;

- [01:00:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3603) if you are training on 4 set it 4. So this is the&nbsp; logic. Set multi GPU and set the GPU IDs 0, 1, 2, 3&nbsp;&nbsp;

- [01:00:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3614) like this and that's it. Now we are ready to use&nbsp; multi GPU however there are two things that you&nbsp;&nbsp;

- [01:00:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3620) need to change. The first thing that you need to&nbsp; change is you need to divide the epoch number to&nbsp;&nbsp;

- [01:00:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3625) the number of GPUs. So it is going to be 50 and&nbsp; it is automatically going to handle everything&nbsp;&nbsp;

- [01:00:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3631) for us. Let's save every 20 epochs. This doesn't&nbsp; change with the number of GPUs. It still will save&nbsp;&nbsp;

- [01:00:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3638) basic number of the epochs and the learning&nbsp; rate. You need to set a new learning rate as&nbsp;&nbsp;

- [01:00:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3643) you increase number of GPUs or the batch size.&nbsp; There isn't an exact formula so the suggested&nbsp;&nbsp;

- [01:00:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3649) formula is new learning rate equal to number&nbsp; of GPUs multiplied with batch size divided by&nbsp;&nbsp;

- [01:00:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3656) 2 then the older learning rate. So our&nbsp; new learning rate becomes like this:&nbsp;&nbsp;

- [01:01:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3661) learning rate multiplied with 4 multiplied with 1&nbsp; because we are using batch size 1 divided by 2&nbsp;&nbsp;

- [01:01:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3667) and this is the new learning rate. There is also&nbsp; using directly multiplying without dividing 2 or&nbsp;&nbsp;

- [01:01:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3674) square root and as I said there is not an exact&nbsp; formula but dividing by 2 is commonly used. So&nbsp;&nbsp;

- [01:01:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3680) this is the new learning rate. Why? Because we&nbsp; have 4 GPUs. So multiply with 4 and divide by 2.&nbsp;&nbsp;

- [01:01:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3686) This is the new learning rate. And let's say&nbsp; RunPod train 4x GPU for this one. You should&nbsp;&nbsp;

- [01:01:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3694) always save your configuration like this. Save&nbsp; it and let's start the training. I am still not&nbsp;&nbsp;

- [01:01:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3699) going to apply the T5 attention mask to see the&nbsp; speed and compare with the Massed Compute but I&nbsp;&nbsp;

- [01:01:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3706) can already say that A40 GPU on RunPod is slower&nbsp; than A6000 on Massed Compute and it is also more&nbsp;&nbsp;

- [01:01:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3714) expensive. However as I said you can always rent&nbsp; more powerful GPUs such as you can rent 4x L40S&nbsp;&nbsp;

- [01:02:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3722) GPU and it will train like in 30 minutes maybe&nbsp; faster with maximum possible quality. So it is&nbsp;&nbsp;

- [01:02:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3729) up to you to rent number of GPUs and the certain GPU. You&nbsp; can also rent 4x 4090. That time you need to use&nbsp;&nbsp;

- [01:02:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3738) the lower VRAM configuration. Which one you need&nbsp; to use? Like rank 4 or rank 3 to see the speed&nbsp;&nbsp;

- [01:02:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3745) and you can still use multiple of them at the&nbsp; same time exactly same settings just the base&nbsp;&nbsp;

- [01:02:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3750) configuration changes. And what is the change&nbsp; in the base configuration? With the high VRAM&nbsp;&nbsp;

- [01:02:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3755) configuration we train in 16-bit so the quality&nbsp; loss is minimal. With the low VRAM we are training&nbsp;&nbsp;

- [01:02:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3762) in 8-bit. So when doing multi GPU training&nbsp; you will see that the total optimization steps&nbsp;&nbsp;

- [01:02:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3768) displayed as 750 instead of 3000. Why? Because&nbsp; it is dividing the number of steps equally to&nbsp;&nbsp;

- [01:02:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3776) on each GPU therefore it will display 750 steps.&nbsp; Everything will work exactly as same. This will&nbsp;&nbsp;

- [01:03:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3784) be almost equal to a training batch size 4 but&nbsp; this time we will gain linear speed increase. When&nbsp;&nbsp;

- [01:03:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3791) you increase the batch size on a single GPU you&nbsp; don't get such speed increase actually I tested&nbsp;&nbsp;

- [01:03:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3795) and batch size 2 just a little bit increases the&nbsp; speed nothing like using two GPU. Currently this&nbsp;&nbsp;

- [01:03:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3802) speed is 5.25 seconds it and it is getting better.&nbsp; You may think that it is same as before but now&nbsp;&nbsp;

- [01:03:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3809) you see because each time when one step is done&nbsp; actually we are training 4 images. We are doing&nbsp;&nbsp;

- [01:03:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3815) first step of the previous. So you need to divide&nbsp; this number to 4 to get the actual speed and it is&nbsp;&nbsp;

- [01:03:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3821) just amazing. We almost got 100% linear increase.&nbsp; So our speed is increased like 4 times compared to&nbsp;&nbsp;

- [01:03:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3830) the before. With SDXL there weren't such speed&nbsp; increase but with FLUX training on a multiple&nbsp;&nbsp;

- [01:03:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3835) GPU we are almost getting such perfect linear&nbsp; increase based on the number of GPUs. Previously&nbsp;&nbsp;

- [01:04:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3843) you had to use SXM machines to get a linear&nbsp; speed increase with multi GPU but with FLUX&nbsp;&nbsp;

- [01:04:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3849) you don't need to use such configuration because&nbsp; SXM machines are extremely expensive. It is the&nbsp;&nbsp;

- [01:04:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3855) link between GPUs. With PCI Express link in these&nbsp; GPUs we are still getting almost linear increase&nbsp;&nbsp;

- [01:04:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3862) no performance loss. You see we are almost getting&nbsp; to the previous speed but this time batch size is&nbsp;&nbsp;

- [01:04:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3868) 4. So we are training 4 images at one time and it&nbsp; is going to take like 1 hour 2 minutes to complete&nbsp;&nbsp;

- [01:04:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3875) this training. It is just amazing. Looks like the&nbsp; training speed stabilized at 4.95 seconds per it.&nbsp;&nbsp;

- [01:04:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3882) So now I will wait for training to finish then&nbsp; we will continue and I see that it doesn't use&nbsp;&nbsp;

- [01:04:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3889) my all GPUs. This is weird. Yeah probably nvitop&nbsp; is broken. Yes it doesn't get updated. So let's&nbsp;&nbsp;

- [01:04:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3895) start a new terminal nvitop and yes nvitop looks&nbsp; like broken. It doesn't display all of the GPUs&nbsp;&nbsp;

- [01:05:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3904) because this is impossible. Can we see the usage&nbsp; in here in pods? Okay it doesn't show. This is&nbsp;&nbsp;

- [01:05:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3910) weird. However it shows we are training 750 steps.&nbsp; So it has to use. Let's also look at the logs. It&nbsp;&nbsp;

- [01:05:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3918) should have loaded 4 times. Yes I can see that it&nbsp; loaded 4 times. So it is working but the status of&nbsp;&nbsp;

- [01:05:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3925) the GPUs are not accurate. This was accurate on&nbsp; Massed Compute but in here it doesn't accurate.&nbsp;&nbsp;

- [01:05:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3930) So don't trust it. Trust the values that you see&nbsp; here and we are going to see the results at the&nbsp;&nbsp;

- [01:05:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3935) end. So the training has been completed. 750 steps&nbsp; are completed and it took 62 minutes to train on 4&nbsp;&nbsp;

- [01:05:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3946) A40 GPU with one of the very best configurations.&nbsp; Now how you can use them? You can download them to&nbsp;&nbsp;

- [01:05:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3952) your computer and use or you can use them on&nbsp; RunPod as well. I will show both of them. So&nbsp;&nbsp;

- [01:05:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3957) to use on RunPod you can watch this SwarmUI cloud&nbsp; tutorial. It is amazing or you can also use Forge&nbsp;&nbsp;

- [01:06:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3964) Web UI. Either one of them works and I am going&nbsp; to show both of them. When we go to the SwarmUI&nbsp;&nbsp;

- [01:06:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3970) cloud tutorial we have a link there. This link. When you watch the tutorial you will know it.&nbsp;&nbsp;

- [01:06:15](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3975) So in this link there is a RunPod installer. You&nbsp; should watch the tutorial if you don't know how&nbsp;&nbsp;

- [01:06:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3981) to do it. So I will just download this installer&nbsp; file. I will show quickly. So first I will install&nbsp;&nbsp;

- [01:06:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3987) and run it very quickly. I am not going to repeat&nbsp; everything in that tutorial. Let's just copy paste.

- [01:06:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3992) It failed because I didn't upload the file. So&nbsp; let's just upload the file and let's just name it&nbsp;&nbsp;

- [01:06:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=3999) to accurate. Okay let's just install it. So the&nbsp; installation is getting completed as exactly as&nbsp;&nbsp;

- [01:06:45](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4005) shown in the SwarmUI cloud tutorial for FLUX. Okay&nbsp; so the installation has been completed and the&nbsp;&nbsp;

- [01:06:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4011) SwarmUI started on the RunPod. To use our LoRAs&nbsp; first of all we need to move the files into the&nbsp;&nbsp;

- [01:06:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4019) accurate folders. So I will move the first VAE&nbsp; file. So cut it. Move into the SwarmUI into the&nbsp;&nbsp;

- [01:07:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4027) models into the VAE and paste there. Then let's&nbsp; move to the workspace. We need to move clip large&nbsp;&nbsp;

- [01:07:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4034) and the T5 text encoder. Cut it. By the way we&nbsp; need to rename text encoder to the accurate name&nbsp;&nbsp;

- [01:07:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4041) or it will re-download it. What is the accurate&nbsp; name for the SwarmUI? I don't know from the&nbsp;&nbsp;

- [01:07:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4047) memorization but I will look from my computer and&nbsp; this is the accurate name. So I will just rename&nbsp;&nbsp;

- [01:07:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4054) it to this name and yes. I just noticed that we&nbsp; did put these two into the inaccurate folder.&nbsp;&nbsp;

- [01:07:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4060) They go into the clip not clip vision. So let's&nbsp; just paste it and VAE is in the accurate folder.&nbsp;&nbsp;

- [01:07:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4068) Okay as a last step we are going to move the&nbsp; main FLUX.1 DEV safetensors file. Cut it. Move&nbsp;&nbsp;

- [01:07:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4073) into the SwarmUI into the models. Put it into unet folder. If you don't see the unet folder you need&nbsp;&nbsp;

- [01:07:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4079) to generate it yourself. How you can generate? You&nbsp; can click here and generate a new folder and name&nbsp;&nbsp;

- [01:08:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4085) it as unet. Then let's return back to the models&nbsp; folder. Click refresh and it should appear here.&nbsp;&nbsp;

- [01:08:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4091) Then let's generate a single image first. Let's&nbsp; see the model then we will generate multiple&nbsp;&nbsp;

- [01:08:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4098) images compare checkpoints. Moreover since we have&nbsp; 4 GPUs running right now we can add more backends&nbsp;&nbsp;

- [01:08:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4106) to it which I am going to do right now. So click&nbsp; here to add more backends. I have shown all of&nbsp;&nbsp;

- [01:08:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4112) this in the main cloud tutorials for SwarmUI.&nbsp; Okay this is just extra. So GPU id 1 GPU id 2&nbsp;&nbsp;

- [01:08:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4121) and GPU id 3. Moreover you can add a new command&nbsp; --fast. This will improve the speed significantly&nbsp;&nbsp;

- [01:08:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4129) on newer GPUs and then save. Once you save them it&nbsp; will restart the backends. Okay let's return back&nbsp;&nbsp;

- [01:08:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4136) to generate. Of course since we set the fast it&nbsp; is restarting. Okay let's just wait for backends&nbsp;&nbsp;

- [01:09:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4143) to load. We can always go to the logs and put into&nbsp; debug and we can see. Yes it is now going to load&nbsp;&nbsp;

- [01:09:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4150) everything. Yeah it is starting on each backend&nbsp; right now. We can see that it is just starting&nbsp;&nbsp;

- [01:09:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4157) yes. Then let's hit generate again. So it is 1&nbsp; current generation 1 queued 2 waiting on model&nbsp;&nbsp;

- [01:09:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4163) load. Why I do this? Because I am verifying the&nbsp; models and everything is set into the accurate&nbsp;&nbsp;

- [01:09:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4170) place. Then I will use my LoRA to generate and my&nbsp; LoRAs are not visible here yet because I also need&nbsp;&nbsp;

- [01:09:35](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4175) to move them. So let's go back to the workspace.&nbsp; Where are our LoRAs? They are inside train folder&nbsp;&nbsp;

- [01:09:42](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4182) inside model. You see my LoRAs are here. I am just&nbsp; going to select everything then cut them and let's&nbsp;&nbsp;

- [01:09:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4189) move back into the workspace into the SwarmUI&nbsp; into the models into the LoRA folder and paste&nbsp;&nbsp;

- [01:09:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4196) them here. And image is getting generated almost&nbsp; ready. It is also doing inpainting because we have&nbsp;&nbsp;

- [01:10:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4203) segment face with 0.7 70% denoise inpaint with&nbsp; photo of OHWX man. This is equal to using after&nbsp;&nbsp;

- [01:10:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4211) detailer a detailer extension on Automatic1111 web UI. Okay this is the base image. Then let's&nbsp;&nbsp;

- [01:10:17](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4217) refresh the LoRAs. LoRAs appeared. For example&nbsp; let's use this LoRA 80 epoch. Let's generate.&nbsp;&nbsp;

- [01:10:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4224) Okay now it is loading the LoRA and it is going&nbsp; to generate. We can always see in the server&nbsp;&nbsp;

- [01:10:30](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4230) logs. Yes it loaded the LoRA and it is generating&nbsp; image right now and we can see already preview. It&nbsp;&nbsp;

- [01:10:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4237) is inpainting the face right now. Inpainting face&nbsp; is optional however I find it improving the face&nbsp;&nbsp;

- [01:10:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4243) quality. By the way this GPU is slower than the&nbsp; Massed Compute RTX A6000 GPU and we got an image.&nbsp;&nbsp;

- [01:10:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4250) It is really really good. So how you can find&nbsp; the best checkpoint? To find the best checkpoint&nbsp;&nbsp;

- [01:10:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4255) we are going to use tools grid generator and in&nbsp; here first select the LoRA. LoRAs here fill all&nbsp;&nbsp;

- [01:11:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4262) like this select delete the (none) LoRA. Then I am&nbsp; going to use multiple prompts because we already&nbsp;&nbsp;

- [01:11:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4268) have prompts. Return back to downloads folder&nbsp; and inside test prompts we already have prompts&nbsp;&nbsp;

- [01:11:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4274) for the SwarmUI. I have eyeglasses so I'm going&nbsp; to use these prompts. Okay like this and you see&nbsp;&nbsp;

- [01:11:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4280) the prompt separator is this. These two is from&nbsp; separator and everything is set. Let's also give&nbsp;&nbsp;

- [01:11:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4287) a name to our grid like test1. Let's also save&nbsp; the grid config like test one and hit generate.&nbsp;&nbsp;

- [01:11:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4294) Now this is going to queue the generation on all 4&nbsp; GPUs and it will generate them like in 20 minutes&nbsp;&nbsp;

- [01:11:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4301) not like 4 hours because we are using 4 GPUs even&nbsp; though we are doing 30 + 18 so 48 steps for&nbsp;&nbsp;

- [01:11:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4309) each image. It will be done in like 20 minutes&nbsp; not like 4 hours. We will see it. Meanwhile&nbsp;&nbsp;

- [01:11:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4315) let's also upload all the LoRAs into the Hugging&nbsp; Face so we can download into our computer we can&nbsp;&nbsp;

- [01:12:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4322) use them later at a time anytime we want. So to&nbsp; upload models to the Hugging Face I already have a&nbsp;&nbsp;

- [01:12:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4328) tutorial here and I already have a notebook file.&nbsp; Go to this link. You see how to save download your&nbsp;&nbsp;

- [01:12:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4334) models and at this link you will see Hugging&nbsp; Face upload version 6. This is just updated&nbsp;&nbsp;

- [01:12:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4340) today. Click this link to download it. Then return&nbsp; back to your workspace. Upload the downloaded file&nbsp;&nbsp;

- [01:12:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4348) into here. Double click and open it. Now first of&nbsp; all we need to install the dependencies with this&nbsp;&nbsp;

- [01:12:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4354) cell. Just run it one time. Then you need to get&nbsp; your Hugging Face token. To get your Hugging Face&nbsp;&nbsp;

- [01:12:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4361) token go to the Hugging Face. Also you need&nbsp; to generate a model folder. So first generate&nbsp;&nbsp;

- [01:12:47](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4367) a model new model. Everything will be saved&nbsp; here. Let's say test RunPod video. You can make&nbsp;&nbsp;

- [01:12:53](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4373) it public private. I'm going to make it private.&nbsp; Copy the model path here and we are going to use&nbsp;&nbsp;

- [01:12:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4379) very fast new upload feature. Just paste it there.&nbsp; Then go to the settings go to the access token.&nbsp;&nbsp;

- [01:13:06](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4386) You need to register an account. It is free don't&nbsp; worry and they don't charge you anything. They&nbsp;&nbsp;

- [01:13:11](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4391) are just amazing. Click select "write". Give a name&nbsp; test delete 2 like this and create token. Copy&nbsp;&nbsp;

- [01:13:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4399) this. This is important. Go back to here paste&nbsp; your token. Play this cell one time. It will set&nbsp;&nbsp;

- [01:13:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4405) your Hugging Face token and now we are ready. So&nbsp; you need to also set the LoRA path. Our LoRA path&nbsp;&nbsp;

- [01:13:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4411) is let's find it. It is inside SwarmUI currently&nbsp; inside models inside LoRAs. So right click and&nbsp;&nbsp;

- [01:13:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4418) copy path and delete this part and paste it. You&nbsp; see it's always starting with backslash and repo&nbsp;&nbsp;

- [01:13:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4424) type is model. This is important. Whatever the&nbsp; repo type you just generated you need to use it&nbsp;&nbsp;

- [01:13:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4429) and then just click the play icon and it will&nbsp; start uploading. You see it is going to upload&nbsp;&nbsp;

- [01:13:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4435) 12.3 gigabytes. According to the your pod speed it&nbsp; may be completed in 2 minutes actually in Massed&nbsp;&nbsp;

- [01:14:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4442) Compute it was only 2 minutes or 10 minutes 20&nbsp; minutes but this is the fastest way of uploading&nbsp;&nbsp;

- [01:14:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4449) models to the Hugging Face. It just arrived&nbsp; very recently so I am keeping everything very&nbsp;&nbsp;

- [01:14:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4454) up to date and at the same time it is generating&nbsp; the grid right now. You see estimated is 1 hour&nbsp;&nbsp;

- [01:14:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4460) but it will get better. Already we have generated&nbsp; like 20 images. We can always see the generation&nbsp;&nbsp;

- [01:14:26](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4466) speed in the debug. You see 1.13 it second is a&nbsp; really really good speed by the way. The upload&nbsp;&nbsp;

- [01:14:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4473) is slow on the RunPod though it was way faster on&nbsp; the Massed Compute. Okay it hashed first then it&nbsp;&nbsp;

- [01:14:39](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4479) will start the upload. The uploaded files will&nbsp; appear here which is our repository. This is a&nbsp;&nbsp;

- [01:14:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4484) model. It matters whether it is dataset or model.&nbsp; Okay it is saying processed. Wow it was fast. So&nbsp;&nbsp;

- [01:14:52](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4492) it uploaded everything. Let's refresh the files&nbsp; and all appeared here. So it took like 3 minutes&nbsp;&nbsp;

- [01:14:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4499) to upload everything and we have uploaded all&nbsp; of our models. This is just mind-blowingly fast&nbsp;&nbsp;

- [01:15:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4505) upload. Thank you so much Hugging Face you&nbsp; are amazing. So we saved everything into&nbsp;&nbsp;

- [01:15:10](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4510) the cloud forever until we delete them and we can&nbsp; download them anytime we wish. How you download?&nbsp;&nbsp;

- [01:15:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4516) For downloading I also have a new download. This&nbsp; one snapshot download. You just enter your repo&nbsp;&nbsp;

- [01:15:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4523) path here and the folder path wherever you want&nbsp; to download. For example let's download into the&nbsp;&nbsp;

- [01:15:28](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4528) workspace workspace test 2 like this and let's run&nbsp; this cell. This will download everything. Okay it&nbsp;&nbsp;

- [01:15:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4537) says that there is no directory workspace.&nbsp; Oh I need to put this into here. I'm going&nbsp;&nbsp;

- [01:15:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4543) to update this script so it will be fixed when&nbsp; you are using. Okay let's just play and yes it&nbsp;&nbsp;

- [01:15:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4549) started downloading. Don't worry on the RunPod&nbsp; we get this error because we are using the proxy&nbsp;&nbsp;

- [01:15:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4555) but in here all the files will be appearing after&nbsp; a while. This is a super fast download. It has&nbsp;&nbsp;

- [01:16:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4562) resume also this upload has resume capability as&nbsp; well. I fixed that error and updated file to the&nbsp;&nbsp;

- [01:16:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4569) version 7 and I already can see the LoRA files&nbsp; are downloaded. So this is huge, huge speed of&nbsp;&nbsp;

- [01:16:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4576) downloading. This is how you can save and download&nbsp; later and use. Grid generation has been completed.&nbsp;&nbsp;

- [01:16:22](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4582) We click here to open it. If not all of the images&nbsp; are loaded, refresh the page. I am going to use&nbsp;&nbsp;

- [01:16:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4589) auto scale images to viewport width and now all&nbsp; you need to do is check each checkpoint and decide&nbsp;&nbsp;

- [01:16:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4597) which one is working best. There is no easier way&nbsp; unfortunately, so it is a personal thing. You need&nbsp;&nbsp;

- [01:16:43](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4603) to check every checkpoint and decide which one is&nbsp; working as best. Then you can use the checkpoint&nbsp;&nbsp;

- [01:16:49](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4609) to generate images as you wish. I am still&nbsp; working on better workflows, better configuration,&nbsp;&nbsp;

- [01:16:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4615) so hopefully the results will become better when&nbsp; you are watching this tutorial. I will update the&nbsp;&nbsp;

- [01:17:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4622) configuration files. Currently I am searching for&nbsp; training the text encoder CLIP large model, so we&nbsp;&nbsp;

- [01:17:08](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4628) will hopefully see a better workflow soon. As a&nbsp; final step, I will show how you can use the Forge&nbsp;&nbsp;

- [01:17:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4634) Web UI on this RunPod machine. So for using Forge&nbsp; Web UI on RunPod, I have automatic installer. It&nbsp;&nbsp;

- [01:17:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4640) is here, you see under this section of the post.&nbsp; Let's go there and in the attachments you will&nbsp;&nbsp;

- [01:17:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4647) find Forge installer. This may be a higher version&nbsp; when you're watching, so click this link to&nbsp;&nbsp;

- [01:17:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4652) download it. Then go to the workspace and generate&nbsp; a new folder as Forge installed like this. Enter&nbsp;&nbsp;

- [01:17:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4660) inside it, upload the zip file, then right-click&nbsp; and extract archive. So you will not get confused,&nbsp;&nbsp;

- [01:17:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4668) the new files, it will be a clear one. And then&nbsp; you need to use RunPod instructions.txt file. You&nbsp;&nbsp;

- [01:17:55](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4675) can also extract it onto your computer and upload.&nbsp; So for installing the Forge Web UI, we are going&nbsp;&nbsp;

- [01:18:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4681) to run this command. Open a new terminal, copy&nbsp; paste it. So it is going to install Forge Web UI&nbsp;&nbsp;

- [01:18:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4687) into the stable diffusion web ui Forge under this&nbsp; folder. Once you install it under this folder,&nbsp;&nbsp;

- [01:18:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4694) you need to delete this part "cd workspace". Don't&nbsp; Forget that if you install it into your workspace,&nbsp;&nbsp;

- [01:18:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4700) then you don't need to delete it. So we are going&nbsp; to use this as like this. We just deleted the&nbsp;&nbsp;

- [01:18:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4707) first "cd workspace" part and we just made it like&nbsp; this. So whether you install into your workspace,&nbsp;&nbsp;

- [01:18:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4714) you can keep them. Whether you don't install&nbsp; it your workspace into a separate folder,&nbsp;&nbsp;

- [01:18:38](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4718) you keep it like this. Just wait for installation&nbsp; to be completed. Okay, so the Forge Web UI&nbsp;&nbsp;

- [01:18:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4724) installation has been completed. To start it now&nbsp; I will use this. As I said, be careful where you&nbsp;&nbsp;

- [01:18:50](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4730) have installed it and run this command inside it.&nbsp; If you have installed into workspace, it is fine,&nbsp;&nbsp;

- [01:18:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4736) but if you didn't install into not workspace, it&nbsp; will fail. Yes, we are currently failing because&nbsp;&nbsp;

- [01:19:02](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4742) of this. So I have to make it like this. So&nbsp; it will directly move into this folder. Open&nbsp;&nbsp;

- [01:19:07](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4747) a new terminal inside this folder and just copy&nbsp; paste it like this. Pay attention to the paths.&nbsp;&nbsp;

- [01:19:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4753) You will understand them as the time passes&nbsp; and it will help you in long run. Always you&nbsp;&nbsp;

- [01:19:19](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4759) can message me on Patreon or on Discord server and&nbsp; I will help you. So now we just need to wait for&nbsp;&nbsp;

- [01:19:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4765) start and we also need to move the files. So let's&nbsp; move the files while it is starting. Current our&nbsp;&nbsp;

- [01:19:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4772) files are inside here models unet. So let's move&nbsp; this file into the Forge Web UI unet. It will be&nbsp;&nbsp;

- [01:19:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4780) inside Forge install web ui Forge inside models&nbsp; inside stable diffusion. Put it here. Let's go&nbsp;&nbsp;

- [01:19:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4788) back to the SwarmUI and models and we have LoRAs.&nbsp; Let's move our LoRAs. Okay, click first file,&nbsp;&nbsp;

- [01:19:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4797) then while keep pressing shift select all like&nbsp; this. Cut, move back to the workspace into the&nbsp;&nbsp;

- [01:20:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4804) Forge install into the models inside LoRAs. LoRA&nbsp; folder not generated yet, so let's copy it later.&nbsp;&nbsp;

- [01:20:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4812) Go to the SwarmUI models VAE. So we can just cut&nbsp; or copy. Go back to Forge install stable diffusion&nbsp;&nbsp;

- [01:20:21](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4821) Forge models VAE, paste it. Go back to the SwarmUI&nbsp; inside models inside CLIP. This is important. Move&nbsp;&nbsp;

- [01:20:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4831) both of them to the Forge install stable diffusion&nbsp; Forge models and it will be inside text encoder.&nbsp;&nbsp;

- [01:20:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4840) Paste here. Now we just need to copy the LoRAs.&nbsp; Let's just wait application to start. Okay,&nbsp;&nbsp;

- [01:20:46](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4846) I know why it has failed because we didn't install&nbsp; it into the workspace. My script of installer has&nbsp;&nbsp;

- [01:20:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4854) failed. We can see the script here. It was here.&nbsp; So we need to copy this and modify it. So how&nbsp;&nbsp;

- [01:21:01](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4861) we gonna modify it? We are just going to change&nbsp; this workspace to like this Forge install. Okay,&nbsp;&nbsp;

- [01:21:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4869) this will fix it. So let's terminal. So you should&nbsp; install into workspace and not into Forge install,&nbsp;&nbsp;

- [01:21:16](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4876) otherwise you need to do all of this and now let's&nbsp; remove this share and start a new terminal. Okay,&nbsp;&nbsp;

- [01:21:24](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4884) I had prepared scripts to install into&nbsp; workspace. Once we installed into the subfolder,&nbsp;&nbsp;

- [01:21:29](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4889) it caused a lot of issues. So better to install&nbsp; into workspace. It is the best way. Now it's&nbsp;&nbsp;

- [01:21:34](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4894) starting but I will not delete these parts of&nbsp; the video because you may always encounter some&nbsp;&nbsp;

- [01:21:40](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4900) issues and you are learning how to fix them. This&nbsp; is helpful in the long run and it will help you to&nbsp;&nbsp;

- [01:21:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4908) understand the concepts what we are doing better.&nbsp; So now we will get a Gradio live share. Second&nbsp;&nbsp;

- [01:21:54](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4914) time start should be way faster than the first&nbsp; time start. Even the second time start on RunPod&nbsp;&nbsp;

- [01:21:59](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4919) is taking too long. On Massed Compute it is almost&nbsp; instant. Okay, so this time we got a Gradio live.&nbsp;&nbsp;

- [01:22:05](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4925) Let's open it and we should also move our LoRAs.&nbsp; So let's go back to SwarmUI models LoRA. Let's&nbsp;&nbsp;

- [01:22:14](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4934) select all cuts, move back the workspace into&nbsp; Forge install web ui Forge models LoRA and paste&nbsp;&nbsp;

- [01:22:23](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4943) it here and we got everything and we got the first&nbsp; web. So let's refresh and let's select all these 3&nbsp;&nbsp;

- [01:22:31](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4951) and FLUX and text to image. Okay, let's use some&nbsp; of our test prompts. For example this one. I will&nbsp;&nbsp;

- [01:22:37](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4957) first generate a prompt without my LoRA, then I&nbsp; will use with my LoRA. Okay, so I will use 1024&nbsp;&nbsp;

- [01:22:44](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4964) to 1024 and let's generate. Don't Forget to select&nbsp; all these 3 and the checkpoint itself. As I said,&nbsp;&nbsp;

- [01:22:51](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4971) if you install directly into workspace your Forge&nbsp; web, you will not have any of the issues that&nbsp;&nbsp;

- [01:22:57](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4977) I had. However, I have shown them so you learn&nbsp; more stuff. Okay, now it is going to generate an&nbsp;&nbsp;

- [01:23:04](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4984) image. First loading it. We can see the VRAM usage&nbsp; somewhere around here. Where it is? Here. Okay,&nbsp;&nbsp;

- [01:23:12](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4992) now it is loading the model. Okay, we got the&nbsp; first image generated. Then we are going to&nbsp;&nbsp;

- [01:23:18](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=4998) apply our LoRA. Let's go there, refresh and LoRAs&nbsp; should appear. Yes, for example let's use this one&nbsp;&nbsp;

- [01:23:25](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5005) and generate. When you first time generate a LoRA,&nbsp; the Forge Web UI patches it and for patching it&nbsp;&nbsp;

- [01:23:32](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5012) uses a significant amount of VRAM. This doesn't&nbsp; exist on the SwarmUI. I didn't see in the logs.&nbsp;&nbsp;

- [01:23:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5021) This is a disadvantage of the Forge Web UI. Also&nbsp; I like the SwarmUI better for using the FLUX,&nbsp;&nbsp;

- [01:23:48](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5028) but if you want to use Forge Web UI, here how you&nbsp; use it. So the patching has been done and then we&nbsp;&nbsp;

- [01:23:56](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5036) are going to see the generated image. Okay, we got&nbsp; it. Currently we are not doing any face inpainting&nbsp;&nbsp;

- [01:24:03](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5043) so the face quality is not optimal level, but&nbsp; you know how to use the Forge Web UI. It is&nbsp;&nbsp;

- [01:24:09](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5049) like Automatic1111 Web UI. There are also other&nbsp; things and I need to make a dedicated tutorial&nbsp;&nbsp;

- [01:24:13](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5053) for Forge Web UI. So I will end the tutorial&nbsp; here. I hope you have enjoyed it. Please keep&nbsp;&nbsp;

- [01:24:20](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5060) subscribed because I am going to fully research&nbsp; fine-tuning of the FLUX and I bet it will be many&nbsp;&nbsp;

- [01:24:27](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5067) times better than the LoRA training on FLUX. We&nbsp; are going to see it hopefully. Moreover, I am&nbsp;&nbsp;

- [01:24:33](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5073) working on finding optimal training parameters for&nbsp; CLIP large model when training the FLUX LoRA. So&nbsp;&nbsp;

- [01:24:41](https://www.youtube.com/watch?v=-uhL2nW7Ddw&t=5081) hopefully we will get better results compared&nbsp; to what we get now. Hopefully see you later.

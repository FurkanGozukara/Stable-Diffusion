# FLUX Full Fine-Tuning / DreamBooth Training Master Tutorial for Windows, RunPod & Massed Compute

## Full tutorial link > https://www.youtube.com/watch?v=FvpWy1x5etM

[![FLUX Full Fine-Tuning / DreamBooth Training Master Tutorial for Windows, RunPod & Massed Compute](https://img.youtube.com/vi/FvpWy1x5etM/sddefault.jpg)](https://www.youtube.com/watch?v=FvpWy1x5etM "FLUX Full Fine-Tuning / DreamBooth Training Master Tutorial for Windows, RunPod & Massed Compute")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/FLUX-Full-Fine-Tuning-DreamBooth-Training-Master-Tutorial-for-Windows-RunPod-and-Massed-Compute.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/FLUX-Full-Fine-Tuning-DreamBooth-Training-Master-Tutorial-for-Windows-RunPod-and-Massed-Compute.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


If you want to train FLUX with maximum possible quality, this is the tutorial looking for. In this comprehensive tutorial, you will learn how to install Kohya GUI and use it to fully Fine-Tune / DreamBooth FLUX model. After that how to use SwarmUI to compare generated checkpoints / models and find the very best one to generate most amazing images ever. Moreover, this tutorial will work on training everything such as training a person, an art style, a pet, an item, an object, or general Fine-Tuning (the post will be updated for this later).

üîó Full Instructions, Configs, Installers, Information and Links Shared Post (the one used in the tutorial) ‚§µÔ∏è

‚ñ∂Ô∏è [https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-112099700](https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-112099700)

The tutorial shows how to train 100% privately on Windows locally and also on the very best cheapest Cloud providers RunPod and Massed Compute same as in your local computer. Moreover the tutorial shows auxiliary tools like Ultimate Preprocessing APP for preparing training images dataset, ultra fast uploading and downloading models to Hugging Face Jupyter notebook, SUPIR upscaler to enhance images to next level and so on.

Still fixing video subtitles / captions as well

Video Chapters (still writing them)

[00:00:00](https://youtu.be/FvpWy1x5etM?t=0) Introduction

[00:00:22](https://youtu.be/FvpWy1x5etM?t=22) Why Fine-Tuning / DreamBooth is better than LoRA training and what is the difference

[00:03:39](https://youtu.be/FvpWy1x5etM?t=219) How long preparation of this tutorial taken and how i prepared it

[00:04:09](https://youtu.be/FvpWy1x5etM?t=249) How much time each training takes and what are the training speeds and VRAM usages of the configs

[00:05:38](https://youtu.be/FvpWy1x5etM?t=338) The list of things that you are going to learn from this tutorial

[00:10:47](https://youtu.be/FvpWy1x5etM?t=647) Technical difference between LoRA and Full Fine-Tuning / DreamBooth

[00:12:33](https://youtu.be/FvpWy1x5etM?t=753) Windows (private local training) part of the tutorial starts with how to install Kohya GUI for FLUX training

[00:14:15](https://youtu.be/FvpWy1x5etM?t=855) How to install Kohya GUI on Windows accurately

[00:17:46](https://youtu.be/FvpWy1x5etM?t=1066) Picking the accurate configuration

[00:22:52](https://youtu.be/FvpWy1x5etM?t=1372) Using Image Cropper

[00:25:15](https://youtu.be/FvpWy1x5etM?t=1515) Using Image Resizer

[00:26:42](https://youtu.be/FvpWy1x5etM?t=1602) Kohhya Workflow

[00:27:27](https://youtu.be/FvpWy1x5etM?t=1647) Downloading Models

[00:28:50](https://youtu.be/FvpWy1x5etM?t=1730) Changing Output Directory

[00:30:57](https://youtu.be/FvpWy1x5etM?t=1857) Destination Path

[00:31:32](https://youtu.be/FvpWy1x5etM?t=1892) Clikcing Prepare Training Data

[00:34:30](https://youtu.be/FvpWy1x5etM?t=2070) Starting Training

[01:13:49](https://youtu.be/FvpWy1x5etM?t=4429) Massed Compute (cheap private cloud training) part of the tutorial starts with how to install Kohya GUI for FLUX training

[01:32:02](https://youtu.be/FvpWy1x5etM?t=5522) How to increase empty storage on Massed Compute and how many checkpoints you can save

[02:01:41](https://youtu.be/FvpWy1x5etM?t=7301) RunPod (cheap private cloud training) part of the tutorial starts with how to install Kohya GUI for FLUX training



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=0) Greetings everyone. Today I will show you how to do full Fine-Tuning /

- [00:00:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4) DreamBooth training of the FLUX Dev Model to generate the very best possible images by

- [00:00:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=11) doing training. You may be wondering why you should do Fine-Tuning / DreamBooth training instead

- [00:00:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=16) of LoRA training because the Fine-Tuning training yields way better results compared to LoRA

- [00:00:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=22) training. For example, on the left side we see the result of LoRA training and on the right side we

- [00:00:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=29) see the result of Fine-Tuning. They are both looking amazing. The difference coming from the

- [00:00:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=34) following prompt. When we pay attention to the prompt, we will see that there is a thick beard

- [00:00:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=41) in the prompt. In the training images, I never had such a thick beard. Therefore,

- [00:00:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=46) the LoRA training completely failed to generate my image with a thick beard. However,

- [00:00:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=53) the Fine-Tuning was perfectly able to generate a thick beard. The prompt also has a blue beard,

- [00:00:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=58) and I also generated amazing images with a blue beard. This is another example. We can see that

- [00:01:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=65) the LoRA training was extremely overfit compared to the DreamBooth / Fine-Tuning training. You can see

- [00:01:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=73) that. Or this is another example. We again see that Fine-Tuning yields way better results compared to

- [00:01:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=81) the LoRA training. And especially, Fine-Tuning training shines when you generate images that

- [00:01:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=88) are stylized, not realistic. So this prompt is 3D CGI rendering. And in the above, we see the

- [00:01:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=97) results of the LoRA training. It is totally realistic as you are seeing right now. Nothing

- [00:01:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=101) related to CGI or 3D. However, when we look at the images in the bottom, which is Fine-Tuning /

- [00:01:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=108) DreamBooth training, it is way more stylized compared to the LoRA training. So the quality

- [00:01:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=115) and generalization of the Fine-Tuning is

- [00:01:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=118) way better compared to the LoRA with the completely same dataset and same training

- [00:02:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=124) durations. And another thing is that in my 15 images dataset, I don't have any expressions.

- [00:02:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=130) Therefore, LoRA completely fails to do any expressions. However, with Fine-Tuning,

- [00:02:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=136) even though I don't have any expressions, any emotions in the dataset, Fine-Tuning is able

- [00:02:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=141) to generate. And when I train with 256 images, of course, both of them is able to generate perfect

- [00:02:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=148) quality expressions and emotions. Still, Fine-Tuning is way better compared to the LoRA.

- [00:02:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=153) This is another example. You see the LoRA training fails to stylize images compared to the DreamBooth.

- [00:02:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=161) And here another example. You see the above images are LoRA images.

- [00:02:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=165) They are not stylized. However, DreamBooth is way more stylized.

- [00:02:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=170) And here another example. You see I am trying to portrait myself as an old sage. And we see that the

- [00:02:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=177) Fine-Tuning is able to age me perfectly compared to the LoRA training. And here another example. Again,

- [00:03:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=184) when it is stylized images, the Fine-Tuning shines. And here another example. This is with the 15

- [00:03:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=190) images dataset. You see that the LoRA is way more overfit. It is containing elements from

- [00:03:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=196) the training dataset images. However, the quality of the Fine-Tuning is way way better compared to

- [00:03:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=202) LoRA. And here another example related to the stylization. This is another example

- [00:03:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=208) of how LoRA is overfit. And this is another example of stylization.

- [00:03:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=213) LoRA completely fails to stylize. However, Fine-Tuning is way way powerful.

- [00:03:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=219) So this tutorial has been prepared after working for literally weeks. Literally weeks. It is a

- [00:03:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=226) very big tutorial. A very long tutorial. However, I have chaptered everything accordingly. So

- [00:03:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=232) look at the video chapters to find the information that you are looking for.

- [00:03:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=237) I have also shared the different configuration full training logs that you can open and look

- [00:04:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=243) how much time they have taken, what were their speed, and which checkpoints were the best.

- [00:04:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=249) I am also sharing configurations for Fine-Tuning and in addition to LoRA training, each

- [00:04:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=256) configurations have their VRAM usages, their time durations they take, so you will just

- [00:04:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=262) load the configuration and start training immediately.

- [00:04:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=265) Not only for Fine-Tuning, but I also have for LoRA training, however, I don't recommend

- [00:04:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=271) LoRA training. Because to obtain the very high quality, the highest quality in LoRA training,

- [00:04:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=276) you need at least 30 GB VRAM having GPU.

- [00:04:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=280) But with Fine-Tuning, as low as 6 GB having GPU, you can obtain the very best, highest possible quality.

- [00:04:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=289) So this is amazing. With Fine-Tuning, we do not lose any quality

- [00:04:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=293) even if we have lower VRAM having GPU, because we are doing optimization, it is using shared VRAM.

- [00:05:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=301) Only difference is that lower VRAM GPUs are slower compared to the higher VRAM GPUs.

- [00:05:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=307) Each configuration also has the step speed timing as you are seeing right now.

- [00:05:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=312) So it is way better to wait and obtain highest quality compared to doing LoRA training.

- [00:05:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=318) I am also sharing amazing testing prompts. I will also show how you are going to use

- [00:05:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=323) use them to find your best checkpoint. You will also understand the prompting style and strategy as well.

- [00:05:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=331) So as I said, this tutorial is going to be a huge tutorial.

- [00:05:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=334) What I am going to show in this tutorial, let me show you.

- [00:05:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=337) First of all, this tutorial is the result of huge amount of research.

- [00:05:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=343) And finally, after I have found the very best configuration for each case, I have compared

- [00:05:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=349) it and decided the very best checkpoints. Then I have compared each checkpoint.

- [00:05:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=353) You see, I have done trainings with 15 images dataset and 256 images dataset.

- [00:05:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=358) I have compared batch size 1 versus batch size 7. I have compared LoRA versus Fine-Tuning and DreamBooth.

- [00:06:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=365) And I have decided the very best checkpoint for each case and compared each one.

- [00:06:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=371) The full comparisons grids are shared. The links will be here. You will get access to this page.

- [00:06:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=377) The link will be in the description of the video.

- [00:06:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=379) You will be able to download the training images datasets as well. You see 15 images and 256 images.

- [00:06:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=385) So by looking each of the full grids, you will understand how I decided the best checkpoint

- [00:06:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=391) and how systematically and empirically I have researched the best hyperparameters.

- [00:06:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=397) Moreover, I am sharing full grids of the comparisons between LoRA, Fine-Tuning, between 15 images,

- [00:06:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=403) 256 images, between realism and stylization. Therefore you will access everything and see yourself. This is weeks of research

- [00:06:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=413) and in this tutorial you will learn everything.

- [00:06:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=416) This is like a full lecture, not like a single tutorial.

- [00:06:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=419) Moreover, I have shared the timings and durations and the possible cost of every training so

- [00:07:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=426) that you can decide which training to use.

- [00:07:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=428) I will show how to train on your Windows computer, on RunPod, and on Massed Compute.

- [00:07:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=435) The first part of the tutorial will be for Windows. It will be the most detailed tutorial.

- [00:07:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=440) Then the second part will be for Massed Compute. And the third part will be RunPod.

- [00:07:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=444) So I will also add their timings and you will be able to jump to their timings and start

- [00:07:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=450) from there. Don't worry about that.

- [00:07:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=451) I also have shared my conclusions so you really need to read this amazing article from top to bottom.

- [00:07:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=458) But we are not done yet.

- [00:07:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=459) I will show this amazing tool to how to preprocess your training images with just one click under few minutes.

- [00:07:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=468) I will show how I have installed and used this on Windows, RunPod, and Massed Compute to preprocess

- [00:07:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=475) and prepare my 256 images dataset. This will be an amazing speedup for your process.

- [00:08:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=482) Moreover, I will show how to do grid comparison on the amazing SwarmUI, how to install it,

- [00:08:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=488) use it for your trained models, where to put the models, which are the best settings to

- [00:08:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=494) generate images, and as I said, how to do grid comparisons to decide your best configurations. You see?

- [00:08:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=501) I have done so many testings and you will learn everything.

- [00:08:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=505) In addition, I will show how to install and use SUPIR, the very best upscaler, to properly

- [00:08:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=510) upscale your generated images to the very best, very top quality upscaling.

- [00:08:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=517) You won't believe the details that SUPIR adds when you upscale your images. I will show everything.

- [00:08:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=523) Moreover, I will introduce you the Hugging Face Upload and Download Notebook, Jupyter Notebook.

- [00:08:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=530) With this notebook, you will be able to upload models very fast to the Hugging Face, then

- [00:08:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=535) later download them from Hugging Face very fast.

- [00:08:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=538) You can use this on your Windows computer or on RunPod and Massed Compute to backup

- [00:09:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=543) your data or download back your data very quickly.

- [00:09:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=547) This is optimized for the latest version of the Hugging Face libraries. This is just working blazing fast.

- [00:09:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=555) But this is not all. I also have prepared articles to convert the full Fine-Tuning /

- [00:09:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=560) DreamBooth checkpoints into the FP8 version so you can save half space and use them later.

- [00:09:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=568) Moreover, you may be saying that you are always showing how to train yourself.

- [00:09:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=573) I have prepared an amazing research for training style.

- [00:09:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=578) I have shared every detail of this style training, including consistent dataset or non-consistent

- [00:09:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=585) dataset, comparing with captions or without captions. I have shared the training dataset with captions. I have shared all the checkpoints.

- [00:09:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=593) So by reading this amazing research, you will be able to train whatever you want with the

- [00:10:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=600) configurations and workflow that I am going to share. You can train yourself. You can train your pets.

- [00:10:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=605) You can train your style. You can train your car, your items, your accessories, your clothing, literally everything. With FLUX

- [00:10:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=613) you will get the best possible training model after fully watching this tutorial video.

- [00:10:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=620) Before starting the tutorial video, if you are on Windows, please watch these Windows requirement tutorials.

- [00:10:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=627) I also recommend to watch Windows LoRA training tutorial and Cloud LoRA training tutorial.

- [00:10:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=633) Moreover, I have amazing Learn SwarmUI tutorial on Cloud, on Windows, and I also have a SUPIR upscaler video.

- [00:10:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=641) Everything is here. The link of this post will be shared in the description of the video as well.

- [00:10:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=646) Finally, before starting the tutorial. What is

- [00:10:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=650) the difference between Fine-Tuning and LoRA in terms of technical details? With full Fine-Tuning

- [00:10:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=656) we are training the entire model, all of the model weights, but with LoRA, it is an optimization.

- [00:11:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=663) We are only training additional layers that is like training only some portion of the model.

- [00:11:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=670) So it is an optimization. Therefore, Fine-Tuning will yield the very best results compared to the LoRA, whichever

- [00:11:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=678) the LoRA training you do. There is also DoRA training. I know that.

- [00:11:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=682) Hopefully, I will also research DoRA training and compare. There is also Open FLUX and FLUX Dev De-Distil.

- [00:11:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=690) Hopefully, I am also going to research them. Accordingly, I will update my configurations and my instruction post.

- [00:11:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=698) So whenever you are watching, you will get always the most accurate and the newest information.

- [00:11:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=705) Moreover, I will compare the newest optimizers and the LoRA training strategies later.

- [00:11:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=712) They will all be researched after this tutorial.

- [00:11:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=715) However, you still need to watch this tutorial because I can not cover everything again and again.

- [00:12:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=721) And another additional thing is that when you upscale generated images, you may be getting these vertical lines.

- [00:12:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=728) This is way more reduced with Fine-Tuning compared to LoRA. This is verified.

- [00:12:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=734) So Fine-Tuning reduces the vertical lines that you may get when you

- [00:12:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=739) generate high-resolution images with FLUX training. So now the tutorial will begin.

- [00:12:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=745) First part will be Windows, second part will be Massed Compute, and the third part will be RunPod.

- [00:12:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=750) The durations are as you are seeing. Let's begin. So as usual, I have prepared a very detailed post.

- [00:12:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=757) The link of this post will be in the description of the video.

- [00:12:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=760) Please read it from top to the bottom. Also the video will have full video chapters, detailed video chapters.

- [00:12:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=767) So you can look at the video description and jump to the video chapters that you are interested in.

- [00:12:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=774) I already have 2 FLUX training tutorials which are linked here.

- [00:13:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=780) So I am going to avoid repeating the same stuff. You need to watch these 2 and afterwards this tutorial.

- [00:13:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=789) To use the Kohya GUI on Windows, you need to have some requirements installed which are Python, CUDA, Git,

- [00:13:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=797) cuDNN, and C++ tools. All of them is explained in this new video.

- [00:13:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=803) So please also watch this video as well. And I also have some suggested tutorials.

- [00:13:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=809) Learn how to use SwarmUI, learn how to use SwarmUI on Cloud, or learn how to use FLUX.

- [00:13:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=815) So if you are not experienced with these, please watch these tutorials, then watch this tutorial.

- [00:13:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=822) It will help you tremendously. They are one time watching. And you will get experienced enough to follow this tutorial.

- [00:13:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=828) So let's download the Kohya installer.

- [00:13:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=831) Please use my installer because Kohya is still not merged the FLUX branch into the main branch.

- [00:13:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=839) And at the same time, I will also install the SwarmUI. So let's go here.

- [00:14:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=844) And here in the attachments section, you will see that there is Windows installer and the Linux installer.

- [00:14:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=851) For Massed Compute, we already have installed it. So I will use the Windows installer.

- [00:14:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=855) So let's begin with the Kohya installer. I am going to install it directly into my R drive.

- [00:14:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=861) What you need to run is run the Windows install step 1. I have shown everything in the main tutorials.

- [00:14:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=868) So nothing has changed it basically. Therefore I will be skipping a lot of parts.

- [00:14:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=874) Just select option 1 and that's it. Let's also install SwarmUI. You see SwarmUI Fine-Tuning. Double click. More info.

- [00:14:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=880) Run anyway. Do not run these scripts as administrator. Because it will take a lot of time.

- [00:14:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=885) It will cause path related issues for you. And this is the SwarmUI installer as you are remembering.

- [00:14:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=891) I will agree. Customize settings. Let's use modern dark or modern light. Next. Next. Okay. Next. I don't need anything.

- [00:14:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=899) Next. And yes that's it. SwarmUI installed. As you are seeing backends are still loading. And model not found.

- [00:15:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=905) We will use the models after we have completed the training.

- [00:15:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=909) So you can leave this as it is or close it. Actually I will close before starting the training.

- [00:15:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=915) Moreover, using the SwarmUI is not mandatory. You can also use Forge Web UI.

- [00:15:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=921) But I recommend using SwarmUI because it is very very optimized for the FLUX.

- [00:15:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=926) It uses ComfyUI as a backend. So it runs super fast on any GPU.

- [00:15:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=932) So the installation of the Kohya has been completed.

- [00:15:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=935) As you remember in the original video you can set the Accelerate. But I am not going to show again.

- [00:15:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=941) Now as a next step. You are going to run the Windows Update Kohya Step 2.

- [00:15:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=946) By the way if you already have installed Kohya please do a fresh installation. Why?

- [00:15:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=953) Because Kohya GUI upgraded to Gradio version 5. So you need to install a fresh installation.

- [00:15:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=959) Then on Windows Torch 2.5 makes huge speed improvement. Therefore execute this Windows install Torch 2.5.

- [00:16:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=969) It is almost about to be released. Maybe today maybe tomorrow. And click on it.

- [00:16:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=975) So currently xFormers is not compatible with Torch 2.5. Therefore we are going to uninstall xFormers.

- [00:16:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=982) And we are going to install Torch 2.5.

- [00:16:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=985) On Linux on cloud we use Torch 2.4.1 because it is working fast.

- [00:16:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=990) But on Windows we need Torch 2.5 for speed up. Then start the Windows Kohya.bat file.

- [00:16:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=998) We are going to use this bat file Windows start because the difference is that this bat file.

- [00:16:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1004) Has this option which is no verify. That way it will not uninstall Torch 2.5 that we have installed.

- [00:16:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1013) So you see this is the newest interface of the Kohya GUI. Nothing is actually changed.

- [00:16:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1018) Everything is same as the LoRA. The difference is that with Fine-Tuning we load into the DreamBooth tab.

- [00:17:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1026) Do not load the configurations into Fine-Tuning tab because this is slightly different. It requires different dataset preparation.

- [00:17:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1034) It requires different dataset preparation. So we are going to use DreamBooth.

- [00:17:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1036) You may be wondering why we are using DreamBooth if we are doing Fine-Tuning.

- [00:17:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1040) When you do DreamBooth training without regularization images actually it is same as Fine-Tuning.

- [00:17:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1047) So DreamBooth is a special technique that is trying to reduce model forgetting whatever it knows with prior reservation loss.

- [00:17:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1057) But when we don't use regularization images it is becoming same as the Fine-Tuning. Okay.

- [00:17:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1064) So I want you to pick the accurate configuration according to your needings. According to your GPU.

- [00:17:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1070) What is my GPU? Let's remember pip install nvitop and then just type nvitop.

- [00:17:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1077) And currently I have RTX 3090 and RTX 3060. Let me show you my NVIDIA SMI, nvidia-smi

- [00:18:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1086) And you can see my GPUs here. You see this is RTX 3090 and RTX 3060.

- [00:18:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1092) And I have only above 3060. And I have about 17 gigabytes of VRAM empty.

- [00:18:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1097) So first of all you need to restart your computer and disable all the startup applications and

- [00:18:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1102) reduce your VRAM usage before starting training. This is super important. Always verify how much VRAM that you are using.

- [00:18:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1109) Therefore, let's go to the pick configuration from here. You see this folder.

- [00:18:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1114) Then go to the installation folder which is here. You see. And inside this folder we have DreamBooth tab Fine-Tuning.

- [00:18:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1122) And in here. You will see this. You see that each configuration has their VRAM usage.

- [00:18:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1127) Since I have only like 18 gigabytes of VRAM free, I am going to use this configuration

- [00:18:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1132) in the video tutorial.

- [00:18:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1134) But as I said, when you free up your VRAM, you can also use this 24 gigabyte configuration.

- [00:19:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1140) All these configurations working. However, if you use this 16, 12, 10 gigabyte configurations, you need more RAM memory.

- [00:19:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1148) And virtual RAM memory will not be sufficient. You need physical RAM memory. So you see.

- [00:19:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1153) This is my RAM memory. I have just upgraded to 2x 32 gigabytes because 4x 16 gigabytes were not stable.

- [00:19:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1162) Therefore you need to upgrade your RAM memory. Then you will be able to use these lower configurations.

- [00:19:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1169) Upgrade to 64 gigabyte or 48 gigabyte and you should be fine.

- [00:19:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1173) However, if you are going to use 24 gigabyte configuration, 32 gigabyte is also sufficient to run these configurations. Okay.

- [00:19:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1181) Let's pick the 16 gigabyte configuration. And everything else is same as setting up as the LoRA.

- [00:19:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1188) But I will do a quick setup. And this time I want to show you something else.

- [00:19:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1193) You see I have got 256 images that I have collected with my mobile phone. This is an overkill dataset.

- [00:20:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1203) This is a very big dataset. You don't need such big dataset.

- [00:20:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1206) However, if you don't want to spend too much time to prepare a very good dataset and you've

- [00:20:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1213) want to just get a lot of emotions, full body shape, accurate body shape, proportional

- [00:20:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1219) body shape, and full of emotions, you can collect such dataset and then you can crop them.

- [00:20:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1226) But cropping all of these dataset into the accurate format would take huge time, right?

- [00:20:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1233) Because you need to manually edit all of them and crop them. Therefore, I have prepared an ultimate subject cropper.

- [00:20:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1240) The link is here. Let me show you.

- [00:20:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1243) You see suggested auxiliary tools and you will see ultimate batch image processing tool.

- [00:20:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1248) This is working on Linux, on cloud, on Windows. Let's download the zip file. This is not mandatory.

- [00:20:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1255) You can also manually crop them, but this will make your job much easier.

- [00:20:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1259) So let's just copy paste it here and let's extract here.

- [00:21:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1263) Enter inside the folder and just use Windows install.bat file.

- [00:21:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1268) You see there is also commands for how to run it on RunPod. It works all of there.

- [00:21:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1275) Just follow the instructions. Meanwhile, as you see, the SwarmUI updated backends and loaded it, but currently we don't

- [00:21:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1283) need it. Therefore, I am going to just close the SwarmUI terminal from here.

- [00:21:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1287) We will use it after we have completed the training. And currently the automatic cropper is getting installed.

- [00:21:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1295) Okay, it is installed. Now let's close it. And how we gonna use it? Just use Windows start file.

- [00:21:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1300) Run anyway. You see, I don't run any of these scripts as administrator because it changes the way

- [00:21:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1308) it is executed. First of all, you need to use image cropper than image resizer.

- [00:21:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1313) I suggest you to have 1024 to 1024 pixels for training.

- [00:21:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1318) Many times I am asked that can you use different resolutions. I suggest you to use 1024 as initially done.

- [00:22:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1326) Then you can enable bucketing and train with different resolutions and compare them.

- [00:22:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1330) Currently, this tool is able to select these detection classes. Person, bicycle, car, motorcycle, airplane, bus.

- [00:22:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1338) So if you have a dataset that contains any of these, you can use this tool to automatically crop them.

- [00:22:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1344) So these were the my images raw images. They are very big images. Let me show you one of them.

- [00:22:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1350) For example, this image is 2577 pixels to 2577 pixels as you are seeing right now.

- [00:22:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1358) Or for example, this image is 2577 pixels to 2577 pixels as you are seeing right now.

- [00:22:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1360) Let's open this one too. This one is 3000 to 4000.

- [00:22:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1365) So this is a collection of images that is taken during several months in different times in different places.

- [00:22:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1371) First of all, we need to enter our input folder like this. Then enter your output folder.

- [00:22:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1377) Let's select a folder inside here. And you see I am not using any space character in my folder names.

- [00:23:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1384) Please do not use any space character or special characters. And let's say processed dataset like this.

- [00:23:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1390) Aspect ratio, you can enter different aspect ratios and it will crop them with different aspect ratios.

- [00:23:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1396) I will show you what does this mean.

- [00:23:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1398) If you want to save YOLO images, you can also save them like YOLO faces or YOLO classes.

- [00:23:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1405) Okay, let's say YOLO classes. And number of threads, you can use more number of threads too.

- [00:23:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1410) It will improve your speed. Let's use 8. You can also overwrite existing files or do not.

- [00:23:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1416) So it will skip the existing files. And you can also save as PNG.

- [00:23:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1422) When you just uncheck this, it will save as GPX. I will save as a PNG. And crop images.

- [00:23:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1428) Let's follow the status here. This is a super optimized application.

- [00:23:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1433) We will see that it is super fast as you are seeing right now. It is fully utilizing my GPU.

- [00:23:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1438) It is saving all the images right now. So the images are getting saved inside here.

- [00:24:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1443) You see processed dataset and they are getting cropped. So what does this crop mean? And why you need it?

- [00:24:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1451) Okay, for example, let's compare with this image. This is cropped image. And let's open it with paint.net.

- [00:24:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1457) So it is cropped like this. However, there is one key issue. You see this is not 1024 to 1024.

- [00:24:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1464) It is not 1 to 1 ratio. Because this cropper will not crop the subject.

- [00:24:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1469) It will try to crop with the perfect aspect ratio if possible. So in which cases it was possible?

- [00:24:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1474) Let's see one of the cases that it was possible. Okay, for example. In this case. It was possible.

- [00:24:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1480) You see this is 1 to 1 ratio. Let's find the original version of this image.

- [00:24:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1485) So this is the original image. You see it is not 1 to 1 ratio right now.

- [00:24:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1489) We can see that it is 4624 to 3472. But it is 2948 to 2948.

- [00:24:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1499) So it perfectly cropped the subject and made it 1 to 1 ratio. You can of course do this manually.

- [00:25:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1507) But this tool will not do it. It will do that.

- [00:25:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1510) And in some cases like this, it will not be able to crop subject without cutting the body parts.

- [00:25:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1516) So the second stage is using the image resizer. This will resize every image into the accurate resolution.

- [00:25:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1523) So this will look at this folder under the folder that you give.

- [00:25:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1528) Therefore, you need to give this folder as a pet. You see there is this folder. It is matching.

- [00:25:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1533) Then input folder and output folder. Let's say final dataset like this. And you can also decide number of threads.

- [00:25:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1541) Let's make it 8. You see there is also overwrite existing files and resize without cropping.

- [00:25:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1546) So this will center image and add a white background. This is up to you. Let's use the resize images.

- [00:25:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1552) And meanwhile, let's also look at the YOLO classes. So these were the classes that it has found.

- [00:25:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1557) Let's open this image to see. So you see this was the YOLO detected class person.

- [00:26:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1563) So you can use any classes that it supports to crop. Images like this.

- [00:26:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1569) This is the logic of the automatic cropper.

- [00:26:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1571) However, this is not able to fit into a spec ratio that we want. Therefore, it was not perfect.

- [00:26:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1578) Now with the final dataset. You see 1024x1024. We will see that it did crop with focusing face.

- [00:26:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1586) And this is it. So this is the best that you can get from this image.

- [00:26:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1591) You see it is 1024x1024 pixel perfect right now. All images are now 100. And our dataset is ready.

- [00:26:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1601) Let's return back to the Kohya.

- [00:26:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1603) This is exactly the same on the RunPod or on the Massed Compute as well.

- [00:26:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1607) So you can also crop your dataset there. Or you can crop them on your computer and upload there.

- [00:26:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1613) First of all, you need to pick your model. And many people are making mistakes when picking the models.

- [00:27:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1620) Please use the models that our downloader downloads. Which are Official FLUX 1 Development Model. You see these are pre-configuration.

- [00:27:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1629) These are for the message compute image. Therefore, I need to pick it from my own computer.

- [00:27:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1635) That is why FLUX 1 is not selected. Because after you pick this, it will be selected.

- [00:27:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1641) So where you can find them. I have the links.

- [00:27:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1644) But I suggest you to use the Windows download training model bot files. Okay, more info run anyway.

- [00:27:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1650) And it will download all the necessary model files with maximum speed. Let's see the speed.

- [00:27:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1657) This downloader also has resume capability. So for whatever reason, if download fails, you can execute it again.

- [00:27:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1665) And it will continue downloading. And let's just wait. Okay, the download has started.

- [00:27:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1670) You see it is downloading all of the files simultaneously. And look at this speed.

- [00:27:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1675) It is 100 megabytes per second on my own personal computer. It is way faster on the cloud services.

- [00:28:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1683) So this is the maximum speed that you can download accurate models.

- [00:28:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1687) Please use this downloader if you get any tensor not matching error. Any error at all actually.

- [00:28:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1693) So that you can be sure you are using the accurate models. Okay, so the download has been completed.

- [00:28:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1699) You see it shows that download completed. Let's close it. Then we are going to pick the files.

- [00:28:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1704) Click this icon. Go to the download which will be here.

- [00:28:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1708) You see they are in the same folder where I have run the downloader here.

- [00:28:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1713) So the first one is this one. After I selected this model, you see the FLUX 1 became selected.

- [00:28:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1720) Then give a name to your trained model. So I am going to use this name like this.

- [00:28:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1725) You can give any name. Okay, then everything is set here. You don't need to change.

- [00:28:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1730) What you need to change is output directory. There are two ways that you can do.

- [00:28:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1735) In this tutorial, I will show how to use dataset preparation. It is easier.

- [00:29:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1740) For FLUX, I don't recommend detailed captions. Unless you don't have a consistent dataset. What does consistent means that?

- [00:29:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1751) I have a style training tutorial. The link is here. When you go to here, this is a public page.

- [00:29:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1756) You will see all the experiments and datasets that I have used and experimented.

- [00:29:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1762) You will see all the results, their conclusions. And when I didn't use a consistent dataset, the captioning helped.

- [00:29:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1770) However, when I used a consistent dataset, then the captioning didn't help. So, as a caption, what you should enter?

- [00:29:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1778) You should enter an instance prompt. I prefer OHWX. And as a class prompt, this is a man dataset.

- [00:29:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1784) So, I'm going to use man. You need to decide class prompt according to your class.

- [00:29:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1790) When you read this 3D cartoon style FLUX experiments, you will understand better. So, please read this page.

- [00:29:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1798) I have shared the datasets, used captions, the models, checkpoints, everything. This was a LoRA training. But everything is same.

- [00:30:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1806) Nothing changes. The logic is totally same. Then training images directory.

- [00:30:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1811) You can use here or you can give the path directly. So, where was our images? It was here.

- [00:30:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1818) 1024 final. Let's copy this. Paste it here. Then regularization images. We don't use regularization images.

- [00:30:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1825) For FLUX, it doesn't help. And very important thing. By default, the repeat is 40.

- [00:30:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1831) However, for FLUX, we don't use regularization images. Therefore, we don't use repeating. We use repeat 1. Don't forget this.

- [00:30:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1839) So many people is forgetting this part. The repeating will be 1. Not more.

- [00:30:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1844) Repeating is only needed when you use regularization images. It is only useful for SDXL and SD 1.5 trainings.

- [00:30:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1852) I have tutorials for them. You can watch them later. And the destination.

- [00:30:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1857) So, destination means that where it will save images and save the generated model file.

- [00:31:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1864) So, as a destination, I am going to use the SwarmUI installation. Which is here.

- [00:31:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1870) So, the SwarmUI installation currently needs diffusion models folder for Fine-Tuning model files. Don't forget that. You see here.

- [00:31:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1879) Diffusion models. So, I will give this folder as a destination directory. So, everything will be saved there.

- [00:31:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1885) And I will be able to use the generated checkpoints directly. Prepare training dataset.

- [00:31:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1891) And after you click it, you need to watch what is happening on the screen. From the cmd. Let's see.

- [00:31:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1896) Okay. Too many values needed. Let's see. Okay. I think it is currently copying right now.

- [00:31:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1902) Let's also verify the folder. Images are here. They are getting copied. Yes, I see. They are all copied.

- [00:31:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1909) And you see. It will save them inside model folder. It will work. I think it is done.

- [00:31:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1914) This is just a warning. Not important. After that, you need to click copy info to respective fields. Click that.

- [00:32:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1921) And what does that button do is. It will set the output directory, logging directory, and regularization directory.

- [00:32:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1928) I don't recommend use logging. Sometimes it causes errors. And you could set all of these manually as well.

- [00:32:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1935) So, what other changes that you need to set? You only need to set few parameters.

- [00:32:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1941) So, what you need to set is epoch. Epoch is depending on your dataset. Your training dataset.

- [00:32:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1948) In this post, I have explained a lot of stuff. Such as 15 images compared with 256 images trainings.

- [00:32:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1957) And their timings, their best epochs.

- [00:32:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1961) For example, when the batch size is 1, I find that 80 epoch is best for 256 images.

- [00:32:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1967) When batch size is 7, I find another one. For 15 images, it was 160 epochs or 140 epochs.

- [00:32:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1976) So, you really need to read entire thing in this post.

- [00:33:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1981) And decide how many epochs that you want to go.

- [00:33:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1984) To be sure, you can always go up to 200 epochs.

- [00:33:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1988) But it will take more time depending on your training dataset.

- [00:33:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1991) So, since this is 256 images, I am going to do until 100 epochs.

- [00:33:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=1997) And I will save every 10 epochs. Or you can even save every 5 epochs.

- [00:33:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2001) But be careful, each checkpoint will be 24 gigabytes. Therefore, be careful with that.

- [00:33:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2006) So, you can save like every 10 epochs, 10 checkpoints, it will be 240 gigabytes.

- [00:33:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2011) And other than that, you don't need to change anything else.

- [00:33:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2014) However, if you get out of VRAM error or if you cannot reduce your VRAM usage.

- [00:33:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2020) So, currently my VRAM usage is 7 gigabytes. And I have got 17 gigabytes free VRAM.

- [00:33:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2026) What you can do, you can increase the blocks to swap to reduce required VRAM usage.

- [00:33:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2032) But since we loaded 16 gigabytes configuration, this should work. And I will just click start training.

- [00:33:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2039) Oh, by the way. I have forgotten something.

- [00:34:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2041) Which is, I need to set this VAE path, clip path and T5 path. So, click here.

- [00:34:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2047) Set the VAE from here. Like this. Set the clip large path. These are automatically downloaded here. And T5 set.

- [00:34:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2054) Which is, let's see here. So, you see these are the paths that I did set on my computer.

- [00:34:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2060) Don't forget them. And please use the models that I have shared.

- [00:34:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2065) If you use other models, you may get errors. And it is being very hard to debug them.

- [00:34:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2070) And that's it. Okay. Start training. And let's watch the training process. This was the auto cropper.

- [00:34:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2077) And this is our Kohya. So, you need to pay attention to the CMD.

- [00:34:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2082) If there is errors, you need to share the errors with me. Let's see if there is an error.

- [00:34:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2087) It shows how many images found. How many steps it is going to do.

- [00:34:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2091) With 256 images, it is going to do 25600. Because we have 100 epochs.

- [00:34:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2096) I have explained all the details in the original tutorials. First, it will cache. Then, it will start training.

- [00:35:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2102) So, the memory usage started. Okay. So, the training has started. You see it is using 20.55 gigabytes currently.

- [00:35:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2110) And the speed is 23.5 seconds. The speed will get decreased as it goes.

- [00:35:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2117) So, you need to wait at least 200 steps to get the accurate speed.

- [00:35:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2121) Otherwise, you will not get the accurate speed. So, you see it is getting decreased.

- [00:35:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2125) Every second, it will get decreased more. What is the speed that I am supposed to get?

- [00:35:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2131) When you look at the training configurations, it also shows you the speed.

- [00:35:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2135) So, 16 gigabytes speed is supposed to be like 14 seconds on RTX A6000 GPU.

- [00:35:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2142) Since I have RTX 3090 Ti, it should be almost same.

- [00:35:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2147) However, this was the case when I am not using my computer. Currently, I am recording a video.

- [00:35:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2153) I am running another applications. So, therefore, it will be slower on my case.

- [00:35:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2159) But these are the speeds that you should get with RTX 3090.

- [00:36:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2162) If you have 4090, you will get better speeds. Don't forget that you will get like half of them.

- [00:36:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2168) So, 14 seconds will be like 7-8 seconds. 10 seconds will be like 5-6 seconds. I have some Patreon supporters.

- [00:36:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2176) They reported that they are getting like 6 seconds IT on 24 gigabytes configuration. It is just amazing.

- [00:36:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2183) And there is 48 gigabytes configuration. When we use it on the cloud, we will see the speed.

- [00:36:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2190) So, these configurations have both speed and their VRAM requirements. This is super important to pay attention.

- [00:36:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2196) Not only Fine-Tuning configurations, but my LoRA configurations also have them. So, you see, LoRA configurations have different ranks.

- [00:36:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2205) What does that mean? That means that they are sorted by quality. With LoRA, we cannot get same quality.

- [00:36:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2212) With the lower amount of VRAM. We have to sacrifice quality. Rank ones are the best quality.

- [00:37:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2220) Rank two, rank three, rank four. So, the quality degrades. There aren't that much difference. But the quality matters.

- [00:37:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2227) And each one has VRAM usage and also the speed.

- [00:37:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2231) Of course, the speed is faster at some lower ranks for the lower GPUs.

- [00:37:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2235) Moreover, with LoRA training, we can do multi-GPU training. However, with Fine-Tuning,

- [00:37:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2241) it requires 80GB GPUs and it is not very efficient because of that. So, I don't recommend.

- [00:37:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2249) What I recommend for speed-upping the Fine-Tuning training,

- [00:37:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2253) get a powerful GPU like L40s or like H100 and use batch size 7 or bigger batch sizes.

- [00:37:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2261) And what is the logic of batch sizes? The batch size logic is like this.

- [00:37:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2266) I recommend multiplying original batch size 1 learning rate with square root of the batch size.

- [00:37:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2274) So, let's say our default learning rate is like this. It is not like that, but let's say like this.

- [00:37:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2279) And I want to do batch size 15. So, what would be the multiplication?

- [00:38:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2285) When you type Google square root list, you will get a list like this.

- [00:38:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2289) So, you can see the square root parameters. So, let's say your batch size is 15.

- [00:38:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2295) Therefore, you need to multiply your learning rate with 3.78. Of course, this is not enough.

- [00:38:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2301) It is not 100% accurate. For example, for finding the batch size 7, I compared every learning rate,

- [00:38:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2308) and I found the very best working one. So, every batch size requires new experimentation.

- [00:38:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2314) But this is somewhat okay to do. So, with 15, it would be like multiplying this with 3.7829.

- [00:38:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2323) And this would be my newest learning rate. So, batch size 1 learning rate multiplied with the

- [00:38:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2330) square root of the newer batch size. Okay, after 25 steps, it became like 16.91 seconds.

- [00:38:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2337) Also, my installer now installs Triton as well. I just included it into the installer from the Triton releases.

- [00:39:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2347) Maybe you are following me on the Reddit, and I have shared the Triton 3 published.

- [00:39:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2353) So, I just implemented it into my installer. And this speed is just amazing.

- [00:39:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2358) We are almost getting same as the speed on the Linux, and my computer is not free.

- [00:39:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2364) So, maybe it will be just exactly same as Linux.

- [00:39:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2367) Previously, there was a huge speed difference between the Linux and Windows, but not anymore. So, this is just amazing.

- [00:39:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2376) Maybe Triton has increased the speed as well. I didn't test it yet. I just included it.

- [00:39:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2382) But this speed is amazing. It is very close to the speed that I got on the Linux.

- [00:39:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2387) How do I know?

- [00:39:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2389) Because currently I am using the 16 GB configuration, and it was 13.8 seconds on RTX A6000 on Linux.

- [00:39:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2397) I am currently at the 16.68 seconds, and I am using a lot of other applications like recording video.

- [00:40:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2405) There are some other applications running right now.

- [00:40:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2407) Therefore, this is a great speed, and it may reach to this one if we wait more.

- [00:40:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2412) Because you need to wait at least 200 steps to get the accurate speed. Okay, guys.

- [00:40:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2417) While I am recording and training right now, PyTorch 2.5 officially released, and we are

- [00:40:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2424) already using it on the Windows with which file? With using Windows install Torch 2.5.

- [00:40:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2432) And now, once the xFormers is updated, I will update all the configurations to xFormers,

- [00:40:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2439) and I will update this file to install xFormers as well.

- [00:40:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2442) I don't know when will Kohya update the installation to Torch 2.5.

- [00:40:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2446) However, my installers will be always up to date. That is why supporting me and following me is super important.

- [00:40:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2454) You see, Torch 2.5 was installed 17 minutes ago just while I am recording the tutorial.

- [00:41:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2462) So this is just amazing. Once the xFormers is also published for Torch 2.5, I will update the installers.

- [00:41:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2469) And my installer is also including the latest Triton installer.

- [00:41:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2475) As you are seeing right now, I just replied one of the requests. Can I make a tutorial?

- [00:41:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2480) Yes, I am making a tutorial right now.

- [00:41:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2483) I am replying all the questions that you have on the Patreon or on the Discord or on the Reddit as well.

- [00:41:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2490) Okay, so we are down to like 16.34 seconds IT with 55 steps.

- [00:41:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2495) It will get faster and faster as you are seeing right now.

- [00:41:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2499) Therefore, I am going to terminate the training because I have done all these trainings there on the Hugging Face.

- [00:41:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2506) You can see their names.

- [00:41:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2507) You see, 15 images Laura, 15 images Base Size 1, 256 images Base Size 1, Laura, DreamBooth.

- [00:41:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2515) I have compared every combination and after that, I have prepared this tutorial.

- [00:42:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2520) So I am going to use these files to show how to use them on SwarmUI right now.

- [00:42:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2525) To terminate the training, let's just stop it. And you see, my GPU usage is around like 25%.

- [00:42:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2532) Therefore, I am getting... 25% lesser speeds compared to what I could get. So this is important.

- [00:42:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2540) Keep that in mind. Now, how we are going to use them.

- [00:42:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2543) So if I had continued training, these checkpoints would have been inside this folder.

- [00:42:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2550) Therefore, I am copying the downloaded files there right now to show you.

- [00:42:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2554) You see the JSON files of the training were saved here. And you see there is sample folder.

- [00:42:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2560) About samples during the training, I don't recommend them. You can set them here. Why I don't recommend them?

- [00:42:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2567) Because samples will increase your VRAM usage.

- [00:42:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2571) Therefore, batch size saving configuration on the Massed Compute with 48 GB GPU will not work.

- [00:42:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2578) You will get out of VRAM error during the sample generation.

- [00:43:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2583) It can also happen on your Windows computer as well, depending on the configuration that you are using.

- [00:43:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2588) So I don't recommend samples. They increase the VRAM usage. They don't work as expected.

- [00:43:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2594) Usually, from my experience, instead of that, now we are going to use the grid generation of the SwarmUI to find the best checkpoint and decide which one is best.

- [00:43:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2605) And with Fine-Tuning, you can always continue training how.

- [00:43:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2609) You can select your latest checkpoint instead of this one, and it will continue from the latest checkpoint.

- [00:43:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2616) Continue training your model. Moreover, if you have multiple GPUs, you can decide which GPU to be used.

- [00:43:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2624) You can use it from the Accelerate launch options. Distributed GPUs. You need to make this the GPU ID accordingly.

- [00:43:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2631) So since my first GPU is RTX 3090, I made it 0.

- [00:43:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2636) If I wanted to train on RTX 6090, I would be needed to make it 1.

- [00:44:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2642) And by the way, it works. I have tested it. It just works amazing.

- [00:44:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2646) All you need to do is having 64 GB of RAM memory.

- [00:44:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2650) If you have like 32 GB, it will not work. On the RTX 3090, it will not work.

- [00:44:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2654) If you want to train on RTX 3090 or like 16 GB GPUs, you need to have at least 48 GB of RAM memory.

- [00:44:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2662) Physical RAM memory. So the models are here. Let's just start the SwarmUI.

- [00:44:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2666) As usual, I will just show as an example to find the best checkpoint.

- [00:44:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2671) By the way, these are not the best checkpoints. I have recorded the best checkpoints. Let me show you them.

- [00:44:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2677) Normally, this is written in the Patreon post, but these are my best checkpoints after trainings.

- [00:44:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2682) For 15 images, I found that 160 epochs was the best with batch size 1.

- [00:44:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2688) 140 epochs with batch size 7. So 70 epochs with batch size 1, but 256 images.

- [00:44:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2696) And with batch size 7, it was 40 epochs. So these were my best checkpoints.

- [00:45:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2702) It depends on each one's individual assessment and dataset. There is not a one for all rule.

- [00:45:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2710) So you need to assess it yourself. And now I will show how to assess it.

- [00:45:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2714) So to start the SwarmUI, enter inside the SwarmUI.

- [00:45:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2717) And in here, you will see that there is update and launch. First of all, I recommend to update it.

- [00:45:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2723) From here, let's update it. So it will be latest version. And then I recommend launch Windows.bat file.

- [00:45:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2730) This is super useful. And it will tell me that I am missing models. But the models are here.

- [00:45:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2737) However, what I am missing right now, I am missing the clip large model and VAE model.

- [00:45:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2742) All these are explained in the main tutorial. But let's quickly also copy them. So our files were here.

- [00:45:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2749) So VAE file, let's copy it into the models, into the VAE here. Then let's copy the T5XXL from here.

- [00:45:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2758) This requires a certain name to work. Otherwise, it will redownload it. You put this into clip model.

- [00:46:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2765) And you also put the clip large into the clip model. You see clip folder. And that's it.

- [00:46:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2771) So either you need to give certain name or we need to set it from here, which I will show.

- [00:46:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2776) So first of all, let's select one of the models checkpoint from here like this.

- [00:46:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2780) And let's make it 30 steps. I prefer 40 steps for best quality. Then resolution is 1024.

- [00:46:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2788) In the sampling, I prefer this sampler. I find it best. iPNDM. You see this one.

- [00:46:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2794) And I find that FLUX guidance scale 4 is best. And then what I need to set is.

- [00:46:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2801) The advanced model add-ons. You see. You click here to see them. Don't forget that. In here, VAE is.

- [00:46:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2808) Let's see. It doesn't see. I think we need to refresh the models folder. Maybe refresh the page.

- [00:46:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2813) Let's refresh the page. Okay. Let's look again. VAE. Yes. Clip large model here. Yes. And T5 model here.

- [00:47:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2822) So it will not download. But you can also download the FP8.

- [00:47:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2825) Actually, if you don't put anything there, it will download the FP8 version automatically.

- [00:47:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2829) And in the advanced model add-ons, you see. In the advanced sampling, you can set it 16-bit.

- [00:47:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2834) However, since my GPU is not over 28 gigabytes right now, I am going to use this one 8-bit.

- [00:47:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2840) So this is the accurate one. And that's it. We are ready. So which prompts you can use.

- [00:47:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2846) You can type your prompts. But I have test prompts here. That is specially designed for this formula.

- [00:47:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2851) And there is one crucial thing, which is in-painting phase to get the best quality.

- [00:47:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2856) So first of all, let's generate an image without in-painting. Then let's generate with in-painting. So the prompts are here.

- [00:47:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2862) Let's open one of the prompts. Let's use this prompt.

- [00:47:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2865) By the way, this will not be the best quality because this is just a 4D epoch and the best

- [00:47:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2869) one was 70. And you see there is segmentation part. First, I will not do segmentation.

- [00:47:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2876) Let's make the seat something like this. Then I will do the segmentation.

- [00:47:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2879) When you hit the generate, you will see that there is one current generation, one queued,

- [00:48:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2883) one waiting on model load. When you go to server logs and debug, you will see what is happening. Okay.

- [00:48:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2891) I am still downloading the T5 XXL even though I have selected the T5 XXL here.

- [00:48:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2897) So this is definitely a bug. And how can I fix it? This is the name it is requiring.

- [00:48:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2903) So when I enter inside the clip model, I will just terminate the SwarmUI and I will rename

- [00:48:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2909) this to this. So this was the name it was looking for.

- [00:48:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2912) So let's restart the SwarmUI and prevent downloading it what we have. By the way, this is 16-bit version.

- [00:48:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2920) So it will use slightly more VRAM. Okay. It is getting loaded. Just wait the backend to load.

- [00:48:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2925) And if you are using RTX 4000 series, you can add an extra argument here. It will speed up how?

- [00:48:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2932) Edit and add dash dash fast. It will speed up your generation speed. Okay. Let's generate.

- [00:48:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2938) Let's go to server logs debug. And now it will not download the T5 XXL. Okay.

- [00:49:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2945) You see it is loading the model weight D type, which is the accurate one. Model type FLUX.

- [00:49:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2949) Let's look at the RAM usage. You see the RAM usage is increasing.

- [00:49:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2953) That is why I recommend 64 gigabytes RAM memory.

- [00:49:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2957) Because when it loads the model first time, it will cast it. And how you can save the model size?

- [00:49:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2965) I also have an article for that, which is here.

- [00:49:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2968) You see, if you want to convert FP16 checkpoints to FP8, when you go to this article, you will

- [00:49:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2973) see that you can use Kohya to convert, which is here. LoRA tools.

- [00:49:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2978) And in here, you will see that I will just zoom out, which is merge LoRA, merge FLUX LoRA here.

- [00:49:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2986) Then you will select your model from here. Let me demonstrate it. So where was our models?

- [00:49:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2993) Inside, inside SwarmUI, inside models, inside diffusion models, model like this.

- [00:49:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=2999) Then what you need to do is just select the same folder here. Let's say FP8 like this.

- [00:50:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3007) And select the same folder. Select the FP8 from here. This is it. Just merge model.

- [00:50:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3011) And it will generate FP8 version. I tested it. It works perfect.

- [00:50:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3014) And our image is generated with 1.7 second IT. This is a decent speed, 1.7 second IT.

- [00:50:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3022) Let's go to the here. And this is the image generated.

- [00:50:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3026) This image is a close shot, therefore it doesn't need face inpainting. So let's select another one from here.

- [00:50:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3032) Don't worry, I will show everything of this. Okay. Let's use the tiger image. Because this one is really good.

- [00:50:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3038) I really need face inpainting. Let's generate. The second generation will be faster. Let's see. Okay. It is just doing.

- [00:50:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3044) Loading. And now it is generating. I recommend SwarmUI really because it has old optimizations and it will work better

- [00:50:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3052) than the other UIs. Okay. It is working. We can also see the usage here.

- [00:50:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3058) So it is fully utilizing the VRAM.

- [00:51:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3060) My computer is running a lot of applications as I said numerous times recording video and

- [00:51:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3065) therefore it is just limited. Okay. The speed is this time even better. 1.5 second IT.

- [00:51:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3071) RTX 4090 is reaching 2.2 IT second with fast option. So 4090 is amazing.

- [00:51:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3078) I am waiting the RTX 5090 to upgrade hopefully and make videos of it.

- [00:51:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3084) We will see hopefully once it is published. Okay. This one failed because I have the YOLO.

- [00:51:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3090) So let's just generate it without it. Okay. I just noticed a major error which is here. You see?

- [00:51:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3097) I have XXL model. It was inaccurately selected. Therefore I was getting very weird images.

- [00:51:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3104) So now I will fix it and try again to show you.

- [00:51:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3108) And I will set 10 images, generate 10 images and compare them.

- [00:51:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3111) I am also downloading the best checkpoint to show on the best checkpoint.

- [00:51:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3115) If your generation speed becomes very slow just restart the SwarmUI and it should get

- [00:52:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3121) fixed and we have got quite a bit of images ready. So interrupt all sessions from here.

- [00:52:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3127) You can also right click and generate forever and when I go to the history I can see the

- [00:52:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3132) generated images. However, when you look at the face you will see that they are not very good.

- [00:52:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3137) This is expected because the face is very small area and this is only 1024 pixel image.

- [00:52:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3146) Not a great resolution. So how we can fix this issue?

- [00:52:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3150) To fix this issue we are going to use face in painting. That is the key. So for example.

- [00:52:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3156) Let's reuse these image parameters. And for face in painting I recommend yellow face version 9c.

- [00:52:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3164) This is fine-tuned model by the after detailer extension developer. So where is this?

- [00:52:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3171) When you go to the test prompts inside the zip file download the zip file.

- [00:52:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3175) You will see how to download yellow face. Open that file. So this is the link. Download it.

- [00:53:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3181) This is the small file you see like this. 50 megabytes. Copy it. This is your SwarmUI models.

- [00:53:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3187) In here you need to generate a new folder. New folder is YOLO version 8. Like this.

- [00:53:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3193) Enter inside it and put it there. So this is like it.

- [00:53:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3197) Once you put it like that it will work.

- [00:53:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3199) And then let's go back to the here and let's copy paste the format. Now this format is important.

- [00:53:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3206) How you format it matters. So let's put it here. And what does this format do is.

- [00:53:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3212) It is going to find the first face here. By the way. The faces are from left to right currently.

- [00:53:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3218) But there is also going to have a new feature. It is not added yet.

- [00:53:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3222) When you go to the regional prompting. You will have a sort mechanism here.

- [00:53:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3227) Once that is added to the SwarmUI. This new option will be like the segmentation sort order largest to smallest.

- [00:53:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3235) With this way it will in paint your face if there are multiple faces in the generated image.

- [00:54:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3240) It will in paint the maximum size having face which will be likely your face.

- [00:54:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3246) It is not merged into SwarmUI yet. But hopefully you will see it when you are watching this tutorial.

- [00:54:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3251) And you should sort by largest to smallest to get the accurate face.

- [00:54:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3256) Sometimes it may in paint the face of the animal too. So this one is the first face.

- [00:54:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3262) Then 0.7 is the in painting denoise strength. I find that this is working best.

- [00:54:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3268) And 0.5 is the I think something related to the thresholds. And generate. Now this will regenerate the image.

- [00:54:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3276) But also in paint the face. Let's watch it. While I am recording video this becomes even slower.

- [00:54:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3282) As I said if you have a more powerful GPU it will be way faster.

- [00:54:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3286) If you are not running other applications it will be way faster. You can always watch the status here.

- [00:54:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3291) And maybe ComfyUI will add torch compiled precompiled versions on the installation.

- [00:54:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3298) Because now we have Triton packages on Windows. So it may become even faster.

- [00:55:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3303) And now it is starting the face in painting. Yes. We can see that it is loading the YOLO model.

- [00:55:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3309) Okay it started in painting the face. So this has masked the face.

- [00:55:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3314) And now it is in painting the face right now.

- [00:55:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3316) This is the best segmentation model that I have found so far to in paint faces. It works really well.

- [00:55:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3322) You can always use the segment feature of the SwarmUI as well. However I recommend this for in painting faces.

- [00:55:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3329) You should watch my main tutorial to learn more about SwarmUI. And it is getting done. Oh.

- [00:55:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3336) I have 10 images. So I don't need. So interrupt all sessions and here.

- [00:55:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3339) So you see after face in painted it is way better. So how was it before?

- [00:55:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3345) It was like this before. Let's compare. So from this image you see this is the face to this image.

- [00:55:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3351) It looks way way better and it looks very natural. It looks very high quality. This is an amazing image.

- [00:55:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3357) There is no visible error in the image. It looks amazing. It is amazing quality from this to this.

- [00:56:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3365) The face is amazing. The size of the face, shape of the face, anatomy of the face. Everything is amazing.

- [00:56:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3372) With Fine-Tuning everything is amazing.

- [00:56:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3373) And now we are ready to compare the checkpoints and decide which one is the best.

- [00:56:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3379) To do that we will use the tools and grid generator. This is same for LoRA as well.

- [00:56:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3384) Just what we select is changing. Give a name like test1. And first row will be model.

- [00:56:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3391) You can just fill and delete the ones. So. Let's compare all these.

- [00:56:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3396) And in the second one we are going to use prompt.

- [00:56:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3398) So for prompting I have the prompts here with realism prompt.

- [00:56:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3401) To convert this into the SwarmUI format go to the replace, put like this and replace with this one.

- [00:56:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3409) Then let's use like this and it is ready. So this is the separator.

- [00:56:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3414) I also have pre prepared it like this.

- [00:56:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3417) And when you copy paste it you will see that all the prompts are here like this.

- [00:57:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3421) You see they are separated with this one. And then you will just hit generate grid.

- [00:57:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3425) So it is going to generate 113 images right now because I have 1,2,3,4 models and 28 different prompts.

- [00:57:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3434) After that we will compare the results. So the results will be here. You see the grid test1.

- [00:57:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3439) Alright so the grid generation has been completed.

- [00:57:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3442) When you click load grid config you can see the history from here. And you can load it.

- [00:57:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3447) You can name it. You can save it. So let's open the grid generation. And now.

- [00:57:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3452) This is totally personal that you analyze all of the checkpoints and decide which one looking best.

- [00:57:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3460) So you see this is the 20 epoch, this is 30, this is 40, and this is the 70 epoch.

- [00:57:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3466) The 70 epoch is the best one that I have made a lot of grid testing.

- [00:57:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3470) This is 20, 30, 40, and 70 epoch. So this is totally up to you.

- [00:57:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3477) You need to decide whether it became over training, over fit, or under training.

- [00:58:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3482) By the way, if you are aiming stylization, early epochs yields better stylization.

- [00:58:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3489) After collecting sufficient amount of stylized images, you can retrain yourself with stylized

- [00:58:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3497) images and you can obtain way better stylized images.

- [00:58:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3501) So that is what I suggest to do if you want stylization.

- [00:58:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3505) In the Patreon post, I have shared full grids. For example, let's open one of them.

- [00:58:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3511) This is totally up to you. 256 images, batch size 7. Let's go to there.

- [00:58:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3516) There are both realism and stylized epochs.

- [00:58:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3519) Then open with downloading them, download both of them, and open them with any image editor you have.

- [00:58:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3525) Currently, it is opened with Paint.net, which is a free editor.

- [00:58:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3530) So you see it is starting from the epoch 10 to the epoch 100.

- [00:58:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3534) And when we analyze the results, we will see that the epoch 100 is over fit. How do we know?

- [00:59:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3542) Well, in this prompt, look at the background. It includes elements from my training images.

- [00:59:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3548) The quality of the armor is also decreased. How do we know? Let's compare it with the epoch 40.

- [00:59:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3555) So the epoch 40 is around somewhere around here. Yes.

- [00:59:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3558) Okay, when we look at the epoch 40, you can see the armor is much better. The quality is kept.

- [00:59:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3564) The background is lesser over fit. And this is how you can compare. For example, this is the epoch 40.

- [00:59:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3572) When we compare it with the epoch 100, we can see that the quality of the armor degraded a lot.

- [00:59:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3578) The overfit is there. For example, look at this one.

- [00:59:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3581) This is the stylized image supposed to be, but this is a fully realistic image.

- [00:59:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3585) And let's compare it with the epoch 10. So you see the difference. The epoch 40 is here.

- [00:59:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3590) I have chosen the epochs, the best epochs, best checkpoints based on the realism. But if you need stylization

- [00:59:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3598) you can of course. And of course use the earlier checkpoints like this one, you see.

- [01:00:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3603) So as it is the earlier checkpoints, it will become more stylized.

- [01:00:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3608) So this is how you compare the checkpoints and decide which one is best one. Let's open the stylized ones.

- [01:00:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3616) For example, the stylized ones are here. And this is it.

- [01:00:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3620) This is a really great stylized output or this one, you see, or this one.

- [01:00:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3625) By the way, these are not cherry picks. These are the grid generation.

- [01:00:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3629) So, as you generate more images, you will get way better results.

- [01:00:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3634) Okay, for example, this one, this is a really good example.

- [01:00:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3636) It is starting from this image and it will become more like this one, you see, or like this one.

- [01:00:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3644) And the last one, you see, it is totally overfit, so it loses its capability of doing stylized output.

- [01:00:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3651) Or this one, you see, this is almost like real image and then let's go to the 4D epoch,

- [01:00:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3655) you see, much better. So this is how you decide the best one. The best epoch.

- [01:01:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3660) This is totally personal and the rule doesn't change for whether you train style, whether

- [01:01:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3665) you train object, whether you train your pet. So it is totally up to you.

- [01:01:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3670) Whichever you like the most, it will be yours. And you see, from this stylized image, it is totally under-trained.

- [01:01:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3676) It becomes like this. This is pretty decent. And the last one is more like a real image.

- [01:01:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3682) So this is how you compare.

- [01:01:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3684) When you compare the stylization with the LoRA, you will see that the LoRA is very, very inferior.

- [01:01:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3690) For example, let's download the same training, but for LoRA with batch size 7.

- [01:01:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3696) You will see that it can't do any stylization at all compared to the Fine-Tuning.

- [01:01:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3702) For example, let's see, yes, totally realistic, this is also like real.

- [01:01:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3707) Early epochs still better, but it is way, way more overfit.

- [01:01:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3711) You see, from these two, almost becomes like a real image. The stylization is lost very early.

- [01:01:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3717) The Fine-Tuning is lost very early. The Fine-Tuning is way better than the LoRA. You can also compare yourself.

- [01:02:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3722) You will see that the stylization of LoRA is very inferior to the stylization of Fine-Tuning.

- [01:02:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3729) Realism is also like that. Realism is close, but with the stylization, it is way, way more obvious.

- [01:02:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3736) Okay, for example, this is like the test on my own computer.

- [01:02:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3741) You see, so 20 epoch, 30, 40, and 70 epoch. Alright. And if you want to save these models.

- [01:02:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3748) On Hugging Face, just register an account for free and go to the new model.

- [01:02:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3754) Give a model name like test, delete, later. You can make it public or private. Create model.

- [01:02:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3760) Then all you need to do is go to the files and versions and click add file and upload files.

- [01:02:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3767) Then you can drag and drop all the files that you want to save.

- [01:02:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3770) For example, let's save the diffusion models, model, maybe these two. So drag and drop. And click commit changes.

- [01:02:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3778) And they will get hashed and uploaded. So on your computer or on Massed Compute, you can use this strategy.

- [01:03:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3787) But don't worry. I will show you how to use notebook as well.

- [01:03:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3791) Notebook is extremely useful in many cases like downloading repositories or uploading to repositories.

- [01:03:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3798) But on the Windows computer, this is the easiest way to use the upload and download. So let's cancel this.

- [01:03:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3805) So let me also show you how to use the upload and download. Notebook as well.

- [01:03:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3811) The notebook is shared here. Ultra fast upload and download notebook. Let's go to that post.

- [01:03:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3817) For this to work, we need to install Jupyter lab.

- [01:03:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3821) When you go to the Jupyter org, you will see how to install.

- [01:03:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3824) It is so easy once you have python installed. So let's open a cmd. Copy paste it.

- [01:03:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3830) It will install the Jupyter lab. Okay Jupyter lab installed.

- [01:03:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3833) After it is installed, all you need to do is running this command. So let's open it.

- [01:03:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3838) And just run it. It will start the Jupyter lab like this. You see the interface has started.

- [01:04:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3844) This is the interface that we have on the RunPod. So how you can use the notebook?

- [01:04:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3849) Just download the notebook from here. Then go to here and click this upload icon. And upload the notebook.

- [01:04:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3856) You will see the notebook here. Double click and open it. All you need to do is install it.

- [01:04:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3861) So once you install, it will be ready. It will be installed with the python.

- [01:04:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3866) So you see it is getting installed. Then which features we have?

- [01:04:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3870) First of all, you need to set your Hugging face token. Otherwise it will not work.

- [01:04:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3875) And how you gonna get your token? Go to the here. You see there is a link here.

- [01:04:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3878) And generate a token. Let's say delete later. Okay write and create token. And copy.

- [01:04:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3886) After you copy it to token replace and play this cell and your token will be set.

- [01:04:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3891) Now you can use any features here. You see there is very fast new upload function. Let me show you.

- [01:04:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3898) This is for uploading. Let's go to the newest made repository here. Copy its path and paste it here.

- [01:05:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3907) So I prefer to use this cell. You can also use this cell. It is repo type model.

- [01:05:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3912) This is important. The repo type must match. And the folder path. So I want to upload this folder.

- [01:05:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3918) Or maybe let's upload a something smaller which is image directory. So let's go to the SwarmUI outputs.

- [01:05:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3924) And let's upload this folder. So you put it here like this. And then you click play.

- [01:05:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3931) This is a massively optimized upload. You see it is uploading everything like this. It is super fast. Super efficient.

- [01:05:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3939) And it has full resume capability. And it also caches.

- [01:05:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3943) So if you have the same files it will just skip them. And it is getting uploaded.

- [01:05:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3948) Then we can mass download them. I will show that too. So this is extremely useful.

- [01:05:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3954) This way you can upload everything very fast. And download very fast. You see it is uploading everything.

- [01:05:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3959) All the generated images. With super fast speed on my computer. But it doesn't change. It is same on cloud.

- [01:06:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3966) It is same on Massed Compute. Wherever you use.

- [01:06:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3969) Then when you go to files and versions you see it is uploaded as the folder.

- [01:06:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3973) So inside the raw we can see the raw generated images.

- [01:06:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3976) Inside the grid we can see the grid generated images. You see everything is generated. Whatever I have generated.

- [01:06:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3984) And they are now all saved inside here. So how we gonna download.

- [01:06:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3988) For downloading I have a special cell which is here. So let's enter the repository name.

- [01:06:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=3994) And where we want to download. Let's download into here. With a different name. Let's say gg.

- [01:06:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4001) And then play the cell. And it will mass download them. You see it is massive downloading 254 files.

- [01:06:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4009) And when we go to here we will see the gg folder. And inside there we will see the folders.

- [01:06:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4014) And inside here. All the images are getting downloaded. So with this way you can upload your models. Save them.

- [01:07:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4021) And you can download your models very fast or images.

- [01:07:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4024) This is the way of uploading and downloading files to hugging phase with super amazing speed.

- [01:07:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4031) And finally how you can upscale generated images with the FLUX.

- [01:07:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4036) There are upscalers in the SwarmUI or in the other uis. However the very best upscaler is the super.

- [01:07:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4043) So what is super if you don't know. There is a video here.

- [01:07:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4046) That you can learn how to use super. So let's go to this tutorial. Now this is the super tutorial.

- [01:07:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4052) So in here you will see the how to use tutorial. And you will get the download page.

- [01:07:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4058) Let's go to the download page from here. And this is the super app. Let's click here to download.

- [01:07:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4064) I also added the super installer here. So you can also click here to go to the post as well.

- [01:07:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4070) So it is so straightforward to install and use. Let's install it into gdry. Okay.

- [01:07:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4076) And let's just exit all here. It downloads a lot of files. So it may take some time.

- [01:08:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4081) Install that bat file as usual. All of my installers working with the same way.

- [01:08:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4086) So once you know how to use them. You will be able to use all of them.

- [01:08:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4090) So the installation of super is continuing. We have upgraded our downloader of models.

- [01:08:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4097) It is downloading all the models ultra fast and way better if downloading of the models fails for any reason.

- [01:08:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4104) We have Windows resume fix model download. So you can also use this if any error occurs.

- [01:08:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4112) And also you can check out if there are any error messages while installing and tell me

- [01:08:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4118) if there are any. The requirements are so easy. The requirements are posted here.

- [01:08:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4122) By following this tutorial, you can install the requirements. All of my scripts are using the same requirements.

- [01:08:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4128) So these are the latest requirements that works with almost all of the AI applications.

- [01:08:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4134) Okay, so the model download has been completed. You see there is press any key to continue.

- [01:09:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4140) This may be a little bit confusing.

- [01:09:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4142) But when you see that press any key to continue, it means that it has been completed.

- [01:09:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4148) And it was really fast. Just hit a key. Then to start it, click Windows start super app bat file.

- [01:09:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4154) Run anyway. Now when starting, these options are important. The VRAM usage of the super totally depends on your time.

- [01:09:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4164) If you want to do high upscale on a low VRAM machine like 24 GB, 16 GB, or 12, start

- [01:09:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4173) as FP8 option 2. Then start as tiled option 1. Keep models. Start with auto move to CPU option 1.

- [01:09:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4182) You can start as light dim or dark dim. Let's start with a dark dim actually. Okay.

- [01:09:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4188) So these are the most optimal options for VRAM usage.

- [01:09:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4192) If you rent a cloud machine, you can use FP16 and not tiled. It will be way faster.

- [01:10:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4200) It is so easy to use. You can also upscale batch or not. You should watch the tutorial.

- [01:10:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4206) So for example, let's upscale this image. Right click. Save as. Into the downloads. For example. Then click here. Downloads.

- [01:10:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4214) Select the image. You can type the prompt yourself or you can let the LLaVA to apply it. Okay.

- [01:10:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4222) Apply LLaVA. Also we have presets. You see the presets are here. There is default and replicate.

- [01:10:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4229) Or you can save your presets. Default preset is the most loyal to the original image preset. Upscale. Target.

- [01:10:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4238) So currently it is 1 megapixel. Let's make it 2. So it will be 4 megapixels like this.

- [01:10:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4243) Then there is one key that I am going to show you which is face prompt.

- [01:10:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4247) If you apply face prompt. It will upscale face again.

- [01:10:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4252) It is very useful if the face is a distant face.

- [01:10:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4255) If it is like a close shot like this to the face.

- [01:10:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4258) You probably don't need it and how you can enable it. In the face options.

- [01:11:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4263) Enable bg background restoration and face restoration. With this way you can upscale face as well.

- [01:11:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4270) Actually I will also show that. So to be able to show it.

- [01:11:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4273) We need to pick an image that has a distant face.

- [01:11:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4276) Okay for example let's upscale this image instead of that one. With this way.

- [01:11:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4281) We will be able to see the impact of the face upscale. So let's just select the other image.

- [01:11:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4287) This is a very distant face having image. So for a face prompt I will use photo of a man.

- [01:11:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4294) Just this. And the prompt will come from the LLaVA. You can also use the Joy Caption, ChatGPT,

- [01:11:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4300) or any others. This is inline embedded LLaVA. And it is going to use Juggernaut XL version 9.

- [01:11:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4307) But we also download realviz excel. And Juggernaut XL. And Juggernaut 11. There is also Wildcard XL lightning.

- [01:11:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4313) This is for lightning version. So we don't need it right now. Let's use the Juggernaut 11.

- [01:11:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4319) And let's just upscale. So we can follow the VRAM usages from here.

- [01:12:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4325) By default if you have multiple gpus it will load the LLaVA into second gpu.

- [01:12:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4331) And other one will be loaded into your first gpu. So this is how it works.

- [01:12:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4337) It is super amazing from this point of view. So currently it is upscaling with very minimal amount of VRAM.

- [01:12:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4344) The initial load will be slower. But once you have loaded. Once you have made first upscale.

- [01:12:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4351) The consequent upscales will be way faster than the first time. So the upscale has been completed. Let's download it.

- [01:12:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4358) And let's compare it. I will use image sli and neve album. So this is the original.

- [01:12:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4364) And this is the upscaled version. And let's compare. I say that. There is no other upscale.

- [01:12:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4369) It is as loyal as this one to the original image and upscaled this much.

- [01:12:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4376) So from here to this one. And when you look at the face.

- [01:13:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4380) You will see that it is upscaled as well. Face upscaling may break the face sometimes.

- [01:13:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4385) So you may be needed to play with the settings.

- [01:13:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4389) However, from this to let's see again this is a very distant image to this one.

- [01:13:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4395) You see how much details it has added. Also when we open it.

- [01:13:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4399) You can see that now it is HD compared to this image. So it was this image to this image.

- [01:13:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4406) You can see the details. This is the only upscaler that adds real details.

- [01:13:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4412) You see it is way way better.

- [01:13:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4414) Also as I said if you want speed and if you have 24 GB VRAM.

- [01:13:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4418) Start with FP8 and without tiled VAE. This will speed up more than two times.

- [01:13:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4425) And it should work on 24 GB GPUs. Okay.

- [01:13:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4429) Now it is time to start using everything on Massed Compute on cloud.

- [01:13:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4435) So if you don't have a GPU this is the best service that you can use all of these AI tools.

- [01:14:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4442) So how we gonna use on the Massed Compute.

- [01:14:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4444) First download the attached zip file latest zip file here or also in the bottom of the

- [01:14:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4451) post and extract it. So put it anywhere. Extract all. Then. Enter inside the folder.

- [01:14:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4458) The folder of the extracted zip file.

- [01:14:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4461) As I said it is same as the LoRA training but I will show quickly.

- [01:14:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4465) So open the Massed Compute FLUX instructions txt. Please use this link to register the Massed Compute.

- [01:14:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4471) Set up your billing. Add some credits. Then go to the deploy. Now this screen is super important.

- [01:14:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4478) You will see that this is by default selected. This is double GPU and I don't recommend it.

- [01:14:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4483) You don't need it. So we are going to use RTX A6000.

- [01:14:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4486) People are selecting sometimes spot instance and alt config. Both of these options have 24 gigabytes of RAM.

- [01:14:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4494) You see 24 gigabytes and it is insufficient. It is not enough. You will get kill it errors.

- [01:15:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4501) You will get errors. It will not work or the spot instance also 24 gigabytes.

- [01:15:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4505) So if you go with these options, you need to select at least two GPUs.

- [01:15:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4510) However if you select RTX A6000, only single GPU is sufficient.

- [01:15:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4515) Now if you go with these options, you need to select at least two GPUs.

- [01:15:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4516) If you want to take more backups, more checkpoints, the 256 gigabytes is not sufficient.

- [01:15:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4523) Therefore you still need to do two GPUs. However it is up to you.

- [01:15:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4527) You can also use one GPU and backup the generated checkpoints on the hugging phase and delete the previous ones.

- [01:15:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4534) So let's go with one GPU. It is the most optimal one. Creator and SECourses. This is super important.

- [01:15:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4540) Select our image SECourses. You see it is 62 cents per hour. But we have a coupon which is permanent.

- [01:15:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4548) So verify and deploy. There were two machines. So we just rented one of them. They are very famous.

- [01:15:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4555) They are getting very famous and they are adding more machines.

- [01:15:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4559) We have the representatives of the Massed Compute in our channel, in our discord channel.

- [01:16:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4565) So you should join our discord channel and you can message me. Message them. They will reply.

- [01:16:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4571) Hopefully you see these two persons are the representatives of the Massed Compute.

- [01:16:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4575) Massed Compute computers, ship, and the nick b. Okay, it is getting initialized. Just wait patiently.

- [01:16:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4582) And meanwhile, if you don't have the thinlink client yet, go to here. You see the link is here.

- [01:16:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4587) And download according to your operating system. Let me reinstall to show you. Just download it. Open it. Click yes.

- [01:16:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4595) Click next. Accept. Next. Install. That's it. And run thinlink client.

- [01:16:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4600) And in here, you need to set the username to Ubuntu. Actually, you will see the username here.

- [01:16:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4605) That you need to set. Then go to options. Go to the local devices. Uncheck all and just check drivers.

- [01:16:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4612) Click details. And you need to add a folder here. So how are you going to add it? Click add.

- [01:16:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4616) And you need to select a path from your drives. This will be your synchronization folder.

- [01:17:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4622) This is the folder that you generate on your computer. So I have a folder here, mass compute.

- [01:17:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4628) This is the folder I generated. Then make it read and write. Click ok. Click ok.

- [01:17:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4635) That folder will be used for synchronization.

- [01:17:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4638) And what you need to do is copy the downloaded zip file into that folder, which is mass compute

- [01:17:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4644) you see here. Then wait for initialization. It will take few minutes as most. So the initialization has been completed.

- [01:17:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4651) Click here to copy IP address. Paste here. Click the password. Paste here. And connect.

- [01:17:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4657) If you click end existing session, it will close all of the open applications in the remote server.

- [01:17:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4665) It is useful when you have synchronization issues.

- [01:17:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4668) Also, I don't recommend to transfer big files by using the ThinLinc client. It will not work.

- [01:17:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4675) So you can use your Google Drive, OneDrive, or Hugging Face. Any cloud storage devices that you have.

- [01:18:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4682) Okay, so this is the interface of the Massed Compute.

- [01:18:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4686) And this is a special image that we have so many stuff. We have one trainer installed.

- [01:18:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4691) We have forged web ui installed. We have automatic API.

- [01:18:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4695) 11.11 web ui installed we have jupiter lab installed we have pinocchio installed and we have SwarmUI

- [01:18:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4702) installed moreover we have run SwarmUI with cloud player directly so that you can access from your

- [01:18:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4709) computer and use it these are the update buttons you should use them to update the versions of

- [01:18:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4716) these applications before using them however for Kohya currently you should use my installers

- [01:18:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4722) because Kohya is still not in the main branch so how we gonna use it click here or go to the home

- [01:18:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4728) it doesn't matter and in here you will see thin drives these are synchronization you can also use

- [01:18:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4734) the Patreon open the google chrome login your Patreon download from there you can log in

- [01:19:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4740) anything from chrome and use it so in the mass compute i will have the folders on my

- [01:19:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4746) synchronization folder these are you see these are my synchronization folders so i will drag and drop this in

- [01:19:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4752) I'm going to the downloads folder, moreover I need images for training.

- [01:19:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4757) My images are inside the pictures and I will show the 256 images big expression dataset raw file.

- [01:19:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4766) So I will first zip it then I will transfer it. So this is a big file.

- [01:19:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4772) For transferring this I will use the vtransfer or I can use the hugging face as well.

- [01:19:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4779) Maybe I should use hugging face it will be faster.

- [01:19:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4781) Yes this is a big file you see this is 1.22 gigabytes and using the tilnink client to

- [01:19:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4788) transfer it would be very slow.

- [01:19:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4791) So as I have shown I can use the hugging face and I am going to use this folder.

- [01:19:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4799) Currently this is private folder so I need to login to download it but I will make it

- [01:20:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4803) momentarily to transfer my images. You see I am showing you a lot of different stuff at the same time.

- [01:20:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4810) So you can learn everything. So I will just commit changes and upload it here.

- [01:20:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4814) I could also use the Jupyter notebook that I have shown in the Windows tutorial part of this video.

- [01:20:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4820) You really should watch it. But hugging face is super amazing to transfer files very quickly.

- [01:20:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4826) Meanwhile this is getting uploaded let's install the Kohya on the Massed Compute.

- [01:20:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4831) Do not install anything inside this drive it will not work.

- [01:20:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4834) Always copy them to the downloads folder like this and install here. So this is super important.

- [01:20:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4839) Right click and extract here and it will be extracted like this and all you need to

- [01:20:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4845) do is follow the Massed Compute Kohya FLUX instructions.

- [01:20:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4848) So copy this line this is the installation go back to the folder where you have extracted

- [01:20:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4854) click this three dots icon open terminal and paste and hit enter then it will update the

- [01:21:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4861) current installation of Kohya to the latest FLUX branch with accurate libraries and it will start it.

- [01:21:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4869) So this will make our Kohya ready to train.

- [01:21:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4871) I can start training in here within few minutes but it will take some time currently because

- [01:21:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4876) I am showing you more things. Then in the instructions there is also download models.

- [01:21:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4883) We also added a quick download models button here.

- [01:21:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4886) This is for to quickly download models and start using with the SwarmUI.

- [01:21:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4890) But I recommend you to follow this method because I may update it later.

- [01:21:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4895) So go back to the folder open a new terminal.

- [01:21:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4898) You need to be inside this folder wherever you have extracted so the scripts will work.

- [01:21:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4903) Paste and hit enter and it will download the necessary models to the here.

- [01:21:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4908) So I will be able to quickly use the configurations that we have prepared.

- [01:21:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4914) And meanwhile let's also install super application and automatic cropper to the Massed Compute as well.

- [01:22:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4923) You may be wondering what are they. So I have shown this in the Windows tutorial.

- [01:22:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4928) But I will show here too. The super is used for upscaling. It is the link here.

- [01:22:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4934) The tutorial is here. And batch image processing is used to batch prepare images.

- [01:22:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4940) So I am assuming that you might have skipped the Windows tutorial part.

- [01:22:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4944) So let's download them and let's install them in Massed Compute as well.

- [01:22:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4948) Once you understand the logic of my installers you will be able to install everything.

- [01:22:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4953) So let's copy paste to our synchronization folder. Let's go back to them.

- [01:22:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4958) Here we have the folder of the synchronization which is tindrives. Inside home tindrives mass compute.

- [01:22:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4963) We will have the zip files here. And super and ultimate image process. Let's move them to the downloads.

- [01:22:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4970) And let's extract here. Okay extracted. And let's also extract image pre-processed here.

- [01:22:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4977) So to install them we have Massed Compute instructions here. Let's open it. And let's copy.

- [01:23:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4984) I will just install right now. I will use them after the training. Okay let's just install.

- [01:23:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4990) So this will install the super and let's also install this one. We have Massed Compute instructions file.

- [01:23:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=4996) Let's copy this. Okay and let's just start terminal. And install.

- [01:23:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5001) I prepared my scripts for RunPod, Massed Compute, and Windows.

- [01:23:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5006) So you will be able to use everything that I have prepared on your Windows computer or

- [01:23:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5011) on the cloud machines with the cheapest prices. Kohyo is getting updating we are waiting that.

- [01:23:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5016) Also the hugging face upload has been completed so to download this right click and copy link address.

- [01:23:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5022) Then I will change the settings of these two from private to public momentarily.

- [01:23:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5028) Okay after making it public go back to your Massed Compute and paste it.

- [01:23:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5034) Actually it didn't copy sometimes this happens.

- [01:23:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5036) So what you need to do is you need to copy the download link one more time. Copy link address.

- [01:24:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5042) Go back to Massed Compute. Paste. And. It didn't copy. This shouldn't be happening. Let's copy. Let's see.

- [01:24:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5050) Yes it's copied. And paste. Okay. For some reason copy paste is not working. This has never happened before.

- [01:24:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5057) Yeah I will reconnect to the thinlink client. So I closed it. Just copy the password again. And connect.

- [01:24:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5064) Then I will right click and copy link address. You see the kohyo interface has been started automatically.

- [01:24:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5071) So just paste. Okay it doesn't copy for some reason. So I will. Enter there. Manually.

- [01:24:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5077) Normally it should work but for some reason it doesn't work so it is fine. The file was here.

- [01:24:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5083) I will just click download. After that all I need to do is return back to private.

- [01:24:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5089) The download will continue but no one else will be able to download my file.

- [01:24:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5094) So this is the way that I use sometimes. Okay it is downloaded and the kohyo interface loaded.

- [01:24:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5099) Now everything is same as LoRA training. Just the configuration changes.

- [01:25:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5105) Instead of loading into LoRA we will load into DreamBooth tab. So let's load the configuration.

- [01:25:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5111) On Massed Compute I recommend to use batch size 7. So the folder was inside download. Inside DreamBooth.

- [01:25:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5119) Inside kohyo FLUX DreamBooth. And inside DreamBooth tab. You see DreamBooth tab. And in here you see batch size 7.

- [01:25:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5127) This requires minimum 48 gigabytes of VRAM gpu. And you cannot use sampling during loading.

- [01:25:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5135) Otherwise you will get out of VRAM error. Okay the configuration loaded.

- [01:25:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5139) So these files are already downloaded and they are already set for the Massed Compute. We can see them.

- [01:25:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5146) So you don't need to change them. What you need to change is model output name.

- [01:25:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5150) So you can give any name like test1, test2, test3. And the training images.

- [01:25:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5155) This is the most important part we need to set.

- [01:25:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5158) Okay for preparing the images let's first extract the transferred images. You can prepare the images.

- [01:26:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5165) You can prepare them on your computer or you can prepare them in here.

- [01:26:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5168) So I will show how to prepare here. Big expression dataset raw. But this is a raw dataset.

- [01:26:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5174) You need to crop them and you need to make them 1024 pixels.

- [01:26:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5179) For this I will use the ultimate image preprocess.

- [01:26:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5183) So let's open back the Massed Compute instructions and let's use this. So for using this open a new terminal.

- [01:26:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5190) You see I click these three dots and open terminal. Paste it. I have explained this application in details.

- [01:26:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5198) So you should watch that part of the tutorial. It will start as a Gradio Live URL.

- [01:26:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5202) But you can also open the local URL from here if you are using locally.

- [01:26:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5207) Then where was our raw images? The raw images are here. So let's copy its path.

- [01:26:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5213) To copy its path, control L. The control L will select the folder path here. Control C to copy.

- [01:27:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5220) And input folder path. First of all you need to do image cropping. Then. You need to use image resizer.

- [01:27:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5226) Let's make the output as like A1 in the downloads. We can also save the images and everything.

- [01:27:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5233) Let's set it as 8 threads. This is a super optimized application. So this is a person class.

- [01:27:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5240) You can also use other classes if you have. And save as png and just crop images.

- [01:27:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5245) Let's watch the process here. It should be pretty fast. Okay it started.

- [01:27:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5250) You can see it will be done in 5 minutes. 4 minutes. It is getting better over time. 3 minutes.

- [01:27:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5256) You see. It is cropping all the images. So it should be done in few minutes. Under 3 minutes.

- [01:27:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5262) We can also see the VRAM usage. So nvitop. Like this. And it will show the memory usages.

- [01:27:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5269) So this is our GPU. It is using like 5 gigabytes, 6 gigabytes right now.

- [01:27:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5273) And it will be done in 3 minutes. So what is this doing is.

- [01:27:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5277) It is cropping the subject without cropping itself. So the cropping itself.

- [01:28:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5282) Means that it is not cropping the body parts.

- [01:28:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5284) But it is trying to crop zoom in with possible with trying to match the aspect ratio.

- [01:28:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5291) You should watch the Windows part. I explain in details. Okay. The preprocess of the cropping has been ended.

- [01:28:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5297) We can see the files inside here.

- [01:28:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5300) So what we need to do is we need to give the parent folder path downloads A1 into the image

- [01:28:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5306) resizer. I suggest you to use 1024 to 1024. I suggest you to use 1024 to 1024.

- [01:28:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5312) This is a baseline. It is a baseline. Without enabling bucketing.

- [01:28:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5316) Once you have a baseline model, you can enable bucket and compare with training multiple resolutions.

- [01:28:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5321) So let's make the output folder as A2 like this.

- [01:28:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5326) And you can override existing files or you can resize without cropping.

- [01:28:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5331) So therefore it will expand the image with white background. Let's make this also like 12 threads and resize images.

- [01:28:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5338) You see it is very fast. So it is going to take like one minute to resize all the images.

- [01:29:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5342) This is a super optimized application.

- [01:29:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5344) And when we go to the A2, we can see that it is resizing into the exact 1024 pixel resolution.

- [01:29:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5353) We can see the details. Let's see image. Yes, here.

- [01:29:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5357) The process is also displayed on the Gradio interface like this. This is a super advanced Gradio application.

- [01:29:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5363) We also have some other options here, but they are not fully working yet.

- [01:29:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5367) The fully working parts are image cropper and image resizer at the moment. So the resizes have been completed.

- [01:29:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5374) Now we can move forward. So what we need to set is the output directory.

- [01:29:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5380) You see the output directory is by default inside stable SwarmUI. Actually this is SwarmUI. The name shouldn't confuse you.

- [01:29:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5388) This is the latest version of SwarmUI. So it is set into the accurate folder.

- [01:29:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5391) Now we save them inside diffusion models for the full checkpoints. And then we need to use dataset preparation.

- [01:29:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5399) You can also manually prepare. I had explained it. But for your easiness, I will use ohwx and man.

- [01:30:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5406) And if you are training style or other objects, you need to decide the class from accordingly.

- [01:30:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5411) Now this is super important. Many people are skipping this part. We are going to use repeat one.

- [01:30:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5417) Multiple repeats only useful when you are using regularization images.

- [01:30:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5421) Since we are not using regularization images with the FLUX, it is useless. So make the repeating one.

- [01:30:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5427) Put the training images folder which is here. So control L. Copy the one. Put the path. Paste it here.

- [01:30:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5433) You can also use pic folder. And destination. When you set the destination, it will also overwrite the output model.

- [01:30:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5441) So where I am going to put the destinations, I will copy this and put the destination here.

- [01:30:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5445) And prepare training data. Once you hit prepare training data, you should watch here.

- [01:30:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5450) Currently it shows a warning like this but it is not important.

- [01:30:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5454) You can verify whether they are put or not. So go to the home. Go to the apps. Inside SwarmUI.

- [01:31:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5461) SwarmUI. UI. Inside Models. Inside diffusion models. And images. You see, it is properly formatted. Repeating one or hwxman.

- [01:31:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5471) And images are here. So now it will save the models inside this folder.

- [01:31:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5476) Because it changed the output folder here. But not changed it yet. Why?

- [01:31:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5481) Because I need to copy info to respective fields. Now it is changed like this.

- [01:31:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5486) I also don't recommend to save logs. It may cause errors it had in the past.

- [01:31:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5490) And what else you need to change?

- [01:31:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5492) Only you need to change the number of epochs that you want to train.

- [01:31:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5497) Now in this article, I have in details explained how many epochs I have trained.

- [01:31:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5503) 15 images, 256 images, and which epochs I have found best.

- [01:31:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5508) So according to the number of images you have, you can decide.

- [01:31:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5512) Since this is 256 images, 100 epochs is a good number to train.

- [01:31:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5517) And I can save only certain number of checkpoints. Why?

- [01:32:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5522) Because my hard drive is limited and since I have also installed the super and other

- [01:32:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5528) apps, when I click properties, it will show how much free space I have.

- [01:32:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5532) I have only got 28.5 GB free space right now. So I am out of space.

- [01:32:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5539) So I need to rent multiple GPUs or what I can do is, I can delete some of the apps here

- [01:32:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5547) to open some space which once I can delete. For example, I can enter inside stable diffusion and inside models.

- [01:32:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5554) You will see that there are some models already downloaded.

- [01:32:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5557) If you are not going to use them, you can select all of them and delete all of them.

- [01:32:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5562) Actually you can directly delete all the stable diffusion web UI. It will open some space.

- [01:32:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5567) I am deleting with shift delete. So it is deleting entirely. You see it is deleting everything.

- [01:32:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5573) You can also delete the one trainer if you are not going to use the one trainer.

- [01:32:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5577) And open more space in your virtual machine. Let's see if we can delete anything else.

- [01:33:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5583) We have the files, images. So we don't need these images anymore since we have processed them, copied them.

- [01:33:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5591) So let's just delete all these two to open more space.

- [01:33:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5594) And inside super, there are multiple models that are downloaded inside checkpoints. You see Juggernaut 11, Juggernaut XL, RealVisXL.

- [01:33:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5604) Since I am going to show Juggernaut 11.

- [01:33:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5606) I am going to delete the other ones as well to open more space.

- [01:33:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5610) Let's go back to apps and let's delete the one trainer too to open more space.

- [01:33:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5615) And then we will calculate the space we have. So let's go back to downloads. Can we delete anything else?

- [01:33:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5621) No. Let's right click and properties. So we have 90 gigabytes of free space. The super is taking huge space.

- [01:33:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5629) If you install super you really should get at least two GPUs. Let me show you.

- [01:33:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5634) The super is taking like 60 gigabytes.

- [01:33:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5636) Right now with all the models it has, let's look at the checkpoints one more time. Yeah.

- [01:34:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5642) These are all necessary. Okay. Let's see how much space we have.

- [01:34:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5646) So now we have 93 gigabytes of space and we deleted everything that we can delete inside apps.

- [01:34:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5654) We can also delete stable diffusion forge web UI if you are not going to use it.

- [01:34:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5659) I'm going to use SwarmUI so I am also going to delete it too. These are all opening spaces.

- [01:34:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5664) So you see we have so many apps. Let's go back. Let's see how many apps installed in this image.

- [01:34:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5668) Therefore it is very easy to use. Start using it but it is using space.

- [01:34:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5672) For more space you need to rent a machine with multiple GPUs. You can also rent powerful GPUs like L40s.

- [01:34:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5681) The L40s is really really super GPU that you can use and it has 625 gigabytes of space.

- [01:34:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5688) Much more space. So this is a very recommended GPU with batch size seven.

- [01:34:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5693) It will train at least two times faster. Faster than the A6000.

- [01:34:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5698) Okay I think it is also deleted let's see how much space we have. We have 100 gigabytes.

- [01:35:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5703) Now how you are going to calculate how many checkpoints you can have.

- [01:35:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5707) You can delete the early checkpoints by following the training or upload them to the hugging phase then delete.

- [01:35:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5713) But we can have four checkpoints because each checkpoint will be 24 gigabytes.

- [01:35:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5718) So how we can calculate 100 epochs save every 25 epoch and it will save four checkpoints.

- [01:35:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5725) And that's it we are ready you should save the configuration because if something happens

- [01:35:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5730) you need to send me configuration so I can compare.

- [01:35:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5733) Remember the configuration is uploaded into dream boot up not into LoRA.

- [01:35:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5737) You could also use the batch size one which was you could use the 48 gigabytes batch size one.

- [01:35:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5743) If you want batch size one yields slightly better quality.

- [01:35:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5747) But this is super fast and start training you don't need to do anything else and you

- [01:35:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5752) should close the other applications. So that they won't use your VRAM. So I'm closing everything.

- [01:35:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5759) I will just let the kohya run. Okay let's look at our VRAM yes now it is going to start.

- [01:36:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5766) So first of all it is caching. Okay so the training has started with batch size seven 256 images.

- [01:36:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5774) It is going to take like 30 hours for 100 epochs but when you look at the Patreon post

- [01:36:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5783) that I have prepared. You will see that I have found best epoch is around 40 epochs.

- [01:36:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5788) So the duration was much much lesser. You can see the durations for 15 images.

- [01:36:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5794) It takes around 2 hours 35 minutes with batch size seven. So around $1 cost.

- [01:36:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5801) So you need to calculate the number of images that you should use and calculate the price that you need.

- [01:36:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5807) The most it takes was around $10. Because with batch size one. It takes a lot of time.

- [01:36:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5814) With 256 images but these are the best prices for the best quality.

- [01:36:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5819) Believe me none of the online platforms will give you such quality.

- [01:37:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5824) So you need to train yourself your model also I don't know any platform that supports fine

- [01:37:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5829) tuning and the difference between Fine-Tuning and the LoRA training quality is like day and night.

- [01:37:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5836) There is a huge quality difference I have done all of these trainings they are all provided in this folder.

- [01:37:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5844) Of course you cannot download them this is a pro basis but I have done everything now

- [01:37:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5849) I will download them and show them on the Massed Compute how to use it.

- [01:37:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5853) Okay so I have downloaded four models and they are completed now I will move them into the accurate folder.

- [01:37:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5860) So let's just select all of them with shift key cut move to the home apps inside stable

- [01:37:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5867) SwarmUI inside models inside diffusion models. So they would be.

- [01:37:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5873) So we already saved inside this folder let's put there so we are emulating what would be

- [01:38:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5880) the result of the training then how we are going to start the stable SwarmUI before

- [01:38:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5884) starting it I will show one another thing this is super important to do I suggested

- [01:38:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5891) go to the downloads and inside Kohya FLUX dream boot you will see test prompts which

- [01:38:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5897) I am going to use and inside here there is how to download YOLO face this is yielding

- [01:38:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5902) way better face in painting so you should do this so copy this line open a chrome and

- [01:38:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5909) paste and it will download the model it is around 50 megabytes so cut it go to the home

- [01:38:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5915) apps stable SwarmUI models and generate a folder here its name will be like this YOLO

- [01:38:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5922) version 8 don't forget that this is the name YOLO version 8 and paste it there the txt

- [01:38:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5928) file also saying you that and now we are ready. So.

- [01:38:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5932) So let's move to the desktop control alt D it will show the desktop first of all update

- [01:38:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5938) your SwarmUI so double click and run this this will update it to the latest version

- [01:39:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5942) you see it is getting updated and it is done it has started however I cannot use this directly

- [01:39:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5948) in my computer to use it directly in my computer just close this and let's see if anything

- [01:39:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5954) else is open let's also close this and use the run cloudflare stable SwarmUI link this

- [01:39:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5962) will start it in cloudflare so the link will be around here in a moment yes open it from

- [01:39:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5968) here right click open link now I can use this in my computer it will be way faster and easier

- [01:39:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5974) just return back to your computer and now I can use SwarmUI in my computer but it will

- [01:39:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5981) run on the Massed Compute it is amazing so first of all let's generate one image and

- [01:39:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5987) then let's use the grid generator to compare models and find the model and let's see how

- [01:39:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5992) it is using it and this is the best one so when I go to the models and refresh I will

- [01:39:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=5995) see all the models are here let's select one of them like this and since this is FLUX model

- [01:40:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6001) I will use 30 steps and cfg scale will be one don't forget that display advanced options

- [01:40:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6007) and in here in the sampling I use ip and dm this is the best sampler that I find for the

- [01:40:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6014) FLUX then FLUX guidance scale will be four and in the advanced sampling I will use the

- [01:40:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6022) I will use the default 16-bit because my GPU has 48 GB so this is the best quality.

- [01:40:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6029) Also in here you can manually select the models currently they are not there.

- [01:40:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6034) To have them there I need to download them or I can move the files which I am going to

- [01:40:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6040) do. So this VAE file will be right click and move to. Okay follow me closely.

- [01:40:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6046) You can do this after the training has been completed.

- [01:40:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6049) Move into the Ubuntu, move into apps, move into SwarmUI, move into models, move into VAE. Select.

- [01:40:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6057) Then let's move to T5XXL.

- [01:40:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6059) Actually T5XXL and clip large moves into the same folder so select both of them right click.

- [01:41:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6066) Then click move to. Okay let's go to the Ubuntu, apps, stable SwarmUI, models, clip, and select. So that's it.

- [01:41:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6076) We are ready. Then I need to refresh the software. Select this page. It will keep the already set settings.

- [01:41:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6082) You see. And in the advanced model select VAE like this. Select the clip large from here.

- [01:41:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6090) And select the T5XXL from here. You see. And we are done.

- [01:41:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6095) So as for prompting in the downloaded file you will see that we have test prompts.

- [01:41:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6102) So let's use one of the prompts from here like this one. Okay.

- [01:41:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6106) And this will also use the face in painting so we will have tested everything is working or not.

- [01:41:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6112) Let's generate. Then go to the server in the logs in the debug. You can see what is happening.

- [01:41:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6119) Okay you see it is downloading the T5XXL even though I have selected it.

- [01:42:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6124) This is a bug that I am going to report. It shouldn't download it because I have selected it.

- [01:42:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6129) So how can I fix this issue? You need to copy this. Copy this like this.

- [01:42:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6134) Then you need to close this. We will restart it.

- [01:42:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6139) Go back to the home, apps, SwarmUI, models and in here go to the clip.

- [01:42:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6145) And we are going to rename this. You see it was downloading so let's just delete it.

- [01:42:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6150) We don't need it. And let's just rename like this.

- [01:42:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6153) So now it will be using the FP16 version of the T5.

- [01:42:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6157) This is certainly a bug that I am going to report. Okay. It is loading. And loaded.

- [01:42:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6163) Now I have a new URL. I know that this is new.

- [01:42:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6166) It is not very convenient until it is getting fixed. This is the way. Now I need to load again.

- [01:42:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6172) And I need to reset the parameters unfortunately. But you know the parameters setup. Select the model from here.

- [01:43:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6180) Don't forget it. It is inside the models. And sampling will be iPNDM.

- [01:43:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6185) You could also use the FP8 version but I don't like it. So this is the 4.

- [01:43:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6190) And inside here, advanced models, VAE. Now you don't need to even set. Because they are all set automatically.

- [01:43:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6198) We just need to set the preferred D-type. And there is one more thing. Regional prompting.

- [01:43:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6203) There will be sort faces by the largest to smallest. It is not available here yet.

- [01:43:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6210) It will be hopefully available. This new option will be like the segmentation sort order. Largest to smallest.

- [01:43:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6217) With this way, it will inpaint your face.

- [01:43:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6220) If there are multiple faces in the generated image, it will inpaint the maximum.

- [01:43:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6225) Size having face, which will be likely your face.

- [01:43:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6229) It is not merged into SwarmUI yet, but hopefully you will see it when you are watching this tutorial.

- [01:43:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6234) And we are all set. So let's copy the prompt again and paste and generate.

- [01:44:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6240) And let's go back to server, logs, debug. And it will start. So you can follow everything with debug option.

- [01:44:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6248) It says that clip missing. We have the clip there actually. Let's see. Okay. Let's start generation.

- [01:44:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6256) Moreover, in the backends, you can add multiple backends here if you have multiple GPUs.

- [01:44:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6261) And you can edit and add dash dash fast on RTX 4000 series L40s.

- [01:44:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6268) It will speed up the generation significantly. But doesn't work on A6000 or on RTX 3000 series.

- [01:44:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6276) So let's go back to logs. And yes, it has generated with an amazing speed like this.

- [01:44:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6281) And let's see the generation. Now it is inpainting the face right now. So let's go to the image history.

- [01:44:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6287) You can see this was the original generation. And this is the face inpainting. Original generation and face inpainting.

- [01:44:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6294) Face inpainting is super important in distance shots. And yes, you see this is the image generated.

- [01:45:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6301) It's the perfect quality. Now we can use the tools. Grid generator. In here, give a name like test.

- [01:45:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6308) I have shown everything on Windows part. But let's show quickly. Fill. Select the downloaded models. So this one.

- [01:45:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6315) This will be the models. And select the prompt. And in here, I have prompts already formatted for the grid.

- [01:45:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6323) Or you can manually format too. Let's open this one. This is my formatted. So what it is?

- [01:45:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6328) It is just separating the prompts with these two. You see? This one. These characters.

- [01:45:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6334) And it is how it is working. Then let's just hit generate grid. And it will generate a grid.

- [01:45:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6339) Then you will use grid to make a comparison. And find the best image.

- [01:45:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6345) This is the main server where I make my experimentation. So you see it has 8 GPUs.

- [01:45:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6355) And you can see that it has that regional prompting sorting that I have mentioned. You see? Segmentation sort order.

- [01:46:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6362) So in here, I have all the test results inside the tools grid generator.

- [01:46:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6368) So I will load one of the grid and show you how I am comparing the checkpoints.

- [01:46:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6373) For example, let's open 256 images, batch size 1 realism. And let's load the grid configuration.

- [01:46:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6381) You see these models doesn't exist anymore. But I have the grid configuration. Let's open it.

- [01:46:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6386) And all the images will appear here. So this is the 20 checkpoint, 40 checkpoint.

- [01:46:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6392) You see 60, 70, 80, and 100, 120, 140, 100. And the final one. When you have batch size 7.

- [01:46:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6402) And when you have 15 images. It will not be exactly as same. However it will do exact same steps.

- [01:46:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6409) So the epoch numbers may be different. But it is okay. Let's open 256 images grid. Let's click load.

- [01:46:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6416) And 256. Batch size 7 realism 2. Okay let's open this one. And let's go to here.

- [01:47:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6423) Okay this is the 10 epoch. You see the 10 epoch resemblance is not good. 20 epoch. 30 epoch. 40.

- [01:47:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6430) 50. 60. 70. And as it goes to the end it will become way more over trained.

- [01:47:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6437) You see I find that 40 epoch is the best. You see this is the 40 epoch. 40. 40 epoch.

- [01:47:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6444) And as I go to the end it will become lesser generalized model. So this is the 100 epoch.

- [01:47:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6451) And let's compare it with the 40.

- [01:47:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6453) The 40 epoch has a way better armor as you are seeing right now.

- [01:47:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6456) But the last one is very over trained. This is totally up to you. To how to assemble. It says.

- [01:47:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6462) So you need to decide the best checkpoint. So you see if it is a stylized prompt like this.

- [01:47:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6468) This is the 10 epoch. It is the most stylized one. However as I go to the further epochs.

- [01:47:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6475) So more training. It will become more realistic. So this is the 40 epoch. And this is 50. 60.

- [01:48:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6481) And the last one. So you see the last image became exactly as totally realistic. This is how you decide.

- [01:48:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6488) For example this is also another stylized one. The first ones are very realistic.

- [01:48:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6492) This one is very stylized as you are seeing. Or this one.

- [01:48:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6495) And as I go it will become like this. So it is up to you to decide.

- [01:48:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6499) Also in here you will see all of the grid comparisons that I have.

- [01:48:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6504) That way you can look each comparison grid files and see how they have performed.

- [01:48:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6511) For example let's look at the 256 images base size 7 Fine-Tuning style epoch. Go to this link.

- [01:48:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6518) Click to download. And then open it. Then you can see the results. Every checkpoint.

- [01:48:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6525) So this is the 10 checkpoint. 10 epoch. And as I go you see the 30 epoch became very similar.

- [01:48:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6531) And 40 is the best one I like. It may change at every test.

- [01:48:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6536) So you see how it is performing. The last epoch becomes very very realistic compared to early epochs.

- [01:49:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6543) So you can also look these results and see each one impact. Moreover inside the file you will see that.

- [01:49:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6550) There is different config training logs. So these are the entire training logs.

- [01:49:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6556) For example let's look at the 256 images base size 7 Fine-Tuning logs.

- [01:49:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6562) You will see that it started this date. And the entire training logs are here. The speed.

- [01:49:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6568) The time it take. The best epochs I have found. I have written everything in this article.

- [01:49:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6575) So you need to read this post from top to bottom very carefully. So this is how.

- [01:49:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6580) How we decide the best checkpoint. Now what about how we are going to use the upscaler. Okay.

- [01:49:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6588) I recommend to use super upscaler. Because it is the best. You can also use the upscaler of the SwarmUI.

- [01:49:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6595) Like here more upscale 2x or other upscalers. However nothing will yield as good as the super upscaler.

- [01:50:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6603) So to run the super upscaler. I will close this to free up the VRAM. And now my VRAM.

- [01:50:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6610) Is empty. Then I will go to the downloads. And super. And the instructions file. Massed Compute instructions.

- [01:50:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6620) And I will copy this. And start a terminal. Open terminal. Paste.

- [01:50:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6625) Now which options you should use on the Massed Compute. Since this is a 48 gigabyte GPU.

- [01:50:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6631) I will show you the best options. Up to a certain size. Because the super depends on your target resolution.

- [01:50:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6638) If it is too big. It will give you out of VRAM error.

- [01:50:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6641) But up to like 4 megapixel 6 megapixel. This config should work very well. And it will work very fast.

- [01:50:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6648) So we are going to use FP8. Because there is not much difference. And it will reduce the VRAM usage.

- [01:50:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6655) Then I am going to use without tiled VAE. Let me show you. Without tiled VAE.

- [01:51:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6661) This will speed up the generation significantly. Option 1. Then you can select this option 1 here too.

- [01:51:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6668) And start with. Light dim. So it will start to super.

- [01:51:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6671) And I will be able to use it on both inside the Massed Compute. And also in my computer.

- [01:51:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6676) But it will run on the Massed Compute. You see the current VRAM is like 33 megabytes.

- [01:51:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6682) And it is starting a Gradio live share. Now I will open it in my computer.

- [01:51:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6687) So I will show as an example as I have shown in the early part of the tutorial.

- [01:51:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6693) Okay click here. And select image. For example. I am going to use this image.

- [01:51:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6697) Because this has a very small face. And I will show you the face upscale feature as well.

- [01:51:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6704) So let's make the target upscale 2x. I have a tutorial for this.

- [01:51:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6707) So you should watch the super tutorial to learn it you see. Super upscale tutorial.

- [01:51:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6712) And I will use the lava captioning. You can also type your prompt here.

- [01:51:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6716) And for face I will just use photo of a man. Like this. We have presets like default and replicate.

- [01:52:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6723) I am going to use default. Because default is the most loyal to the original.

- [01:52:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6727) I am going to use default. I will use the original image. And Juggernaut 11 is selected.

- [01:52:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6730) There were other models we had deleted. There is also you see STXL lightning 2 with STXL lightning model.

- [01:52:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6737) And there is face option. So I'm going to enable background restoration and face restoration.

- [01:52:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6742) It will upscale face separately and paste it back. It may not work in some of the options.

- [01:52:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6748) But it should work. And then we are ready. Click process single. The first time loading will be slow.

- [01:52:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6754) But then consequent ones will be very fast.

- [01:52:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6757) So, the upscale has been completed, this did twice upscale, first upscaled the entire image,

- [01:52:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6772) then upscaled the face and pasted it back, let's download it.

- [01:52:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6778) So you click here to download, then let's go to the image sli to compare, original image

- [01:53:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6783) and select the upscaled image and let's compare.

- [01:53:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6786) So, you can see the humongous details, improvements in the image, you see, from this to this,

- [01:53:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6795) and with amazing loyal to the image.

- [01:53:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6798) There is no such other upscaler in the world right now that can upscale this good.

- [01:53:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6804) And this has a very distant face, so it is like this.

- [01:53:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6809) You can also try other base models if you don't like, you can change the face prompt to improve it.

- [01:53:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6815) However, let me show you this upscale, so this image was this, and now it is this.

- [01:53:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6822) So from this to this, this is a humongous details, humongous details improvement, none

- [01:53:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6828) of the other upscalers that you will use will yield this kind of performance.

- [01:53:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6834) We also have a comparison slider like this on the super.

- [01:53:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6838) So what you can do, you can pick the best images that you have generated and use the batch option.

- [01:54:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6843) It automatically also captions them like this, so you don't need to worry about that.

- [01:54:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6850) This is a very advanced super application, watch the tutorial to learn more.

- [01:54:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6854) So the second upscale will be way faster, let's try it.

- [01:54:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6858) And it immediately starts upscaling, you see upscaling the face, then it will upscale the

- [01:54:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6863) background, then it will merge them.

- [01:54:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6866) It is also really fast, you see the speed, this is an amazing speed, this is the face upscaling.

- [01:54:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6871) You see it in the real time right now. Since we are not using tiling, it is really fast.

- [01:54:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6876) And if you have a RTX 4090, if you use other models, it will be really really fast, depending

- [01:54:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6883) of the GPU that you pick, that you have.

- [01:54:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6887) This is RTX A6000, this is a super cheap GPU, it is only 31 cents per hour.

- [01:54:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6892) But it is just amazing, amazingly fast for many of the tasks that you can do.

- [01:54:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6898) So how you can back up the generated models, images, inside messages?

- [01:55:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6903) Well, the best way to do it is to download the Massed Compute, to use later or download

- [01:55:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6906) to your computer. The best way is uploading them to the Hugging Face.

- [01:55:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6910) And for that task, I have an amazing JupyterLab notebook.

- [01:55:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6915) The JupyterLab Hugging Face notebook is here, let's go to there.

- [01:55:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6919) It also has a tutorial video, you can watch it.

- [01:55:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6922) Let's download the latest notebook from the attachments here, put it into your method compute synchronization folder like this.

- [01:55:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6930) And in the Massed Compute. Go to the. And in here, run JupyterLab. You see run JupyterLab, double click it.

- [01:55:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6937) This is the interface that we have on RunPod.

- [01:55:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6940) So what we are going to do here, go to the thin drives, mass compute.

- [01:55:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6945) You can also move the file to the downloads as usual. And double click the Hugging Face download.

- [01:55:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6951) So you see, this is the file, how we are going to use it.

- [01:55:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6954) First install the requirements with this cell, it will install the requirements.

- [01:55:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6958) Then go to the Hugging Face and register a free account.

- [01:56:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6962) After you register the account and verified your email, go to the settings.

- [01:56:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6966) In the settings, go to the access token. You see, there are a lot of tokens here.

- [01:56:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6971) I will generate a new token, create new token, write permission like this, create token and copy this token.

- [01:56:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6979) This is super important. Then you need to set token. You see it has been installed, replaced with your token.

- [01:56:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6985) Okay, it is copy pasted accurately. Play one time. Now you see it is login successful. So we are done.

- [01:56:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6992) We have everything. Now I can use the upload, download, everything I want. So let's make a demo upload.

- [01:56:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=6999) Go to the here, you see click here, click new model. Let's say temp delete 2.

- [01:56:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7005) You can make it public or private. Let's make it private and create model. Then copy the path.

- [01:56:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7011) So this is our Hugging Face repository path. Replace your repo ID with it.

- [01:56:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7016) You see like this and it is model. Then set the upload folder.

- [01:57:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7021) So whichever the folder that you want to. Let's go to the home, apps, SwarmUI, model, diffusion models.

- [01:57:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7028) So you can upload entire model like this. It will upload all the models, save it here.

- [01:57:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7034) But it will take some time. However, we can make as an example. So let's upload the entire diffusion models.

- [01:57:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7042) Control L and control C. Then I am going to change this path, delete like this. Paste it. And yes.

- [01:57:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7051) This will upload all the models and my training images and play.

- [01:57:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7056) This is going to do a huge speed upload. You will be amazed by the speed it has.

- [01:57:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7063) It is also uploading the cached files, image files, everything. This is the ultimate speed upload to the Hugging Face.

- [01:57:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7071) Let's see how much time it will take. So it has already uploaded 768 images and their cache files.

- [01:57:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7079) And now uploading. The big model files.

- [01:58:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7083) You can see that here it is going to upload total 97 gigabytes of files. It will be really fast.

- [01:58:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7090) So all of the models have been uploaded in few minutes as you are seeing right now.

- [01:58:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7095) They are permanently saved.

- [01:58:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7097) And now I can click and download them to my computer to use anywhere else I want with

- [01:58:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7104) the same way. So let me show you how I can download them again. So let's copy this. And.

- [01:58:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7111) Stop everything. You see. Already uploaded. Completed. This is super fast. Clear cell output of all cells.

- [01:58:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7117) To download a repository back again with a very fast download. I have a download cell as well.

- [01:58:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7124) So the fastest download is this one. Copy paste your repo id here. And where you want to download. Okay.

- [01:58:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7131) For example let's download here.

- [01:58:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7132) By the way I need to delete these ones because there is not enough space right now.

- [01:58:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7138) So let's also download here. So what I am going to do is I will copy this path.

- [01:59:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7143) I will delete everything like this. They will get deleted. Yes.

- [01:59:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7148) And then I will just change this path to that path. It doesn't matter.

- [01:59:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7153) You can use this on your computer or any other platform. Let's just play. Now it will download everything back.

- [01:59:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7160) You see it already started downloading. It is a super fast download. We can see the files are getting downloaded.

- [01:59:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7166) Yes. As you are seeing right now. And it will download the models as well. This is just super fast.

- [01:59:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7172) The speed of the Massed Compute is like 10 times better than the RunPod.

- [01:59:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7176) Even if you get the very fast ports on RunPod they are really really slow compared to massive compute.

- [01:59:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7182) This is one of the best advantages of the Massed Compute.

- [01:59:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7186) When it is downloading big files you may not see progress like this as I cannot see right now.

- [01:59:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7192) However don't worry. Just wait until download has been completed. And it will be completed hopefully in a short time.

- [02:00:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7201) You will see that they are getting downloaded. Unfortunately currently it doesn't show the download status in the JupyterLab interface.

- [02:00:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7209) But I think the Hugging Face team will solve it as well.

- [02:00:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7213) Just wait until you see the download completed message.

- [02:00:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7217) It is still downloading and during the download you will see that kernel status busy so until

- [02:00:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7224) it becomes non-busy it means that it is working. You see here.

- [02:00:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7229) So you see in the end that is download completed and the kernel status is idle.

- [02:00:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7236) So in like 10 minutes it downloaded over 100 gigabytes and all the files are in the folder.

- [02:00:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7244) So this is how you can upload and download models and save them on your Hugging Face account to your.

- [02:00:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7251) Then download again on your computer and so on.

- [02:00:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7254) And final thing about the Massed Compute is that until you terminate your pod it will keep using your credit.

- [02:01:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7264) So therefore you have to use this delete your instance and terminate your pod.

- [02:01:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7272) If you use this stop it will not stop spending your credits. Therefore do not forget that.

- [02:01:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7278) Back up everything because everything will be completely deleted then after you have saved everything.

- [02:01:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7284) Everything on like your Google Drive or on Hugging Face wherever it is or on your computer.

- [02:01:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7290) Click this icon it will ask you to delete like this and delete it.

- [02:01:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7295) After that it will not use any of your credits this is super important do not forget that.

- [02:01:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7301) All right it is time to record the part of the RunPod how to do Fine-Tuning of FLUX

- [02:01:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7307) models with Kohya GUI on RunPod. As you have seen in the previous parts. Massed Compute.

- [02:01:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7312) Actually the best cloud service to do the Fine-Tuning but if you have RunPod credits

- [02:01:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7318) or if you want permanent storage RunPod is the choice.

- [02:02:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7322) So let's download the zip file from here or from the attachments.

- [02:02:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7325) Enter inside the zip file and you will see RunPod install instructions txt. Open it. There is a registration link.

- [02:02:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7333) Please use that. And there is RunPod permanent network storage tutorial.

- [02:02:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7337) So you can watch this tutorial to learn how to use network permanent storage. After you have done that.

- [02:02:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7342) After you sign up and logged in and set up your billing address and put your credits.

- [02:02:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7349) It is time to start your pod. Go to the pods and in here we will use deploy.

- [02:02:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7354) So recently RunPod community cloud is becoming worse and worse. Therefore I recommend to use secure cloud.

- [02:02:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7361) It is expensive but it will work faster.

- [02:02:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7364) I find that us texas 3 is the best one but you can also try other ones.

- [02:02:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7369) I will make this tutorial on l40s. This is a very powerful software. It has a very powerful GPU.

- [02:02:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7373) It has 48 gigabytes of VRAM and it is like power of RTX 4090.

- [02:02:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7379) So first of all click change template here. We are going to use pytorch template 2.1.

- [02:03:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7384) Yes we are installing other versions of pytorch and cuda but this template is working. Don't worry about it.

- [02:03:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7391) Use this template. If any other template becomes necessary you will see the selection template changed in

- [02:03:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7399) the RunPod install instructions txt file. So always follow the instructions when you are watching my tutorials.

- [02:03:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7406) Then click edit template. I am also going to show how to use the find unit models on SwarmUI.

- [02:03:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7413) Therefore we are going to add 7801 port this is for the SwarmUI.

- [02:03:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7418) And I am going to make the persistent disk 400 gigabytes. Then save overrides and we are ready.

- [02:03:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7425) Then click deploy on demand. After that click the my pods or your pods will be here.

- [02:03:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7430) And the machine will start. We got a pretty weak machine if you ask my opinion.

- [02:03:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7436) So you can rent multiple machines and use the best one. For example let's try another machine from here.

- [02:04:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7443) And let's make the disk like this. And the ram memory ok there is not a ram memory.

- [02:04:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7448) Ok let's try this one. To see if we will get a better machine.

- [02:04:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7452) Unfortunately the machines of the RunPod is getting worse and worse every day. Ok let's deploy and try.

- [02:04:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7459) Ok both looks like identical. No. You see the bottom one has a better upload and download speed.

- [02:04:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7465) So let's use that one and let's delete this one.

- [02:04:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7468) Unfortunately this is one of the worst sides of the RunPod.

- [02:04:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7472) You don't get a very good upload or download speed.

- [02:04:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7474) Especially the hard drive speed is very slow because this is shared with a lot of users.

- [02:04:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7479) Not with only you. Once you see the connect button appeared click connect. Click the jupyterlab interface.

- [02:04:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7485) Then click this icon to upload downloaded zip file which is here. You will see that there is uploading status.

- [02:04:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7491) In the bottom you can upload a lot of files from here. And right click and extract archive.

- [02:04:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7497) So we will have all the files that we need on the RunPod interface. Then click refresh.

- [02:05:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7501) Yes it is extracted. Open the RunPod install instructions.txt file. And run the first part.

- [02:05:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7508) This will start installing the Kohya on RunPod. Meanwhile we should also download the models.

- [02:05:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7514) So downloading of models are here. These are for training. So open a new terminal. And see.

- [02:05:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7520) If my browser is problematic. Yes. Okay. Open and hit enter. So while installing we will also download the models.

- [02:05:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7529) Let's look at the speed. The speed is around 75 megabytes per second.

- [02:05:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7533) This is very slow compared to the Massed Compute. I can even reach there like 1 gigabyte per second.

- [02:05:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7540) So this is very slow. And meanwhile we can also install SwarmUI.

- [02:05:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7544) It is totally up to you with which order you do these things. But not to get you confused.

- [02:05:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7550) I will not do them right now. However I will upload my training images.

- [02:05:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7555) So they will be ready while these are getting installed.

- [02:05:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7558) In this tutorial as an example I am going to use my 256 expression dataset. This one.

- [02:06:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7565) I have explained it in details in the Windows tutorial part. So you should watch it.

- [02:06:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7570) This is 1.22 gigabytes in size. So therefore uploading this from the interface will be slow. What you can do?

- [02:06:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7578) You can use runpodctl. The link is here. Just click to download it.

- [02:06:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7583) This is an exe from the official runpodctl.

- [02:06:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7586) Then you need to move this into a folder like runpodctl folder in the C drive. Like here. You see.

- [02:06:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7594) Put it there. Then you should rename it to runpodctl. I had it but I will just rename.

- [02:06:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7599) Then you need to add this to your system environment path. So you see we opened the system environment path.

- [02:06:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7605) Environment variables path. It was here. But I will just rename it.

- [02:06:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7608) But I will just delete it to show you. Click new. And click browse. Then go to this pc.

- [02:06:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7615) It was inside the runpodctl folder here. Like this. Then click ok. And ok. After that when you type runpodctl.

- [02:07:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7623) Like this. You should see it. Yes. It is ready. So how I am going to upload by using runpodctl.

- [02:07:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7630) Open a new terminal here. So it is ready.

- [02:07:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7633) Then open a terminal in the folder where your file is located. Which is here. Big expression dataset.

- [02:07:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7641) Open a cmd. Type runpodctl.send. And the file name like this. Then it will give you a link like this.

- [02:07:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7648) Copy it with ctrl c. Then paste it here. And it will start uploading from your computer to the RunPod.

- [02:07:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7655) It has a decent upload speed as you are seeing right now. Using interface may also work.

- [02:07:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7661) But may not also work. Because this is a big file.

- [02:07:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7664) The installation of the Kohya takes huge time on RunPod. Because of its speed.

- [02:07:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7668) Therefore, while waiting the installation of the Kohya, we can preprocess our images.

- [02:07:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7676) You can manually process all the images on your computer and upload or you can process them on RunPod.

- [02:08:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7683) Which I am going to show right now. So our zip file has been uploaded here.

- [02:08:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7688) Let's sort by the last modified. And let's see. Yes. Here. Big expression dataset. Right click. And extract archive.

- [02:08:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7695) Then to preprocess them. I have an amazing preprocessor that I have developed. Which is ultimate batch image preprocessing.

- [02:08:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7703) I have shown this in the Windows tutorial part. So you can watch it to learn in more details.

- [02:08:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7709) And you can use this on your computer as well. Even without any GPU.

- [02:08:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7713) So here click zip file to download. You can also download from the attachments always. Then click upload.

- [02:08:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7721) Upload the zip file. And you see it is here. Right click and extract archive. Let's refresh.

- [02:08:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7726) So the new files are extracted which is RunPod instructions read.

- [02:08:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7731) So to install it we are going to run this command. You see my installers are all same.

- [02:08:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7737) And copy pasted. But sometimes they may have same naming. So they may overwrite the other ones.

- [02:09:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7743) Be careful with that. It started installing the ultimate image preprocessor.

- [02:09:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7749) I will show how to use it on the RunPod after install it. Alright. So the ultimate image preprocessor.

- [02:09:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7755) And the kohya. First part. Installed. Let's see how much time it took.

- [02:09:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7759) So it took exactly 20 minutes for the first part of the kohya installation.

- [02:09:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7764) Now after you see this is like this running on local url.

- [02:09:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7769) You need to run the second part of the kohya installation which is here. So open a new terminal.

- [02:09:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7776) And execute it. And meanwhile we can also preprocess our training images. To do that.

- [02:09:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7782) Let's return back to the image preprocessor. Let's do that. Let's open the instructions file. And open another terminal.

- [02:09:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7788) And execute it. Once we have our images ready on RunPod. We will start training immediately with the kohya guide.

- [02:09:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7796) And you see all of my scripts are very transparent. You can look at them. You can learn them.

- [02:10:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7802) You can change them. Utilize them as you wish. Okay. Let's open the Gradio Live. This is the interface.

- [02:10:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7808) First we are going to use image cropper. Then we will use image resizer. To get the perfect images.

- [02:10:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7813) So our training images. That's what we are going to use. This data set is here. Copy path. Like this.

- [02:10:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7818) Input folder. And always put a backslash to the beginning in RunPod. Don't forget that. Then output folder.

- [02:10:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7825) Let's say croppd. Like this. This is the aspect ratio that I recommend. 1024 to 1024. Do not use bucketing.

- [02:10:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7833) Until you have a base model with 1024. Once you have a base model trained.

- [02:10:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7838) You can enable bucketing and compare two trainings. And let's make the number of threads like. 12. Like this.

- [02:10:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7845) You can also change the number of threads. Overwrite existing files. These are the classes that it supports.

- [02:10:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7849) You can extract all of these classes automatically.

- [02:10:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7852) Since I am a person training right now, I will make it person and save as PNG and crop images.

- [02:10:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7858) Then you can follow the process here. It is super optimized, super fast.

- [02:11:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7862) Watch the Windows tutorial part to understand better what does this application do actually.

- [02:11:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7868) Of course, you can also manually crop your images by your hand and upload to the run

- [02:11:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7873) pod and train there. These are all your options.

- [02:11:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7876) But if you have a very big dataset like me, like 256, which is an overkill, by the way,

- [02:11:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7882) you can use this tool. And as I said previously, I have all the comparisons here.

- [02:11:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7888) So you can compare the impact of 15 images, 256 images, how much time they are taking,

- [02:11:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7894) what they are costing on the cloud platforms. Everything is shared here, their durations, everything.

- [02:11:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7899) So you see under one minute it will be completed. And the auto cropped images will be.

- [02:11:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7904) Save it inside the cropped folder.

- [02:11:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7906) What does this application do is zooming in the subject and trying to match the aspect ratio.

- [02:11:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7912) If it cannot match, then the resizer algorithm will make it match. Alright, the cropping completed under two minutes.

- [02:12:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7920) Then we are going to use resize. To resize, we are going to give this folder path.

- [02:12:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7925) The image resizer will look exactly this folder path under this given path.

- [02:12:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7930) And let's make the output path as images ready. Like this. And save as png.

- [02:12:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7936) You can set the threads again. Let's make it 8.

- [02:12:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7939) Also you can resize without cropping center image and expand with white background. But I don't recommend that.

- [02:12:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7945) And it will start processing. This is also very fast process.

- [02:12:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7949) This will make the images perfectly 1024 pixel with maximum best possible quality.

- [02:12:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7955) And you see it is already processing everything with multi-threading.

- [02:12:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7959) Developing this application took a lot of time, but it is a master. And the processing completed under one minute.

- [02:12:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7964) So all the images are ready. We have processed 256 images in under 3 minutes. Fully automatically.

- [02:12:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7972) Now, let's close this window and let's return back to the Kohya installation.

- [02:12:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7977) So this was killed because we have run the second part of the installation, which was,

- [02:13:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7982) let's see, which was where? Yes, here. So this is our Kohya running right now.

- [02:13:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7987) Let's open the Gradio Live and this is the latest interface of the Kohya. Since we are doing DreamBooth Fine-Tuning.

- [02:13:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7994) We are going to use DreamBooth tab.

- [02:13:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=7996) Do not use FineTuningTab because this requires different setup and there is no difference

- [02:13:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8001) actually in training when you don't use regularization images so we are going to use DreamBooth tab.

- [02:13:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8006) And when you are doing a LoRA training, you are going to use LoRA tab.

- [02:13:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8009) If you load inaccurate tab, the config will get corrupted so you need to use a fresh config.

- [02:13:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8016) So if you load DreamBooth config into LoRA, it will get corrupted.

- [02:13:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8019) If you load LoRA into DreamBooth, it will get corrupted. Never forget that. Many people are making mistakes.

- [02:13:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8025) So this is super important. How we are going to load the configuration?

- [02:13:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8029) Return back to the extractions and you will see that we have DreamBooth tab FineTuningConfig. Enter inside it.

- [02:13:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8035) Since this is a 48 GB GPU, I am going to use batch size 7.

- [02:14:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8040) I have explained the impact of batch size 7.

- [02:14:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8043) It slightly reduces the quality but it speeds up the training significantly.

- [02:14:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8049) So therefore, I will right click and copy path. And put a backslash. And load like this.

- [02:14:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8054) And then just load. And everything is loaded.

- [02:14:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8057) But you see FLUX is not selected yet because you have to fix the paths.

- [02:14:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8061) So the paths will be like this. Workspace. And that's it.

- [02:14:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8065) And then when you refresh it, it will automatically select the FLUX as you are seeing.

- [02:14:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8069) Give a name to outputs like my test, ramport, any name. Now training images.

- [02:14:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8075) We need to set the accurate folders. You can either manually prepare as I have shown in the LoRA tutorial.

- [02:14:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8081) Or let's use the dataset preparation. Instance prompt. I use OHWX. You can also use your custom unique prompts.

- [02:14:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8088) Class token. This is a man class. You can decide the class according to your dataset.

- [02:14:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8094) It can be painting, driving, car, animal, cat, dog, whatever. And training images directory.

- [02:14:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8099) Now to this directory we are going to give the final processed images. So they were here. Images ready.

- [02:15:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8106) Right click and copy path. Actually not here. They are inside here. Right click and copy path.

- [02:15:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8112) You see this folder. And put a backslash to the beginning. And this is super important.

- [02:15:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8117) We don't use repeating with FLUX. Repeating is only useful when you are using regularization classification images.

- [02:15:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8124) Since we don't use them with FLUX. It is one. Don't forget that.

- [02:15:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8128) People are making this mistake so many times. Please use repeating one with FLUX. Until regularization images starts working.

- [02:15:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8136) If they starts working I will make another quick video and show you the logic. And the destination directory.

- [02:15:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8142) If the SwarmUI were already installed I would use the SwarmUI path directly.

- [02:15:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8148) As I have shown in the Windows and methods compute tutorial. But it is not installed yet.

- [02:15:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8153) So let's make the destination directory as workspace final training models. Whatever you want. Then click prepare training data.

- [02:16:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8162) You will see that it is getting copied right now. It should display the copy has been completed. Yes.

- [02:16:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8168) There is this warning. But it is not important. We can verify everything was copied. So where?

- [02:16:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8175) They will be copied inside the final training models. Inside image and one or hwxman.

- [02:16:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8181) One is the repeat and this is my caption right now. I don't use captioning because it reduces likeness.

- [02:16:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8187) As I said read everything here to learn more. And everything is ready.

- [02:16:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8191) Then you need to click copy info to respective fields.

- [02:16:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8194) So it will fix the image folder, output path and everything. After you copy it.

- [02:16:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8200) You can always change the output from here.

- [02:16:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8203) I don't recommend logs because when you do very long training logging causes errors, throwing errors.

- [02:16:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8209) Moreover, I don't recommend sampling. So what else do we need to change?

- [02:16:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8215) And I will explain why I don't recommend sampling.

- [02:16:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8217) You need to change the number of epochs according to the number of images you have.

- [02:17:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8221) For example, I found that 40 epoch was best for batch size 7 when I am training with 256 images.

- [02:17:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8228) 140 was best when I am training with 15 images. So for these many images, usually 100 epoch is best.

- [02:17:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8236) And how many checkpoints do you want to get? This totally depends on your hard drive space, empty space.

- [02:17:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8242) Because one checkpoint will be 24 gigabytes. And calculate accordingly. Since I have 400 gigabytes, I can get 10 checkpoints.

- [02:17:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8251) And it should be sufficient. So 10 checkpoints. Nothing else you need to change here. Okay.

- [02:17:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8256) Because we don't use anything else differently. Then in the very bottom, there is samples. I don't recommend samples.

- [02:17:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8263) Because with batch size 7, it is fully utilizing the VRAM of the 48 gigabyte.

- [02:17:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8269) And when you take samples, it uses more VRAM during training. And it will cause out of VRAM error.

- [02:17:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8275) Therefore, do not use samples. We are going to use grid comparison of the SwarmUI. Then save your config.

- [02:18:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8283) And go back to bottom and start training. You don't need to do this.

- [02:18:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8286) You don't need to change any other parameters. Oh, we have forgotten something. What did we forgot?

- [02:18:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8291) We have forgotten the setting the paths here. You see? These paths have to be set.

- [02:18:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8296) Currently, I know from memorization workspace. Like this. Because I have downloaded them there.

- [02:18:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8301) If you have put them into different paths, all you need to do is find the files.

- [02:18:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8306) For example, clip large. Right click. Copy path. Then this is clip large. Put a backslash. Copy path. Like this.

- [02:18:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8314) This is the logic. Since we have downloaded them into the workspace, it is like this.

- [02:18:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8319) So you see, you need to set VAE path, clip large path, and T5 path. Otherwise it will not work.

- [02:18:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8325) And do not use other files.

- [02:18:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8326) Use my downloader because other variants that you find on the internet may not work. And don't worry.

- [02:18:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8333) When you have a 24 GB GPU, we still use these files. It doesn't change.

- [02:18:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8338) And they are automatically casted accordingly. And then start training. Then watch the training happen.

- [02:19:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8344) You see, it shows that I have 256 images, therefore one epoch will be 256 steps.

- [02:19:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8350) Epoch 100, so we are going to train 256 multiplied with 100 but divided by 7 because batch size

- [02:19:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8357) is 7. And the training, starting as you see, it is caching the latency right now.

- [02:19:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8362) After caching, it will load the models and the model loading takes a lot of time on the

- [02:19:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8367) RunPod because their disks are pretty slow compared to master compute. So you just need to wait here.

- [02:19:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8373) It has been over 10 minutes and we are still waiting RunPod to load the model to start

- [02:19:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8380) training even on this very powerful and expensive GPU. So let's install nvitop to see the status.

- [02:19:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8388) pip install nvitop and then just type nvitop like this.

- [02:19:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8393) Yes, you see, it is very, very slowly loading model into the VRAM. It is like crawling.

- [02:20:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8400) This speed is just so annoying. You are losing so much money because of this.

- [02:20:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8405) And I have reported this to the RunPod team. They don't care.

- [02:20:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8408) Their hard drive speeds are terrible compared to the master compute.

- [02:20:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8412) It would have started like 10 times already on master compute.

- [02:20:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8415) And it has been over 10 minutes and still loading, trying to load model to the VRAM

- [02:20:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8420) so the training will start. So therefore, you will be also very likely to wait this much. Don't be surprised.

- [02:20:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8429) Get ready for it.

- [02:20:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8430) So the training has been going on for a while over one hours and the speed of the training

- [02:20:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8437) is very disappointing. And let me show you why. So the current speed is 21.21 second IT.

- [02:20:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8446) And how much we are paying? We are paying currently $1.03 per hour.

- [02:20:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8453) So we are getting this speed with $1 per hour. And when we look at the hours.

- [02:20:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8459) Training speeds on the master compute with a single A6000 GPU, you will understand what I mean.

- [02:21:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8467) When you pay attention to the configuration files, you will notice that they are containing

- [02:21:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8472) both VRAM usages and the training speeds.

- [02:21:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8475) The training speed of the batch size 7 on the master compute was 29 seconds per IT.

- [02:21:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8482) So you see, there is a little bit difference between two. The L40S is faster. Like 25%.

- [02:21:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8490) I was waiting 100% speed difference and it is three times more expensive.

- [02:21:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8496) So therefore I don't recommend this GPU for training at least on RunPod because I have

- [02:21:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8502) seen that some of the pods were way slower than what they are supposed to be.

- [02:21:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8507) You should test the speed on Massed Compute as well because this speed is very slow compared

- [02:21:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8513) to what it should have been. It should have been like 15 seconds per IT. Maybe even lesser.

- [02:21:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8519) And we can see that it is fully utilizing the entire GPU right now, but only limited

- [02:22:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8525) to 350 watts per hour.

- [02:22:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8527) I don't know if this is the reason, but we are using also secure cloud, the best GPUs they have.

- [02:22:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8534) However, this speed is very, very disappointing. I will tell you that much.

- [02:22:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8538) So what we are going to do right now, I am not going to wait 20 hours. Why?

- [02:22:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8543) Because as I said, I have done over one week of trainings.

- [02:22:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8547) And I have done over a week of training. I have done huge amount of comparisons.

- [02:22:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8550) So all of my models are already here. The trained models with these configurations with the same setup.

- [02:22:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8556) I am going to download 4 checkpoints and compare them with using the SwarmUI.

- [02:22:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8561) So you will learn how you will do after training. I have cancelled the training and this is the GPU.

- [02:22:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8568) So how I can download them fast? We can use the notebook file that I have prepared.

- [02:22:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8574) However, I will show that later.

- [02:22:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8576) So, for now, I will show easier way, which is, first of all, decide which models you want to download.

- [02:23:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8583) I am going to download Batch Size 7, 30, 40, and 50 epochs to show you. So, they are here.

- [02:23:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8590) First of all, to download them, I need to make this repository public.

- [02:23:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8594) Yes, it is a security vulnerability, but once you started the downloading, you can change its settings again.

- [02:23:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8601) Currently, it is access request based, so I will disable access request, then what I

- [02:23:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8607) am going to do is just right click, copy link address, open a new terminal here, and type

- [02:23:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8613) wget and the link.

- [02:23:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8615) By the way, we should remove the download at the end, so it will be like this.

- [02:23:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8620) Just delete this part, and yeah, we need to put wget, paste, delete the end of the string,

- [02:23:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8626) attach it, and it will start downloading. You see, it is downloading. Let's start all again.

- [02:23:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8630) So, the next one is 40 epoch, right click, copy link address, wget, paste the link, delete

- [02:23:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8637) the end part from here, enter, and then this one, copy link address, open a new terminal,

- [02:24:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8645) wget, paste, and delete the end, and it's entered. So the downloads have been started.

- [02:24:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8651) Now I will enable access request again, and I will make manual review. And the repository is safe again.

- [02:24:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8657) It can be private. It can be public. This is a fast way of downloading.

- [02:24:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8662) Don't worry, I will also show more secure way of using Hugging Face notebooks.

- [02:24:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8667) Now meanwhile they are getting downloaded, let's also install SwarmUI, because after training I recommend using SwarmUI.

- [02:24:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8675) However, you can also download the trained models to your computer and use that.

- [02:24:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8680) I will show you how to do that. You can use runpodctl, but it is not very fast.

- [02:24:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8685) The fastest way is uploading into Hugging Face like I did. And downloading from your computer.

- [02:24:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8691) For example, if I click this link, it will start downloading into my computer as you are seeing right now.

- [02:24:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8696) So how we gonna install SwarmUI? I already have tutorials for SwarmUI. There is the installers. The installer is here.

- [02:25:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8704) This is a public post by the way. And we are going to download the install linux.sh file.

- [02:25:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8710) Then we will upload it into the workspace. And let's sort by the last modified. So it is. Let's see.

- [02:25:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8718) I think we did it. I need to first refresh. Then. I still don't see. Yes.

- [02:25:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8723) You need to make it name it like this or you need to change the prompt. Okay.

- [02:25:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8726) Then open a new terminal. And we are going to follow the prompts here. So this is the installation prompt.

- [02:25:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8733) Copy paste it. And it will start installing the SwarmUI.

- [02:25:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8735) If you have watched the tutorial video, you will remember it.

- [02:25:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8738) By the way, I keep these scripts updated so they keep working because constantly there

- [02:25:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8743) are some errors that needs to be fixed. For example, just today. I have reported an error here.

- [02:25:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8750) They are aware they are going to fix it. When you are watching the tutorial, it will be probably fixed.

- [02:25:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8755) So you won't be bothering with this error or other errors.

- [02:25:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8758) So it is taking huge time and effort to keep everything updated. And the models are getting downloaded.

- [02:26:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8764) As you are seeing, their speed is very, very bad.

- [02:26:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8767) If you ask my opinion, this is a very powerful GPU pod. Okay. So the SwarmUI started on 7801.

- [02:26:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8774) Now we need to connect that port from here.

- [02:26:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8777) That is why we have added this port to connect SwarmUI interface. And then click agree. Customize settings.

- [02:26:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8785) You can use modern dark, modern light, whatever you want. Next. Just yourself. Next. ComfyUI backend.

- [02:26:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8791) Don't download anything because we don't need. And I am sure install now. And it will start the installation.

- [02:26:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8797) It is really, really fast to install.

- [02:26:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8799) So when you change the repository private to public or not, the started downloads continue.

- [02:26:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8806) However, others will not be able to start new downloads.

- [02:26:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8809) That is why I prefer this way to quickly download models sometimes.

- [02:26:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8813) And the installation of the SwarmUI is continuing as you are seeing right now.

- [02:26:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8817) After the installation of the SwarmUI, it will start like this. You need to wait backends to be completely loaded.

- [02:27:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8824) You can also go to the logs and debug to see what is happening. It is installing the necessary requirements.

- [02:27:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8831) Our models are still getting downloaded. Meanwhile, we need to do two things. First of all.

- [02:27:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8835) We need to move the VAE file. So right click. Cat. Enter inside the SwarmUI. Enter inside models.

- [02:27:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8843) Enter inside VAE. And paste. So we are moving the file into here. You see.

- [02:27:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8848) Then we need to move the T5XXL and the clip large. However, SwarmUI needs a certain naming of T5XXL.

- [02:27:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8858) Which I have written here. You will see it that under here. Rename T5XXL to t5xxl_enconly. To this one.

- [02:27:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8865) So copy this from the post link. Click F2 and paste. You see I have renamed the file.

- [02:27:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8872) Then select clip large and T5XXL. Right click and cat. Then move into SwarmUI. Move into models. Move into clip.

- [02:28:01](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8881) This is the folder. Paste. Okay. The only thing left is now waiting models to be finished.

- [02:28:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8887) We will move them into the diffusion models folder. This is the new requirement. Don't forget that.

- [02:28:13](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8893) Previously it was unit. It is still supporting unit.

- [02:28:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8896) But FLUX models goes into the diffusion models folder if they are the main diffusion files of the FLUX.

- [02:28:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8904) There are different variants of the FLUX. They may be required to put into the different folders.

- [02:28:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8909) But our training checkpoints will go into the diffusion models folder.

- [02:28:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8914) And there is one another thing that I want to show you. To improve the faces of the generations.

- [02:28:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8920) I use a special YOLO model. To download that YOLO model, enter inside the test prompts.

- [02:28:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8927) And you will see how to download YOLO face. Enter inside it.

- [02:28:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8930) This is the link that you are going to use. Right click and copy. Then go back to the SwarmUI.

- [02:28:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8936) And enter inside the models. Here we are going to make a new folder.

- [02:29:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8942) The folder name will be YOLO version 8. Like this. This is mandatory. Enter inside it. Click. Plus icon.

- [02:29:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8950) Open a new terminal. Type wget. And the link. And it will download the model into here.

- [02:29:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8956) You will see it. Yes. 55 megabytes. Now we are ready to use the best face masking model.

- [02:29:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8963) This really improves quality. Believe me. You will see the difference. And it is getting installed.

- [02:29:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8968) Actually I have shown the difference in the Windows tutorial part.

- [02:29:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8971) So you can look at the chapters and see where was it. Actually you should watch the Windows tutorial part.

- [02:29:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8977) Okay. All the models are fully downloaded. We can see them.

- [02:29:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8981) Now what we need to do is go back to workspace. And select the models that we have downloaded.

- [02:29:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8986) Actually you won't be needed to do this because I have downloaded. But you will be training.

- [02:29:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8992) If you have previous trainings. Yes. You need to do that. Enter inside SwarmUI. Models. Diffusion models.

- [02:29:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=8999) This is where the models has to be put. And we are all ready. And there is one final thing.

- [02:30:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9005) Since this is a 4000 series GPU. We will edit here. And add dash dash past.

- [02:30:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9012) And it will make the generations faster. This works for RTX 4000 based series.

- [02:30:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9019) It doesn't make difference on the RTX 3000 series.

- [02:30:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9021) But this will make the generations speed up on the RTX 4000 like 4090 or like L40S. Okay.

- [02:30:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9030) It is ready now. Now the settings of the SwarmUI matters. A lot of people are making mistakes.

- [02:30:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9036) First of all let's go to models and refresh. Then our models arrived here. So let's select the 50 checkpoint.

- [02:30:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9042) I prefer using 40 steps. But 30 to 40 working best. CFG scale is 1 for FLUX. Don't forget that.

- [02:30:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9050) Then enable advanced options. Sampling. I prefer this iPNDM sampler here. This is the best one.

- [02:30:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9058) And I prefer FLUX guidance scale 4. Then there is advanced sampling. And I prefer default here.

- [02:31:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9067) There is also advanced models add-ons. That you can select them. You can see the T5 XXL here.

- [02:31:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9072) However there is currently a bug. Even if you select it is still looking for this file.

- [02:31:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9076) And if it doesn't exist it is downloading. But we have it right now. So it shouldn't download.

- [02:31:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9082) And there is one another thing that I would like to show you. Which is in the regional prompting.

- [02:31:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9087) There will be a new option in future. It is not published yet.

- [02:31:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9092) This new option will be like the segmentation sort order. Largest to smallest.

- [02:31:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9097) But this way it will inpaint your face. If there are multiple faces in the generated image.

- [02:31:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9103) It will inpaint the maximum size having face. Which will be likely your face.

- [02:31:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9109) It is not merged into SwarmUI yet. But hopefully you will see it when you are watching this tutorial. Okay.

- [02:31:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9114) We are all set. Now we have the testing prompts here.

- [02:31:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9119) In the downloaded zip file we can open that inside the test prompts folder here. And there are the prompts.

- [02:32:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9127) There are for grid generation and for regular. I am going to use this prompt for example.

- [02:32:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9132) Let's make a test. Then we will do grid generation. So this is going to generate an image.

- [02:32:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9137) Then it will inpaint face with the yellow face model that we have.

- [02:32:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9140) Let's generate and see the progress in the logs. So it shouldn't download the T5 model.

- [02:32:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9146) It should just load model and then start generation. Yes. It is starting doing everything right now.

- [02:32:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9153) You may also get this message. It is not important. So it is loading the model. The model waits.

- [02:32:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9158) We can also watch the status of the load from here. It is going to load into VRAM.

- [02:32:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9163) However, model loadings on the RunPod is just super slow. Extremely slow because of their hard drives.

- [02:32:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9169) So the model has been loaded and the generation has happened.

- [02:32:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9173) This is the speed current as you are seeing 2 IT per second.

- [02:32:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9177) And the image has been generated with face inpainting.

- [02:33:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9182) Now let me show you the difference of the face inpainting that we use. To see the real difference.

- [02:33:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9187) You need to use a distant shot prompt. For example, this is a distant shot prompt. Let's put it.

- [02:33:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9194) And let's remove the face inpainting. Let's generate an image. This is a really fast GPU.

- [02:33:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9200) It should be really fast. And this is the image. You see the face is like this.

- [02:33:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9204) Now I will reuse parameters. So it will generate the same image.

- [02:33:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9208) And then I will use our segment model like this. And let's hit generate.

- [02:33:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9213) So we will see the quality difference. From this face. To the which face.

- [02:33:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9218) By the way, you can also use the default segment feature of the SwarmUI.

- [02:33:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9223) However, it is not working as quality as this one. It requires some more delicate settings here.

- [02:33:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9230) Like changing the segment threshold max. Or other parameters.

- [02:33:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9234) This YOLO model works out of the box with my settings perfect. With 70% denoise. With this threshold max.

- [02:34:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9242) You see it is now inpainting the face. And we will see. Yes. The face has been fixed.

- [02:34:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9248) So we can compare from this face. You see. From this face. To this face.

- [02:34:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9254) And it looks really really great. The image itself is not very great. There are some errors, mistakes.

- [02:34:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9258) But the face has been fixed for a very distant shot.

- [02:34:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9262) So how you are going to test the generated checkpoints. Go to the tools. Go to the grid generator.

- [02:34:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9268) And give a name to your generation. So you can load back. Let's say test1. Like this.

- [02:34:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9274) You can also save grid config. First select model. Fill in.

- [02:34:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9277) And then delete the ones that are not like your checkpoints. Then enter the prompt. And in here.

- [02:34:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9284) I already have grid formatted prompts. You can use the realism prompt. And there is also eyeglasses.

- [02:34:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9290) So the format is very simple. You separate prompts with these two. When you separate the prompts with this character.

- [02:34:56](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9296) You can use the comma in your prompts as well. So you need to use this. These two characters. Okay.

- [02:35:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9302) Copy it. Paste it there. You see they are separated like this. And it is ready.

- [02:35:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9307) It is going to generate the grid. Let's generate the grid.

- [02:35:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9310) It should be pretty fast on this GPU because it is really fast.

- [02:35:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9314) We will see how fast it will become. First it will load the model.

- [02:35:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9318) The model loading will be unfortunately very slow on the Massed Compute.

- [02:35:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9322) But other than that it should be really really fast.

- [02:35:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9325) So I already have generated grids in my other Massed Compute instance. Grid generator.

- [02:35:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9331) Let's load some of them to look how they will load. Look after generation.

- [02:35:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9335) So this is 256 Fine-Tuning which is batch size 7. Yes here 256 load grid config.

- [02:35:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9344) So you see after generation has been completed you will click this link.

- [02:35:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9348) And it will load the grid like this. And you will see all the generated checkpoints comparison.

- [02:35:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9354) Now this is totally up to you to decide the best checkpoint that you like.

- [02:35:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9358) You need to consider the likeliness and also overfitting. As the model becomes smaller.

- [02:36:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9364) You will notice the degrade in the quality of the environment, in the clothing, in the face and everything.

- [02:36:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9371) So 100 epoch is pretty much overfit. You can see this is the armor details of the 100 epochs.

- [02:36:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9378) As I go to the beginning you will see the armor looks much better.

- [02:36:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9382) So you need to decide which is resembling enough and also have the good details. For example the 40 epoch.

- [02:36:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9389) This is what I have decided. This is the 40 epoch of another prompt.

- [02:36:34](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9394) And you can see the 100 epoch has a very very bad armor. Let's compare two.

- [02:36:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9399) So you will see from this to this.

- [02:36:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9401) So you see it was like this and now it is like this.

- [02:36:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9405) So you need to decide the best checkpoint you want.

- [02:36:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9407) The stylized prompts will work better at the earlier epochs like this. This is a stylized prompt.

- [02:36:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9413) And as I move to the end of the training you will see that it becomes a fully realistic image like this.

- [02:37:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9420) And this is another stylized prompt. It becomes like realistic and earlier epochs will be much better stylized like this.

- [02:37:09](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9429) So it is totally up to you to decide which epoch is best. It is totally up to you.

- [02:37:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9434) You need to consider both overfitting. For example the background is totally overfit in this image.

- [02:37:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9441) And when I go to the beginning it is lesser overfit. So it is up to you to decide.

- [02:37:26](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9446) And this is the way of comparing grids and deciding the best checkpoint. For example the first.

- [02:37:32](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9452) The first tenth epoch is not like me at all. It will become like me as I move.

- [02:37:38](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9458) And the last one supposed to be most alike but it is totally overfit. Or in this image.

- [02:37:44](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9464) The armor is overfit. As I go to the here you see it is way better. Way more generalized.

- [02:37:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9471) And the difference even excels in the stylized configurations.

- [02:37:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9477) In the Patreon post I have shared full grids of each testing you see. 256 images base size 1 Fine-Tuning.

- [02:38:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9484) 256 images dataset base size 7. You can download the full grids. And look the difference.

- [02:38:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9491) Click download after opening link. Then open the downloaded image. And decide yourself how they are changed with the epochs.

- [02:38:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9500) Everything is shared on the Patreon post in details. Both for LoRA and for Fine-Tuning DreamBooth of the training.

- [02:38:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9507) And now for upscaling images I recommend using super. Super is the very best upscaler.

- [02:38:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9513) It is different than the all other upscalers. We already have tutorial for super here. And the scripts are here.

- [02:38:40](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9520) Let's download to super installer. Let's download to super. Then let's go to our workspace here.

- [02:38:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9528) And upload the downloaded super file. Then right click and extract archive.

- [02:38:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9535) This is also taking a lot of space to install. And you will see the RunPod instructions txt.

- [02:39:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9540) Then we will copy this. Open a new terminal. And paste it. And it will start installing super.

- [02:39:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9548) And how you are going to save the generated models and the images to download or use later.

- [02:39:15](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9555) To do that we are going to use the notebook file that I have prepared.

- [02:39:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9560) This is an amazing notebook file. You will see the notebook file here.

- [02:39:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9564) You see ultra fast upload and download as a backup. So let's go to that post.

- [02:39:28](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9568) And you will see the notebook file at the attachments. This is the latest version. Then upload it into workspace.

- [02:39:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9575) And it is here. Double click it. First of all we need to install the requirements. Just play to install.

- [02:39:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9582) It will install the requirements. Then you need to register a Hugging Face account. And get a token.

- [02:39:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9588) So the tokens are here. Let's get a new token. Writing token like this. Create token. Copy the token.

- [02:39:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9595) After installation of the cell has been completed. You see it is idle. Replace the token here. Play.

- [02:40:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9602) And once you played it. You are set to upload and download from your model folders. Repositories.

- [02:40:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9608) Let's go to here. Click here. Click new model. Give any name. Delete. Later. Like this.

- [02:40:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9614) You can make it public, private. Let's make it private. Copy the directory id. And put it here.

- [02:40:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9621) Then select the folder that you want to save. If you want to save backup the models. Then enter inside.

- [02:40:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9627) The models folder which is inside SwarmUI. Inside models. And inside diffusion models. So here.

- [02:40:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9635) So right click and copy as path. Change the path here like this. Then click play.

- [02:40:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9641) And it will start uploading them to there. It doesn't show the status unfortunately.

- [02:40:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9646) So you need to wait until the kernel status is idle. However it is uploading. Also once it is completed.

- [02:40:53](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9653) It will show upload completed. The same rule applies to the download. It doesn't show the status.

- [02:40:59](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9659) But it is working with the fastest way. This is the fastest way. It is uploading 71 gigabytes of file.

- [02:41:06](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9666) If you have more checkpoints. It will take longer of course. So you need to just wait.

- [02:41:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9671) And meanwhile our super is getting installed. So where was it? It is here.

- [02:41:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9677) We just need to wait it to upscale. That is the last part of the tutorial. How to upscale greatly.

- [02:41:23](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9683) And I will also show how to download from Hugging Face to the RunPod.

- [02:41:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9687) Let's see how to download from Hugging Face. You can download it from the RunPod by using this notebook.

- [02:41:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9689) This notebook has so many cells. You can read all of them. It allows you to download single file.

- [02:41:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9695) Upload single file. Or other features. It has all of them. The upload of the RunPod is taking huge time.

- [02:41:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9701) However the download is more decent right now. We have a very special way of downloading models.

- [02:41:47](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9707) For the super we have improved it significantly. And yes it is completed. How do we know?

- [02:41:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9712) Now, once it is completed, you will see virtual environment made and installed properly.

- [02:41:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9718) So let's use the super while it is getting uploaded, then I will show download as well.

- [02:42:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9723) How we gonna use the super?

- [02:42:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9725) The commands are here, the RunPod instructions as usual, but you need to run these commands

- [02:42:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9731) in the workspace usually, wherever you have installed, and it will start to super with sharing.

- [02:42:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9737) By the way, we also need to terminate the running SwarmUI, because it is also using the GPU.

- [02:42:24](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9744) So how I am going to do that? Let's interrupt all sessions, and there were a lot of generations too.

- [02:42:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9751) So let's open the grid for loading, and I will use some of the images generated here

- [02:42:36](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9756) right now for upscaling. Okay, it is getting loaded. Okay, I think we can use this image.

- [02:42:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9763) Then let's turn off the server from shutdown server. I don't know if we need it.

- [02:42:49](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9769) Let's see if it will actually let's not shut down the server, but let's turn off the back end.

- [02:42:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9775) So when you turn off the back end, it will free up the VRAM.

- [02:42:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9778) Yes, now you can turn on the back end and start using again. This is a better approach.

- [02:43:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9784) So the super options I recommend to start as FB8 to use lesser VRAM and start with a tiled VAE.

- [02:43:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9792) The tiled VAE is necessary when you are going to upscale.

- [02:43:17](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9797) If you are going to upscale into a very big resolution, if you get out of VRAM error,

- [02:43:20](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9800) then keep models always in the GPU because I want it faster and start with light dim.

- [02:43:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9807) The settings depends on the GPU that you are using.

- [02:43:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9809) If you have a limited VRAM, you should pick option 2, option 1, and option 1 here to use

- [02:43:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9817) the least amount of VRAM. Unfortunately, the loading will take time as usual. Hugging face upload is still continuing.

- [02:43:45](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9825) Now we need to wait for it to load. Let's wait for start of the super.

- [02:43:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9828) And the super started with the Gradio Live.

- [02:43:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9831) Let's open the link and from the generated images, let's download this image. Ok, let's download into downloads.

- [02:43:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9837) So I prefer the Gradio Live Share. Ok, so the interface has loaded.

- [02:44:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9842) The first thing is selecting our upscaling image. As an example, I will use this one.

- [02:44:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9847) So click here and upload, wait for upload to be completed.

- [02:44:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9850) Then as a second thing, select and decide your preset. Some people prefer replicate. It adds more details.

- [02:44:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9858) However, it changes the face more. Therefore, I prefer default load preset after selecting it.

- [02:44:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9865) You can also set your presets and load them later. And decide the upscaled resolution.

- [02:44:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9870) I'm going to make it 2x. Apply lava so it will automatically generate caption for me.

- [02:44:35](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9875) I prefer Juggernaut 11 or RealVisXL version 5. It is up to you. Let's use the Juggernaut 11.

- [02:44:41](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9881) And there is one another option which is improving the face. So what does that mean?

- [02:44:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9886) That means that it will upscale face separately and paste it back. So let's compare both of them.

- [02:44:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9892) Let's upscale without face first. Then upscale with the face as well. Okay, process single.

- [02:44:58](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9898) You can also do batch processing and everything. So it is starting to process.

- [02:45:03](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9903) The first time loading will be always slower. However, consequent ones will be way faster.

- [02:45:08](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9908) Alright, the first upscale has been completed. Let's compare it. So click here to download. Okay.

- [02:45:14](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9914) Then let's open the image SLI. Alright, let's load the first image. Then let's load the second image.

- [02:45:21](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9921) And let's upload. And we can see the details. So this is the details that it has added.

- [02:45:27](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9927) You can see it is still super loyal to the image as you are seeing right now.

- [02:45:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9931) It is just amazing. Amazing quality improvements. Let's look here. You see from this to this. This to this.

- [02:45:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9939) So what else you can do? What you can do is enable BG restoration and face restoration.

- [02:45:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9943) And enter a face prompt like photo of a man. You can decide the prompt what it will be.

- [02:45:50](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9950) This time it will do two times upscale. First it will upscale the face.

- [02:45:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9955) Then it will upscale the entire image. And try to merge them. However, in some cases this is failing.

- [02:46:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9962) But we will see if it will work this time. And second time upscale completed as well.

- [02:46:07](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9967) It was way faster because it immediately started. Let's download that too. And let's make a new comparison. Okay.

- [02:46:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9976) The original image. Previous upscale. And the last upscale. Let's upload. Sometimes face upscaling is not working.

- [02:46:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9985) So we will see. See if there is a difference. Yes, there is a significant difference in the face details.

- [02:46:31](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9991) Let me demonstrate you. So from this face you see there are a lot of errors here to this face.

- [02:46:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=9997) Now the face looks way better. You see the eyes, the eyeglasses, everything is looking way better.

- [02:46:42](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10002) As you are seeing right now. The birth. It is way way better.

- [02:46:46](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10006) This is the power of upscaling with the super enhancement. All right.

- [02:46:51](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10011) So the upload of the models has been completed.

- [02:46:55](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10015) Let's look at the time it took only for 70 gigabytes of file. So started here.

- [02:47:02](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10022) And the upload has been completed here. So it took around 28 minutes to upload. Now how we can download.

- [02:47:12](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10032) Let's verify them here. So they are all here. All you need to do is later you are downloading.

- [02:47:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10038) If you want to download your computer, just click here to download to your computer.

- [02:47:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10042) Or if you want to download into the new pod later a time clear outputs of all cells.

- [02:47:29](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10049) And in here you will see downloads folder, which is let's see. There are so many options we have here.

- [02:47:37](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10057) This is the fastest download. So enter your repo name. Enter the path. Like workspace GG.

- [02:47:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10063) And then just click download. And it should start downloading right away. However, it doesn't show the status.

- [02:47:52](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10072) So you need to wait until it is downloaded. It depends on the pod speed, unfortunately.

- [02:47:57](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10077) But this is how you can fastest way upload and download models. Save them. Back up them.

- [02:48:05](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10085) This is the fastest way on the RunPod. And the download has been completed. You see download completed.

- [02:48:10](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10090) So when the download has been completed, you will see this message like this. Don't forget that.

- [02:48:16](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10096) On the RunPod, you can stop your machine and it will use way lesser money.

- [02:48:22](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10102) However, still it will use your credits. So you need to delete your pod to not spend any money.

- [02:48:30](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10110) Don't forget that. Currently it will still use some money.

- [02:48:33](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10113) You see it will be really low like 44 cents per hour depending on the storage that you have and the machines you have.

- [02:48:39](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10119) But if you don't want to use any money, you need to terminate this.

- [02:48:43](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10123) Also, if you have storage here, you need to delete them as well. Otherwise, they will use your money.

- [02:48:48](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10128) So don't forget to delete the permanent storage as well if you don't want to spend any credits.

- [02:48:54](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10134) Back up everything on the hugging phase. Then delete the pod network storages that you have.

- [02:49:00](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10140) Now we can see that it is zero. Okay, this is it. I hope you have enjoyed.

- [02:49:04](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10144) The total tutorial took me more than like 10 hours to record. If you have any questions, please ask me.

- [02:49:11](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10151) Also, I will do a lot of new research and everything that I have found will be published on the Patreon page.

- [02:49:18](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10158) It will get updated.

- [02:49:19](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10159) All you need to do will be just load the configuration, follow the new instructions, and do training.

- [02:49:25](https://www.youtube.com/watch?v=FvpWy1x5etM&t=10165) Hopefully see you in future amazing tutorials.

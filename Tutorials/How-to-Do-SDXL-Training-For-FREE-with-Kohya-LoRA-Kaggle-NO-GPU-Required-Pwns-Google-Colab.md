# How to Do SDXL Training For FREE with Kohya LoRA - Kaggle - NO GPU Required - Pwns Google Colab

## Full tutorial link > https://www.youtube.com/watch?v=JF2P7BIUpIU

[![How to Do SDXL Training For FREE with Kohya LoRA - Kaggle - NO GPU Required - Pwns Google Colab](https://img.youtube.com/vi/JF2P7BIUpIU/sddefault.jpg)](https://www.youtube.com/watch?v=JF2P7BIUpIU "How to Do SDXL Training For FREE with Kohya LoRA - Kaggle - NO GPU Required - Pwns Google Colab")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-to-Do-SDXL-Training-For-FREE-with-Kohya-LoRA-Kaggle-NO-GPU-Required-Pwns-Google-Colab.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-to-Do-SDXL-Training-For-FREE-with-Kohya-LoRA-Kaggle-NO-GPU-Required-Pwns-Google-Colab.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


If you don't have a strong GPU for Stable Diffusion XL training then this is the tutorial you are looking for. We will use Kaggle free notebook to do Kohya SDXL LoRA training. In this tutorial you will master Kohya SDXL with Kaggle! üöÄ Curious about training Kohya SDXL? Learn why Kaggle outshines Google Colab! We will uncover the power of free Kaggle's dual GPU. üî• Step-by-step guide inside! Boost your skills and make the most of FREE Kaggle resources! üí° #Training #SDXL #Kaggle

Kaggle Kohya SDXL Notebook File ‚§µÔ∏è

[https://www.patreon.com/posts/kohya-sdxl-lora-88397937](https://www.patreon.com/posts/kohya-sdxl-lora-88397937)

Tutorial GitHub Readme File ‚§µÔ∏è

[https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Do-Free-Google-Colab-Like-Kaggle-SDXL-LoRA-Training.md](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Do-Free-Google-Colab-Like-Kaggle-SDXL-LoRA-Training.md)

SECourses Discord To Get Full Support ‚§µÔ∏è

[https://discord.com/servers/software-engineering-courses-secourses-772774097734074388](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388)

[00:00:00](https://youtu.be/JF2P7BIUpIU?t=0) Introduction to how to do amazing FREE training of Stable Diffusion XL without owning a GPU

[00:02:35](https://youtu.be/JF2P7BIUpIU?t=155) How to register Kaggle to get a free account to do free training

[00:03:05](https://youtu.be/JF2P7BIUpIU?t=185) How to verify your phone number in Kaggle to be able to use cloud GPUs for free

[00:03:55](https://youtu.be/JF2P7BIUpIU?t=235) How to generate a Kaggle notebook and start Stable Diffusion XL free Kohya SS LoRA training

[00:04:20](https://youtu.be/JF2P7BIUpIU?t=260) How to download and import SDXL LoRA training notebook

[00:05:46](https://youtu.be/JF2P7BIUpIU?t=346) How to properly with correct config start session on Kaggle to begin training

[00:05:56](https://youtu.be/JF2P7BIUpIU?t=356) How to enable GPU on Kaggle

[00:06:34](https://youtu.be/JF2P7BIUpIU?t=394) How to see how much GPU time you have used and how much you have left on Kaggle

[00:06:49](https://youtu.be/JF2P7BIUpIU?t=409) How to look at used resources in your Kaggle session such as disk space, GPU, CPU, RAM

[00:07:00](https://youtu.be/JF2P7BIUpIU?t=420) How to clone Kohya SS GUI and install it on a free Kaggle notebook

[00:07:21](https://youtu.be/JF2P7BIUpIU?t=441) How to understand and use pathing structure of Kaggle

[00:07:37](https://youtu.be/JF2P7BIUpIU?t=457) Where is our root / working directory in Kaggle

[00:09:57](https://youtu.be/JF2P7BIUpIU?t=597) How to know when the installation of Kohya SS GUI has been completed

[00:10:14](https://youtu.be/JF2P7BIUpIU?t=614) How to download ground truth regularization / classification images

[00:13:17](https://youtu.be/JF2P7BIUpIU?t=797) How to upload your regularization / classification images and use them

[00:14:13](https://youtu.be/JF2P7BIUpIU?t=853) How to use your previously uploaded images / datasets in your Kaggle training sessions

[00:16:00](https://youtu.be/JF2P7BIUpIU?t=960) How to start Kohya SS GUI on Kaggle notebook

[00:16:31](https://youtu.be/JF2P7BIUpIU?t=991) How to access started Kohya SS GUI instance via publicly given Gradio link

[00:17:09](https://youtu.be/JF2P7BIUpIU?t=1029) Starting to setup Kohya SDXL LoRA training parameters and settings

[00:17:40](https://youtu.be/JF2P7BIUpIU?t=1060) Which source model we need to use for SDXL training a free Kaggle notebook

[00:18:55](https://youtu.be/JF2P7BIUpIU?t=1135) How to prepare training dataset easily with dataset preparation feature of Kohya SS GUI

[00:19:26](https://youtu.be/JF2P7BIUpIU?t=1166) How to upload your training images and prepare them for SDXL training

[00:20:25](https://youtu.be/JF2P7BIUpIU?t=1225) How get and set folder path of training and regularization / classification images

[00:20:51](https://youtu.be/JF2P7BIUpIU?t=1251) Where to and how to save training results and how to generate training folders

[00:21:44](https://youtu.be/JF2P7BIUpIU?t=1304) How to copy info to folders tab

[00:22:09](https://youtu.be/JF2P7BIUpIU?t=1329) Setting up all training parameters

[00:23:44](https://youtu.be/JF2P7BIUpIU?t=1424) Network Rank Dimension trade-off

[00:24:44](https://youtu.be/JF2P7BIUpIU?t=1484) Continuing to setting up all training parameters

[00:25:54](https://youtu.be/JF2P7BIUpIU?t=1554) How to start training after everything is set

[00:26:54](https://youtu.be/JF2P7BIUpIU?t=1614) What is the formula of calculating number of training total steps

[00:27:54](https://youtu.be/JF2P7BIUpIU?t=1674) How to execute training command

[00:29:10](https://youtu.be/JF2P7BIUpIU?t=1750) How to calculate necessary number of classification / regularization images that you need

[00:31:05](https://youtu.be/JF2P7BIUpIU?t=1865) Training started

[00:31:24](https://youtu.be/JF2P7BIUpIU?t=1884) Why it shows total number of epochs double of the number we did set

[00:32:10](https://youtu.be/JF2P7BIUpIU?t=1930) Where is our SDXL LoRA training checkpoints are saved and how to download them

[00:33:07](https://youtu.be/JF2P7BIUpIU?t=1987) Why generated safetensor files, checkpoints are 228 MBs

[00:33:27](https://youtu.be/JF2P7BIUpIU?t=2007) How to enable allow multiple files download in your browser to download generated LoRA checkpoints

[00:33:37](https://youtu.be/JF2P7BIUpIU?t=2017) How to download all of the checkpoints as a single file - zip them all

[00:34:27](https://youtu.be/JF2P7BIUpIU?t=2067) How to download LoRA safetensors folder entirely

[00:35:04](https://youtu.be/JF2P7BIUpIU?t=2104) How to extract and open downloaded as zip LoRA checkpoints

[00:36:48](https://youtu.be/JF2P7BIUpIU?t=2208) How to save your LoRA checkpoints on your Kaggle account to use later

[00:37:50](https://youtu.be/JF2P7BIUpIU?t=2270) How to use your trained LoRA checkpoints in your Automatic1111 Web UI on your PC

[00:38:50](https://youtu.be/JF2P7BIUpIU?t=2330) How to download and use 750 styles containing styles.csv file

[00:39:40](https://youtu.be/JF2P7BIUpIU?t=2380) How to find best checkpoint of your Kohya SDXL LoRA training

[00:40:07](https://youtu.be/JF2P7BIUpIU?t=2407) How to see used prompts and settings of generated images via png info tab of Automatic1111 Web UI

[00:40:26](https://youtu.be/JF2P7BIUpIU?t=2426) How did I decide to use the certain checkpoint via x/y/z script of Automatic1111 Web UI

[00:41:08](https://youtu.be/JF2P7BIUpIU?t=2468) How to use your LoRAs in Automatic1111 Web UI

[00:42:08](https://youtu.be/JF2P7BIUpIU?t=2528) How to select your LoRA from the interface

[00:44:04](https://youtu.be/JF2P7BIUpIU?t=2644) How to generate same batch with correct seed, how batch seed is determined

[00:44:38](https://youtu.be/JF2P7BIUpIU?t=2678) How to install after detailer (adetailer) extension to improve faces in your generations automatically

[00:45:07](https://youtu.be/JF2P7BIUpIU?t=2707) After detailer extension enabled comparison results

[00:46:01](https://youtu.be/JF2P7BIUpIU?t=2761) How to get amazing likeness - realism having images of your trained subject,

[00:46:27](https://youtu.be/JF2P7BIUpIU?t=2787) How to find best amazing among thousands of generated images by using DeepFace AI similarity script



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=0) Greetings everyone, I have been getting asked how to do Kohya SDXL, Stable Diffusion XL

- [00:00:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=8) training on a free Google Colab.

- [00:00:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=11) Unfortunately, it is not possible to do this training on a free Google Colab because of

- [00:00:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=17) the RAM limitation.

- [00:00:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=19) However, we are going to use a free Kaggle account to do Stable Diffusion XL LoRA training

- [00:00:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=27) fully.

- [00:00:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=28) We are going to do training with both Text Encoder and U-Net with 32 Network Rank Dimensions

- [00:00:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=36) which are extremely optimal settings and we are going to obtain amazing quality images.

- [00:00:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=43) You may be wondering why it is not working on a free Google Colab but working on a Kaggle

- [00:00:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=49) account?

- [00:00:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=50) Because Kaggle is providing dual GPU as you are seeing right now for even free users.

- [00:00:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=57) And it is amazing that they are providing 30 hours per week for free.

- [00:01:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=62) 100% Free!

- [00:01:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=64) So Kaggle is the best alternative of Google Colab and it is even better.

- [00:01:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=69) In this tutorial I will show you step by step setup and training of Kohya SDXL on a free

- [00:01:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=78) Kaggle account.

- [00:01:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=79) Then I will show you how you can use those trained LoRA checkpoints on your computer.

- [00:01:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=86) Hopefully in another tutorial, I will show how you can use Automatic1111 web UI on a

- [00:01:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=93) free Kaggle account.

- [00:01:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=94) So let's say you have a computer that you can run Automatic1111 web UI but you can't

- [00:01:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=100) do Stable Diffusion XL training.

- [00:01:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=103) You can do your training on a free Kaggle account.

- [00:01:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=107) Then you can use your trained LoRA files on your computer.

- [00:01:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=110) So this tutorial is the tutorial that you were looking for if you don't have a strong

- [00:01:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=116) GPU.

- [00:01:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=117) This tutorial is a little bit tricky.

- [00:01:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=119) Therefore, please pay attention to every minute of the tutorial and also join our Discord

- [00:02:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=125) channel and ask me any questions or reply to this video and ask any question.

- [00:02:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=130) So I have prepared a very detailed GitHub readme file.

- [00:02:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=134) All of the instructions and links that you are going to need is shared here.

- [00:02:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=139) If it be necessary I will update this file in future so this tutorial will be always

- [00:02:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=145) up to date.

- [00:02:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=146) Always check out this file when following this tutorial.

- [00:02:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=150) The file link will be in the description of the video and also in the comment section

- [00:02:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=154) of the video.

- [00:02:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=155) We will begin with registering our Kaggle account and you may be wondering what is Kaggle.

- [00:02:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=161) Currently I am logged into my account.

- [00:02:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=163) However, when I open this in a private window like this, you will see two options to register.

- [00:02:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=170) Register with Google.

- [00:02:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=171) Register with email.

- [00:02:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=172) You can register with Google.

- [00:02:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=173) It is very easy.

- [00:02:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=175) After registered and logged in your account, you have to verify your phone number to be

- [00:03:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=181) able to use GPUs provided by the Kaggle.

- [00:03:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=184) So go to settings link and in here you will have your phone number verification option.

- [00:03:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=192) You see my phone number is verified.

- [00:03:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=194) It is also showing how much private data sets that you are using, how much GPU time that

- [00:03:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=200) you can use more.

- [00:03:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=202) This is really really good feature.

- [00:03:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=205) Because on Google Colab we don't see how much GPU time we have.

- [00:03:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=210) On Kaggle it shows you how many hours you can use per week and how much you have used

- [00:03:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=216) already.

- [00:03:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=217) You see it shows each week you get a minimum 30 hours of GPU.

- [00:03:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=221) It also provides TPU timing as well.

- [00:03:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=225) So Kaggle is better than Google Colab if you ask me.

- [00:03:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=229) Kaggle also have more options.

- [00:03:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=231) When you type what is Kaggle to the Google, you can obtain more information.

- [00:03:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=235) So to do Stable Diffusion XL training on Kaggle you need to generate a notebook.

- [00:04:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=242) Click create button here, select new notebook.

- [00:04:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=246) It will load the notebook like this and this is the notebook.

- [00:04:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=251) The notebooks are similar in all of the platforms that you use.

- [00:04:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=255) You can either use the commands that I have shared here or you can download the notebook

- [00:04:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=262) I have shared on my Patreon post.

- [00:04:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=265) So when you open this Patreon post, just click this attachment and download it.

- [00:04:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=271) Then click file, import notebook, browse files.

- [00:04:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=276) Select the downloaded notebook, import and you will have everything necessary here.

- [00:04:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=282) It is totally same if you are not my Patreon supporter, you can use this code that I also

- [00:04:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=289) shared on GitHub.

- [00:04:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=290) Or you can support me and download this notebook directly.

- [00:04:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=293) There are some description here.

- [00:04:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=295) You can pause the video and read it if you wish.

- [00:04:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=298) So we are going to use Kohya GUI SS and we are going to use the latest version.

- [00:05:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=304) This is really important why?

- [00:05:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=306) Because in many other notebooks that you can use on free cloud services like Google Colab

- [00:05:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=312) or Kaggle, they are all specifically certain commit.

- [00:05:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=316) However, on my tutorial, we are going to use the latest version of the Kohya.

- [00:05:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=321) Therefore, we are going to have all the optimization and bug fixes.

- [00:05:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=325) I have spent huge time to figure it out how to make this work on Kaggle.

- [00:05:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=331) Unfortunately, it doesn't work on Google Colab.

- [00:05:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=334) Because Google Colab has very limited RAM.

- [00:05:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=337) Actually, this Kaggle also has very limited RAM.

- [00:05:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=341) However, since it gives us dual GPU, we are going to utilize it.

- [00:05:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=346) So to begin with we need to start our session.

- [00:05:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=349) When you hover your mouse in the right section, you will see accelerator option.

- [00:05:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=354) This is really important.

- [00:05:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=355) You need to pick accelerator GPU T4 x2, which means that it will give us dual T4 GPU.

- [00:06:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=364) Our language is Python.

- [00:06:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=365) We are not choosing persistence so everything will get deleted after we turn it off our

- [00:06:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=371) session.

- [00:06:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=372) So this is really important.

- [00:06:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=373) Don't forget to select accelerator GPU T4.

- [00:06:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=377) This option will not be available if you did not validate your phone number.

- [00:06:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=382) So don't forget to verify your phone number before starting.

- [00:06:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=386) Okay, to start the notebook, we click this icon.

- [00:06:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=389) You see draft session starting and Jupyter is being waited.

- [00:06:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=394) You see, I have already used 11.5 hours out of 30 hours of my GPU time.

- [00:06:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=401) This is really really good when compared to Google Colab.

- [00:06:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=404) You know what you have.

- [00:06:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=405) You know how much you can use.

- [00:06:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=407) All right.

- [00:06:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=408) Our session started.

- [00:06:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=409) When you click here, it will show how much space you are using, how much CPU you are

- [00:06:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=415) using, how much GPU you are using.

- [00:06:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=417) This is really really better than Google Colab.

- [00:07:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=420) So this script will clone Kohya GUI SS into our runtime drive and it will install it.

- [00:07:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=428) It is so simple.

- [00:07:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=429) You see only four lines of script.

- [00:07:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=432) You can also type this or you can copy it from the GitHub file I have shared here.

- [00:07:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=437) So about Kaggle.

- [00:07:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=438) The only thing that you need to know is the path.

- [00:07:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=440) When I click here, you see it shows my Kaggle working directory.

- [00:07:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=446) This is where our files will be saved during runtime, only during runtime.

- [00:07:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=452) So when we terminate our session by clicking here, they will get all deleted.

- [00:07:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=457) So Kaggle Working is our path, our root directory.

- [00:07:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=462) You see it has cloned it into here.

- [00:07:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=464) Now it is installing all of the necessary packages.

- [00:07:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=467) Just patiently wait until this operation is 100% completed and this is the commit that

- [00:07:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=474) I am using right now.

- [00:07:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=475) You can also switch to this commit by making this like this.

- [00:07:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=479) However, I don't suggest you to git checkout unless you get error.

- [00:08:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=483) You can also reply to this video and hopefully I will make the fixes.

- [00:08:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=489) I will make the updates in GitHub and also in the Patreon post for you.

- [00:08:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=493) So meanwhile this is getting installed let me tell you several other things.

- [00:08:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=498) If you haven't watched my previous tutorials about Kohya SDXL LoRA training, I suggest

- [00:08:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=505) you to watch them.

- [00:08:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=506) This LoRA training video is a masterpiece.

- [00:08:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=508) It explains how LoRA training works.

- [00:08:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=512) Fundamentally, this very comprehensive LoRA training video will show you every detail

- [00:08:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=518) about LoRA training on SDXL.

- [00:08:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=521) This is my RunPod LoRA training video.

- [00:08:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=524) Why I also share this because in this video I have shown how to use adetailer / after

- [00:08:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=529) detailer extension to improve faces automatically.

- [00:08:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=533) Moreover, RunPod is also using Unix.

- [00:08:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=536) It is also a cloud service provider, so it also has similarities to Kaggle training and

- [00:09:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=543) in this video I have shown how to sort generated images with the similarity to the training

- [00:09:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=550) image that you provide.

- [00:09:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=551) It is really helpful.

- [00:09:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=553) I will show that and there are 765 styles that you can use in Automatic web UI.

- [00:09:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=558) I will also show you how to use them.

- [00:09:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=561) Very carefully following this tutorial video is really important because there are a lot

- [00:09:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=567) of tricks that you need to do to make it work on Kaggle, all because of the limited RAM

- [00:09:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=574) that Kaggle provides us.

- [00:09:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=576) The Kaggle is only providing 13 gigabyte RAM and this is same with Google Colab as well.

- [00:09:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=581) These are free options.

- [00:09:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=582) Of course you can upgrade your account and get better resources both on Kaggle and also

- [00:09:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=588) Google Colab, but for this to work on a free account, there are several tricks that we

- [00:09:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=593) need to do so.

- [00:09:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=595) Follow this tutorial very carefully.

- [00:09:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=597) The installation has been completed.

- [00:09:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=599) How do we know?

- [00:10:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=600) You see setup finished.

- [00:10:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=602) So it says that the setup has been finished.

- [00:10:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=604) Now before starting the Kohya GUI web instance, I am going to download and extract regularization

- [00:10:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=613) / classification images.

- [00:10:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=614) I am using ground truth regularization / classification images to improve the quality of the training

- [00:10:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=622) and also prevent over training of the model.

- [00:10:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=625) I have spent like 2 days to prepare man data set and also women data set.

- [00:10:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=632) I have collected over 30,000 images from unsplash . com then I have preprocessed them with AI

- [00:10:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=641) tools.

- [00:10:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=642) Then I have hand-picked each one of them to ensure every one of them is highest quality.

- [00:10:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=649) Let me show you one of the example images.

- [00:10:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=652) You see.

- [00:10:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=653) You see the details.

- [00:10:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=654) This is an original image that I use as a classification / regularization images.

- [00:10:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=659) Then I have preprocessed all of them with the latest cropping and resizing script that

- [00:11:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=666) I have coded myself.

- [00:11:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=669) Let me show you the results.

- [00:11:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=670) So all of these dimensions are available on my Patreon post.

- [00:11:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=676) Just resize them into these dimensions is taking over 1 day.

- [00:11:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=681) So this is a huge task that I have made.

- [00:11:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=684) Let me show you the some of the final images in this tutorial.

- [00:11:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=687) We are going to use 1024 to 1024.

- [00:11:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=690) So these are all the face focused 1024 1024 resized images.

- [00:11:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=697) Let me show you one of them like this, you see super high quality.

- [00:11:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=703) Let me show you another one.

- [00:11:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=705) You see super high quality.

- [00:11:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=707) I am not using the SDXL generated images as classification / regularization images because

- [00:11:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=713) using ground truth images is better.

- [00:11:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=716) However, if you are going to use stylized images that you like as a style of the base

- [00:12:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=723) model, you can generate classification images from the base model itself too.

- [00:12:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=728) So when we execute this line, it will download images and also extract them.

- [00:12:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=735) Let me see if there is another error.

- [00:12:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=737) Okay, there is no another error.

- [00:12:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=739) So I just clicked this line and it started downloading and then it will extract images

- [00:12:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=745) into our working directory, Kaggle working directory.

- [00:12:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=748) We will see that.

- [00:12:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=750) After extraction has been completed, it will also delete the zip file.

- [00:12:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=754) This is automatically coming with the attached Patreon post.

- [00:12:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=758) However, when you open this link you will see I have all of the images and their links

- [00:12:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=765) shared here so you can download any specific resolution.

- [00:12:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=770) You need to use the same resolution of your training images.

- [00:12:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=774) So if your training images are 1024 to 1280, you need to use that.

- [00:13:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=780) Or if they are 1280 to 1536, you need to use them.

- [00:13:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=785) These are not just resized images, these are face focused resized images.

- [00:13:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=790) Hopefully, I will make a new video about my new scripts that I used and I will share them

- [00:13:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=796) with you as well.

- [00:13:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=798) Let's say you are not my Patreon supporter and you want to use your own classification

- [00:13:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=802) images.

- [00:13:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=803) To do that we will use this upload icon here.

- [00:13:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=807) Click this.

- [00:13:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=808) You need to set a new data set.

- [00:13:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=811) This will be private by default.

- [00:13:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=813) You see no one else will have access to it.

- [00:13:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=815) Let's say class images.

- [00:13:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=817) You can give any name, then click browse files, select the files that you want to use as classification

- [00:13:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=824) images so I will select some of them from here to show you as an example.

- [00:13:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=829) So let's say these are my classification images.

- [00:13:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=832) Click open.

- [00:13:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=833) They will get uploaded.

- [00:13:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=835) You also need to give a name.

- [00:13:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=837) Like class images.

- [00:13:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=838) You see they are getting uploaded 1 by 1.

- [00:14:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=841) So you need to upload all of the files, then create and after that you will be able to

- [00:14:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=847) use this data set not only in this training but also in your other trainings as well.

- [00:14:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=853) How?

- [00:14:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=854) Click this add data and your data set will appear.

- [00:14:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=858) Here you see class images.

- [00:14:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=859) Just click this icon and it will be added into your training or into your session.

- [00:14:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=865) You see like this.

- [00:14:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=866) Now I can give the path of this folder and I can use all of the images.

- [00:14:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=870) This is also the way that we are going to use to upload our training images as well.

- [00:14:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=876) Normally this is so fast, but this time this is really slow.

- [00:14:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=880) I don't know.

- [00:14:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=881) So this upload feature is really important.

- [00:14:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=884) This is the way to upload data into your Kaggle notebook.

- [00:14:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=888) The advantage of Kaggle is that this data is permanently saved so you don't need to

- [00:14:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=893) upload again and again.

- [00:14:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=895) When you start a new session, just click, add data, select your data sets, find your

- [00:15:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=900) data set from here and click plus icon and it will be added into your current runtime.

- [00:15:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=905) This feature is not existing on Google Colab.

- [00:15:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=909) Maybe you can use Google Drive and import files, but this is much more easier.

- [00:15:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=914) Much more convenient so you just one time upload and you can use it later again and

- [00:15:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=919) again.

- [00:15:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=920) All right.

- [00:15:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=921) The classification images are ready.

- [00:15:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=923) We can see them here.

- [00:15:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=925) When I click this icon, it will expand it.

- [00:15:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=928) There are over 4,000 files so it is a little bit hard to open.

- [00:15:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=932) When I double click this file.

- [00:15:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=934) It should open it somewhere here.

- [00:15:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=936) Okay, it didn't display.

- [00:15:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=938) Maybe I can download here.

- [00:15:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=940) I can click these three dots and click download.

- [00:15:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=942) It is downloaded.

- [00:15:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=944) Yes, you are seeing one of the regularization images.

- [00:15:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=947) It is ready.

- [00:15:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=948) This is also for human data set.

- [00:15:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=950) By default I have added 1024 to 1024.

- [00:15:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=954) If you need other resolutions, just go to the Patreon post and copy the link and replace

- [00:15:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=959) it.

- [00:16:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=960) After that we are ready.

- [00:16:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=961) What are we are going to do is we will start the GUI instance with this command.

- [00:16:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=966) This is the thing that we are going to run after the installation has been completed.

- [00:16:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=970) As in other notebooks that run on cloud, we can execute one cell at a time.

- [00:16:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=977) So if another cell is working, you won't be able to execute another cell.

- [00:16:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=982) That is why I have executed this cell before I started the GUI instance.

- [00:16:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=988) So I made sure that everything is ready.

- [00:16:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=992) Okay, after you run this code it will give you this public Gradio link.

- [00:16:39](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=999) This is the link that you are going to use.

- [00:16:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1001) You see it shows our available GPU here, the CUDA version, and the number of cores that

- [00:16:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1008) it has.

- [00:16:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1009) So click this Gradio link and it will open the Kohya GUI interface for us.

- [00:16:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1015) Allright.

- [00:16:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1016) Now, I will set up everything quickly.

- [00:16:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1019) If you want to learn more about these settings, I suggest you to watch this amazing tutorial

- [00:17:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1026) where I have explained a lot of things in details.

- [00:17:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1030) So we go to the LoRA tab.

- [00:17:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1032) Let's begin with configuration saving so it will be saved inside Kaggle Working.

- [00:17:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1038) test1.json click save and we should see that file has appeared in our working directory.

- [00:17:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1046) So I just expand it.

- [00:17:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1048) Let's close this.

- [00:17:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1049) Let's refresh by clicking here.

- [00:17:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1052) You see test1.json file has been generated.

- [00:17:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1055) You can go here, more actions and you can download and look at it.

- [00:17:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1060) Okay source model: we are going to use custom and in here we are going to use the model

- [00:17:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1067) shared on Hugging Face.

- [00:17:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1069) We are not going to use safetensors file because it is using more RAM at the moment.

- [00:17:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1074) However, I have opened an issue thread on Kohya GitHub repository and they have made

- [00:18:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1080) a new commit.

- [00:18:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1083) Hopefully it will use lesser RAM on in future.

- [00:18:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1085) So we need to copy this.

- [00:18:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1088) This link is also shared in this file.

- [00:18:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1091) In here you see repo name and we just paste it into here pre-trained model name or path.

- [00:18:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1098) We are going to use Stable Diffusion XL base 1.0 model.

- [00:18:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1103) You can also use Kaggle and Kohya to train SD 1.5 based models as well.

- [00:18:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1110) Just use the settings for SD 1.5 version: in this amazing tutorial, I have shown how

- [00:18:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1116) to do Kohya LoRA training on SD 1.5 based versions so you can watch this tutorial to

- [00:18:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1123) learn more about SD 1.5 based versions training.

- [00:18:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1128) Select this checkbox.

- [00:18:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1129) This is really important SDXL model: after you make every change, just click save then

- [00:18:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1135) we go to the data set preparation.

- [00:18:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1137) Now they moved this tab to here which makes a lot of sense.

- [00:19:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1142) So we are going to use ohwx rare token.

- [00:19:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1144) There is also another approach using existing tokens to train yourself such as celebrity

- [00:19:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1150) names.

- [00:19:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1151) Hopefully I will also explore that option and make a comparison video so we will see

- [00:19:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1156) which one is performing better.

- [00:19:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1158) Rare token approach is still working.

- [00:19:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1160) We are going to use man class if you are woman, woman class if you are training something

- [00:19:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1164) else just that class.

- [00:19:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1166) Training images folder.

- [00:19:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1167) Now this is important.

- [00:19:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1169) How you are going to give the path of the folder?

- [00:19:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1172) First we need to upload our training images so I click this icon upload: let's say training

- [00:19:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1178) images as the data set name.

- [00:19:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1180) Let's make it the data set title as well.

- [00:19:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1182) Click browse files.

- [00:19:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1184) My images are inside pictures, inside me new size.

- [00:19:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1189) Inside here.

- [00:19:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1190) You see I am using 13 images.

- [00:19:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1191) These are not the best quality training images.

- [00:19:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1194) Hopefully I will make another tutorial about what kind of images are good quality images

- [00:19:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1199) for training.

- [00:20:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1200) So I click open they will get uploaded.

- [00:20:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1202) You see it says this file already exists in my data set.

- [00:20:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1207) So once this is done you just do the upload and it will start working.

- [00:20:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1212) Currently it wants me to use my existing data set.

- [00:20:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1215) So how am I going to do that?

- [00:20:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1217) I am going to do that with add data, your data set and my images are here.

- [00:20:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1223) My test data set.

- [00:20:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1224) I click plus icon and they will get added here.

- [00:20:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1227) You see now added.

- [00:20:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1229) Copy file path and paste it here.

- [00:20:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1231) Now we are ready.

- [00:20:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1232) I am going to use 25 repeating.

- [00:20:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1235) So for every training image it will use 25 different classification images, regularization

- [00:20:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1241) images.

- [00:20:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1242) Both classification and regularization images meaning same thing.

- [00:20:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1245) So my regularization images are here.

- [00:20:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1247) Copy the directory path, paste it here.

- [00:20:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1250) We are using repeating 1.

- [00:20:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1252) Where I want the trained models and output to be saved.

- [00:20:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1257) So I copied this and I say results.

- [00:21:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1260) So this will be the folder where the trained LoRA checkpoints will be saved.

- [00:21:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1265) So now what I need to do is first click, prepare training data and watch the messages you will

- [00:21:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1272) see here carefully.

- [00:21:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1273) We should see the copy option here.

- [00:21:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1275) So you see it says done creating folder.

- [00:21:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1279) So it copied all of the files both here and also here into our new folder.

- [00:21:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1286) You see results and you see my output is now using more.

- [00:21:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1290) After this operation has been completed, you can delete the classification images folder

- [00:21:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1297) here to open more space.

- [00:21:39](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1299) However, to delete it we need to stop this running GUI.

- [00:21:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1303) I will do that later.

- [00:21:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1304) So after this operation I click copy info to folders tab and when I go to folders now

- [00:21:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1310) you see all of the folder paths are copied correctly.

- [00:21:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1313) You have to exact folder naming structure for Kohya to work.

- [00:21:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1317) So use this data set preparation and what name I want for my LoRAs.

- [00:22:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1323) I will name them as Kaggle test1 and then I click save.

- [00:22:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1329) Now time to set parameters.

- [00:22:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1331) So I am going to use standard LoRA.

- [00:22:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1333) There could be better options but this is what I have found.

- [00:22:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1336) We are not going to use cache latents at the moment because they are causing out of RAM

- [00:22:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1341) error.

- [00:22:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1342) Hopefully it will get fixed in future updates.

- [00:22:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1345) I made a discussion about this with the developers and they are going to implement a fix.

- [00:22:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1350) We are going to use mixed precision as fp16 and save precision as fp16.

- [00:22:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1357) Because the free GPU the Kaggle provides is not supporting bf16.

- [00:22:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1362) We are going to use Adafactor as optimizer.

- [00:22:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1365) I am going to use constant learning rate.

- [00:22:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1368) Okay, optimizer extra arguments.

- [00:22:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1370) This is important.

- [00:22:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1371) We are going to use these extra optimizer arguments so copy them from the GitHub file.

- [00:22:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1378) This is also shared in this Kaggle notebook as well you see here.

- [00:23:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1383) So I copy paste it.

- [00:23:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1384) I am going to use learning rate as 0.0004.

- [00:23:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1389) Let me zoom in so you can see better.

- [00:23:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1391) So this is the learning rate that I am going to use.

- [00:23:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1393) The learning warm up steps doesn't matter because we are using constant.

- [00:23:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1397) Max resolution.

- [00:23:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1398) This is really important for SDXL.

- [00:23:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1400) We are going to use 1024 to 1024.

- [00:23:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1404) Don't forget that.

- [00:23:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1405) I am not using buckets so I suggest you also to use single bucket.

- [00:23:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1410) Make all of your images same resolution.

- [00:23:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1413) Otherwise you may get out of VRAM error.

- [00:23:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1415) Text Encoder learning rate same as the learning rate.

- [00:23:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1418) U-NET learning rate same as the learning rate.

- [00:23:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1421) Network Rank Dimension.

- [00:23:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1422) Now I am going to use 32.

- [00:23:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1424) However, 64 may also work on Kaggle.

- [00:23:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1428) But as you increase your Network Rank Dimension, there is a trade-off.

- [00:23:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1432) The trade-off is let me show you.

- [00:23:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1435) When you go to the GitHub readme file and when you open this Twitter post you will see

- [00:24:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1440) a comparison image here.

- [00:24:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1442) By the way, this is my account so you can follow me on Twitter.

- [00:24:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1445) I am sharing a lot of useful information.

- [00:24:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1447) When you look at these pictures carefully, you will notice that the trees at the background

- [00:24:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1453) in the upper image has less details when compared to the trees at the below image.

- [00:24:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1458) The above image has 256 Network Rank Dimension.

- [00:24:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1463) The below image has 32 Network Rank Dimension. 256 Network Rank Dimension providing more

- [00:24:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1471) details about the subject.

- [00:24:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1472) However, the model itself is forgetting some of the information it has.

- [00:24:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1477) So there is a trade-off between higher Network Rank Dimension and lower Network Rank Dimension.

- [00:24:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1482) 32, 64, even 96.

- [00:24:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1485) You can try with different Network Rank Dimensions and see which one is working best for you.

- [00:24:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1491) But 32 is working very decent.

- [00:24:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1494) Network alpha is 1.

- [00:24:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1496) Let's save the settings.

- [00:24:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1498) Let's go to the advanced setup.

- [00:24:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1499) Now there are several other important settings that we need to set here.

- [00:25:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1504) First of all, Gradient Checkpointing.

- [00:25:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1505) We need this.

- [00:25:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1506) This is slowing down the training.

- [00:25:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1508) However, this is extremely reducing the VRAM usage.

- [00:25:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1513) We are also going to provide additional parameters which is --lowram which is shared here and

- [00:25:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1520) also shared in the GitHub file here lowram.

- [00:25:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1524) Don't forget that this is necessary to make it work on Kaggle, so Gradient Checkpointing,

- [00:25:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1530) lowram, and nothing else we need.

- [00:25:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1533) In future, you can also select full fp16 training.

- [00:25:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1535) This will also further reduce VRAM usage, but it doesn't make difference at the moment

- [00:25:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1541) as far as I have experimented.

- [00:25:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1544) So let's click save.

- [00:25:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1546) But we are not going to click start training because Gradio instance is also using RAM

- [00:25:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1551) and we need every bit of RAM.

- [00:25:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1553) So what we are going to do is print training command.

- [00:25:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1556) Go back to your Kaggle here.

- [00:25:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1559) You need to do this once everything is set.

- [00:26:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1562) So it shows train batch size 1, max train steps 650.

- [00:26:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1566) I noticed my error which is the number of epochs.

- [00:26:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1570) So currently it is going to do training for only 1 epoch.

- [00:26:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1574) However, I find that 200 epochs total training is good for training a person.

- [00:26:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1580) Since our repeating count is 25, when I do 8 epoch, it will be total 200 epochs.

- [00:26:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1587) I explain all of this in the other videos that I have linked.

- [00:26:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1591) So number of epochs is 8, save every epoch is 1.

- [00:26:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1595) Let's save and click print training command and let's get the command one more time.

- [00:26:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1602) So select this, ctrl-c and copy it, open a new notepad file, paste it, and check out

- [00:26:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1608) the command that you are seeing.

- [00:26:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1610) This is my command at the moment.

- [00:26:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1612) I am verifying everything.

- [00:26:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1614) It is going to do 5200 steps.

- [00:26:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1616) Why?

- [00:26:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1617) Let me calculate it for you quickly.

- [00:27:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1620) So I have 13 images.

- [00:27:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1622) I am doing 25 repetition at every epoch.

- [00:27:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1626) I am going to train up to 8 epochs and I have classification / regularization images.

- [00:27:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1631) So it doubles the number of steps number of training.

- [00:27:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1634) So I have 5200 steps.

- [00:27:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1638) Everything is looking correct.

- [00:27:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1639) So I have copying this and after that I need to stop this running cell.

- [00:27:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1646) Let's clear everything so I right click somewhere and I click clear outputs or clear all outputs.

- [00:27:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1653) Everything is cleared.

- [00:27:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1655) Let's delete the classification images directory so we will have more space.

- [00:27:39](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1659) Let's click this.

- [00:27:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1660) We can delete this.

- [00:27:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1662) Why?

- [00:27:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1663) Because we already copied all of the images into results folder here so when we refresh

- [00:27:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1668) it, it will get refreshed soon.

- [00:27:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1670) After that we are going to execute command from here.

- [00:27:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1674) So put an exclamation mark to the beginning, paste the command that you have copied and

- [00:27:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1679) click this cell.

- [00:28:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1681) This cell will start training.

- [00:28:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1683) You see, my currently used hard drive space is also reduced to 2.7 gigabyte.

- [00:28:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1689) This process will take a lot of time.

- [00:28:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1692) For 5200 steps it is going to take like 7 hours.

- [00:28:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1696) But since this is free this is better than nothing.

- [00:28:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1700) If you don't have a GPU.

- [00:28:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1701) If you don't want to pay the paid cloud services you can use this.

- [00:28:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1706) Just start it and left it open.

- [00:28:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1709) It gives you 30 hours per week which is amazing.

- [00:28:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1712) So it is going to download necessary model files.

- [00:28:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1716) You will see all of the messages are being printed here.

- [00:28:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1720) Image count: 13, number of repeats 25.

- [00:28:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1722) These are really important.

- [00:28:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1724) Verify them.

- [00:28:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1725) You see this is the folder name.

- [00:28:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1726) Use ohwx as a rare token.

- [00:28:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1729) Don't use some random tokens or use some existing celebrity name token.

- [00:28:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1734) That is another approach.

- [00:28:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1735) I am not using it yet.

- [00:28:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1736) I am not using captioning.

- [00:28:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1738) Hopefully, I will also explore the captioning effect in future, so stay subscribed.

- [00:29:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1743) This is the number of classification / regularization images it has found, but it is not going to

- [00:29:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1749) use all of them.

- [00:29:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1750) It is only going to use number of repeating multiplied with image count.

- [00:29:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1754) So how many regularization / classification images I need?

- [00:29:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1757) I need 13 multiplied with 25 = 325.

- [00:29:20](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1760) This is the number of images I need.

- [00:29:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1763) If I have made number of repeating more or if I had more images for training, I would

- [00:29:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1769) need more classification / regularization images.

- [00:29:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1772) So here it is showing 338 total images.

- [00:29:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1777) Why?

- [00:29:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1778) Because 325 classification images plus number of training images is equal to this.

- [00:29:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1782) Okay, it is showing the more messages.

- [00:29:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1785) It is downloading the SDXL files from the Hugging Face.

- [00:29:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1789) We are going to use Diffuser files, not the safetensor file because this uses lesser RAM.

- [00:29:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1795) So it has downloaded all of the files.

- [00:29:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1798) Now it is converting U-NET.

- [00:30:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1800) You can also watch the progress here.

- [00:30:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1802) You see this much RAM is being used.

- [00:30:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1804) This is the GPU RAM.

- [00:30:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1806) First GPU second GPU.

- [00:30:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1807) We are going to fully use all of the RAM of the both GPUs.

- [00:30:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1812) In free Google Colab it is not working because free Google Colab is only providing 1 GPU

- [00:30:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1818) and same amount of RAM.

- [00:30:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1819) Therefore, we are getting out of RAM there.

- [00:30:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1822) I have tested a lot of times on Google Colab but all failed.

- [00:30:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1826) I couldn't make it work.

- [00:30:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1828) For making Kaggle work I spent like 2 days.

- [00:30:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1830) A lot of research, a lot of experimentation and testing and this is the best way of making

- [00:30:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1837) it work on Kaggle with also doing Text Encoder training.

- [00:30:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1842) If you only do U-NET training it would use lesser VRAM.

- [00:30:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1847) However, for rare token approach to work you need also Text Encoder training.

- [00:30:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1852) Also let's say you are doing a style training or other trainings you would need a rare token

- [00:30:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1858) approach in many cases.

- [00:30:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1859) You see we are using dimension rank 32.

- [00:31:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1863) Okay and the training started.

- [00:31:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1866) Let's see the speed.

- [00:31:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1867) So it starts with 9.19 seconds.

- [00:31:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1871) It is going to get down about 5 seconds per it.

- [00:31:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1875) In total it is going to take like 7 hours.

- [00:31:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1877) Currently it says 10 hours but it will get decreased over time as it gets more normalized.

- [00:31:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1884) So it has been over 90 minutes and we have 4 epochs so far.

- [00:31:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1889) However, the number of epochs it is displaying is doubled.

- [00:31:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1894) I think this is because it is doing training on dual GPU.

- [00:31:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1898) That is why it is displaying as double epochs, but the total number of steps the number of

- [00:31:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1905) training is equal as it is supposed to be.

- [00:31:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1909) So this is equal to 8 epoch 25 repeating and 13 training images with classification images.

- [00:31:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1916) I asked this on Kohya to verify whether this is because of dual GPU or it is another bug,

- [00:32:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1923) but I am pretty confident and this is because there are two GPUs right now being used.

- [00:32:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1929) So our LoRA checkpoints are saved inside our output folder inside results.

- [00:32:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1935) You see after I click it here it is expanding the folder.

- [00:32:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1939) When I go to model and wait a little bit I will see the saved checkpoints and how you

- [00:32:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1945) can download them.

- [00:32:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1947) When you hover your mouse like this and go to the three dots at the right you will see

- [00:32:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1953) download option.

- [00:32:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1954) Just click them and download them.

- [00:32:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1956) This is the way of downloading them, however it won't show you the progress of download.

- [00:32:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1962) When you open your task manager and when you open your ethernet you will see the download

- [00:32:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1967) is happening.

- [00:32:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1968) You see it is downloading with 100 megabits per second which is my internet connection

- [00:32:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1973) speed so it is super fast when compared to Google Colab and once the download has been

- [00:32:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1979) completed you will see immediately the files are downloaded.

- [00:33:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1983) Let's wait a little bit.

- [00:33:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1984) We should see in a moment.

- [00:33:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1987) Each safetensor file is currently 228 megabytes because our Network Rank Dimension is 32.

- [00:33:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1994) If you go with lesser rank, it will be lesser space.

- [00:33:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=1998) So 16 rank would be 114 megabytes or 64 rank would be like 450 megabytes.

- [00:33:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2007) Okay, files are getting downloaded as you are seeing right now so you can watch your

- [00:33:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2012) download progress from here and the other file download has begin.

- [00:33:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2016) However, if you want to download entire folder, this is the command that you need.

- [00:33:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2022) This command will zip them and you will be able to download all of them.

- [00:33:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2027) I won't wait until this training is completed because I already done the same training with

- [00:33:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2033) exact same parameters.

- [00:33:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2035) So for now I will just stop the training and download all of them as a zip file.

- [00:34:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2041) Let's clear all of the outputs.

- [00:34:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2043) Let's stop the ongoing progress.

- [00:34:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2046) You have to stop it or wait it to be finished to be able to execute this command to zip

- [00:34:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2052) all of the model files.

- [00:34:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2054) So let's expand the results folder one more time.

- [00:34:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2058) Okay, maybe we need to refresh.

- [00:34:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2061) Okay, sometimes you may get this warning message.

- [00:34:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2065) Just wait patiently.

- [00:34:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2068) Okay, now I will execute this command.

- [00:34:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2070) This command will make LoRAs.tar.js file in the working directory.

- [00:34:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2080) This may take a while.

- [00:34:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2081) Just wait until this is completely executed and finished.

- [00:34:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2086) By the way, you need to have sufficient output space to execute this zip file command.

- [00:34:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2093) You see the output space that I am using is getting increased.

- [00:34:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2096) Okay, the execution has been completed.

- [00:34:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2099) Now I see the LoRAs.tar.js file.

- [00:35:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2103) Click here, download.

- [00:35:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2104) So how you can open this.

- [00:35:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2105) You can open it with Winrar.

- [00:35:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2108) Just type Winrar to Google and download from rarlab . com.

- [00:35:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2113) This is the Winrar download site.

- [00:35:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2116) Just go to downloads and download it if you can't extract the downloaded file.

- [00:35:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2121) It is not displaying the download status but from the task manager I can see it is downloading.

- [00:35:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2127) To be able to follow this tutorial you don't even need a computer.

- [00:35:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2132) You can do this tutorial from your Ipad, your Iphone, your Android phone, your Mac, wherever

- [00:35:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2140) you are able to use a browser, and you can upload images and you can type text.

- [00:35:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2146) So it is not limited to computer.

- [00:35:49](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2149) You can follow this tutorial anywhere.

- [00:35:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2151) You see currently it is downloading with full speed of my internet connection.

- [00:35:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2155) Once the download has been completed, I will see the download happening from here.

- [00:36:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2160) Also, when you try to download multiple files, the browser may ask you that this site is

- [00:36:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2167) requesting to download multiple files.

- [00:36:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2170) You see continue allowing automatic downloads of multiple files.

- [00:36:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2174) Just make sure that you have allowed it otherwise you won't get downloads completed.

- [00:36:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2179) So that all of the downloads were completed.

- [00:36:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2182) When I open this download I can see inside of it by double clicking and I can extract

- [00:36:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2189) them and start using them.

- [00:36:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2190) So I will show you how you can use them on your computer with Automatic1111 web UI.

- [00:36:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2197) Hopefully I will make another tutorial for how to use Automatic1111 web UI on a free

- [00:36:42](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2202) Kaggle notebook.

- [00:36:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2204) It will be perhaps next tutorial.

- [00:36:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2206) So stay subscribed and let's say you want to keep your LoRAs on a Kaggle data set that

- [00:36:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2213) you want to use later.

- [00:36:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2214) So how you can do that?

- [00:36:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2216) Let's extract LoRAs into LoRAs2 folder like this.

- [00:37:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2220) So they are getting extracted into this folder.

- [00:37:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2223) Click this upload icon.

- [00:37:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2224) Let's say my LoRAs let's give the same name.

- [00:37:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2228) Browse files, open the folder, select the LoRA safetensors files, open them.

- [00:37:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2233) They will get uploaded into here.

- [00:37:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2236) They will be private unless you make them public.

- [00:37:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2239) So this is the way of uploading and permanently saving files in your account.

- [00:37:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2243) However, you have space like 100 gigabytes but it is really really sufficient and once

- [00:37:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2249) the uploads are completed, just click create icon.

- [00:37:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2253) So for now I will just terminate my session because I have shown everything now.

- [00:37:39](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2259) Time to use these LoRAs on our Automatic1111 web UI.

- [00:37:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2263) So to terminate your session, click here and it will turn off your session and everything

- [00:37:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2267) in this output folder will get deleted permanently.

- [00:37:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2270) I have explained everything from scratch how to install and use Automatic1111 web UI with

- [00:37:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2278) LoRAs in this tutorial video.

- [00:38:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2280) So watch it if you don't know how to use Automatic1111 web UI with LoRAs, let me show you the LoRA

- [00:38:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2287) files from my last Kaggle training before I have recorded this video.

- [00:38:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2291) They are inside models, inside LoRA folder.

- [00:38:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2294) You see these are all the LoRAs I trained on a free Kaggle account starting from 1 to

- [00:38:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2301) 15 and the last checkpoint will not have numbering like this.

- [00:38:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2306) So this is actually number 16.

- [00:38:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2308) Let's fix it like this.

- [00:38:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2310) Okay, number 16.

- [00:38:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2312) These LoRAs have 200 megabytes size because they are Network Rank Dimension 32.

- [00:38:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2317) If you go with Network Rank Dimension 256, they will become like 1.7 gigabytes per checkpoint.

- [00:38:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2325) So how we are going to use it?

- [00:38:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2326) I will just start my Automatic1111 web UI and one another thing I want to mention is

- [00:38:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2331) I have styles.csv file.

- [00:38:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2333) When I open it with notepad++ these are all the styles.

- [00:38:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2338) Where you can download them?

- [00:39:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2341) You can download them in this GitHub readme file.

- [00:39:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2344) Click the styles.txt file.

- [00:39:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2347) After download has been completed open your downloads folder, rename it to .csv file extension

- [00:39:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2355) like this.

- [00:39:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2356) So let me sort it.

- [00:39:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2358) You see styles.csv file and paste it into your main Automatic1111 web UI folder.

- [00:39:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2365) Restart your web UI.

- [00:39:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2367) They will appear in your styles tab.

- [00:39:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2371) Now I will show you that the instance has started.

- [00:39:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2374) So the styles are here.

- [00:39:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2376) You see all of the styles from that styles.txt are here.

- [00:39:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2381) So how you can test and find the best checkpoint.

- [00:39:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2385) I have explained it finding the best checkpoint of LoRAs in this tutorial.

- [00:39:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2390) So please watch it!

- [00:39:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2392) Yesterday I have found my best checkpoint and I have generated over 3,000 images.

- [00:39:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2398) The generated images are all here.

- [00:40:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2400) Let me show you them.

- [00:40:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2401) So these are the images that I have generated over 3,000.

- [00:40:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2405) Let's open one of them.

- [00:40:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2407) So I drag and drop into png info like this and when I send text to image tab I will see

- [00:40:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2414) all of the details.

- [00:40:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2415) So I used the checkpoint 10.

- [00:40:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2418) It could be different for you based on the training images that you have.

- [00:40:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2424) So how did I decide this?

- [00:40:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2425) I used x/y/z checkpoint comparison.

- [00:40:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2429) Let me show you the output of x/y/z checkpoint comparison.

- [00:40:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2432) So it is inside outputs folder, inside text to image grids.

- [00:40:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2438) Let's go to the yesterday and let's open the final grid file and this is the final grid

- [00:40:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2445) file.

- [00:40:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2446) It's a pretty big file.

- [00:40:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2447) So I have analyzed this file and look at the each checkpoint and I decided then the checkpoint

- [00:40:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2454) 10 is the decent one, the sweet one.

- [00:40:57](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2457) So this may change according to everyone cases differently.

- [00:41:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2461) You need to find your best checkpoint.

- [00:41:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2463) As I said, watch this tutorial to learn how to do x/y/z checkpoint comparison.

- [00:41:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2468) All right so how you can use your trained LoRA.

- [00:41:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2472) Since we have done training with ohwx man, this is my main prompt that I have to use.

- [00:41:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2478) So I am going to use cinematic style as I have used yesterday.

- [00:41:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2483) I select cinematic style.

- [00:41:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2485) I set the resolution 1024 to 1024.

- [00:41:29](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2489) Use the same resolution that you have used for training.

- [00:41:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2492) This is really important and crucial.

- [00:41:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2495) You shouldn't use 512.

- [00:41:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2496) Select the correct VAE file.

- [00:41:39](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2499) If you select SD 1.5 version VAE, you will get very problematic output.

- [00:41:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2506) So either select correct VAE, SDXL VAE or none.

- [00:41:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2512) If you had set previously your VAE from Stable Diffusion VAE in here, then it could be using

- [00:41:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2519) the SD 1.5 version VAE.

- [00:42:02](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2522) So make sure that you have selected correct VAE.

- [00:42:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2524) I explained all of this in the previous video.

- [00:42:08](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2528) Now time to select our LoRA.

- [00:42:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2530) Currently the interface is here, but it will be moved to here for selecting LoRA.

- [00:42:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2536) When you are watching it could be already published.

- [00:42:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2538) So I click here.

- [00:42:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2539) With in the new version of Automatic1111 web UI, you will see the interface like this.

- [00:42:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2545) So click LoRA, find the LoRA that you have done your training.

- [00:42:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2550) So my LoRA is at the very bottom.

- [00:42:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2552) You see test Kaggle.

- [00:42:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2554) So I am going to use test Kaggle 10.

- [00:42:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2556) Like this, let's close the LoRA interface in the interface.

- [00:42:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2561) You will click here for text to image tab to return back and I need nothing else.

- [00:42:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2567) Currently after detailer extension is not enabled.

- [00:42:51](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2571) What does this extension do?

- [00:42:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2572) This extension masks automatically the face and inpaint it with the prompt you used here

- [00:43:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2580) or with the prompt you define here it is totally optional.

- [00:43:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2585) So let's generate 12 images and then let's regenerate them with after detailer extension.

- [00:43:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2591) So let's hit generate.

- [00:43:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2592) Since this style is applied, you will see the executed prompts here.

- [00:43:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2598) Currently it doesn't show because we are doing batch, but after batch we will see it.

- [00:43:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2603) So the very important part of using LoRA is appending the LoRA name into your prompt like

- [00:43:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2610) this.

- [00:43:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2611) Don't forget that.

- [00:43:32](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2612) This is the most crucial part.

- [00:43:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2614) So here are results.

- [00:43:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2615) When I click one of the images, I will see the fully executed prompt.

- [00:43:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2620) So the style prompt is added like this cinematic film still ohwx man.

- [00:43:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2626) This is our rare token and class token.

- [00:43:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2628) This is our LoRA prompt and the rest of the style and there is the negative prompt that

- [00:43:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2634) is coming from style and the other settings.

- [00:43:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2636) So these are the base images generated.

- [00:44:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2640) Now let's also apply after detailer and compare it.

- [00:44:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2645) To have same batch I will use the last seed so I click here.

- [00:44:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2651) It will use the last seed.

- [00:44:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2652) This should be the seed of the first.

- [00:44:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2655) So see this here and here you see.

- [00:44:17](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2657) When you do a batch it increases seed by one so it will be same.

- [00:44:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2661) You see when I click the seed is increased by one.

- [00:44:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2665) All right let's generate with enabling after detailer and compare the results.

- [00:44:31](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2671) So this was the first results without after detailer and we will see the effect of after

- [00:44:37](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2677) detailer.

- [00:44:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2678) You can install the after detailer from extensions.

- [00:44:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2681) It is just very easy to install.

- [00:44:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2684) Go to available, load from, find the after detailer from here.

- [00:44:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2688) It is in the installed tab so I need to uncheck this and after detailer is here.

- [00:44:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2694) So you need to find this install and restart.

- [00:44:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2696) Then you will have this extension.

- [00:44:59](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2699) All right.

- [00:45:00](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2700) It is almost done.

- [00:45:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2701) Okay after detailer results has arrived now time to compare them.

- [00:45:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2705) So I copy paste into paint .net and now we can have a comparison.

- [00:45:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2711) Okay let's see.

- [00:45:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2712) Do we have much improvements?

- [00:45:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2716) Perhaps we need to compare one by one.

- [00:45:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2718) Yeah there is a slight improvement in the images.

- [00:45:21](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2721) Still, you may not get your best results.

- [00:45:24](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2724) Okay let's for example, look at this one.

- [00:45:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2726) This is after detailer.

- [00:45:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2728) Not very much like me, but face is decent and this is without after detailer.

- [00:45:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2734) You see how dramatic effect the after detailer has in a distance shot.

- [00:45:40](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2740) To have beautiful images even in distant shots you need higher resolution training not even

- [00:45:46](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2746) 1024 to 1024.

- [00:45:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2748) You need like 1280 to 1536 to have good faces in distant shots.

- [00:45:55](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2755) So after detailer will make your job easier to get more quality images.

- [00:46:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2761) So how you can get very alike images with your training with easiness?

- [00:46:06](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2766) Stable Diffusion is the numbers game.

- [00:46:09](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2769) So what you need to do is generate a lot of images like you are seeing here.

- [00:46:15](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2775) Over 3,000 images then find the best looking ones.

- [00:46:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2779) However, it is extremely time consuming to find the best ones by looking all of the images

- [00:46:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2786) so what else you can do?

- [00:46:27](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2787) I have an amazing script that I have developed myself by using DeepFace AI.

- [00:46:33](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2793) This script will sort all of the images based on a reference image.

- [00:46:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2798) So I give this image as a base image based on this real training image.

- [00:46:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2804) The AI will sort images by similarity to this image.

- [00:46:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2808) So let's see the similarity sorted images which are here.

- [00:46:53](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2813) When you look at the file names you will see the distance which means the similarity between

- [00:47:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2821) the base image and this AI image.

- [00:47:05](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2825) If the distance is smaller, the image is more similar to the your base image.

- [00:47:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2830) So from these images you can easily find the very best looking images like this.

- [00:47:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2836) You see it is very very similar.

- [00:47:18](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2838) It is super high quality.

- [00:47:19](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2839) Yes of course we are losing some details.

- [00:47:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2842) It is because of the resolution of training.

- [00:47:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2846) Perhaps with high resolution fix we could get better images.

- [00:47:30](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2850) I didn't do much testing but you see the similarity is very canny.

- [00:47:35](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2855) Very good.

- [00:47:36](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2856) Or let's look at another image.

- [00:47:38](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2858) These are cinematic style prompts and they are really really looking decent.

- [00:47:44](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2864) Let's look another one for example this one.

- [00:47:47](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2867) You see with this way you can very easily sort images and find the best looking ones.

- [00:47:54](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2874) I will also look for different workflows to even obtain better higher quality results.

- [00:48:01](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2881) I am in search.

- [00:48:03](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2883) Hopefully I will experiment with using celebrity token strategy.

- [00:48:07](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2887) I will also do full DreamBooth training and I believe I will get even better results.

- [00:48:14](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2894) But for now this workflow is working very decent.

- [00:48:16](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2896) You can also use this workflow for style teaching or for other objects teaching whatever you

- [00:48:22](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2902) want.

- [00:48:23](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2903) So stay subscribed for this.

- [00:48:25](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2905) This is all for today.

- [00:48:26](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2906) I hope you have enjoyed it.

- [00:48:28](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2908) Please go to Stable Diffusion tab from here, Star our repository, fork it and watch it.

- [00:48:34](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2914) Also, if you become sponsor of me, I would appreciate that very much.

- [00:48:39](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2919) You can also support me on Patreon.

- [00:48:41](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2921) You can buy me a coffee, you can follow me on medium.

- [00:48:43](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2923) You can follow me on CivitAI.

- [00:48:45](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2925) You can follow me on Deviantart.

- [00:48:48](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2928) You can also subscribe our channel.

- [00:48:50](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2930) You can also follow me on Linkedin.

- [00:48:52](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2932) This is my Udemy Stable Diffusion course with over 100 students.

- [00:48:56](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2936) Let me open it and show you.

- [00:48:58](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2938) You see we have over 133 students with 4.8 stars.

- [00:49:04](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2944) I hope you also consider to purchase my course here and support me and you can also follow

- [00:49:10](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2950) me on Twitter.

- [00:49:11](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2951) I am sharing a lot of useful information on Twitter so please also follow me here as well.

- [00:49:12](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2952) Hopefully see you in another amazing tutorial.

- [00:49:13](https://www.youtube.com/watch?v=JF2P7BIUpIU&t=2953) See you later.

# Wan 2.2, FLUX & Qwen Image Upgraded: Ultimate Tutorial for Open Source SOTA Image & Video Gen Models

## Full tutorial link > https://www.youtube.com/watch?v=3BFDcO2Ysu4

[![Wan 2.2, FLUX & Qwen Image Upgraded: Ultimate Tutorial for Open Source SOTA Image & Video Gen Models](https://img.youtube.com/vi/3BFDcO2Ysu4/sddefault.jpg)](https://www.youtube.com/watch?v=3BFDcO2Ysu4 "Wan 2.2, FLUX & Qwen Image Upgraded: Ultimate Tutorial for Open Source SOTA Image & Video Gen Models")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Wan-22-FLUX-and-Qwen-Image-Upgraded-Ultimate-Tutorial-for-Open-Source-SOTA-Image-and-Video-Gen-Models.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Wan-22-FLUX-and-Qwen-Image-Upgraded-Ultimate-Tutorial-for-Open-Source-SOTA-Image-and-Video-Gen-Models.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Wan 2.2, Qwen Image, FLUX, FLUX Krea, all these models are the SOTA open-source models and in this master tutorial I will show you how to use these models in the easiest, most performant, and most accurate way. After doing almost one week of research, I have determined the very best presets and prepared this tutorial. With literally one click you will be able to install, download models, set presets, and use these amazing models. Wan 2.2 is currently the king of video generation models and now it is super fast with lightx2v Wan2.2-Lightning LoRAs. Moreover, Qwen Image is now ultra-fast with the recently released 8-step LoRA with almost no quality loss. Furthermore, I have updated FLUX and FLUX Krea presets to improve image generation quality. Finally, I have trained FLUX Krea with our existing DreamBooth and LoRA training workflows, analyzed and shared the results in this tutorial. As additional information, I have shown the upcoming Qwen Image editing/inpainting model and the Qwen Image training application I am developing.

‚ñ∂Ô∏è SwarmUI Installers, Presets and Model Downloader App : üîó [https://www.patreon.com/posts/114517862](https://www.patreon.com/posts/114517862)

‚ñ∂Ô∏è ComfyUI Backend Installer : üîó [https://www.patreon.com/posts/105023709](https://www.patreon.com/posts/105023709)

‚ñ∂Ô∏è FLUX / FLUX Krea DreamBooth Training : üîó [https://www.patreon.com/posts/112099700](https://www.patreon.com/posts/112099700)

‚ñ∂Ô∏è FLUX / FLUX Krea LoRA Training : üîó [https://www.patreon.com/posts/110879657](https://www.patreon.com/posts/110879657)

‚ñ∂Ô∏è Main SwarmUI Installation Tutorial : üîó [https://youtu.be/fTzlQ0tjxj0](https://youtu.be/fTzlQ0tjxj0)

‚ñ∂Ô∏è RunPod SwarmUI Installation Tutorial : üîó [https://youtu.be/R02kPf9Y3_w](https://youtu.be/R02kPf9Y3_w)

‚ñ∂Ô∏è Massed Compute SwarmUI Installation Tutorial (starting [00:21:32](https://youtu.be/3BFDcO2Ysu4?t=1292)) : üîó [https://youtu.be/8cMIwS9qo4M](https://youtu.be/8cMIwS9qo4M)

Video Chapters

[00:00:00](https://youtu.be/3BFDcO2Ysu4?t=0) Introduction to New State-of-the-Art AI Models

[00:00:43](https://youtu.be/3BFDcO2Ysu4?t=43) Wan 2.2 vs Wan 2.1 Image-to-Video Comparison

[00:01:43](https://youtu.be/3BFDcO2Ysu4?t=103) Huge Improvement with New Wan 2.2 Text-to-Video Presets

[00:02:44](https://youtu.be/3BFDcO2Ysu4?t=164) More Examples of New Wan 2.2 Presets (Text & Image-to-Video)

[00:03:08](https://youtu.be/3BFDcO2Ysu4?t=188) Using RIFE for Smooth Frame Interpolation (2x FPS)

[00:04:30](https://youtu.be/3BFDcO2Ysu4?t=270) Image Generation: Wan 2.2 Realism vs FLUX Dev & Krea Dev

[00:05:08](https://youtu.be/3BFDcO2Ysu4?t=308) Introducing Ultra-Fast Qwen Image 8-Step Preset

[00:05:44](https://youtu.be/3BFDcO2Ysu4?t=344) Coming Soon: Qwen Image Editing Capabilities Preview

[00:06:10](https://youtu.be/3BFDcO2Ysu4?t=370) Comparing Qwen Image Presets (High Quality, Fast & Realism)

[00:07:14](https://youtu.be/3BFDcO2Ysu4?t=434) Behind the Scenes: The Extensive Testing Process for Presets

[00:07:42](https://youtu.be/3BFDcO2Ysu4?t=462) FLUX Krea Dev Training Experiments (DreamBooth & LoRA)

[00:08:21](https://youtu.be/3BFDcO2Ysu4?t=501) Updates: Qwen Training App, ComfyUI & SwarmUI Installers

[00:08:59](https://youtu.be/3BFDcO2Ysu4?t=539) How to Update SwarmUI and ComfyUI Installations

[00:10:05](https://youtu.be/3BFDcO2Ysu4?t=605) Importing New Presets into SwarmUI

[00:10:51](https://youtu.be/3BFDcO2Ysu4?t=651) Easiest Way: Using the Automatic Preset Import Script

[00:12:22](https://youtu.be/3BFDcO2Ysu4?t=742) Using the Model Downloader for Required AI Models

[00:13:22](https://youtu.be/3BFDcO2Ysu4?t=802) Configuring Downloader for ComfyUI & Forge WebUI

[00:15:31](https://youtu.be/3BFDcO2Ysu4?t=931) Demo: Generating a Wan 2.2 Image-to-Video (8-Steps)

[00:17:02](https://youtu.be/3BFDcO2Ysu4?t=1022) Using Google Studio AI for High-Quality Prompt Generation

[00:18:19](https://youtu.be/3BFDcO2Ysu4?t=1099) Starting the Generation & Multi-GPU Trick

[00:19:46](https://youtu.be/3BFDcO2Ysu4?t=1186) Advanced Video Options: Frames, FPS, and RIFE Settings

[00:21:11](https://youtu.be/3BFDcO2Ysu4?t=1271) Demo: Generating a Wan 2.2 Text-to-Video (8-Steps)

[00:22:27](https://youtu.be/3BFDcO2Ysu4?t=1347) Live Result: Image-to-Video Generation Finished

[00:23:34](https://youtu.be/3BFDcO2Ysu4?t=1414) Demo: Ultra-Fast Image Generation with Qwen (8-Steps)

[00:24:50](https://youtu.be/3BFDcO2Ysu4?t=1490) Live Result: Text-to-Video Generation Finished (Amazing Quality)

[00:25:21](https://youtu.be/3BFDcO2Ysu4?t=1521) Generation Speed Analysis & Downloading Your Video

[00:26:38](https://youtu.be/3BFDcO2Ysu4?t=1598) Comparing FLUX Krea Dev & Qwen Realism Presets

[00:28:46](https://youtu.be/3BFDcO2Ysu4?t=1726) How to Upscale Images to 2x High Resolution

[00:29:47](https://youtu.be/3BFDcO2Ysu4?t=1787) Summary of New Presets and Recommendations

[00:30:40](https://youtu.be/3BFDcO2Ysu4?t=1840) In-Depth: Training on FLUX Krea Dev (LoRA & DreamBooth)

[00:33:48](https://youtu.be/3BFDcO2Ysu4?t=2028) Coming Soon: One-Click Qwen Image Training Application

[00:36:11](https://youtu.be/3BFDcO2Ysu4?t=2171) Join The Community (Discord & Reddit) & Final Words

Advancements in AI Image and Video Generation in 2025

The year 2025 has marked a pivotal era for AI-driven content creation, with models pushing boundaries in realism, speed, and versatility. From text-to-video (T2V) to image editing, innovations like Mixture-of-Experts (MoE) architectures and enhanced prompt adherence are transforming industries such as film, advertising, and design.

Alibaba's Tongyi Wanxiang (Wan) 2.2 stands out as the first MoE-based video diffusion model, boasting 27 billion parameters (14B active) for cinematic T2V and image-to-video (I2V) at 720p resolution. It excels in motion dynamics, lighting control, and ultra-fast rendering, outperforming predecessors like Wan 2.1 in physics simulation and quality. Open-sourced on July 28, 2025, it's ideal for creators seeking high-fidelity outputs.

Qwen-Image, another Alibaba gem, is a 20B parameter MMDiT foundation model specializing in complex text rendering in English and Chinese, even in intricate scenes. Released in August 2025, it supports precise editing, style preservation, and multilingual prompts, surpassing benchmarks in text incorporation and aesthetics. Its open-source nature makes it a go-to for detailed image generation.

Black Forest Labs' Flux.1 [dev], a 12B parameter flow transformer, shines in text-to-image tasks with exceptional detail and commercial viability.

Some background music by NoCopyrightSounds  : [https://gist.github.com/FurkanGozukara/681667e5d7051b073f2e795794c46170](https://gist.github.com/FurkanGozukara/681667e5d7051b073f2e795794c46170)



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=0) Greetings everyone. Today I am going to introduce&nbsp; how to use state-of-the-art image generation and&nbsp;&nbsp;

- [00:00:07](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=7) video generation models with easiest and&nbsp; most accurate and best performance. I have&nbsp;&nbsp;

- [00:00:14](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=14) been relentlessly testing new Wan 2.2 LoRAs to&nbsp; update our presets. Moreover, not only Wan 2.2&nbsp;&nbsp;

- [00:00:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=24) LoRAs, but I also tested FLUX Dev and Qwen&nbsp; Image as well. And I will show all of them&nbsp;&nbsp;

- [00:00:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=32) to you in this tutorial video so that you&nbsp; will see the significant differences and&nbsp;&nbsp;

- [00:00:38](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=38) improvements we have for each preset. For&nbsp; example, here we are seeing the difference&nbsp;&nbsp;

- [00:00:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=45) between Wan 2.1 and new Wan 2.2 image-to-video&nbsp; model differences. As you can see that we have a&nbsp;&nbsp;

- [00:00:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=53) significant improvement with image-to-video. And&nbsp; this is the image used to generate those videos.&nbsp;

- [00:01:01](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=61) The difference in text-to-video is even more&nbsp; significant. This is Wan 2.1 text-to-video&nbsp;&nbsp;

- [00:01:07](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=67) base model and let's see what it generates. So you&nbsp; see, this was what we were generating with Wan 2.1&nbsp;&nbsp;

- [00:01:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=75) base model. And this is the prompt used. When we&nbsp; compare it with Wan 2.1 Fusion X text-to-video,&nbsp;&nbsp;

- [00:01:21](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=81) this is the result. As you can see, the result is&nbsp; also not good with Fusion X text-to-video. When&nbsp;&nbsp;

- [00:01:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=88) we move to old Wan 2.2 high quality text-to-video&nbsp; result, this is the result we get. This was our&nbsp;&nbsp;

- [00:01:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=96) best result with Wan 2.2 text-to-video previously.&nbsp; However, with the updated configuration,&nbsp;&nbsp;

- [00:01:43](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=103) let's see the results. So this is our Wan 2.2&nbsp; high quality text-to-video 20 steps. And let's&nbsp;&nbsp;

- [00:01:49](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=109) see the significant difference. So you see,&nbsp; there is a huge difference between this older&nbsp;&nbsp;

- [00:01:55](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=115) version to this newer version. By the way, if&nbsp; you are feeling that it is too fast, you can&nbsp;&nbsp;

- [00:02:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=120) reduce FPS. I will explain all of that. This is&nbsp; 24 FPS, 121 frames video. Moreover, we have a new&nbsp;&nbsp;

- [00:02:09](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=129) Wan 2.2 text-to-video 8 steps, and this is just&nbsp; amazing. You see, with only 8 steps, we are able&nbsp;&nbsp;

- [00:02:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=137) to generate this amazing video just from text. 24&nbsp; FPS, 121 frames video takes less than 5 minutes&nbsp;&nbsp;

- [00:02:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=148) on RTX 5090. If you generate 16 FPS, 81 frames&nbsp; video, it will be even faster, under 3 minutes.&nbsp;

- [00:02:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=156) Moreover, here another example with Wan 2.2 high&nbsp; quality text-to-video 20 steps, and you see this&nbsp;&nbsp;

- [00:02:44](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=164) is like an animation level quality. With only 20&nbsp; steps, I updated all the presets and newer presets&nbsp;&nbsp;

- [00:02:52](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=172) are generating amazing videos. This is 24 FPS&nbsp; and 121 frames, and you see the quality. And here&nbsp;&nbsp;

- [00:03:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=180) another example of Wan 2.2 image-to-video with&nbsp; only 8 steps. This is 16 FPS, 81 frames video,&nbsp;&nbsp;

- [00:03:08](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=188) and I can make RIFE 2x FPS increase and make&nbsp; it much more fluent. All I need is making this&nbsp;&nbsp;

- [00:03:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=196) frame interpolation enabled with making it&nbsp; 2x. And now it is regenerating it with 2x FPS&nbsp;&nbsp;

- [00:03:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=205) increase. Moreover, I have updated my Windows&nbsp; installation of SwarmUI, RunPod installation,&nbsp;&nbsp;

- [00:03:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=212) and Massed Compute installation to automatically&nbsp; install RIFE frame interpolation and also famous&nbsp;&nbsp;

- [00:03:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=220) TeaCache. They will be automatically installed&nbsp; when you make a fresh installation of Windows&nbsp;&nbsp;

- [00:03:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=225) or RunPod or Massed Compute with the newest zip&nbsp; file. But always, you can manually install like&nbsp;&nbsp;

- [00:03:52](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=232) clicking here, install TeaCache, or when you go&nbsp; to the image-to-video, you will see that there is&nbsp;&nbsp;

- [00:03:58](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=238) install RIFE, and from there you can install RIFE&nbsp; frame interpolation. And this is result of RIFE 2x&nbsp;&nbsp;

- [00:04:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=245) FPS increase. This is different seed, therefore&nbsp; the video is different, but you can see that it&nbsp;&nbsp;

- [00:04:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=251) looks much more smooth this way. Moreover, here&nbsp; another example of Wan 2.2 text-to-video with 8&nbsp;&nbsp;

- [00:04:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=258) steps, and you see the quality. This is generated&nbsp; with only 8 steps, therefore it is really fast,&nbsp;&nbsp;

- [00:04:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=265) and you can see that it is pretty good,&nbsp; pretty decent even though it is only 8 steps.&nbsp;

- [00:04:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=270) Furthermore, now we have Wan 2.2 image&nbsp; realism preset as well. With this preset,&nbsp;&nbsp;

- [00:04:37](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=277) you can generate really, really good realistic&nbsp; images like this. These are raw images. It is&nbsp;&nbsp;

- [00:04:42](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=282) not very good at stylized images like this.&nbsp; And when we compare same prompt with FLUX Dev,&nbsp;&nbsp;

- [00:04:49](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=289) this is the FLUX Dev result for realistic prompt,&nbsp; and this is FLUX Dev result for stylized prompt.&nbsp;&nbsp;

- [00:04:56](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=296) And let's compare with FLUX Krea Dev. This is&nbsp; FLUX Krea Dev. FLUX Krea Dev is also amazing at&nbsp;&nbsp;

- [00:05:02](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=302) realism, especially with humans. Its stylized&nbsp; prompt is like this as you are seeing right&nbsp;&nbsp;

- [00:05:08](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=308) now. It is also pretty decent. And now we have&nbsp; Qwen Image 8 steps. This is really, really fast,&nbsp;&nbsp;

- [00:05:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=315) like 10 times faster than before. This is Qwen 8&nbsp; steps fast result for realistic prompt, and this&nbsp;&nbsp;

- [00:05:22](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=322) is the stylized prompt result of the Qwen. As you&nbsp; are seeing, Qwen is unchallenged if your aim is&nbsp;&nbsp;

- [00:05:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=330) not realism. Hopefully, I will also make a video&nbsp; for realism of Qwen soon with training it, but so&nbsp;&nbsp;

- [00:05:37](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=337) far, these are the results and these are amazing. Qwen Image editing just has been published while&nbsp;&nbsp;

- [00:05:44](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=344) I was editing this video. It is looking&nbsp; amazing, extremely promising. Hopefully,&nbsp;&nbsp;

- [00:05:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=350) I will make a full tutorial, one-click install&nbsp; presets for it very soon. So it is not ready yet,&nbsp;&nbsp;

- [00:05:57](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=357) but I am showing you what it is capable of,&nbsp; what demo images they have published. Hopefully,&nbsp;&nbsp;

- [00:06:02](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=362) it is coming very soon. So stay subscribed&nbsp; and our tutorial is continuing right now.&nbsp;

- [00:06:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=370) And this is Qwen high quality preset we have. This&nbsp; is the result for realism prompts, and this is the&nbsp;&nbsp;

- [00:06:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=376) result for stylized prompt. As you can see that&nbsp; with stylized prompt, the 8 steps really fast&nbsp;&nbsp;

- [00:06:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=384) preset is almost same quality as high quality.&nbsp; Therefore, we are getting like 10 times speed gain&nbsp;&nbsp;

- [00:06:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=392) with almost no quality loss, as you are seeing,&nbsp; this to this. This is amazing. We also have Qwen&nbsp;&nbsp;

- [00:06:39](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=399) realism fast prompt. You see this is definitely&nbsp; more realistic than the high quality or 8 steps.&nbsp;&nbsp;

- [00:06:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=407) Let me show you, this is 8 steps, this is high&nbsp; quality, and this is our Qwen realism prompt.&nbsp;&nbsp;

- [00:06:52](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=412) It really makes it realistic and it's also faster&nbsp; than high quality of Qwen. And this is the result&nbsp;&nbsp;

- [00:06:58](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=418) of Qwen realism. It also made stylized prompt&nbsp; somewhat degree more realistic output compared&nbsp;&nbsp;

- [00:07:06](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=426) to the high quality or Qwen fast results. To find out all these new presets, I have&nbsp;&nbsp;

- [00:07:14](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=434) literally done hundreds of generations, analyzed&nbsp; hundreds of results. For example, let's open this&nbsp;&nbsp;

- [00:07:22](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=442) one randomly and let's see the result. This is the&nbsp; grid test that I did, and these are the results of&nbsp;&nbsp;

- [00:07:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=448) the grid test. So I did hundreds of tests like&nbsp; this. I have been doing this for several days,&nbsp;&nbsp;

- [00:07:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=454) analyzed all of them, and prepared these amazing&nbsp; presets for you. Furthermore, I did a DreamBooth&nbsp;&nbsp;

- [00:07:42](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=462) training on FLUX Krea Dev. This was our original&nbsp; post if you remember. And when you scroll down,&nbsp;&nbsp;

- [00:07:48](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=468) you will see that I have posted the comparison&nbsp; results of the FLUX Krea Dev with each epoch&nbsp;&nbsp;

- [00:07:55](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=475) grid. And in this tutorial, I will also&nbsp; analyze these and show you. I also did a&nbsp;&nbsp;

- [00:08:01](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=481) LoRA training on FLUX Krea Dev as well. The&nbsp; post is also updated and posted full grid as&nbsp;&nbsp;

- [00:08:08](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=488) well. So I will analyze the grid and compare&nbsp; results and make my comment on this training.&nbsp;

- [00:08:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=496) Another thing that I have to mention is that&nbsp; I am working on Qwen Image training right now,&nbsp;&nbsp;

- [00:08:21](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=501) developing an application. We will talk&nbsp; about this as well in this video. Moreover,&nbsp;&nbsp;

- [00:08:26](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=506) I have updated our ComfyUI installer as well.&nbsp; Now it will automatically install FFMPEG, RIFE,&nbsp;&nbsp;

- [00:08:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=512) and TeaCache on Massed Compute, and it is made&nbsp; more robust to update all of the extra nodes that&nbsp;&nbsp;

- [00:08:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=520) we automatically install. And finally, our SwarmUI&nbsp; installer. This is where we will get our presets,&nbsp;&nbsp;

- [00:08:46](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=526) our installers. This is a big update, and&nbsp; now we have automatically importing presets&nbsp;&nbsp;

- [00:08:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=533) feature as well. So let's begin the tutorial. So as usual, follow the links in the description&nbsp;&nbsp;

- [00:08:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=539) of the video. Download the SwarmUI model&nbsp; downloader latest version. Also download&nbsp;&nbsp;

- [00:09:04](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=544) the ComfyUI installer latest version. Move them&nbsp; into your installation folder and extract all&nbsp;&nbsp;

- [00:09:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=552) files and overwrite everything. You can use any&nbsp; extraction method. Everything is extracted. Let's&nbsp;&nbsp;

- [00:09:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=558) sort by name. Then update your SwarmUI. You see,&nbsp; Windows update SwarmUI, but before doing that,&nbsp;&nbsp;

- [00:09:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=564) I recommend you to update your ComfyUI as&nbsp; usual. So put the latest zip file into your&nbsp;&nbsp;

- [00:09:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=570) ComfyUI installation, extract and overwrite&nbsp; all the files, then first run Windows update&nbsp;&nbsp;

- [00:09:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=576) ComfyUI.bat file. We also improved the update&nbsp; process. Now it is much more robust. Okay,&nbsp;&nbsp;

- [00:09:42](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=582) update has been completed. Then return back&nbsp; to SwarmUI. Let's sort by name. Windows update&nbsp;&nbsp;

- [00:09:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=587) SwarmUI.bat file. Okay, run. It will update it&nbsp; with maximum accuracy and robustness, and it&nbsp;&nbsp;

- [00:09:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=594) will start the SwarmUI as usual. So if you don't&nbsp; know how to install ComfyUI and SwarmUI and setup,&nbsp;&nbsp;

- [00:10:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=600) this is the tutorial that you need to watch, but&nbsp; if you already have them installed, you are ready.&nbsp;

- [00:10:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=605) And the latest version of SwarmUI will start like&nbsp; this. You see, these are my existing presets. Let&nbsp;&nbsp;

- [00:10:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=611) me demonstrate you something. I will just make&nbsp; this like this, edit. And how you are going&nbsp;&nbsp;

- [00:10:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=615) to update the new presets that we have? Either&nbsp; you can use import preset feature, choose file,&nbsp;&nbsp;

- [00:10:22](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=622) go back to installation folder, amazing SwarmUI&nbsp; presets, overwrite. But if you have leftovers&nbsp;&nbsp;

- [00:10:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=628) that we have changed names or some other stuff,&nbsp; they will be staying here. But this is the way&nbsp;&nbsp;

- [00:10:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=634) of keeping your existing presets. If you want&nbsp; a clean import, you need to delete every one&nbsp;&nbsp;

- [00:10:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=640) of them like this and then import. I recommended&nbsp; the author of SwarmUI to add must delete option,&nbsp;&nbsp;

- [00:10:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=647) but it is not available yet. So I have&nbsp; developed a solution myself. You see,&nbsp;&nbsp;

- [00:10:51](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=651) Windows preset delete import.bat file. This file&nbsp; will ask you import or not. When you click yes,&nbsp;&nbsp;

- [00:11:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=660) it will automatically delete your existing&nbsp; presets, then it will import everything. However,&nbsp;&nbsp;

- [00:11:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=665) for this to work, you need to have SwarmUI&nbsp; running in 7861 port, which is the default port.&nbsp;&nbsp;

- [00:11:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=672) Currently, my SwarmUI is running in different port&nbsp; because I started it with Windows update file,&nbsp;&nbsp;

- [00:11:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=678) so I will close it. Let's close this as well and&nbsp; let's use the Windows start SwarmUI.bat file. This&nbsp;&nbsp;

- [00:11:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=684) will start it with the accurate port. And you&nbsp; see it is started. I will fix this issue when&nbsp;&nbsp;

- [00:11:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=688) you are watching. I will make both of them same&nbsp; port, but this is a reminding thing. Then I will&nbsp;&nbsp;

- [00:11:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=694) double-click Windows preset delete and import.bat&nbsp; file, click yes. And you see it deleted all of my&nbsp;&nbsp;

- [00:11:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=700) existing presets and imported new ones. Moreover,&nbsp; it will back up your existing presets into presets&nbsp;&nbsp;

- [00:11:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=707) backup folder that it generates automatically.&nbsp; And you see this is my deleted presets. They were&nbsp;&nbsp;

- [00:11:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=713) saved here. Now our presets are ready. Don't&nbsp; forget to click refresh icon because it may&nbsp;&nbsp;

- [00:12:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=720) still display older presets. Also, let's sort&nbsp; by name, and now all of our presets are ready.&nbsp;

- [00:12:06](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=726) So how you are going to use these presets? These&nbsp; presets will automatically select model files as&nbsp;&nbsp;

- [00:12:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=732) well. To be able to use them, you need to use&nbsp; Windows start download models up.bat file or&nbsp;&nbsp;

- [00:12:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=738) change the model names, paths yourself. This&nbsp; application is being developed. I am adding&nbsp;&nbsp;

- [00:12:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=745) new models, adding new bundles, improving its&nbsp; features. Currently, it supports so many models&nbsp;&nbsp;

- [00:12:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=750) that you can download. I recommend you to use&nbsp; SwarmUI bundles. We have Qwen Image core bundle.&nbsp;&nbsp;

- [00:12:35](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=755) It shows all the models, their sizes. We have Wan&nbsp; 2.2 core 8 steps bundle. It shows all the models&nbsp;&nbsp;

- [00:12:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=761) it is going to download, sizes. For example, with&nbsp; new Wan 2.2 presets, we are using these four new&nbsp;&nbsp;

- [00:12:48](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=768) LoRAs. Moreover, we have Wan 2.1 core bundle. You&nbsp; see all the models. We have FLUX models bundle.&nbsp;&nbsp;

- [00:12:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=774) So you can download all these bundles, then you&nbsp; will be ready to use all of them. So I recommend&nbsp;&nbsp;

- [00:12:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=779) to download them. For today's tutorial, you need&nbsp; to download Qwen Image core bundle, click it.&nbsp;&nbsp;

- [00:13:04](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=784) You need to download Wan 2.2 8 steps core bundle.&nbsp; And if you want to also test Wan 2.1, you need to&nbsp;&nbsp;

- [00:13:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=791) download this one. And if you want to also use&nbsp; FLUX, you need to download this one. These are&nbsp;&nbsp;

- [00:13:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=796) the core bundles. These are state-of-the-art&nbsp; image and video generation models. So just&nbsp;&nbsp;

- [00:13:22](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=802) download them and you will be ready. Moreover, if you are a ComfyUI user or&nbsp;&nbsp;

- [00:13:26](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=806) if you are fond of Focus, we support both of them.&nbsp; For ComfyUI, select this ComfyUI folder structure,&nbsp;&nbsp;

- [00:13:33](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=813) go back to your ComfyUI installation and go inside&nbsp; models like this, copy this path and give its path&nbsp;&nbsp;

- [00:13:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=821) like this. So now it will download into accurate&nbsp; ComfyUI folders such as LoRAs is changing with&nbsp;&nbsp;

- [00:13:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=827) ComfyUI compared to SwarmUI. Moreover, if you&nbsp; are Forge WebUI user, just check this out and&nbsp;&nbsp;

- [00:13:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=834) then give its path here, then it will download&nbsp; into there. Again, it is same for Forge WebUI,&nbsp;&nbsp;

- [00:13:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=839) you need to give this path. For example, we also&nbsp; have installer for Forge WebUI. It is updated,&nbsp;&nbsp;

- [00:14:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=845) it has more features. It is fully supporting&nbsp; RTX 5000 series. And if you want to make it&nbsp;&nbsp;

- [00:14:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=852) use lowercase folder names, just check this and&nbsp; when you click remember settings, it will save&nbsp;&nbsp;

- [00:14:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=858) them and when you start next time, it will use&nbsp; them. Moreover, you can manually download models&nbsp;&nbsp;

- [00:14:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=864) one by one. For example, image generation models,&nbsp; Qwen Image models. You see we have Qwen GGUF Q4,&nbsp;&nbsp;

- [00:14:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=870) GGUF Q5. So if you are low on VRAM, you can use&nbsp; them. However, with SwarmUI and ComfyUI, it will&nbsp;&nbsp;

- [00:14:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=876) automatically do block swapping, so you don't even&nbsp; need that. FLUX models, we have all of them here.&nbsp;&nbsp;

- [00:14:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=881) We have FLUX GGUF models, you see, all of them. We&nbsp; have High Dream models. However, I don't recommend&nbsp;&nbsp;

- [00:14:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=887) High Dream anymore. Qwen is coming so strong. It&nbsp; is the best model if you ask my opinion. Stable&nbsp;&nbsp;

- [00:14:52](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=892) Diffusion 1.5 models, Stable Diffusion XL models.&nbsp; So we support so many models. We support image&nbsp;&nbsp;

- [00:14:57](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=897) upscaling models, YOLO masking models. We have&nbsp; text encoders, UMT5 text encoders, CLIP models.&nbsp;&nbsp;

- [00:15:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=905) We have video generation models, huge, Wan 2.1&nbsp; official models, Wan 2.1 Fusion X models, Wan 2.1&nbsp;&nbsp;

- [00:15:13](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=913) LoRAs like this, Wan 2.2 official models. You&nbsp; see, we have also GGUF models, Wan 2.2 LoRAs.&nbsp;&nbsp;

- [00:15:20](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=920) So check this application out, and if you need any&nbsp; other models, you can message me from this video&nbsp;&nbsp;

- [00:15:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=925) or from Patreon, and hopefully I will add them. Once you downloaded all the models and imported&nbsp;&nbsp;

- [00:15:31](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=931) new presets, how you are going to use them? This&nbsp; is important. For example, Wan 2.2 image-to-video&nbsp;&nbsp;

- [00:15:37](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=937) 8 steps. Let's do a demo with it. So first of all,&nbsp; click Quick Tools and Reset params to default.&nbsp;&nbsp;

- [00:15:44](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=944) This is mandatory. Do this at every step and&nbsp; you will not have any issues. Then click this&nbsp;&nbsp;

- [00:15:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=950) hamburger menu and direct apply. Do not select it.&nbsp; Make direct apply. This is working better. You see&nbsp;&nbsp;

- [00:15:56](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=956) it did set every parameter, including the models&nbsp; and everything. Then click Init Image because&nbsp;&nbsp;

- [00:16:03](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=963) this is an image-to-video model. Choose file. For&nbsp; example, let's use this Pikachu for animation. So&nbsp;&nbsp;

- [00:16:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=970) I will select it. This is my image resolution,&nbsp; and this is the base resolution of the model.&nbsp;&nbsp;

- [00:16:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=975) You can always change the base resolution and&nbsp; it will automatically calculate new resolution&nbsp;&nbsp;

- [00:16:20](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=980) based on that. How you can change? From models,&nbsp; you see this model is automatically selected,&nbsp;&nbsp;

- [00:16:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=984) click here, edit metadata. Make sure that its&nbsp; architecture is accurate and this is the base&nbsp;&nbsp;

- [00:16:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=990) resolution of the model that you can change&nbsp; for automatic calculation, then save. Then&nbsp;&nbsp;

- [00:16:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=994) click this res and use closest aspect ratio. I&nbsp; recommend this. You can also use exact aspect&nbsp;&nbsp;

- [00:16:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1000) ratio for not cropping it, but closest aspect&nbsp; ratio is better. Then all I need to do is write&nbsp;&nbsp;

- [00:16:46](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1006) my prompt here. Do not change this. This is how it&nbsp; uses both of the lightning LoRAs because Wan 2.2&nbsp;&nbsp;

- [00:16:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1014) works with base and refiner model. This is how we&nbsp; are setting up two LoRAs for each of the models.&nbsp;

- [00:17:02](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1022) For writing a prompt to this image, I will use&nbsp; our prompt generation file. So type Google, Google&nbsp;&nbsp;

- [00:17:09](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1029) Studio AI. This is for free. Enter inside there.&nbsp; Click this plus icon after you log in with your&nbsp;&nbsp;

- [00:17:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1035) account. It is for free. This is amazing. Upload&nbsp; file. Go back to your SwarmUI model installation&nbsp;&nbsp;

- [00:17:21](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1041) and you will see that, let's sort by name, and&nbsp; you will see that we have video models prompt&nbsp;&nbsp;

- [00:17:26](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1046) generate guidance. This guidance can be used for&nbsp; Qwen Image generation as well. It is amazing. I&nbsp;&nbsp;

- [00:17:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1052) will type this. Write me a prompt for uploaded&nbsp; image with a very intense action scene. You can&nbsp;&nbsp;

- [00:17:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1060) type anything. Then I will click this upload icon&nbsp; and I will select my image. So upload both of&nbsp;&nbsp;

- [00:17:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1067) the files for Google Studio AI to process. I will&nbsp; make temperature like 50%. I like it. Set thinking&nbsp;&nbsp;

- [00:17:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1074) budget to maximum. Make sure that grounding with&nbsp; Google Search is off. So these are the parameters&nbsp;&nbsp;

- [00:17:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1079) and run. This model is just amazing. This is for&nbsp; free. Google is still providing Gemini Pro with&nbsp;&nbsp;

- [00:18:06](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1086) maximum context size, with maximum features in&nbsp; Google Studio AI. So leverage it for yourself&nbsp;&nbsp;

- [00:18:13](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1093) until it becomes paid. Okay, so it will do&nbsp; the thinking and write a prompt for us by&nbsp;&nbsp;

- [00:18:19](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1099) using our amazing video models prompt generation&nbsp; guidance. Okay, we are getting the prompt here. So&nbsp;&nbsp;

- [00:18:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1105) let's copy this and paste it here. If we read the&nbsp; prompt, it is cinematic, high contrast lighting,&nbsp;&nbsp;

- [00:18:31](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1111) low angle shot with a dynamic handheld camera&nbsp; feel, an intense action scene unfolds in a misty,&nbsp;&nbsp;

- [00:18:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1116) primal forest where a hyper-realistic, furry&nbsp; Pikachu is suddenly ambushed on a slick,&nbsp;&nbsp;

- [00:18:42](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1122) mossy rock by a churning stream, and it goes on.&nbsp; Just pause the video and read it. Then generate.&nbsp;

- [00:18:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1127) So currently, I am running this on RunPod because&nbsp; I am recording this video in my laptop right now.&nbsp;&nbsp;

- [00:18:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1134) So I want it to be fast and I will show you a&nbsp; trick. This is a usual setup that I have shown&nbsp;&nbsp;

- [00:18:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1139) you numerous times. I have installed the ComfyUI&nbsp; and I am using Sage Attention. This is exactly&nbsp;&nbsp;

- [00:19:04](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1144) same in my local computer as well. If you look at&nbsp; my local computer, this is its backend. Currently,&nbsp;&nbsp;

- [00:19:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1150) since I closed its terminal, it shows that it&nbsp; is failed to send. You see, this is my ComfyUI&nbsp;&nbsp;

- [00:19:14](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1154) installation. I am still using Sage Attention. By&nbsp; the way, currently Sage Attention is working with&nbsp;&nbsp;

- [00:19:19](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1159) Qwen Image as well when you update your ComfyUI&nbsp; and SwarmUI to the latest version. So use it.&nbsp;&nbsp;

- [00:19:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1165) And the generation will start soon. It is first&nbsp; loading the models. Okay, generation started.&nbsp;&nbsp;

- [00:19:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1170) Yeah, the trick that I was going to show you is&nbsp; that you see there is OverQueue. When I make this&nbsp;&nbsp;

- [00:19:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1174) zero, as soon as I hit generate, it will start the&nbsp; generation on next available GPU. So currently I&nbsp;&nbsp;

- [00:19:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1181) have four GPUs, so I can use all of them at the&nbsp; same time. And the generation started. By the way,&nbsp;&nbsp;

- [00:19:46](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1186) what else parameters that you can set other&nbsp; than the prompt? Let's click this way,&nbsp;&nbsp;

- [00:19:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1190) advanced options, and in here you will see that&nbsp; in the image-to-video, video frames. This is super&nbsp;&nbsp;

- [00:19:56](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1196) important. This determines the length of your&nbsp; video. Currently, since my video FPS is 24, which&nbsp;&nbsp;

- [00:20:04](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1204) is set is here, you see video FPS, this is what&nbsp; the image-to-video models uses. This will be 73&nbsp;&nbsp;

- [00:20:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1210) minus 1, the first frame, divided by 24. So this&nbsp; will be 3 seconds video. If you want it longer,&nbsp;&nbsp;

- [00:20:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1217) you can set this as 81 frames and 16 FPS, then it&nbsp; will be 5 seconds video, or you can even make it&nbsp;&nbsp;

- [00:20:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1225) 121 frames and 24 FPS, it will be 5 seconds video.&nbsp; So it is up to you. Test with your case and see&nbsp;&nbsp;

- [00:20:33](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1233) which one is working better. If you make it 16&nbsp; FPS, then I recommend you to also enable video&nbsp;&nbsp;

- [00:20:39](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1239) frame interpolation. When you set this as two,&nbsp; it will make it double FPS with almost realistic&nbsp;&nbsp;

- [00:20:48](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1248) quality. This is working great. By the way, I&nbsp; also have implemented automatic installation&nbsp;&nbsp;

- [00:20:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1253) of this video frame interpolation RIFE and also&nbsp; TeaCache into the installers. So when you next&nbsp;&nbsp;

- [00:21:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1260) time install, it will be automatically installed&nbsp; for both Windows and RunPod and Massed Compute.&nbsp;

- [00:21:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1265) So meanwhile this is getting generated, let's also&nbsp; generate a text-to-video. So quick tools, reset&nbsp;&nbsp;

- [00:21:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1271) params to default. Let's go back to preset, and&nbsp; I'm going to use Wan 2.2 text-to-video 8 steps.&nbsp;&nbsp;

- [00:21:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1277) So click here, direct apply. Everything is set,&nbsp; you see. Just type my prompt here, and I need to&nbsp;&nbsp;

- [00:21:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1284) change the resolution whichever I want. Let's make&nbsp; this 16:9, so this will be the resolution. How&nbsp;&nbsp;

- [00:21:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1290) many frames I want? Let's change the frame count&nbsp; for this. The frame count of text-to-video is set&nbsp;&nbsp;

- [00:21:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1296) here. So text-to-video and image-to-video uses&nbsp; different panels on SwarmUI. Then let's make this&nbsp;&nbsp;

- [00:21:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1301) 81 frames. I will make this 16 FPS and I will make&nbsp; it double FPS increase with RIFE and hit generate.&nbsp;&nbsp;

- [00:21:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1310) Then this will generate the video. By the way,&nbsp; if you want to see how it works in ComfyUI, go&nbsp;&nbsp;

- [00:21:56](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1316) to ComfyUI workflow and import from generate tab.&nbsp; It will import it. Let's just wait for it to load.&nbsp;&nbsp;

- [00:22:04](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1324) Okay, it is loaded. Import from generate tab,&nbsp; and this is the workflow that it uses. From here,&nbsp;&nbsp;

- [00:22:09](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1329) you can also verify how it is working and you will&nbsp; see that it is using both of the LoRAs accurately,&nbsp;&nbsp;

- [00:22:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1335) both of the base models accurately. I did&nbsp; spend huge time to prepare these easy-to-use,&nbsp;&nbsp;

- [00:22:22](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1342) very easy-to-use presets. And this is the&nbsp; generated video, live generated video from&nbsp;&nbsp;

- [00:22:27](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1347) image. You see with only 8 steps, and this is the&nbsp; quality of the generation. This is really good.&nbsp;&nbsp;

- [00:22:33](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1353) This is 3 seconds video. Let's see how much time&nbsp; it took. The generation took 3 minutes. You see,&nbsp;&nbsp;

- [00:22:39](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1359) only 3 minutes to generate this&nbsp; amazing quality video with Wan 2.2.&nbsp;

- [00:22:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1365) Let's also generate an image since we have updated&nbsp; Qwen Image with fast preset. I could use this&nbsp;&nbsp;

- [00:22:51](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1371) prompt, but let's give another command here. Make&nbsp; this prompt to generate a static image, not video.&nbsp;&nbsp;

- [00:23:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1380) Then hit run and let's see what we will get.&nbsp; So this way, you can both get video generation&nbsp;&nbsp;

- [00:23:06](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1386) prompts or you can get image generation prompts.&nbsp; Okay, we have a prompt here. Let's see. So let's&nbsp;&nbsp;

- [00:23:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1392) use both of the prompts to generate. First, let's&nbsp; use this prompt. So I will click quick tools,&nbsp;&nbsp;

- [00:23:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1396) reset params to default. Then what I need to do&nbsp; is select my preset. So let's sort this by name&nbsp;&nbsp;

- [00:23:22](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1402) to not get confused because it is by default is&nbsp; different. Then I will select Qwen Image 8 steps&nbsp;&nbsp;

- [00:23:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1408) ultra fast. So direct apply, write my prompt, and&nbsp; generate. This will really fast generate an image&nbsp;&nbsp;

- [00:23:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1414) with Qwen Image and the quality is just amazing.&nbsp; You will see in a moment. Currently it is loading&nbsp;&nbsp;

- [00:23:39](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1419) the model on next available GPU. You can always&nbsp; see it from server logs, debug, and let's see&nbsp;&nbsp;

- [00:23:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1425) what is happening. So you see it shows that got&nbsp; prompt on the ComfyUI 2. This means it is on the&nbsp;&nbsp;

- [00:23:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1430) third GPU right now. It is loading the model.&nbsp; Everything is automatically downloaded with my&nbsp;&nbsp;

- [00:23:55](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1435) automatic downloader. Everything is automatically&nbsp; set. So I am making this extremely easy to use and&nbsp;&nbsp;

- [00:24:01](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1441) way cheaper to use than online services. And&nbsp; everything is same in your local computer as&nbsp;&nbsp;

- [00:24:07](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1447) well. So just use it with your local computer if&nbsp; you have a decent GPU, or if you want to scale it,&nbsp;&nbsp;

- [00:24:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1452) use it on a cloud service like Massed Compute,&nbsp; which I recommend, or like RunPod. It is either&nbsp;&nbsp;

- [00:24:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1457) way fine. So this is the generation of the video.&nbsp; The Qwen Image model is still being loaded. RunPod&nbsp;&nbsp;

- [00:24:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1464) is really slow when loading the models. On my&nbsp; computer, this is almost lightning fast. Second&nbsp;&nbsp;

- [00:24:29](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1469) video is almost done. Once this Qwen Image model&nbsp; loaded, we will be able to generate way faster.&nbsp;&nbsp;

- [00:24:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1474) Okay, you see the generation started. It is really&nbsp; fast. This is real-time generation. It is really&nbsp;&nbsp;

- [00:24:39](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1479) fast. And generation almost finished. We will&nbsp; see in a moment. And you see now it is working&nbsp;&nbsp;

- [00:24:44](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1484) with Sage Attention as well. Okay, the image has&nbsp; been generated. Let's see it. My internet is slow,&nbsp;&nbsp;

- [00:24:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1490) unfortunately. Yes, you see, this is an amazing&nbsp; composition as you are seeing right now. So let's&nbsp;&nbsp;

- [00:24:57](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1497) see the other prompt that it generated. I will&nbsp; just... Oh, by the way, this is the text-to-video&nbsp;&nbsp;

- [00:25:03](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1503) result. Let's also see that. Yes. This has been&nbsp; generated with 8 steps from text-to-video. You&nbsp;&nbsp;

- [00:25:09](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1509) see the quality? This is just amazing, amazing&nbsp; quality with an amazing prompt. Wan 2.2 is&nbsp;&nbsp;

- [00:25:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1516) just amazing. This is mind-blowing quality. And how much time did this take? We generated&nbsp;&nbsp;

- [00:25:21](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1521) this live when we are recording the video. This&nbsp; took only 3.86 minutes, under 4 minutes, as you&nbsp;&nbsp;

- [00:25:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1528) are seeing. And this is 81 frames, 5 seconds video&nbsp; with RIFE interpolation 2x. So this is actually&nbsp;&nbsp;

- [00:25:35](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1535) 32 FPS right now. So I can just download this.&nbsp; How? Click more, download, and it will download&nbsp;&nbsp;

- [00:25:42](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1542) it into your computer. When I open it, I can&nbsp; view it in my computer. When I see properties,&nbsp;&nbsp;

- [00:25:48](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1548) I can see FPS. By the way, it is not exactly 5&nbsp; seconds because we are trimming first four frames,&nbsp;&nbsp;

- [00:25:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1554) which usually causes some color differences. So&nbsp; maybe you noticed it with other generations. This&nbsp;&nbsp;

- [00:26:01](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1561) is why. Okay, let's return back to generation of&nbsp; the static image. Let's generate because currently&nbsp;&nbsp;

- [00:26:06](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1566) setup is selected for Qwen Image. And the next&nbsp; generation will be much faster. So the first&nbsp;&nbsp;

- [00:26:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1571) generation was 86 seconds. Let's see the second&nbsp; generation. Okay, it is getting generated with 8&nbsp;&nbsp;

- [00:26:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1577) steps with Qwen Image. And it is done. Yes. Yes,&nbsp; you see the quality? This took only 20 seconds.&nbsp;&nbsp;

- [00:26:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1585) You see Qwen Image only taking 20 seconds with 8&nbsp; steps. Making these presets really took huge time&nbsp;&nbsp;

- [00:26:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1592) of me. So I really recommend you to use them. Let's also generate with FLUX Krea Dev. I also&nbsp;&nbsp;

- [00:26:38](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1598) updated that. So reset params to default.&nbsp; Let's direct apply FLUX Krea Dev here and&nbsp;&nbsp;

- [00:26:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1605) generate. Now it will generate with FLUX Krea Dev.&nbsp; Meanwhile it is generating with FLUX Krea Dev,&nbsp;&nbsp;

- [00:26:50](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1610) let's also generate with Wan 2.2 image realism.&nbsp; This is not a very realistic prompt, but let's&nbsp;&nbsp;

- [00:26:56](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1616) see. Reset params to default, direct apply. Just&nbsp; type the prompt here. Do not change whatever it&nbsp;&nbsp;

- [00:27:02](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1622) writes here. This is important to work accurately.&nbsp; Okay, generate. So whenever you change a model,&nbsp;&nbsp;

- [00:27:08](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1628) a preset, always quick tools, reset params to&nbsp; default to not make any mistakes. Then direct&nbsp;&nbsp;

- [00:27:14](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1634) apply. Okay, this is I think FLUX Krea... Oh,&nbsp; this is probably Qwen Image realism because the&nbsp;&nbsp;

- [00:27:20](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1640) Qwen models were already loaded on my GPUs. Yes,&nbsp; this is Qwen Image realism. This is not a very&nbsp;&nbsp;

- [00:27:27](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1647) realistic prompt. I will also make a realistic&nbsp; prompt. Oh, really good. You see? Still really,&nbsp;&nbsp;

- [00:27:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1652) really high quality even though this is a not a&nbsp; real realistic prompt. This is not a prompt of a&nbsp;&nbsp;

- [00:27:37](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1657) man. Let's make the prompt for a realistic one.&nbsp; Photo of a an handsome man wearing an expensive&nbsp;&nbsp;

- [00:27:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1665) suit in an amazing garden. Let's generate. And&nbsp; this is FLUX Krea Dev. You see FLUX Krea is also&nbsp;&nbsp;

- [00:27:52](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1672) extremely optimized for realistic images. This is&nbsp; really, really good, really, really decent image.&nbsp;&nbsp;

- [00:27:58](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1678) Our presets are also using the very best available&nbsp; samplers and schedulers, all optimized for highest&nbsp;&nbsp;

- [00:28:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1685) quality with minimal loss of speed. Qwen Image&nbsp; realism generating this realistic prompt,&nbsp;&nbsp;

- [00:28:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1692) rather realistic. And here, this is raw generation&nbsp; of Qwen Image realism. Probably I need to work on&nbsp;&nbsp;

- [00:28:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1698) the prompt. This is a very primitive prompt.&nbsp; Let's also try this prompt on FLUX Krea Dev.&nbsp;&nbsp;

- [00:28:23](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1703) So I will just direct apply and just type it.&nbsp; Since it is loaded on the GPU, it will right away&nbsp;&nbsp;

- [00:28:29](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1709) use it. You see with the SwarmUI, it is handling&nbsp; everything automatically for me and really fast.&nbsp;&nbsp;

- [00:28:35](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1715) I am using four GPUs at the same time. If you&nbsp; have multiple GPUs on your computer, whether it&nbsp;&nbsp;

- [00:28:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1720) is on cloud service or whether it is on your local&nbsp; computer, it will work. And this is FLUX Krea Dev.&nbsp;

- [00:28:46](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1726) Let's also do 2x upscale. So I will just direct&nbsp; apply. This is selecting FLUX Dev by default,&nbsp;&nbsp;

- [00:28:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1733) but I am going to just change the model from&nbsp; here. So if your model names are different,&nbsp;&nbsp;

- [00:28:58](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1738) you need to also change them. Let's generate.&nbsp; This time, we will both generate and 2x upscale&nbsp;&nbsp;

- [00:29:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1745) with our upscaling workflow and let's see the&nbsp; results. The upscaling will be slow because&nbsp;&nbsp;

- [00:29:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1750) the resolution is now will be four times&nbsp; higher compared to what we were generating,&nbsp;&nbsp;

- [00:29:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1755) so it will be taking four times duration. We can&nbsp; always see server logs. By the way, it won't be&nbsp;&nbsp;

- [00:29:21](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1761) exactly four times. Why? Because we are doing&nbsp; lesser steps this time. Okay, it will be still&nbsp;&nbsp;

- [00:29:26](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1766) pretty fast. Okay, upscaling started. So this&nbsp; is how you use the presets. This is four times&nbsp;&nbsp;

- [00:29:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1772) upscaled. Let's open in a new tab. The resolution&nbsp; is 2048 to 2048. Let me make it default. Okay,&nbsp;&nbsp;

- [00:29:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1781) so this is upscaled FLUX Krea Dev image. So this is how you use presets. I recommend you to&nbsp;&nbsp;

- [00:29:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1787) try all of them. If you want the highest quality,&nbsp; then we have Wan 2.2 high quality 20 steps. As you&nbsp;&nbsp;

- [00:29:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1794) do more steps, it becomes better, but quality of&nbsp; this also amazing. And we also have Wan 2.2 high&nbsp;&nbsp;

- [00:30:01](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1801) quality 20 steps. This is also super quality. This&nbsp; takes long. I am also keeping older presets from&nbsp;&nbsp;

- [00:30:07](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1807) now on, which is beginning with Z letter, Z old&nbsp; Wan 2.2 high quality, Z old Wan 2.2 8 steps. So&nbsp;&nbsp;

- [00:30:15](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1815) you don't need to use them, but I'm just keeping&nbsp; them if you want to compare later. Moreover,&nbsp;&nbsp;

- [00:30:19](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1819) the Qwen 8 steps ultra fast is matching with Qwen&nbsp; Image high quality and it is almost like six times&nbsp;&nbsp;

- [00:30:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1828) to 10 times faster than the high quality that we&nbsp; had previously. So use this Qwen Image 8 steps&nbsp;&nbsp;

- [00:30:34](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1834) and it is amazing as I just shown you. For FLUX&nbsp; context, follow the tutorial for FLUX context.&nbsp;

- [00:30:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1840) Okay, what about FLUX Krea Dev training? Because&nbsp; I have been getting asked of it. FLUX Krea Dev&nbsp;&nbsp;

- [00:30:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1847) training is right away working with our FLUX&nbsp; Dev training. Just use the latest zip file,&nbsp;&nbsp;

- [00:30:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1853) download models, it will automatically download&nbsp; FLUX Krea Dev as well. And I have made training,&nbsp;&nbsp;

- [00:30:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1859) but not only made training, I also posted&nbsp; comparisons and my opinions. FLUX Krea Dev is&nbsp;&nbsp;

- [00:31:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1865) requiring either higher learning rate slightly or&nbsp; more epochs. My followers also verified that. So&nbsp;&nbsp;

- [00:31:12](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1872) you can download these epoch grid comparisons from&nbsp; here. The links are in the post. And when you open&nbsp;&nbsp;

- [00:31:18](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1878) them, you will see full quality grid comparisons&nbsp; like this. For example, this is epoch 150,&nbsp;&nbsp;

- [00:31:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1885) trained on same data set. I also trained with&nbsp; slightly lower and higher learning rate. So this&nbsp;&nbsp;

- [00:31:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1890) is our FLUX Dev DreamBooth. This is slightly lower&nbsp; FLUX Krea Dev DreamBooth. This is same as FLUX Dev&nbsp;&nbsp;

- [00:31:38](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1898) learning rate, and this is slightly higher FLUX&nbsp; Dev learning rate on FLUX Krea. So in my opinion,&nbsp;&nbsp;

- [00:31:45](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1905) FLUX Krea is working better at some prompts&nbsp; and some cases. For example, for this prompt,&nbsp;&nbsp;

- [00:31:52](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1912) FLUX Krea is definitely better, more matching&nbsp; to my face, more realistic. For example,&nbsp;&nbsp;

- [00:31:58](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1918) in this case, FLUX Krea Dev is different than&nbsp; FLUX Dev. So it's a taste whichever you like.&nbsp;&nbsp;

- [00:32:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1925) I think FLUX Krea Dev looks more realistic,&nbsp; but FLUX Dev has some better, I don't know,&nbsp;&nbsp;

- [00:32:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1931) maybe details. It is up to you. For example,&nbsp; in this case, let's look at the results.&nbsp;&nbsp;

- [00:32:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1937) So FLUX Dev again looks more colorful, more&nbsp; lively. So it is up to you whichever the one&nbsp;&nbsp;

- [00:32:24](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1944) you like. You can train on both of the models and&nbsp; compare. Our workflows and presets are just right&nbsp;&nbsp;

- [00:32:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1950) away working. Just train, analyze these grids&nbsp; yourself on your computer and decide yourself.&nbsp;

- [00:32:36](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1956) Moreover, I also trained a FLUX Krea LoRA. I&nbsp; also shared the grid, exactly same configuration,&nbsp;&nbsp;

- [00:32:42](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1962) workflow, presets is working. You can download&nbsp; the massive grid from here. When you download it,&nbsp;&nbsp;

- [00:32:48](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1968) you will see the grid. By the way, this grid is a&nbsp; little bit edited because I had to generate FLUX&nbsp;&nbsp;

- [00:32:55](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1975) Krea Dev on FLUX Krea Dev base model and FLUX LoRA&nbsp; on FLUX Dev base model. So I compiled this grid.&nbsp;&nbsp;

- [00:33:02](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1982) This is not raw output of the SwarmUI, but this is&nbsp; accurate way of displaying. It shows starting from&nbsp;&nbsp;

- [00:33:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1990) epoch 125 up to 200 epochs. Compare yourself. I&nbsp; think FLUX LoRA is better than FLUX Krea Dev LoRA,&nbsp;&nbsp;

- [00:33:19](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=1999) but it is up to you. Just train on both&nbsp; of them, whichever version you like more,&nbsp;&nbsp;

- [00:33:25](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2005) just see it. It may not be working on these&nbsp; prompts, but it may work better on your prompts.&nbsp;&nbsp;

- [00:33:30](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2010) So it may be depending on prompts. Definitely FLUX&nbsp; Krea Dev is more realistic when we compare these&nbsp;&nbsp;

- [00:33:37](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2017) two images. FLUX Krea Dev has more realism in&nbsp; itself, but as I said, it depends on your prompt,&nbsp;&nbsp;

- [00:33:43](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2023) your case, your data set. So train and compare&nbsp; and see yourself. It is working right away.&nbsp;

- [00:33:48](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2028) So what about Qwen Image training? Because&nbsp; I have been getting asked of it and what I&nbsp;&nbsp;

- [00:33:55](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2035) believe is that the Qwen Image will surpass the&nbsp; FLUX Dev in every case because its base model is&nbsp;&nbsp;

- [00:34:03](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2043) better than in every case from FLUX Dev, even&nbsp; at the realism, better than FLUX Dev. Its base&nbsp;&nbsp;

- [00:34:10](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2050) resolution is better, its prompt following&nbsp; is better, its prompt composition is better,&nbsp;&nbsp;

- [00:34:14](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2054) everything is better. For training Qwen Image,&nbsp; I am going to use Kohya Musubi Tuner and I am&nbsp;&nbsp;

- [00:34:20](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2060) developing an amazing Gradio application for it&nbsp; with all the features, with all the parameters,&nbsp;&nbsp;

- [00:34:27](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2067) options available. You can see this is the&nbsp; interface. It is not complete yet. I am still&nbsp;&nbsp;

- [00:34:32](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2072) developing it. Then I will find the very best&nbsp; configurations for every GPU. I think as low as&nbsp;&nbsp;

- [00:34:39](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2079) 6 or 8 GB GPUs will be able to train Qwen Image&nbsp; model, maybe 10 GB, we will see it. Then you will&nbsp;&nbsp;

- [00:34:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2087) be able to train Qwen Image on your computer or&nbsp; on cloud service with just one click as we did for&nbsp;&nbsp;

- [00:34:54](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2094) FLUX models. You see there are so many options.&nbsp; I will test all of them. Don't you worry. The&nbsp;&nbsp;

- [00:34:59](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2099) presets will be just ready to use. You will just&nbsp; load it and use it right away. I am adding all the&nbsp;&nbsp;

- [00:35:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2105) features. Moreover, I am adding other features&nbsp; that Kohya is implementing into Musubi Tuner,&nbsp;&nbsp;

- [00:35:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2111) like image captioning, which has been arrived&nbsp; recently. So you will be able to batch caption&nbsp;&nbsp;

- [00:35:17](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2117) with Qwen text encoder itself, Qwen VL itself.&nbsp; You will be able to single image caption or&nbsp;&nbsp;

- [00:35:23](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2123) just batch caption. I don't know if the caption&nbsp; will be necessary for Qwen Image. We will see it&nbsp;&nbsp;

- [00:35:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2128) after we done the research, but I am adding&nbsp; the features. Moreover, I will implement Wan&nbsp;&nbsp;

- [00:35:35](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2135) 2.2 training into this application as well since&nbsp; Kohya is implementing it into Musubi Tuner. This&nbsp;&nbsp;

- [00:35:41](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2141) Musubi Tuner is what is originally made in&nbsp; the original repo of this application, but&nbsp;&nbsp;

- [00:35:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2147) I am developing a completely different one right&nbsp; now. I still didn't delete it. However, what I am&nbsp;&nbsp;

- [00:35:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2153) developing is Qwen Image LoRA. There will be Wan&nbsp; 2.2 training tab and image captioning so far. So&nbsp;&nbsp;

- [00:36:00](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2160) this will be one-click install, one-click setup,&nbsp; one-click download, everything will be so easy,&nbsp;&nbsp;

- [00:36:05](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2165) so ready with highest possible quality, hopefully. So if you have any questions, always ask me. I&nbsp;&nbsp;

- [00:36:11](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2171) recommend you to join our Discord channel. It is&nbsp; SECourses Discord. When you type it to the Google,&nbsp;&nbsp;

- [00:36:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2176) you will get to that. Just join server&nbsp; and message me from there if you want.&nbsp;&nbsp;

- [00:36:21](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2181) We have 11,000 members. We are growing.&nbsp; Currently 1,200 people is online. Moreover,&nbsp;&nbsp;

- [00:36:28](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2188) we have growing Reddit page. You see SECourses.&nbsp; Our member count is growing, our visit count,&nbsp;&nbsp;

- [00:36:35](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2195) everything is growing. By the way, our visit count&nbsp; was over 500k. Currently it is displaying with a&nbsp;&nbsp;

- [00:36:40](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2200) bug. I don't know why. I am posting so many&nbsp; good stuff here, news about AI, technology,&nbsp;&nbsp;

- [00:36:47](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2207) science. You will see so many good stuff here. I&nbsp; recommend you. I'm also sharing news regarding our&nbsp;&nbsp;

- [00:36:53](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2213) developed applications. For example, All-Joy&nbsp; captions have been recently updated. I'm also&nbsp;&nbsp;

- [00:36:58](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2218) posting sometimes research results, the things&nbsp; that I do. For example, Qwen Image inpainting&nbsp;&nbsp;

- [00:37:04](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2224) coming, almost there. I will hopefully also make&nbsp; a video for it. The experiments I am conducting,&nbsp;&nbsp;

- [00:37:09](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2229) a lot of robotics, but AI-related all of stuff&nbsp; I am sharing here if I find them funny. So I&nbsp;&nbsp;

- [00:37:16](https://www.youtube.com/watch?v=3BFDcO2Ysu4&t=2236) really recommend you to join our Reddit as well.&nbsp; Hopefully, see you in next amazing tutorial video.

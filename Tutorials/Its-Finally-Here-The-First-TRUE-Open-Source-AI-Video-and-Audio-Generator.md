# It's Finally Here: The First TRUE Open-Source AI Video & Audio Generator

## Full tutorial link > https://www.youtube.com/watch?v=T00VmkMQRPQ

[![It's Finally Here: The First TRUE Open-Source AI Video & Audio Generator](https://img.youtube.com/vi/T00VmkMQRPQ/sddefault.jpg)](https://www.youtube.com/watch?v=T00VmkMQRPQ "It's Finally Here: The First TRUE Open-Source AI Video & Audio Generator")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Its-Finally-Here-The-First-TRUE-Open-Source-AI-Video-and-Audio-Generator.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Its-Finally-Here-The-First-TRUE-Open-Source-AI-Video-and-Audio-Generator.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Forget waiting lists and expensive APIs. The era of closed-off, corporate-controlled AI video generation is soon over. This is Ovi : The first-ever public, open-source model that generates both VIDEO and synchronized AUDIO, and you can run it on your own computer‚Äîeven with a 6GB GPU! This isn't just a demo; it's a full, step-by-step revolution.

Ovi Pro Premium Download Link : https://www.patreon.com/posts/download-ovi-pro-premium-140393220

Windows Requirements Tutorial : https://youtu.be/DrhUHnYfwC0

SECourses Discord : https://discord.com/servers/software-engineering-courses-secourses-772774097734074388

SECourses Reddit : https://www.reddit.com/r/SECourses/

My LinkedIn : https://www.linkedin.com/in/furkangozukara/

In this ultimate A-Z guide, I'll show you EVERYTHING you need to know to install and master this Sora 2 and VEO3 like AI. We'll go from zero to generating incredible talking videos from text or a single image.

üî• In This Tutorial, You Will Learn To:
üéì Master the Ultimate SORA 2 and VEO 3 Alternative: The first true open-source challenger to OpenAI & Google.
üíª Run on Low-Spec Hardware: We've optimized this to run on GPUs with as little as 6GB of VRAM!
üí∏ Generate for FREE: No credits, no subscriptions. Run it locally on Windows or cheaply in the cloud.
üó£Ô∏è Create Synced Audio & Video: Go beyond silent movies. Make your characters speak with perfect lip-sync.
‚òÅÔ∏è Install ANYWHERE: Complete one-click install guides for Windows, MassCompute, and RunPod.
üñºÔ∏è Animate Any Image: Bring your static images to life with stunning animation and speech.
üöÄ Unlock Pro Features: Dive deep into batch processing, video extensions, LoRA support, and advanced optimizations.

üïí VIDEO CHAPTERS:

0:00 Introduction to OVI: The First Open-Source Audio+Video AI
0:37 Impressive AI Video Generation Demos
1:00 Core Capabilities: Text-to-Video & Image-to-Video Animation
1:26 UI Walkthrough: Uploading Images & Videos
1:39 Auto Cropping, Padding & Aspect Ratio Control
1:53 Adjusting Base & Output Video Resolution
2:23 Using Built-in Examples & Understanding Prompt Structure
2:36 Essential Prompting Syntax: Speaking & Audio Tags
2:49 Built-in Prompt Validation & Syntax Error Checker
3:05 Advanced Feature: Seamless Video Extension & Storytelling
3:52 How Video Extension Uses the Last Frame for Continuity
4:19 Setting Custom Video Duration & FPS Explained
4:38 Using a Video as an Initial Input Frame
4:53 Seed, Disabling Audio & Full Metadata Explained
5:22 How to Use LoRAs with OVI (Video & Sound Layers)
6:38 DEEP DIVE: GPU & Memory Optimization Settings
6:51 Block Swap: Running on Low VRAM GPUs (6GB+)
7:11 CPU Offloading & "Clear All Memory" for Low RAM Systems
7:44 Intelligent Scaled FP8 for VRAM Reduction & Quality
8:25 Tiled VAE Decode: The Key to Low VRAM Performance
8:48 Using the Full Preset System for Different Setups
9:09 Pro Feature: Automated Batch Processing from a Folder
10:32 OVI Installation Guide Introduction (Windows, MassCompute, RunPod)
10:50 Step 1: Download & Extract the Files on Windows
11:12 Step 2: Running the One-Click Installer & Update Script
11:39 CRITICAL: Windows Prerequisite Installation Guide
12:53 Step 3: Using the Resumable Model Downloader
14:52 How to Update the Application
15:06 First Launch & Verification Test
18:18 Pro Tip: Running the App on a Second GPU
20:32 Advanced Prompting Guide: How to Write Effective Prompts
20:53 Using Google Gemini to Generate OVI Prompts (Detailed Walkthrough)
22:02 Pro Tip: Setting Custom Durations Per Prompt Line
23:21 Cloud Guide: How to Install on MassCompute
23:44 Deploying the Machine & Selecting the Right GPU
25:03 Connecting via ThinLinc & Transferring Files
25:45 Running the MassCompute Install Script
28:04 Accessing the App & Performance on MassCompute
29:53 Cloud Guide: How to Install on RunPod
30:21 Configuring the RunPod Pod (Template, Disk, GPU)
31:56 Connecting to JupyterLab & Uploading Files
32:26 Running the RunPod Install & Download Scripts
34:02 Accessing the App on RunPod (Gradio vs Proxy)
38:41 Pro Feature: Using the Gradio Queue System for Batch Jobs
40:45 Final Words, Support & Community Links (Discord, Reddit)



### Video Transcription


- 00:00:00.080 Greetings, everyone. Today, I am going to&nbsp; introduce you to Ovi, which is the first&nbsp;&nbsp;

- 00:00:04.240 public open-source model that can generate&nbsp; both audio and video at the same time,&nbsp;&nbsp;

- 00:00:09.040 like VEO 3 of Google or Sora 2 of OpenAI. We&nbsp; have implemented block swapping and intelligent&nbsp;&nbsp;

- 00:00:15.840 scaled FP8 base model from Kohya Musubi, and&nbsp; tiled VAE decode from ComfyUI, and our design,&nbsp;&nbsp;

- 00:00:23.280 clear all memory and CPU offloading. So with&nbsp; our amazing optimizations and our presets,&nbsp;&nbsp;

- 00:00:29.600 you can use this model locally on your Windows&nbsp; computer. Moreover, I will show on Massed&nbsp;&nbsp;

- 00:00:35.040 Compute and RunPod as well in this tutorial. This little powerhouse is the future of on-device&nbsp;&nbsp;

- 00:00:40.000 AI. We explore it this week on SECourses.&nbsp; People worry about AI taking jobs. At SECourses,&nbsp;&nbsp;

- 00:00:45.600 we teach you how to build with it instead.&nbsp; They say I built this suit in a cave. I have&nbsp;&nbsp;

- 00:00:51.440 watched empires rise and fall like tides.&nbsp; The patterns of history are a code. AI is&nbsp;&nbsp;

- 00:00:57.760 finally learning to read it. Join us at SECourses. As we have seen, it is able to generate extremely&nbsp;&nbsp;

- 00:01:03.760 realistic videos from just text, like this,&nbsp; like this, or you can provide an image input&nbsp;&nbsp;

- 00:01:10.480 like this and it is perfectly able to animate&nbsp; it as well. Moreover, our application has so&nbsp;&nbsp;

- 00:01:16.560 many features like generating multiple videos and&nbsp; automatically merging them like this case. So let&nbsp;&nbsp;

- 00:01:24.000 me show you some of the features that we have. First of all, you can upload either images or&nbsp;&nbsp;

- 00:01:29.600 videos. Let me demonstrate. When you&nbsp; upload a video like this, it will get&nbsp;&nbsp;

- 00:01:34.880 the last frame automatically, or you can upload&nbsp; an image. Based on your selected aspect ratio,&nbsp;&nbsp;

- 00:01:41.600 it will automatically crop it like this. Or,&nbsp; you can enable auto padding feature and it&nbsp;&nbsp;

- 00:01:47.120 will automatically pad. Moreover, you are able&nbsp; to change the base width and height. So when&nbsp;&nbsp;

- 00:01:53.040 you change the base width and height, it will&nbsp; automatically change the video width and height&nbsp;&nbsp;

- 00:01:58.880 like this, and it will automatically crop it.&nbsp; You see, cropped image resolution is here, and&nbsp;&nbsp;

- 00:02:04.160 the base image resolution is here. You can also&nbsp; change the resolution from here like this, and you&nbsp;&nbsp;

- 00:02:10.160 will see the output image immediately, the video&nbsp; that you are going to get immediately. You can,&nbsp;&nbsp;

- 00:02:16.960 of course, always automatically pad. Then when&nbsp; you pad it, it will add black pixels like this.&nbsp;

- 00:02:23.120 We have prepared so many examples to show you how&nbsp; to use this application. Go to the examples tab,&nbsp;&nbsp;

- 00:02:29.280 and you can load any example. It will immediately&nbsp; load the example like this. This model requires&nbsp;&nbsp;

- 00:02:34.720 specific prompting. You need to specify the&nbsp; speaking between &lt;S&gt; and &lt;E&gt; tags like this,&nbsp;&nbsp;

- 00:02:41.360 and you can define the audio properties between&nbsp; &lt;audio_cap&gt; and &lt;/audio_cap&gt; tags like this. Our&nbsp;&nbsp;

- 00:02:49.280 application has built-in validate prompt format,&nbsp; so it will automatically warn you. For example,&nbsp;&nbsp;

- 00:02:55.760 let's make this invalid. Click generate&nbsp; video, and it will show you prompt syntax&nbsp;&nbsp;

- 00:03:00.880 error. You can enable this checkbox to&nbsp; skip automatic validation if you want.&nbsp;

- 00:03:05.680 We have enabled video extension feature. This&nbsp; feature works amazing. Let me demonstrate. Let's&nbsp;&nbsp;

- 00:03:11.360 go to examples. Let's go to text-to-video extend&nbsp; examples or image-to-video extend examples. You&nbsp;&nbsp;

- 00:03:17.280 can use‚Ä¶ When you click load example, it will&nbsp; automatically load the image, automatically&nbsp;&nbsp;

- 00:03:21.760 crop according to your resolution and other&nbsp; settings. And you see, this is a three lines&nbsp;&nbsp;

- 00:03:27.360 of prompt. You can also put new lines, it is fine.&nbsp; And each line will be generated as a single video,&nbsp;&nbsp;

- 00:03:35.120 then it will be automatically merged into a&nbsp; single output, as we have seen in this video.&nbsp;&nbsp;

- 00:03:41.360 Instead of this "enable video extension," you can&nbsp; enable "multiline prompts," and each prompt will&nbsp;&nbsp;

- 00:03:46.160 be generated separately and will not be merged.&nbsp; When we enable the video extension last frame,&nbsp;&nbsp;

- 00:03:52.880 it is using the last frame of the previous video.&nbsp; Let me show you. Let's open the outputs folder,&nbsp;&nbsp;

- 00:03:59.040 and inside here, you will see used source images.&nbsp; And the extension used images will be shown like&nbsp;&nbsp;

- 00:04:06.000 this. So this was the input frame of the second&nbsp; video, and this was the input frame of the third&nbsp;&nbsp;

- 00:04:12.480 video. For image-to-video, again, we are saving&nbsp; which image was used to generate that video.&nbsp;

- 00:04:18.880 You can set duration from here. You can set it&nbsp; like 10 seconds. However, this model is made&nbsp;&nbsp;

- 00:04:24.240 for 5 seconds, and each video is 121 frames with&nbsp; 24 FPS. So when you make it more than 5 seconds,&nbsp;&nbsp;

- 00:04:33.200 the results are good as a video, but the&nbsp; speaking is getting somewhat broken. Moreover,&nbsp;&nbsp;

- 00:04:39.360 when you provide a video input in here,&nbsp; like this one, it will use its last frame,&nbsp;&nbsp;

- 00:04:45.440 and it will automatically combine and generate&nbsp; the merged video. If you enable this checkbox,&nbsp;&nbsp;

- 00:04:51.840 it will not automatically combine it. We have video seed. It is set as 99 as a&nbsp;&nbsp;

- 00:04:57.200 default. You can randomize, and it will randomize&nbsp; seed. Moreover, you can disable audio, so the&nbsp;&nbsp;

- 00:05:02.000 generated video will not have audio. However, this&nbsp; is not preventing speaking of the characters. We&nbsp;&nbsp;

- 00:05:07.920 have full metadata feature. Every generation will&nbsp; be saved with its metadata. So when you open your&nbsp;&nbsp;

- 00:05:14.320 generations and when you open the metadata file,&nbsp; you will see all the information, all the used&nbsp;&nbsp;

- 00:05:20.640 settings for this generation. We support LoRA&nbsp; feature, so you can load your LoRAs as you wish.&nbsp;&nbsp;

- 00:05:27.280 They are working. So far, we have tested 1 to 2.5&nbsp; billion model LoRAs. For example, this glowing&nbsp;&nbsp;

- 00:05:33.680 eyes is working really good. So you can select&nbsp; up to four LoRAs with each one having different&nbsp;&nbsp;

- 00:05:39.040 scale. This model has two layers: video layers and&nbsp; sound layers. So you can apply your LoRA to each&nbsp;&nbsp;

- 00:05:45.040 layer or both of them. Where you need to put&nbsp; your LoRAs is inside the LoRAs folder like this.&nbsp;

- 00:05:50.640 You can use different solvers, but UniPC is&nbsp; working and it is the recommended one. 50&nbsp;&nbsp;

- 00:05:55.680 steps is recommended. So when you are generating a&nbsp; video, it will do 50 steps generation, but you can&nbsp;&nbsp;

- 00:06:00.880 do like 20, it will reduce quality. You can set&nbsp; number of generations. So when you set it as 10,&nbsp;&nbsp;

- 00:06:06.800 it will start generating videos, same video with&nbsp; different seed, so you will get different results&nbsp;&nbsp;

- 00:06:12.720 and you can pick the best one. These are the&nbsp; model-specific parameters. You can play with&nbsp;&nbsp;

- 00:06:17.840 them and see if it is improving your quality, but&nbsp; these are set to best quality right now. When you&nbsp;&nbsp;

- 00:06:24.080 increase the audio guidance scale a little bit,&nbsp; it can follow your speaking prompt more strictly.&nbsp;&nbsp;

- 00:06:31.040 And when you increase video guidance scale, it&nbsp; can follow your video definition more strictly.&nbsp;

- 00:06:38.080 Now we came to our optimization section. We have&nbsp; a massive amount of GPU optimizations. We support&nbsp;&nbsp;

- 00:06:45.040 block swap fully, so as low as 6 GB GPUs, you&nbsp; can use this application. You see, we have&nbsp;&nbsp;

- 00:06:52.560 all the GPU presets. They are all automatically&nbsp; set when you start your application first time,&nbsp;&nbsp;

- 00:06:57.920 it will recognize your GPU, and it will set the&nbsp; best preset automatically for you. Moreover,&nbsp;&nbsp;

- 00:07:03.760 if you want to generate with bigger resolution,&nbsp; you need to increase your block swap, obviously,&nbsp;&nbsp;

- 00:07:09.360 because it will use more VRAM. We have CPU&nbsp; offload. I recommend to never disable this. And&nbsp;&nbsp;

- 00:07:15.280 we have "clear all memory." Now, this feature is&nbsp; extremely important. With this feature, you will&nbsp;&nbsp;

- 00:07:20.640 be able to generate videos even as low as 32 GB&nbsp; RAM memory. However, I recommend more RAM memory.&nbsp;&nbsp;

- 00:07:28.800 If you are on low RAM memory, I recommend this.&nbsp; However, if you have like 96 GB or 64 GB, you can&nbsp;&nbsp;

- 00:07:35.760 uncheck this, and it will make your multiple&nbsp; generations, consecutive generations faster.&nbsp;

- 00:07:41.280 So this model uses T5 text encoder. We support&nbsp; scaled FP8 version of it. We support caching the&nbsp;&nbsp;

- 00:07:48.560 prompt only on CPU. This is still really, really&nbsp; fast. It takes like 10 seconds. We support scaled&nbsp;&nbsp;

- 00:07:54.720 FP8 base model feature, so this reduces VRAM&nbsp; usage like 10 GB when you are not doing any&nbsp;&nbsp;

- 00:08:01.760 block swapping, and the quality is almost same&nbsp; because we have implemented this from famous Kohya&nbsp;&nbsp;

- 00:08:08.160 Musubi tuner, and this is almost same quality&nbsp; as BF16 original model. Why? Because this is&nbsp;&nbsp;

- 00:08:15.840 intelligent scaling. We support Sage Attention,&nbsp; and by default, the model uses Flash Attention.&nbsp;&nbsp;

- 00:08:21.760 My installer will install all of it automatically&nbsp; for you. And we support tiled VAE decode. Without&nbsp;&nbsp;

- 00:08:28.800 this, using this model on low GPUs was impossible,&nbsp; but now as low as 6 GB GPUs can use this model,&nbsp;&nbsp;

- 00:08:37.120 and the quality is same. I didn't notice&nbsp; any quality degrade. By default, it uses&nbsp;&nbsp;

- 00:08:42.880 some video negative prompt and audio negative&nbsp; prompt. You can change this if you wish as well.&nbsp;

- 00:08:48.240 Moreover, we have a full preset system, so you&nbsp; can make any change, save your preset, and when&nbsp;&nbsp;

- 00:08:54.720 you restart your application, it will remember&nbsp; your last used preset and it will automatically&nbsp;&nbsp;

- 00:08:59.920 load it. Moreover, you can switch between presets&nbsp; very easily, and you see it will even auto-crop&nbsp;&nbsp;

- 00:09:05.360 to accordingly set resolution automatically for&nbsp; you. And we support batch processing. This is&nbsp;&nbsp;

- 00:09:11.440 important. For example, yesterday, I did set this&nbsp; folder for batch processing input folder. You see,&nbsp;&nbsp;

- 00:09:18.240 there are prompts, and I have generated 60 videos&nbsp; while I was not on my computer. This is not only&nbsp;&nbsp;

- 00:09:25.200 for text prompts. For example, in this folder,&nbsp; I did set image plus prompt, image plus prompt,&nbsp;&nbsp;

- 00:09:32.000 just prompt, just image (this will be ignored),&nbsp; and just prompt. So the logic is that you give&nbsp;&nbsp;

- 00:09:38.160 this batch folder, you give the output folder&nbsp; as you wish like this, and it will first verify&nbsp;&nbsp;

- 00:09:43.840 the prompts are accurate or not if this is not&nbsp; checked. Then it will automatically recognize&nbsp;&nbsp;

- 00:09:49.520 the aspect ratio of the image, and based on&nbsp; your base height and base width resolution,&nbsp;&nbsp;

- 00:09:55.840 it will automatically crop it, and it&nbsp; will generate the video. It is super&nbsp;&nbsp;

- 00:09:59.520 intelligent. It uses all the settings that&nbsp; you did set here, and leave it as you wish,&nbsp;&nbsp;

- 00:10:05.440 come back after 10 hours, and you will see all&nbsp; your videos generated perfectly. So it matches the&nbsp;&nbsp;

- 00:10:10.640 image file name with the text file name, and it&nbsp; reads the text file name as a prompt and uses this&nbsp;&nbsp;

- 00:10:16.560 as an input image. If there is no input image,&nbsp; it will just use the text file prompt, and it&nbsp;&nbsp;

- 00:10:21.680 will be like text-to-video feature. So this video&nbsp; was text-to-video, this video was text-to-video,&nbsp;&nbsp;

- 00:10:26.640 this video was image-to-video, and this video was&nbsp; text-to-video. It does all of it perfectly fine.&nbsp;

- 00:10:32.320 So how you can install this amazing application?&nbsp; I will show you how to install on Windows,&nbsp;&nbsp;

- 00:10:38.080 on RunPod, and on Massed Compute. We have all&nbsp; one-click installers. The usage is same on all&nbsp;&nbsp;

- 00:10:45.280 platforms: RunPod, Massed Compute, or Windows.&nbsp; So after you installed it, the usage is exactly&nbsp;&nbsp;

- 00:10:50.480 same. Download the zip file. I will show all&nbsp; three installations. I will begin with Windows.&nbsp;&nbsp;

- 00:10:55.440 So let's download the latest zip file. Move the&nbsp; downloaded zip file wherever you want to install.&nbsp;&nbsp;

- 00:11:00.880 For example, let's install into our Q drive.&nbsp; Right-click and let's extract the zip file&nbsp;&nbsp;

- 00:11:05.600 into the Ovi version 8 folder like this. You see,&nbsp; don't use space characters or special characters.&nbsp;&nbsp;

- 00:11:12.800 Then all you need to do is just double-click&nbsp; "windows-install-and-update.bat" file, run,&nbsp;&nbsp;

- 00:11:18.560 and it will start installation. This&nbsp; installation will also automatically&nbsp;&nbsp;

- 00:11:22.800 trigger this model download, but when you are&nbsp; installing, you can also start downloading the&nbsp;&nbsp;

- 00:11:28.320 models. Let's just wait for regular installation.&nbsp; You see, it will generate a virtual environment,&nbsp;&nbsp;

- 00:11:33.760 and it will install all the libraries. I have&nbsp; compiled all the libraries that you need.&nbsp;

- 00:11:38.880 For this installation to work, you need to follow&nbsp; this Windows requirements tutorial. When you&nbsp;&nbsp;

- 00:11:44.480 click this link, you will get to this video. So I&nbsp; recommend you to follow this video with its post.&nbsp;&nbsp;

- 00:11:51.120 It is here. When you open this link, you will see&nbsp; which libraries, which programs that you need to&nbsp;&nbsp;

- 00:11:57.440 install how. This is a very updated post. This&nbsp; is updated 3 September 2025. It is for Torch 2.8&nbsp;&nbsp;

- 00:12:05.040 and CUDA 12.9. It is working with all the GPUs,&nbsp; so this is not only for RTX 5000 series. If you&nbsp;&nbsp;

- 00:12:11.760 have 2000 series, 1000, 3000, 4000, still it is&nbsp; working with all of them. And all the links and&nbsp;&nbsp;

- 00:12:18.480 the instructions are written here as well with&nbsp; the images. So you can follow video along with&nbsp;&nbsp;

- 00:12:24.320 this post, and you will not have any issues.&nbsp; Following these Windows requirements one time&nbsp;&nbsp;

- 00:12:28.560 will let you install all of the applications&nbsp; that I share and all of the AI applications&nbsp;&nbsp;

- 00:12:34.080 that you want to use later. So the installation&nbsp; will be pretty fast if you have cached of these&nbsp;&nbsp;

- 00:12:39.760 libraries. It is installing, almost done.&nbsp; So after installation has been completed,&nbsp;&nbsp;

- 00:12:44.800 scroll top and see if there are any errors. If&nbsp; there are any errors, select everything, copy,&nbsp;&nbsp;

- 00:12:50.080 and paste into a TXT file and message me. So once it is completed, it will start&nbsp;&nbsp;

- 00:12:56.000 downloading the models. I have a very special&nbsp; model downloader. This model downloader uses&nbsp;&nbsp;

- 00:13:01.840 uGet strategy. It starts downloading&nbsp; models with 16 different connections,&nbsp;&nbsp;

- 00:13:07.200 and it is extremely robust. Even if you have a&nbsp; very low speed internet connection, it will work,&nbsp;&nbsp;

- 00:13:12.560 and it has full resume capability. So you&nbsp; see, we have currently downloaded 5 GB of&nbsp;&nbsp;

- 00:13:18.000 the model. Let me close this. Then I will click&nbsp; "windows-download-models-or-resume-download," run,&nbsp;&nbsp;

- 00:13:24.320 and it will start checking and continuing.&nbsp; You see, it is continuing wherever it is left.&nbsp;&nbsp;

- 00:13:29.600 Moreover, this downloader has hash calculation&nbsp; system. Therefore, it will ensure that your&nbsp;&nbsp;

- 00:13:36.240 models are downloaded 100% accurately. So there&nbsp; won't be any cases where the model is corrupted.&nbsp;&nbsp;

- 00:13:43.200 And it will skip already downloaded files. You&nbsp; see, it skipped them. It's extremely robust,&nbsp;&nbsp;

- 00:13:48.880 fast, and really good program. Moreover, let's say you want to make&nbsp;&nbsp;

- 00:13:52.720 a fresh installation but not re-download&nbsp; the models. It is totally fine. You see,&nbsp;&nbsp;

- 00:13:57.200 my model downloads are continuing, but what I am&nbsp; going to do is I will cancel this. I will go back&nbsp;&nbsp;

- 00:14:02.240 to my previous installation, and you see there&nbsp; is a CKPTS folder. This is where the models are&nbsp;&nbsp;

- 00:14:07.360 downloaded. I will cut this and move this back&nbsp; into my new installation like this. Replace all&nbsp;&nbsp;

- 00:14:13.520 files because we have downloaded a few of them.&nbsp; Then when I click "windows-download-or-resume,"&nbsp;&nbsp;

- 00:14:18.880 let's see what happens. Now it will verify the&nbsp; hash of the files. It is quickly verifying them,&nbsp;&nbsp;

- 00:14:24.320 as you can see. Hash verification requires&nbsp; reading the file at least once, but this is&nbsp;&nbsp;

- 00:14:29.440 ensuring that there is no error. This process is&nbsp; also made on RunPod and Massed Compute as well,&nbsp;&nbsp;

- 00:14:35.280 so you will not have any issues. And all files are&nbsp; verified like this. So you should see this message&nbsp;&nbsp;

- 00:14:41.120 once it is all downloaded. I also recommend you&nbsp; to update application always. So since I made&nbsp;&nbsp;

- 00:14:48.080 an update between this installation and while&nbsp; recording video, let me show you how to update.&nbsp;&nbsp;

- 00:14:53.280 All you need to do is clicking the install&nbsp; button again, run. Don't worry, this will not&nbsp;&nbsp;

- 00:14:58.560 install from beginning. So you see, it updated&nbsp; the application. If there is any new library,&nbsp;&nbsp;

- 00:15:03.760 it will install it. If not, it's done like this. Now we are ready to start application. To start&nbsp;&nbsp;

- 00:15:08.800 application, double-click "windows-start-app.bat"&nbsp; file, run, and the application will start. You&nbsp;&nbsp;

- 00:15:14.080 will see that it will automatically pick the&nbsp; accurate GPU for myself, and it picked the 32&nbsp;&nbsp;

- 00:15:20.240 GB GPU preset for me. I recommend you to first&nbsp; test an example and verify it is working. So I&nbsp;&nbsp;

- 00:15:28.320 will load this example. It is loaded. Hit generate&nbsp; video. Do nothing else. This is for verification&nbsp;&nbsp;

- 00:15:35.360 with default settings. Now you should follow&nbsp; the started CMD windows. You will see all the&nbsp;&nbsp;

- 00:15:42.800 information here. We have pretty verbal CMD logs,&nbsp; so you will see everything here. First of all,&nbsp;&nbsp;

- 00:15:51.520 it will create the T5 encoding of this prompt. And&nbsp; we have T5 encoding cache system. So when I run&nbsp;&nbsp;

- 00:15:59.760 this prompt again, it will not use the T5 at all&nbsp; because this cache is saved inside, let me show&nbsp;&nbsp;

- 00:16:06.800 you, inside prompt cache. So it is like 1 MB file.&nbsp; When I generate another video with this prompt,&nbsp;&nbsp;

- 00:16:14.160 it will use that cache file, and it will skip that&nbsp; entirely, and it will speed up our generation.&nbsp;&nbsp;

- 00:16:20.160 So the generation started. It is currently 4&nbsp; second IT on my RTX 4090. Why? Because I am&nbsp;&nbsp;

- 00:16:27.520 also recording a video. Therefore, it is using a&nbsp; lot of GPU power. Normally, this is like 3 second&nbsp;&nbsp;

- 00:16:34.320 IT on RTX 4090. And it is really fast. I mean, it&nbsp; is taking like 3 minutes to generate 121 frames,&nbsp;&nbsp;

- 00:16:44.480 24 FPS, 5-second videos with 720 to 720p&nbsp; resolution. On RTX 4090, you can also generate 960&nbsp;&nbsp;

- 00:16:56.720 to 960. So you see, this is HD resolution without&nbsp; using any block swapping. It is fitting into GPU.&nbsp;&nbsp;

- 00:17:04.320 But let's say it starts not fit into GPU, just&nbsp; enable scaled FP8 model, and it will start using&nbsp;&nbsp;

- 00:17:12.320 lesser 10 GB of VRAM, so it will fit into GPU.&nbsp; With this, you can probably generate 10 second or&nbsp;&nbsp;

- 00:17:19.280 even longer or like 1080p, like this, 1080p, 1080p&nbsp; resolution videos as well. So based on your GPU,&nbsp;&nbsp;

- 00:17:29.440 based on your needs, you can play with these&nbsp; settings, but as I said, for testing, just&nbsp;&nbsp;

- 00:17:35.760 load example, hit generate, and wait for results. Moreover, our cancel feature is working amazing.&nbsp;&nbsp;

- 00:17:42.320 Let me demonstrate you. When I click this&nbsp; cancel, it is immediately canceled. Why?&nbsp;&nbsp;

- 00:17:46.640 Because when "clear all memory" is enabled, it is&nbsp; starting each process as a sub-process. Therefore,&nbsp;&nbsp;

- 00:17:53.200 we can terminate it immediately. So let's load&nbsp; another example. I want to test this example,&nbsp;&nbsp;

- 00:17:58.880 not that one. You see, it is auto-loaded&nbsp; and generate. You can use any example,&nbsp;&nbsp;

- 00:18:03.440 but we had played with some parameters, so let's&nbsp; just cancel this. Let's just refresh the page.&nbsp;&nbsp;

- 00:18:09.040 Let's go example, image-to-video, load example,&nbsp; and hit generate. Yes, let's just wait now.&nbsp;

- 00:18:15.360 While video is being generated, I want to show&nbsp; something else. Some people asking me how can they&nbsp;&nbsp;

- 00:18:22.160 use this application on their second GPU. So you&nbsp; see "windows-start-app" file, copy-paste it, type&nbsp;&nbsp;

- 00:18:28.800 "2nd GPU" or whatever name you want. Right-click&nbsp; and edit this Notepad++. All of my files are text&nbsp;&nbsp;

- 00:18:36.000 files like this, so you can see whatever inside&nbsp; them. It is all 100% secure. What we need to do&nbsp;&nbsp;

- 00:18:42.240 is I will just remove this REM, and this will&nbsp; become available. Now when I start with this,&nbsp;&nbsp;

- 00:18:48.640 it will start using my second GPU. So let's open a&nbsp; terminal, type pip install nvitop. It will install&nbsp;&nbsp;

- 00:18:57.200 the nvitop. Then type nvitop, and you see it is&nbsp; showing how much GPU I am using. This screen is&nbsp;&nbsp;

- 00:19:04.720 extremely important. So you should follow this&nbsp; to see which GPU it is using, how much it is&nbsp;&nbsp;

- 00:19:10.960 using. You should focus that it should use near&nbsp; to the maximum wattage. As much as what it uses,&nbsp;&nbsp;

- 00:19:18.560 that means that you are utilizing your GPU&nbsp; accurately. Moreover, do not close the terminal&nbsp;&nbsp;

- 00:19:23.360 of the application directly like this because we&nbsp; are using sub-processes. First, click cancel all,&nbsp;&nbsp;

- 00:19:29.440 then close your terminal. So always first click&nbsp; cancel, then close your terminal to not have any&nbsp;&nbsp;

- 00:19:34.640 leftover. Otherwise, the process may keep running&nbsp; and keep using your resources until it is done.&nbsp;

- 00:19:41.360 Okay, so the demo video, example video has been&nbsp; generated, the first example. So let's listen it.&nbsp;&nbsp;

- 00:19:47.760 Welcome to the SECourses made premium OV app.&nbsp; As you have seen, it is pretty good quality.&nbsp;&nbsp;

- 00:19:54.240 It is automatically saved inside outputs&nbsp; folder. So you see, we can see it is saved&nbsp;&nbsp;

- 00:20:00.400 here. When you use video extension, it will save&nbsp; individual parts as well. Let me show you what I&nbsp;&nbsp;

- 00:20:07.360 mean. So this is the first part of the generated&nbsp; video. This is second part. This is third part,&nbsp;&nbsp;

- 00:20:13.440 and this is the combination. So you can edit&nbsp; any of them, you can use any of them. We are&nbsp;&nbsp;

- 00:20:18.320 saving all of them for you. Let me show you each&nbsp; one. I have watched empires rise and fall like&nbsp;&nbsp;

- 00:20:24.800 tides. The patterns of history are a code. AI is&nbsp; finally learning to read it. Join us at SECourses.&nbsp;

- 00:20:32.560 So how you can properly write prompts? You can&nbsp; investigate, analyze these examples. They are&nbsp;&nbsp;

- 00:20:40.400 really good basis for you. I have so many examples&nbsp; for you to test out for multiline prompting,&nbsp;&nbsp;

- 00:20:48.000 for video extension prompting, and single video&nbsp; prompting. You see all of them are here. However,&nbsp;&nbsp;

- 00:20:53.680 I prepared a guidance for you. You will see that&nbsp; there is "prompt generate guide in Gemini." Let's&nbsp;&nbsp;

- 00:21:00.320 open the "Gemini prompt gen asking format." Go&nbsp; to Google AI Studio. This is free to use. Just&nbsp;&nbsp;

- 00:21:07.200 log in with your account. From here, select Gemini&nbsp; 2.5 Pro. Upload these two files into Gemini. Then&nbsp;&nbsp;

- 00:21:15.920 read the instructions here. For example, I have&nbsp; "extend video generation guide." Just modify the&nbsp;&nbsp;

- 00:21:22.320 parts that you need. Copy-paste it. Let me&nbsp; show you, and hit generate. Then, actually,&nbsp;&nbsp;

- 00:21:30.240 let's make this media resolution medium. It will&nbsp; make it to read PDF better, and hit generate. Then&nbsp;&nbsp;

- 00:21:37.120 it will give you different prompts based on the&nbsp; instructions, the details that you want. This is&nbsp;&nbsp;

- 00:21:44.400 a good way to generate prompts for video extension&nbsp; or single prompts. It doesn't matter, both of&nbsp;&nbsp;

- 00:21:50.400 them. Moreover, I find that when you want to merge&nbsp; different videos, 4 second is working better.&nbsp;

- 00:21:58.000 And we also support each prompt to have different&nbsp; duration. All you need to do is, beginning of the&nbsp;&nbsp;

- 00:22:05.520 prompt, type the duration like this. So this&nbsp; prompt, this one, this particular prompt, will&nbsp;&nbsp;

- 00:22:12.560 be 3 second. This is working in batch processing&nbsp; or multiline processing or video extension or&nbsp;&nbsp;

- 00:22:18.240 single processing. The application will parse each&nbsp; prompt, and it will see that this is 2 second.&nbsp;&nbsp;

- 00:22:24.720 This one will use the duration that you set&nbsp; here, it is 4, and this one will use the duration&nbsp;&nbsp;

- 00:22:30.720 set there. But you can set each one different&nbsp; duration like this. This gives you more control&nbsp;&nbsp;

- 00:22:38.480 over the generation. You see, this application is&nbsp; designed in mind for professional usage. This is&nbsp;&nbsp;

- 00:22:46.880 a really state-of-the-art application, and you can&nbsp; generate whole animations, videos, video sequences&nbsp;&nbsp;

- 00:22:54.160 with this, whole stories with this application. When you scroll down in our post, you will see&nbsp;&nbsp;

- 00:22:59.760 all the updates that we have made historically.&nbsp; So you can read here to learn a lot of information&nbsp;&nbsp;

- 00:23:06.960 regarding this application development and which&nbsp; features it gets as well. I usually put the latest&nbsp;&nbsp;

- 00:23:14.480 updates just under the first introduction section.&nbsp; You see, the updates are all written here.&nbsp;

- 00:23:21.760 Okay, so let's begin with the Massed Compute. You&nbsp; see, there is "mass-compute-instructions-read.txt"&nbsp;&nbsp;

- 00:23:27.120 file. Double-click it. We have example&nbsp; tutorials for you to learn more about it.&nbsp;&nbsp;

- 00:23:32.160 Now we have a coupon that works on all GPUs.&nbsp; If you want to learn about prices and more,&nbsp;&nbsp;

- 00:23:38.240 you can double-click this link. It will give you&nbsp; more information regarding the GPUs and prices.&nbsp;&nbsp;

- 00:23:44.720 So first of all, please use this link to register&nbsp; Massed Compute. I appreciate that. After login,&nbsp;&nbsp;

- 00:23:51.840 set some billing, some credits. Go to deploy,&nbsp; select your GPU accordingly. If you select this&nbsp;&nbsp;

- 00:23:58.640 RTX Pro 6000 Blackwell, this will work amazing&nbsp; with amazing speed, and the price is also amazing.&nbsp;&nbsp;

- 00:24:04.800 So from category, select creator. From image,&nbsp; select SECourses. We are updating this image.&nbsp;&nbsp;

- 00:24:10.320 Hopefully, it will be way faster in future when&nbsp; initializing. And discount coupon. Now this coupon&nbsp;&nbsp;

- 00:24:16.960 works on all of the GPUs. SECourses, verify,&nbsp; and deploy. And it is deployed. You just need&nbsp;&nbsp;

- 00:24:24.640 to wait for initialization right now. This part is&nbsp; actually same as my other previous Massed Compute,&nbsp;&nbsp;

- 00:24:30.960 so I will show quickly. You need ThinLinc&nbsp; client for connecting. Just Windows, download,&nbsp;&nbsp;

- 00:24:38.480 install it. Once you install it with double-click,&nbsp; from the options, from the local devices, drivers,&nbsp;&nbsp;

- 00:24:45.280 set your shared folder to transfer files.&nbsp; I already did set it. And put the zip file,&nbsp;&nbsp;

- 00:24:52.080 the downloaded zip file into your&nbsp; shared folder. It is here for myself,&nbsp;&nbsp;

- 00:24:57.440 Massed Compute shared folder. I will just put it&nbsp; here. Now I need to wait for machine to start.&nbsp;

- 00:25:03.520 Okay, so the machine has started. Let's copy&nbsp; the login URL. Copy the password. Make sure&nbsp;&nbsp;

- 00:25:08.960 that username is Ubuntu. Also copy-paste it and&nbsp; connect. Continue. Wait for connection to start.&nbsp;&nbsp;

- 00:25:15.920 Okay, click start. Okay, machine started.&nbsp; Go to the home, go to the Thin drives. You&nbsp;&nbsp;

- 00:25:21.840 can also log in your Patreon from this browser&nbsp; and download here as well, but this is easier.&nbsp;&nbsp;

- 00:25:28.080 There is my zip file. I will copy-paste it. I&nbsp; will drag and drop it into my downloads like&nbsp;&nbsp;

- 00:25:33.840 this. Make sure that you install everything on&nbsp; downloads folder, not on the shared drive. And&nbsp;&nbsp;

- 00:25:40.160 extract here. Double-click, enter inside. You see&nbsp; there is Massed Compute instructions. Copy this&nbsp;&nbsp;

- 00:25:46.320 install command. Go back to folder, click these&nbsp; three dots, open in terminal. Right-click and&nbsp;&nbsp;

- 00:25:51.840 paste. And it will start installation. As soon&nbsp; as you see Ovi Pro, you can start downloading&nbsp;&nbsp;

- 00:25:57.680 models to save time. So I will just copy this,&nbsp; go back to folder, open in terminal, right-click,&nbsp;&nbsp;

- 00:26:04.480 and paste. And it will start downloading models&nbsp; simultaneously. Since this is on cloud machine,&nbsp;&nbsp;

- 00:26:10.720 it will be super fast. You see the downloads&nbsp; are super fast. It is downloading with,&nbsp;&nbsp;

- 00:26:15.360 let's see the speed. Okay, 300 MB per second.&nbsp; Yes, almost 400 MB per second, really,&nbsp;&nbsp;

- 00:26:22.160 really fast. And it's also installing. The Massed&nbsp; Compute installation is like 10 times, sometimes&nbsp;&nbsp;

- 00:26:28.560 100 times faster than RunPod. RunPod disks are&nbsp; extremely slow. Therefore, I am recommending the&nbsp;&nbsp;

- 00:26:34.720 Massed Compute. Moreover, this GPU on RunPod is&nbsp; extremely expensive. Let me show you. When I go&nbsp;&nbsp;

- 00:26:40.400 to pods and deploy, you will see that its price&nbsp; is $1.84. $1.84, and also it will cost you disk&nbsp;&nbsp;

- 00:26:52.000 space. It will be like $1.9. On Massed Compute,&nbsp; it is only $1.47. And we have 768 GB of storage,&nbsp;&nbsp;

- 00:27:04.160 192 GB of RAM memory on this machine. So let's&nbsp; just wait for installation to be completed.&nbsp;

- 00:27:10.320 So the downloads of the models finished before&nbsp; the installation, and installation is almost also&nbsp;&nbsp;

- 00:27:16.240 finished. Yes, installation also finished. It will&nbsp; automatically start the application when you first&nbsp;&nbsp;

- 00:27:22.560 time install. Then second time, you can close the&nbsp; terminal and start new one like this. Let me also&nbsp;&nbsp;

- 00:27:29.440 show you that so you won't have any issues. But&nbsp; you can right away use the started one as well.&nbsp;&nbsp;

- 00:27:35.200 So let's close this. Copy this and in here, open&nbsp; in terminal. You will notice that we also have&nbsp;&nbsp;

- 00:27:42.880 multiple GPU option. So when you have multiple&nbsp; GPU, you can set each instance into different GPU&nbsp;&nbsp;

- 00:27:49.840 like this and different output folder like this,&nbsp; and you can use multiple GPUs on same machine,&nbsp;&nbsp;

- 00:27:55.520 generate multiple videos at the same time. It is&nbsp; just same. You just change this GPU ID 1, 2, 3,&nbsp;&nbsp;

- 00:28:02.000 whatever you have. The first one is 0. So the&nbsp; application started, and I can copy-paste this&nbsp;&nbsp;

- 00:28:07.840 link and open it in my browser like this, so&nbsp; it will work faster than using inside ThinLinc&nbsp;&nbsp;

- 00:28:14.480 client. And it is started. It's exactly same as&nbsp; in the Windows, so let's try the first example.&nbsp;&nbsp;

- 00:28:20.720 It is loaded. Generate video. I wonder the speed&nbsp; of the RTX 6000. And you will notice that it has&nbsp;&nbsp;

- 00:28:29.280 selected 96 GB GPU preset, and this GPU doesn't&nbsp; use clear all memory because we have the memory&nbsp;&nbsp;

- 00:28:36.720 as well on this machine. And let's see the speed.&nbsp; You see, to return back the terminal, I am still&nbsp;&nbsp;

- 00:28:43.040 using ThinLinc client. Okay, the speed is 2.48&nbsp; second IT. If I open new terminal and type nvitop,&nbsp;&nbsp;

- 00:28:52.960 I can see how much watt it is using. It is using&nbsp; 500 watts, very good. And around 26.5 GB of GPU.&nbsp;

- 00:29:01.520 Okay, it is already generated. You see, 50 steps&nbsp; inference took only 2 minutes on this GPU. And&nbsp;&nbsp;

- 00:29:09.600 video will appear here. Yes, it is appeared. It&nbsp; is same as in Windows. So I can download from&nbsp;&nbsp;

- 00:29:16.160 here with this icon to download to my PC, or&nbsp; I can go to outputs folder, copy the generated&nbsp;&nbsp;

- 00:29:23.920 everything if you wish, like copy the outputs&nbsp; folder entirely, move back to Thin drives,&nbsp;&nbsp;

- 00:29:30.160 shared folder, paste it there. Then this will&nbsp; appear on your PC as well. When I go back to&nbsp;&nbsp;

- 00:29:36.560 my Massed Compute shared folder, you see the&nbsp; output is here. I can copy-paste it into my PC,&nbsp;&nbsp;

- 00:29:42.160 and it will work. So don't forget to terminate&nbsp; your machine on Massed Compute. If you stop it,&nbsp;&nbsp;

- 00:29:47.360 it will not stop billing. So you need&nbsp; to delete it for not using any credits.&nbsp;

- 00:29:53.600 Now I will show you how to use RunPod. For RunPod&nbsp; usage, we have RunPod instructions read.txt file.&nbsp;&nbsp;

- 00:29:59.600 Double-click and open it. Please use this link&nbsp; to register. I appreciate that. Okay, let's go to&nbsp;&nbsp;

- 00:30:06.320 sign in. After registering, it will automatically&nbsp; sign you probably. Set some billing to your&nbsp;&nbsp;

- 00:30:11.840 account. Then let's go to pods. Then I will&nbsp; delete this older machine because as long as I&nbsp;&nbsp;

- 00:30:17.600 don't delete it, it will use my credits. Terminate&nbsp; pod. Okay, pods. I recommend you to apply these&nbsp;&nbsp;

- 00:30:24.000 filters. NVMe disk, 100 GB of RAM memory, and&nbsp; 4090s are good. However, to not get slow 4090,&nbsp;&nbsp;

- 00:30:34.320 I will also apply a region restriction. So&nbsp; let's see, this one, no. This one, no. This one,&nbsp;&nbsp;

- 00:30:41.120 no. Okay, this one has. So start from very bottom&nbsp; of North America, they are the best ones. Okay.&nbsp;&nbsp;

- 00:30:47.760 You can select multiple GPU if you want to use&nbsp; multiple generations. You can do that. We have it.&nbsp;&nbsp;

- 00:30:53.520 I will click this edit. First of all, change&nbsp; template and select RunPod PyTorch 2.2.0. It will&nbsp;&nbsp;

- 00:31:00.400 say you that this is supported, but don't worry.&nbsp; My installer generating a virtual environment and&nbsp;&nbsp;

- 00:31:06.160 installing PyTorch 2.8 with CUDA 12.9. So make&nbsp; sure that this is selected because scripts are&nbsp;&nbsp;

- 00:31:13.280 made for this. Then click edit and select volume&nbsp; disk like this. If you want to connect also from&nbsp;&nbsp;

- 00:31:19.440 proxy, add 7860, 7861. Set overrides and ready.&nbsp; Also, you can set multiple GPUs if you want&nbsp;&nbsp;

- 00:31:27.200 because we have multiple GPU starting parameters&nbsp; as well. Each GPU can generate different video.&nbsp;&nbsp;

- 00:31:33.920 I will show on single GPU. So this has a volume&nbsp; disk of 200 GB. This is important. Let's verify&nbsp;&nbsp;

- 00:31:42.080 that. Yes, volume storage is 200 because we will&nbsp; download some models. Then wait for connect part&nbsp;&nbsp;

- 00:31:48.960 to initialize. If this takes longer than 1 minute,&nbsp; I just dump the machine and get a new one. Then&nbsp;&nbsp;

- 00:31:55.440 click the JupyterLab. And you need to wait for&nbsp; this JupyterLab to start. If this doesn't start&nbsp;&nbsp;

- 00:32:00.960 in 1 minute, just delete this machine and&nbsp; get a new one. Unfortunately, RunPod is very&nbsp;&nbsp;

- 00:32:05.840 unpredictable. Then I will drag and drop my zip&nbsp; file into this workspace, then wait for upload.&nbsp;&nbsp;

- 00:32:13.760 You see in the bottom it shows uploading. This&nbsp; is important. Wait for it. Okay, upload complete.&nbsp;&nbsp;

- 00:32:19.520 Then right-click and extract archive. Then click&nbsp; this refresh. Okay, extracted. RunPod instructions&nbsp;&nbsp;

- 00:32:25.840 read.txt and select this install command. Open new&nbsp; terminal, copy-paste it, and wait for installation&nbsp;&nbsp;

- 00:32:32.560 to start. When you see the Ovi folder here, you&nbsp; can start download models as well, like this,&nbsp;&nbsp;

- 00:32:38.720 and open new terminal and start downloading.&nbsp; Now just wait for installation to be completed.&nbsp;

- 00:32:44.720 It is installing, and there is one crucial&nbsp; part. If this installation is finished before&nbsp;&nbsp;

- 00:32:51.040 this download finished, it will also start&nbsp; downloading. So then we need to cancel one of&nbsp;&nbsp;

- 00:32:57.600 the downloads. But let's see. On Massed Compute,&nbsp; it was finished, the download was finished faster&nbsp;&nbsp;

- 00:33:04.800 than the installation. I am predicting it will be&nbsp; same here, but the download speed of the RunPod is&nbsp;&nbsp;

- 00:33:11.920 slow. You can see the speed. You see, like 275&nbsp; MB per second. But let's see what will happen.&nbsp;&nbsp;

- 00:33:20.400 But this machine, this machine we got is pretty&nbsp; decent one. It is fast, not very slow. Okay,&nbsp;&nbsp;

- 00:33:26.160 downloads of models finished. We can see that all&nbsp; downloaded, verified. Therefore, there will be&nbsp;&nbsp;

- 00:33:32.720 no problems. Installation is also close to the&nbsp; finish. To cancel download when it is running,&nbsp;&nbsp;

- 00:33:38.720 you can do Ctrl+X or Ctrl+C, and it will cancel&nbsp; the download if simultaneous downloads starts.&nbsp;&nbsp;

- 00:33:47.040 But I doubt that it will happen. Okay, so the&nbsp; installation completed, and you see we saved time&nbsp;&nbsp;

- 00:33:53.120 with starting download and the installation at the&nbsp; same time. You will see that once the application&nbsp;&nbsp;

- 00:33:59.040 started, local URL and Gradio Live like this. So&nbsp; I will connect from Gradio Live. If you want to&nbsp;&nbsp;

- 00:34:07.520 connect from proxy port, go back to your My Pod&nbsp; and click 7861. So this will open the application&nbsp;&nbsp;

- 00:34:14.800 from RunPod proxy. However, I recommend Gradio.&nbsp; It is working better than the RunPod proxy. So,&nbsp;&nbsp;

- 00:34:20.880 as usual, do an example first. So let's try&nbsp; this example, and it will load it here. Wait&nbsp;&nbsp;

- 00:34:29.280 for it. Gradio Live may be a slower sometimes.&nbsp; Let's see if this is faster. Load example. Okay,&nbsp;&nbsp;

- 00:34:36.480 this was faster, the proxy, and generate video.&nbsp; So whichever works better, you can use either&nbsp;&nbsp;

- 00:34:42.160 of them. And now wait for result to verify it is&nbsp; properly working. You can follow the status on the&nbsp;&nbsp;

- 00:34:49.920 terminal started here. To start a new terminal,&nbsp; you need to use this command. But if another&nbsp;&nbsp;

- 00:34:58.240 instance were running, then you should do here and&nbsp; restart pod. You won't need to run the installer&nbsp;&nbsp;

- 00:35:06.400 again with restart and use this to start. If you&nbsp; have multiple GPUs, set the GPU ID and output&nbsp;&nbsp;

- 00:35:13.920 folder like this and start each one of them, and&nbsp; you will be able to generate videos on each GPU,&nbsp;&nbsp;

- 00:35:21.440 and each one will get saved into a different&nbsp; folder, so you will not have any issues. If&nbsp;&nbsp;

- 00:35:27.040 you stop your pod and start again, then you&nbsp; should run the installer again because some&nbsp;&nbsp;

- 00:35:32.480 of the installations may be installed on the&nbsp; container disk, and container disks are reset&nbsp;&nbsp;

- 00:35:39.760 when you stop your pod. Or let's say you are using&nbsp; the storage system, then you need to run installer&nbsp;&nbsp;

- 00:35:47.680 again. If you want to learn more about storage&nbsp; system, I have RunPod permanent network storage&nbsp;&nbsp;

- 00:35:53.440 tutorial here. It is just so easy. You install as&nbsp; usual, then you click deploy with pod with volume&nbsp;&nbsp;

- 00:35:59.680 and select the GPU, select same template. This&nbsp; is important, like RunPod PyTorch 2.6 or 2.2.&nbsp;&nbsp;

- 00:36:07.680 And start. Always select the same template or it&nbsp; will break your application. This is important.&nbsp;&nbsp;

- 00:36:13.840 So let's see the generation started. Okay, it&nbsp; is almost done, I think, while we were talking&nbsp;&nbsp;

- 00:36:20.320 because it is fast. Okay, where it is? Oh, not&nbsp; done yet. It is just loading the models. Yeah,&nbsp;&nbsp;

- 00:36:26.960 model loading is slow. Moreover, we have&nbsp; LoRAs, and our LoRA system is extremely fast,&nbsp;&nbsp;

- 00:36:33.280 robust. I made it really, really optimal. You&nbsp; can also use LoRAs. To use LoRAs on RunPod,&nbsp;&nbsp;

- 00:36:39.520 you need to upload your LoRA into LoRAs folder.&nbsp; You can use runpodctl or like wget. Let me show&nbsp;&nbsp;

- 00:36:47.040 you like wget the link. I also have a tutorial for&nbsp; this. SECourses channel, search wget like this,&nbsp;&nbsp;

- 00:36:54.480 and you will see this. Watch this tutorial, and&nbsp; you will learn how to upload and download models&nbsp;&nbsp;

- 00:37:00.480 to RunPod, Massed Compute, to the cloud services.&nbsp; So you need to put your LoRAs here. After you put&nbsp;&nbsp;

- 00:37:06.480 your LoRAs, you just need to click refresh. Okay,&nbsp; you see, this is the problem of the proxy. It was,&nbsp;&nbsp;

- 00:37:14.000 you know, temporarily disconnected, and now&nbsp; reconnected, but you won't see the result here.&nbsp;&nbsp;

- 00:37:20.000 So where will you see the result? The result will&nbsp; be saved inside, let's go to workspace, inside Ovi&nbsp;&nbsp;

- 00:37:27.600 Pro, inside outputs. So we will get the result&nbsp; from here. You won't get the result from here&nbsp;&nbsp;

- 00:37:32.800 anymore, unfortunately. Okay, it is generating&nbsp; right now. You see, it is 2.94 second IT. It was&nbsp;&nbsp;

- 00:37:39.440 2.48 second on RTX 6000 Pro GPU. Let's just wait. Okay, generation completed. When you refresh, you&nbsp;&nbsp;

- 00:37:47.040 will see the items here. Right-click and download.&nbsp; So this is a way of downloading, or you can go to&nbsp;&nbsp;

- 00:37:53.520 parent folder, right-click and download. You can&nbsp; download all of the generated videos like this, or&nbsp;&nbsp;

- 00:37:59.520 if it was working, you would be able to download&nbsp; from here. So it is better to use Gradio Live and&nbsp;&nbsp;

- 00:38:06.160 select your example, load example. Unfortunately,&nbsp; Gradio Live may be slow sometimes on RunPod. It&nbsp;&nbsp;

- 00:38:14.000 is happening all the time. You just need to&nbsp; wait, and you can use either way. I recommend&nbsp;&nbsp;

- 00:38:18.880 Massed Compute, but you can also use RunPod. It&nbsp; is working. Okay, now it is loading image first,&nbsp;&nbsp;

- 00:38:24.880 then it will auto-crop. We need to wait. You&nbsp; see, it is still loading. The Gradio Live is&nbsp;&nbsp;

- 00:38:30.880 slow sometimes. Yes, it is loading image. Once it&nbsp; is loaded, it will, yes, it is also loading. Okay,&nbsp;&nbsp;

- 00:38:37.040 cropped image is ready. The resolution is here.&nbsp; Just click generate. One of the very nice features&nbsp;&nbsp;

- 00:38:43.040 of the Gradio is that you can open Gradio in&nbsp; multiple tabs, and each click of generate will&nbsp;&nbsp;

- 00:38:51.440 be automatically queued. So you can also use&nbsp; the Gradio queue system. This is same also in&nbsp;&nbsp;

- 00:38:58.960 when you are using in Massed Compute or when you&nbsp; are using in your computer. If you want to queue&nbsp;&nbsp;

- 00:39:04.560 generations, let's start a single application.&nbsp; Don't start multiple applications. Just single&nbsp;&nbsp;

- 00:39:10.000 application. We will just open the Gradio in&nbsp; multiple browser tabs. Okay, this is started.&nbsp;&nbsp;

- 00:39:16.640 So let's click example. Let's hit generate. And&nbsp; then open this tab in another tab. And this time,&nbsp;&nbsp;

- 00:39:23.760 let's load this example and hit generate. You will&nbsp; see that it is queued like this. And it will use&nbsp;&nbsp;

- 00:39:29.440 all the settings that you set for each generation.&nbsp; So this is a global feature of the Gradio,&nbsp;&nbsp;

- 00:39:38.160 and I am making all Gradio applications. This way,&nbsp; you can queue multiple generations, whatever you&nbsp;&nbsp;

- 00:39:44.400 are doing. For example, this is another Gradio&nbsp; Live that is running on RunPod. Let's try another&nbsp;&nbsp;

- 00:39:50.160 example. For example, this one, load it, hit&nbsp; generate, and you will see that it is queued&nbsp;&nbsp;

- 00:39:55.200 like this. So this is a global feature, and this&nbsp; is how you can download models. Don't forget to&nbsp;&nbsp;

- 00:40:02.480 stop your pod. When you stop your pod, it will use&nbsp; very minimal amount of credits of your account on&nbsp;&nbsp;

- 00:40:08.960 RunPod, not on Massed Compute. If you don't want&nbsp; anything to be used, terminate. With permanent&nbsp;&nbsp;

- 00:40:15.040 storage system, there is no close. Let me show&nbsp; you. So let's select the same template. Okay.&nbsp;&nbsp;

- 00:40:21.920 Now I can deploy this on multiple GPUs, as&nbsp; long as you do not overwrite the same file,&nbsp;&nbsp;

- 00:40:28.960 you won't have any issues. So you see, I can start&nbsp; it on multiple GPUs, and then there is no stop&nbsp;&nbsp;

- 00:40:36.800 option because this is just terminate. And when&nbsp; you terminate this, you will not lose any data&nbsp;&nbsp;

- 00:40:42.160 because it is saved inside the storage. Okay, this is all for today. I hope you&nbsp;&nbsp;

- 00:40:47.840 have enjoyed. Please give a like,&nbsp; subscribe, leave a comment. Also,&nbsp;&nbsp;

- 00:40:52.400 we have Patreon exclusive post index here. We have&nbsp; so many different applications, and you can join&nbsp;&nbsp;

- 00:41:00.560 my Discord channel. I recommend it. You see,&nbsp; our Discord channel is here. When you open it,&nbsp;&nbsp;

- 00:41:06.400 you will see our server with 11,000 members. Just&nbsp; join. Also, you can follow me on LinkedIn. I have&nbsp;&nbsp;

- 00:41:14.080 LinkedIn here. This is my real profile. You can&nbsp; follow me here, and I recommend you to join our&nbsp;&nbsp;

- 00:41:21.120 Subreddit. We are getting bigger and better. Let&nbsp; me show you our statistics. We have 400k views,&nbsp;&nbsp;

- 00:41:29.440 we have 7,000 members, we are growing. So&nbsp; hopefully, see you another amazing tutorial video.

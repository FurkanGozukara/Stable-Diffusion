# FLUX 2 vs FLUX SRPO, New FLUX Training Kohya SS GUI Premium App With Presets & Features

## Full tutorial link > https://www.youtube.com/watch?v=RQHmyJVOHXo

[![FLUX 2 vs FLUX SRPO, New FLUX Training Kohya SS GUI Premium App With Presets & Features](https://img.youtube.com/vi/RQHmyJVOHXo/sddefault.jpg)](https://www.youtube.com/watch?v=RQHmyJVOHXo "FLUX 2 vs FLUX SRPO, New FLUX Training Kohya SS GUI Premium App With Presets & Features")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/FLUX-2-vs-FLUX-SRPO-New-FLUX-Training-Kohya-SS-GUI-Premium-App-With-Presets-and-Features.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/FLUX-2-vs-FLUX-SRPO-New-FLUX-Training-Kohya-SS-GUI-Premium-App-With-Presets-and-Features.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


FLUX 2 has been published and I have compared it to the very best FLUX base model known as FLUX SRPO. Moreover, we have updated our FLUX Training APP and presets to the next level. Massive speed up gaings with 0 quality loss and lots of new features. I will show all of the new features we have with new SECourses Kohya SS GUI Premium app and compare FLUX SRPO trained model results with FLUX 2.

Get the SECourses Premium Kohya Trainer DreamBooth / Fine Tuning : [ [https://www.patreon.com/posts/Kohya-FLUX-DreamBooth-Trainer-App-112099700](https://www.patreon.com/posts/Kohya-FLUX-DreamBooth-Trainer-App-112099700) ]

Get the SECourses Premium Kohya Trainer LoRA : [ [https://www.patreon.com/posts/Kohya-FLUX-LoRA-Trainer-App-110879657](https://www.patreon.com/posts/Kohya-FLUX-LoRA-Trainer-App-110879657) ]

DreamBooth Training Tutorial: [ [https://www.youtube.com/watch?v=FvpWy1x5etM](https://www.youtube.com/watch?v=FvpWy1x5etM) ]

LoRA Training Tutorial: [ [https://www.youtube.com/watch?v=nySGu12Y05k](https://www.youtube.com/watch?v=nySGu12Y05k) ]

Qwen Image Realism Tutorial: [ [https://youtu.be/XWzZ2wnzNuQ](https://youtu.be/XWzZ2wnzNuQ) ]

Join our Discord Community: [ [https://discord.com/servers/secourses-Discord-772774097734074388](https://discord.com/servers/secourses-Discord-772774097734074388) ]

‚è±Ô∏è Video Chapters:

[00:00:00](https://youtu.be/RQHmyJVOHXo?t=0) Introduction to New FLUX Training Improvements and Local Training Showcase

[00:00:24](https://youtu.be/RQHmyJVOHXo?t=24) Understanding FLUX SRPO Model: High Realism with Minimal VRAM Requirements

[00:00:38](https://youtu.be/RQHmyJVOHXo?t=38) Updated Configurations for Training Realism on 6GB VRAM GPUs Locally

[00:01:07](https://youtu.be/RQHmyJVOHXo?t=67) FLUX 2 Announcement and Setting Up Comparisons with BFL Playground

[00:01:45](https://youtu.be/RQHmyJVOHXo?t=105) FLUX 2 Dev Model Technical Specs: 32 Billion Parameters and Hardware Challenges

[00:02:11](https://youtu.be/RQHmyJVOHXo?t=131) Overview of Changes in SECourses Premium Kohya Trainer Version 35

[00:02:46](https://youtu.be/RQHmyJVOHXo?t=166) Development Updates: GUI Improvements and Full Torch Compile Support

[00:03:13](https://youtu.be/RQHmyJVOHXo?t=193) LoRA Presets Update: VRAM Optimization and Speed Improvements via Torch Compile

[00:03:27](https://youtu.be/RQHmyJVOHXo?t=207) Introducing On-the-Fly FP8 Scaled LoRA Training Support

[00:03:42](https://youtu.be/RQHmyJVOHXo?t=222) Quality Comparison Analysis: BF16 vs FP8 Scaled Weights LoRA

[00:04:24](https://youtu.be/RQHmyJVOHXo?t=264) VRAM Usage and Speed Analysis: Block Swap Count Reduction with FP8 Scaled

[00:05:12](https://youtu.be/RQHmyJVOHXo?t=312) Why 32GB GPUs Don't Need FP8 Scaled: Fitting Completely with Torch Compile

[00:05:36](https://youtu.be/RQHmyJVOHXo?t=336) DreamBooth Training Specifics: BF16 Mixed Precision and Tab Selection

[00:06:18](https://youtu.be/RQHmyJVOHXo?t=378) New 80GB GPU Configuration: Significant Training Speed Up and Cost Analysis

[00:07:39](https://youtu.be/RQHmyJVOHXo?t=459) New Feature: FLUX FP8 Converter Tool for DreamBooth Models

[00:08:10](https://youtu.be/RQHmyJVOHXo?t=490) Verifying Quality of Converted FP8 Scaled Models vs Original BF16

[00:09:03](https://youtu.be/RQHmyJVOHXo?t=543) New Image Pre-processing Tool: Visualizing How Kohya Sees Your Dataset

[00:09:34](https://youtu.be/RQHmyJVOHXo?t=574) Demonstration of Pre-processing: Identifying Padding and Orientation Issues

[00:10:38](https://youtu.be/RQHmyJVOHXo?t=638) Additional Features: Memory Efficient Loading and CPU Text Encoder Caching

[00:11:23](https://youtu.be/RQHmyJVOHXo?t=683) New Automated Model Downloader Tool: Installation and Model Selection Guide

[00:12:35](https://youtu.be/RQHmyJVOHXo?t=755) FLUX 2 vs FLUX 1 Context: Can the New Model Replace Existing Workflows?

[00:13:03](https://youtu.be/RQHmyJVOHXo?t=783) Setting Up the Generation Comparison: SRPO Fine-tune vs Base vs FLUX 2 Pro

[00:14:13](https://youtu.be/RQHmyJVOHXo?t=853) Analyzing First Comparison Results: Portrait Quality and Realism Assessment

[00:15:02](https://youtu.be/RQHmyJVOHXo?t=902) Second Comparison Test: Handling Unrealistic Elements and Animals in Prompts

[00:15:33](https://youtu.be/RQHmyJVOHXo?t=933) Importance of Resolution and Platform Choice for FLUX 2 Quality

[00:16:24](https://youtu.be/RQHmyJVOHXo?t=984) Analyzing Second Results: Prompt Adherence and Realism in FLUX 2 vs SRPO

[00:17:07](https://youtu.be/RQHmyJVOHXo?t=1027) Testing the Prompt on Nano Banana Pro: Quality Assessment

[00:17:39](https://youtu.be/RQHmyJVOHXo?t=1059) Comparison with Seedream 4 Model and Final Thoughts on FLUX 2 Potential

[00:18:50](https://youtu.be/RQHmyJVOHXo?t=1130) Current Recommendation: Why Qwen Image Realism is the Temporary King

In this video, I demonstrate the newest improvements and features added to our SECourses Premium Kohya Trainer (v35). We have achieved massive performance gains and VRAM reductions, allowing for high-quality FLUX training on GPUs with as little as 6GB of VRAM using the FLUX SRPO model.

I also break down the brand new FLUX 2 announcement! We perform a side-by-side comparison between my locally trained FLUX SRPO model, the base FLUX 1 Dev, and the newly released FLUX 2 Pro model to see if it‚Äôs time to switch workflows.

üöÄ Key Updates Covered:

Full Torch Compile Support: Now enabled across all presets for faster training speeds.

FP8 Scaled LoRA Training: On-the-fly conversion that drastically reduces VRAM usage (0 block swaps on 24GB cards) with zero quality loss.

New Tools: Introducing the "FLUX FP8 Converter" to shrink DreamBooth models to 11.1GB and a new "Image Pre-processing" tool to visualize exactly how Kohya sees your dataset.

Hardware Optimization: New presets ranging from 6GB VRAM consumer cards up to 80GB A100/H100 configurations for lightning-fast training.

FLUX 2 Analysis: A realistic look at the 32-billion parameter giant and how it compares to our optimized FLUX 1 workflow.



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=0) Greetings everyone. Today, I am going to show you&nbsp; our newest improvements and features regarding&nbsp;&nbsp;

- [00:00:07](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=7) FLUX training. These images that I am showing&nbsp; you right now were trained locally with our&nbsp;&nbsp;

- [00:00:14](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=14) newest FLUX Kohya trainer, improved by SECourses&nbsp; (by me), and I have used the FLUX SRPO model.&nbsp;

- [00:00:24](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=24) The FLUX SRPO model is the same as the&nbsp; FLUX Dev model; it uses a minimal amount&nbsp;&nbsp;

- [00:00:30](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=30) of VRAM and doesn't require strong hardware, but&nbsp; it is a very realistic model. With our updated&nbsp;&nbsp;

- [00:00:38](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=38) configurations and training presets, you will&nbsp; be able to train amazing realism-having FLUX&nbsp;&nbsp;

- [00:00:45](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=45) SRPO models, the same as the FLUX Dev model.&nbsp; Our presets are working both on the FLUX Dev&nbsp;&nbsp;

- [00:00:52](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=52) model and the FLUX SRPO model, and as I said, it&nbsp; works as low as with 6 GB of VRAM-having GPUs;&nbsp;&nbsp;

- [00:01:01](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=61) you can train locally on Windows. Furthermore, FLUX 2 has been published&nbsp;&nbsp;

- [00:01:07](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=67) today, a few hours ago, and I am going to&nbsp; make a comparison with FLUX 2. I am going to&nbsp;&nbsp;

- [00:01:14](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=74) use the BFL (Black Forest Labs) playground to make&nbsp; comparisons. For example, this image was generated&nbsp;&nbsp;

- [00:01:22](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=82) with FLUX 2 at 2048 by 2048 pixels. And this image&nbsp; was generated locally on my computer with the FLUX&nbsp;&nbsp;

- [00:01:31](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=91) SRPO model using our FLUX generation preset, and&nbsp; the biggest difference is that the FLUX SRPO model&nbsp;&nbsp;

- [00:01:37](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=97) is very small compared to the FLUX 2 Dev model. The FLUX 2 Dev model is massive; it is 32 billion&nbsp;&nbsp;

- [00:01:45](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=105) parameters, 64.4 GB, and this is BF16, not even&nbsp; FP8 quantized. ComfyUI is already working on&nbsp;&nbsp;

- [00:01:56](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=116) quantized models for the FLUX 2 model. You see,&nbsp; its text encoder is 35 GB. Its quantized FP8 model&nbsp;&nbsp;

- [00:02:04](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=124) is 35 GB. Therefore, currently running the FLUX&nbsp; 2 model on our consumer GPUs will be very hard.&nbsp;

- [00:02:11](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=131) So, what changes do we have with our Kohya&nbsp; trainer, the SECourses Premium Kohya Trainer?&nbsp;&nbsp;

- [00:02:18](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=138) Let me show you them quickly. So, our training&nbsp; tutorials are still 100% valid. You see the&nbsp;&nbsp;

- [00:02:25](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=145) link is here. This is DreamBooth training;&nbsp; this tutorial includes Windows training,&nbsp;&nbsp;

- [00:02:30](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=150) RunPod training, and MassedCompute training.&nbsp; And if you are interested in LoRA training,&nbsp;&nbsp;

- [00:02:34](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=154) this tutorial has LoRA training for Windows;&nbsp; we also have RunPod and MassedCompute as well.&nbsp;&nbsp;

- [00:02:40](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=160) The links will be in the description of the video. So, what changes have we made since these&nbsp;&nbsp;

- [00:02:46](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=166) tutorials? With version 35, we have added so&nbsp; many new features. Now I am developing the GUI&nbsp;&nbsp;

- [00:02:53](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=173) and the SD Scripts; I have forked their original&nbsp; repositories and I am improving them. We are fully&nbsp;&nbsp;

- [00:02:59](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=179) supporting Torch Compile. Let me open all sections&nbsp; to show you the newest changes. So when you search&nbsp;&nbsp;

- [00:03:06](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=186) for "Torch," you will see Torch Compile; all of&nbsp; our new presets are supporting and using this.&nbsp;

- [00:03:13](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=193) The new presets are like this. You see, these&nbsp; are our LoRA presets. I have updated all the VRAM&nbsp;&nbsp;

- [00:03:20](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=200) usages according to the Torch Compile, so now they&nbsp; are faster. Moreover, with LoRA, now we support&nbsp;&nbsp;

- [00:03:27](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=207) FP8 Scaled, just as Musubi Tuner. This was also&nbsp; not a feature in the original Kohya SD Scripts;&nbsp;&nbsp;

- [00:03:35](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=215) now we are on-the-fly converting the base&nbsp; model into an FP8 Scaled model. And what&nbsp;&nbsp;

- [00:03:42](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=222) kind of impact could this be making? From a&nbsp; quality-wise perspective, this is making almost&nbsp;&nbsp;

- [00:03:48](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=228) no difference. So this is BF16 LoRA; this is FP8&nbsp; Scaled weights LoRA. These are from grid images,&nbsp;&nbsp;

- [00:04:01](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=241) so these are not cherry-picked; this is BF16, FP8&nbsp; Scaled. So there is almost no difference between&nbsp;&nbsp;

- [00:04:14](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=254) BF16 versus FP8 Scaled weights while training. What about the VRAM usage difference? So let's&nbsp;&nbsp;

- [00:04:24](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=264) load the configurations to see. Go to the LoRA&nbsp; tab, open all sections. Let's select our LoRA from&nbsp;&nbsp;

- [00:04:31](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=271) our LoRA configuration; the first config will be&nbsp; 24 GB Quality 1. You see this configuration? And&nbsp;&nbsp;

- [00:04:39](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=279) let's see the swap count, block swap count. So&nbsp; when we don't use FP8 Scaled, we have to do 13&nbsp;&nbsp;

- [00:04:48](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=288) block swap count. This means that it will use RAM&nbsp; for 13 blocks of the model. So it will be slow,&nbsp;&nbsp;

- [00:04:56](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=296) basically. And let's look at the 24 GB FP8 Scaled.&nbsp; When I load it and look at the block swap count,&nbsp;&nbsp;

- [00:05:04](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=304) it is zero. This means that you will get a huge&nbsp; amount of speed up if you have a 24 GB GPU.&nbsp;

- [00:05:12](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=312) Moreover, you see I do not have FP8 Scaled for 32&nbsp; GB GPUs. Why? Because they are fitting into VRAM&nbsp;&nbsp;

- [00:05:22](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=322) completely right now since we have Torch Compile&nbsp; enabled in all our configurations, and it is even&nbsp;&nbsp;

- [00:05:29](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=329) reducing the VRAM usage further. These were LoRA&nbsp; configs. So in DreamBooth, sadly, you cannot train&nbsp;&nbsp;

- [00:05:36](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=336) models with FP8 Scaled; currently, only BF16&nbsp; mixed precision training is supported. However,&nbsp;&nbsp;

- [00:05:43](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=343) don't worry, the 32 GB configuration is&nbsp; also fitting into the VRAM completely.&nbsp;

- [00:05:50](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=350) So for DreamBooth, for fine-tuning, don't&nbsp; forget to refresh, go to the DreamBooth tab,&nbsp;&nbsp;

- [00:05:55](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=355) and load from here; otherwise, it will not work.&nbsp; This is very important if you remember from the&nbsp;&nbsp;

- [00:06:01](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=361) original tutorial. The DreamBooth configurations&nbsp; go into here. This is also fine-tuning; do not use&nbsp;&nbsp;

- [00:06:06](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=366) this tab for fine-tuning. The DreamBooth tab is&nbsp; also for fine-tuning, and LoRA for the LoRA tab.&nbsp;

- [00:06:12](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=372) And what other new configurations do we have? When&nbsp; we look at the configurations, we now have an 80&nbsp;&nbsp;

- [00:06:18](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=378) GB GPU configuration. And what is this doing? This&nbsp; is speeding up the training significantly. If you&nbsp;&nbsp;

- [00:06:26](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=386) look at some of the training speeds which I have&nbsp; shared here‚Äîyou see there are example speeds‚Äîyou&nbsp;&nbsp;

- [00:06:33](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=393) can see that the 80 GB configuration on the RTX&nbsp; 6000 Pro is 1.7 seconds/it. This is for batch&nbsp;&nbsp;

- [00:06:41](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=401) size 1, 1024 by 1024 pixels. So if you train 28&nbsp; images with 200 epochs, it is going to take 200&nbsp;&nbsp;

- [00:06:50](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=410) multiplied by 1.7, multiplied by 28. This many&nbsp; seconds, and this is going to take 158 minutes&nbsp;&nbsp;

- [00:06:59](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=419) total. And this will be the highest quality. And how much would this cost you on MassedCompute&nbsp;&nbsp;

- [00:07:05](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=425) with an RTX 6000 Pro? With our coupon, it would be&nbsp; 1.8 multiplied by 0.75, which is $1.35 per hour,&nbsp;&nbsp;

- [00:07:17](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=437) and multiply it by like 2.5 hours, it would cost&nbsp; you like $3.30 total. You can also use an RTX 4090&nbsp;&nbsp;

- [00:07:25](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=445) on RunPod; you see it is 2.66 seconds/it. So&nbsp; we have got amazing speed ups with our newest&nbsp;&nbsp;

- [00:07:33](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=453) configuration compared to our previous tutorial. Another new feature we have is in the Utilities&nbsp;&nbsp;

- [00:07:39](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=459) tab; you will see we have the FLUX FP8 Converter.&nbsp; This is for converting your FLUX DreamBooth models&nbsp;&nbsp;

- [00:07:46](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=466) into FP8, but this is also Scaled FP8, so the&nbsp; quality is amazing. What do you gain by this?&nbsp;&nbsp;

- [00:07:53](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=473) Normally, original models are 22.2 GB; with&nbsp; FP8 Scaled converted models, it is 11.1 GB. So&nbsp;&nbsp;

- [00:08:03](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=483) it will fit into your 12 GB GPUs as well. And do&nbsp; you lose quality? Let me show you. I have tested&nbsp;&nbsp;

- [00:08:10](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=490) all these configurations to verify them. I have&nbsp; grids for all of them. So this is here... okay,&nbsp;&nbsp;

- [00:08:17](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=497) let me open it, and let's uncheck all...&nbsp; and here: BF16, BF16 FP8 converted. So&nbsp;&nbsp;

- [00:08:24](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=504) the converted model versus BF16. So this is the&nbsp; original BF16 model, and this is the FP8 Scaled&nbsp;&nbsp;

- [00:08:32](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=512) converted model. This is the BF16 model; this is&nbsp; the FP8 Scaled model. You see, almost the same.&nbsp;&nbsp;

- [00:08:38](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=518) There is no quality loss when you convert your&nbsp; trained models into FP8 Scaled versions with our&nbsp;&nbsp;

- [00:08:55](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=535) newest tool. This is a very nice addition to&nbsp; our SECourses Premium Kohya GUI application.&nbsp;

- [00:09:03](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=543) Another amazing tool we have is Image&nbsp; Pre-processing. What this does is that&nbsp;&nbsp;

- [00:09:09](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=549) it pre-processes your training images exactly&nbsp; as Kohya is going to do during training. So you&nbsp;&nbsp;

- [00:09:16](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=556) will see your actual training images‚Äîhow they were&nbsp; pre-processed, how they were processed. This will&nbsp;&nbsp;

- [00:09:22](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=562) help you to figure out your inaccurate images&nbsp; or orientation-problematic images. For example,&nbsp;&nbsp;

- [00:09:28](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=568) let's pre-process these images. Input images and&nbsp; output images will be "test pre," and I am going&nbsp;&nbsp;

- [00:09:34](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=574) to select FLUX; I am going to enable bucketing.&nbsp; You can also fix EXIF orientation to use them,&nbsp;&nbsp;

- [00:09:41](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=581) and these are our resolutions.&nbsp; Let's process images. So you see,&nbsp;&nbsp;

- [00:09:44](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=584) it is very fast; it is all pre-processed. When I go to this folder, you see:&nbsp;&nbsp;

- [00:09:50](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=590) this is how FLUX is going to use my images. When&nbsp; you open these images, you see it has added some&nbsp;&nbsp;

- [00:09:58](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=598) padding here; it has inaccurate orientation, so&nbsp; I would have very bad quality training if I had&nbsp;&nbsp;

- [00:10:06](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=606) used these images like this one. I mean,&nbsp; if I had used these images as my dataset,&nbsp;&nbsp;

- [00:10:13](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=613) they would be actually used like this, not&nbsp; like this. So this pre-processing tool will&nbsp;&nbsp;

- [00:10:19](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=619) give you a huge amount of information about your&nbsp; buckets because it will show you different aspect&nbsp;&nbsp;

- [00:10:24](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=624) ratio images as well in here, so I recommend you&nbsp; to use this for pre-processing your dataset to&nbsp;&nbsp;

- [00:10:31](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=631) see how they were actually used during training. What other options do we have as a new feature?&nbsp;&nbsp;

- [00:10:38](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=638) When you go to the presets, you will see that&nbsp; it is starting from 8 GB of GPUs. Moreover,&nbsp;&nbsp;

- [00:10:44](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=644) now I have optimized the model loading. So&nbsp; now we support memory-efficient loading;&nbsp;&nbsp;

- [00:10:51](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=651) therefore, you can do training with lower&nbsp; RAM memory as well‚Äînot only VRAM but also&nbsp;&nbsp;

- [00:10:57](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=657) RAM memory as well. Furthermore, when you start&nbsp; training right now, it will show you the actual&nbsp;&nbsp;

- [00:11:03](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=663) training speed after the very first step. This was&nbsp; problematic previously; now it is fixed. Moreover,&nbsp;&nbsp;

- [00:11:11](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=671) I have added CPU-based text encoder caching so&nbsp; that it will work with lower VRAM GPUs as well.&nbsp;

- [00:11:18](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=678) And we have a new model downloader.&nbsp; So when you download this zip file‚Äîlet&nbsp;&nbsp;

- [00:11:23](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=683) me demonstrate for you‚Äîyou will get to&nbsp; these files. It will contain the newest&nbsp;&nbsp;

- [00:11:28](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=688) configs, DreamBooth tab, LoRA tab; it will have&nbsp; test prompts that you can use, and it will have&nbsp;&nbsp;

- [00:11:35](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=695) "Windows Download Training Models." First of all,&nbsp; I need to start installation so it will generate&nbsp;&nbsp;

- [00:11:40](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=700) a virtual environment so that I can also use the&nbsp; Windows download models. When you run the Windows&nbsp;&nbsp;

- [00:11:46](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=706) download models, it will ask you which model you&nbsp; want to download. It will not download duplicates.&nbsp;&nbsp;

- [00:11:52](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=712) So you can download FLUX Dev FP8 Precision‚ÄîI&nbsp; don't recommend this; this is not needed anymore.&nbsp;&nbsp;

- [00:11:59](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=719) You can download the regular FLUX Dev model as&nbsp; usual, as before. You can download the FLUX Krea&nbsp;&nbsp;

- [00:12:04](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=724) Dev model, but training on the Krea Dev model&nbsp; yields very low quality; I don't recommend it.&nbsp;&nbsp;

- [00:12:11](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=731) For realism, use FLUX SRPO Realism. If you want&nbsp; to use it for other things like stylization, 3D,&nbsp;&nbsp;

- [00:12:18](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=738) anime, use FLUX Dev. So you can directly&nbsp; select your option, and it will download&nbsp;&nbsp;

- [00:12:23](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=743) all the necessary models without any errors&nbsp; because this is also doing hash calculation,&nbsp;&nbsp;

- [00:12:28](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=748) hash verification, so they will be 100% accurate. And now let's make some comparisons with the FLUX&nbsp;&nbsp;

- [00:12:35](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=755) 2 model because it was just published a few&nbsp; hours ago. Will it replace our existing FLUX&nbsp;&nbsp;

- [00:12:42](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=762) workflow? Currently, not yet, because the&nbsp; quality is not there yet. It is a very big&nbsp;&nbsp;

- [00:12:48](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=768) model. V1 is yielding better results, better&nbsp; quality with lower VRAM requirements, but I&nbsp;&nbsp;

- [00:12:55](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=775) will be following FLUX 2 very closely. So let's&nbsp; generate some images and let's make comparisons.&nbsp;

- [00:13:03](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=783) For example, this was generated with a FLUX&nbsp; SRPO trained model with myself. You see,&nbsp;&nbsp;

- [00:13:09](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=789) this is the quality; it is really good. This&nbsp; is 2048 pixels. I will copy the prompt. Then I&nbsp;&nbsp;

- [00:13:15](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=795) will generate it on base FLUX SRPO. For base FLUX&nbsp; SRPO, I am using the FLUX Dev models preset and&nbsp;&nbsp;

- [00:13:23](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=803) also using the upscale preset we have, this one.&nbsp; So let's copy-paste it and let's generate. Then&nbsp;&nbsp;

- [00:13:29](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=809) let's also generate 2048 by 2048 on the FLUX 2&nbsp; model on the FLUX official website. So this is the&nbsp;&nbsp;

- [00:13:38](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=818) highest quality; this is the FLUX 2 Pro model, not&nbsp; the FLUX 2 Dev model, because we will have access&nbsp;&nbsp;

- [00:13:45](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=825) to the Dev model, not the Pro model. ComfyUI is already working on it,&nbsp;&nbsp;

- [00:13:48](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=828) and SwarmUI probably will add it after SwarmUI&nbsp; implements it. Hopefully, I will make a tutorial&nbsp;&nbsp;

- [00:13:55](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=835) and publish the presets as usual with automatic&nbsp; downloading with our downloader application,&nbsp;&nbsp;

- [00:14:01](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=841) so it will be so easy for you to use. Don't&nbsp; worry about that. Okay, this is FLUX SRPO;&nbsp;&nbsp;

- [00:14:06](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=846) it is being generated right now on my PC, and this&nbsp; is the FLUX 2 Pro model; it is also generating.&nbsp;

- [00:14:13](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=853) Okay, so this is the FLUX 2 2048 by 2048 pixels&nbsp; generation. I think it is pretty good quality in&nbsp;&nbsp;

- [00:14:24](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=864) my opinion, but this is the Pro model, not the&nbsp; Dev model, so we need to see it; we need to see&nbsp;&nbsp;

- [00:14:29](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=869) how much time it will take, how much memory&nbsp; it will use. And this is the FLUX SRPO model&nbsp;&nbsp;

- [00:14:36](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=876) for this prompt. Of course, FLUX 2 is expected&nbsp; to have better prompt following, but I can say&nbsp;&nbsp;

- [00:14:44](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=884) that this is a pretty good, pretty high-quality&nbsp; realistic image. And this is my fine-tuned model;&nbsp;&nbsp;

- [00:14:49](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=889) this is also excellent quality as you can see.&nbsp; This is myself, and this is the generated image.&nbsp;

- [00:14:56](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=896) Let's try another prompt and make a&nbsp; comparison. Okay, this one. So this&nbsp;&nbsp;

- [00:15:02](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=902) image has an unrealistic element. You see this&nbsp; animal? This is not a real animal; therefore,&nbsp;&nbsp;

- [00:15:08](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=908) you can see that it doesn't look as realistic&nbsp; as myself, as my image. Let's copy this prompt&nbsp;&nbsp;

- [00:15:14](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=914) and try with the SRPO base model. When you&nbsp; have things in your images, in your prompts,&nbsp;&nbsp;

- [00:15:19](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=919) that are not realistic, not existing in real life,&nbsp; the models will struggle to generate realistic&nbsp;&nbsp;

- [00:15:26](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=926) images. Let's see what FLUX 2 can do for this. By the way, if you use FLUX 2 on other services&nbsp;&nbsp;

- [00:15:33](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=933) like on Fal.ai or anywhere else, the quality is&nbsp; very bad compared to the FLUX 2 on BFL itself.&nbsp;&nbsp;

- [00:15:45](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=945) Moreover, set your resolution to the highest&nbsp; resolution; otherwise, the quality is low&nbsp;&nbsp;

- [00:15:50](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=950) again. So this is the maximum, very best quality&nbsp; of FLUX 2 models. Therefore, when we can locally&nbsp;&nbsp;

- [00:15:57](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=957) generate‚Äîhopefully maybe tomorrow, maybe today‚Äîwe&nbsp; will be able to aim for the maximum quality. But&nbsp;&nbsp;

- [00:16:03](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=963) there is a problem because this would take a&nbsp; huge amount of time with 50 steps; currently,&nbsp;&nbsp;

- [00:16:08](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=968) this is probably what it is doing, maybe 20 steps.&nbsp; We need speed-up LoRAs to be able to use this&nbsp;&nbsp;

- [00:16:15](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=975) model fast; otherwise, it will take a lot of time. Okay, so this is the FLUX 2 model generation. I&nbsp;&nbsp;

- [00:16:24](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=984) think this is pretty cool; the image is realistic.&nbsp; You see this bird is not very realistic,&nbsp;&nbsp;

- [00:16:29](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=989) but this is expected because this doesn't&nbsp; exist in real life. So this is what we get,&nbsp;&nbsp;

- [00:16:34](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=994) but this is a really good image in my opinion.&nbsp; So this was my image. So this is FLUX 2 Pro;&nbsp;&nbsp;

- [00:16:41](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1001) this followed the prompt better perhaps, I&nbsp; am not sure. And this is my generated image.&nbsp;&nbsp;

- [00:16:48](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1008) So this was the prompt, you can read it, and&nbsp; this is the FLUX SRPO base model generation,&nbsp;&nbsp;

- [00:16:54](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1014) not fine-tuned. So my fine-tuned model has the&nbsp; most realism; FLUX SRPO is also very realistic,&nbsp;&nbsp;

- [00:17:00](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1020) and this is FLUX 2. FLUX 2 also has great realism. Let's test this prompt on Nano Banana as well. I&nbsp;&nbsp;

- [00:17:07](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1027) wonder what it can do, so I will make it image&nbsp; only. So this is Nano Banana Pro. Currently,&nbsp;&nbsp;

- [00:17:13](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1033) this doesn't generate very big resolution,&nbsp; but we will see. Okay, this is Nano Banana 2,&nbsp;&nbsp;

- [00:17:20](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1040) Nano Banana Pro generation. I think it is bad, not&nbsp; good. So you see it is not even very realistic,&nbsp;&nbsp;

- [00:17:27](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1047) so the FLUX 2 is better, but we cannot set higher&nbsp; quality with Nano Banana. I don't know, maybe it&nbsp;&nbsp;

- [00:17:32](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1052) can generate higher quality somewhere else, but&nbsp; this is its generation on a third-party provider.&nbsp;

- [00:17:39](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1059) I also want to test this on Seedream 4, so let's&nbsp; see what it can do. This is by default generating&nbsp;&nbsp;

- [00:17:47](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1067) very high resolution. This is a Chinese model as&nbsp; well, but not open source. So the FLUX 2 Dev model&nbsp;&nbsp;

- [00:17:54](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1074) with accurate settings is, we can say, promising.&nbsp; Hopefully, we will get this quality. If we can get&nbsp;&nbsp;

- [00:18:01](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1081) this quality, it is really good. I mean, this is&nbsp; a native generation probably; I don't know if they&nbsp;&nbsp;

- [00:18:06](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1086) are doing some upscaling or native generating.&nbsp; We are doing upscaling with this image with our&nbsp;&nbsp;

- [00:18:11](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1091) preset, but you can see that it has an excellent&nbsp; amount of details. And this is Seedream 4. You&nbsp;&nbsp;

- [00:18:17](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1097) see, Seedream 4 is also a really good model.&nbsp; I think, in my opinion, FLUX 2 is better.&nbsp;

- [00:18:23](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1103) Yeah, it is up to you, you can decide.&nbsp; You can also test on the BFL playground;&nbsp;&nbsp;

- [00:18:29](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1109) they give you 50 free images, so I am using them.&nbsp; And we already have our tutorials for, you know,&nbsp;&nbsp;

- [00:18:36](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1116) installing SwarmUI, using these things locally. So&nbsp; I hope you have enjoyed. Please like, subscribe,&nbsp;&nbsp;

- [00:18:44](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1124) and one more thing that I need to mention: we have&nbsp; got amazing quality with Q1 image models realism.&nbsp;&nbsp;

- [00:18:50](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1130) The tutorial is here. I think this is the king&nbsp; right now until we figure out how to fine-tune,&nbsp;&nbsp;

- [00:18:56](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1136) how to LoRA. So currently the king&nbsp; is Qwen image realism. Therefore,&nbsp;&nbsp;

- [00:19:02](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1142) I recommend you use Qwen image realism until&nbsp; we figure out how to do FLUX 2 training.&nbsp;&nbsp;

- [00:19:15](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1155) For example, this is from Qwen image&nbsp; realism; this is amazing. Watch that&nbsp;&nbsp;

- [00:19:19](https://www.youtube.com/watch?v=RQHmyJVOHXo&t=1159) tutorial to learn more about it. Hopefully see you later.

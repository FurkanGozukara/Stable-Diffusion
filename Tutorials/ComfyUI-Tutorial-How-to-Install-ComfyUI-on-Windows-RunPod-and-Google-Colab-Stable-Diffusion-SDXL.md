# ComfyUI Tutorial - How to Install ComfyUI on Windows, RunPod & Google Colab | Stable Diffusion SDXL

## Full tutorial link > https://www.youtube.com/watch?v=FnMHbhvWUhE

[![ComfyUI Tutorial - How to Install ComfyUI on Windows, RunPod & Google Colab | Stable Diffusion SDXL](https://img.youtube.com/vi/FnMHbhvWUhE/sddefault.jpg)](https://www.youtube.com/watch?v=FnMHbhvWUhE "ComfyUI Tutorial - How to Install ComfyUI on Windows, RunPod & Google Colab | Stable Diffusion SDXL")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/ComfyUI-Tutorial-How-to-Install-ComfyUI-on-Windows-RunPod-and-Google-Colab-Stable-Diffusion-SDXL.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/ComfyUI-Tutorial-How-to-Install-ComfyUI-on-Windows-RunPod-and-Google-Colab-Stable-Diffusion-SDXL.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Updated for SDXL 1.0. #ComfyUI is a node based powerful and modular Stable Diffusion GUI and backend. This UI will let you design and execute advanced Stable Diffusion pipelines using a graph/nodes/flowchart based interface. In this video I will teach you how to install ComfyUI on PC, Google Colab (Free) and RunPod. I will also show you how to install and use #SDXL with ComfyUI including how to do inpainting and use LoRAs with ComfyUI. This is the Zero to Hero ComfyUI tutorial.

Source GitHub Readme File ‚§µÔ∏è

[https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Use-ComfyUI-On-Your-PC-On-RunPod-On-Colab-With-SDXL.md](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Use-ComfyUI-On-Your-PC-On-RunPod-On-Colab-With-SDXL.md)

Automatic RunPod Installer Script File ‚§µÔ∏è

[https://www.patreon.com/posts/runpod-comfyui-86062569](https://www.patreon.com/posts/runpod-comfyui-86062569)

Automatic Windows Installer Script File ‚§µÔ∏è

[https://www.patreon.com/posts/92013455](https://www.patreon.com/posts/92013455)

Our Discord server ‚§µÔ∏è

[https://bit.ly/SECoursesDiscord](https://bit.ly/SECoursesDiscord)

If I have been of assistance to you and you would like to show your support for my work, please consider becoming a patron on ü•∞ ‚§µÔ∏è

[https://www.patreon.com/SECourses](https://www.patreon.com/SECourses)

Technology & Science: News, Tips, Tutorials, Tricks, Best Applications, Guides, Reviews ‚§µÔ∏è

[https://www.youtube.com/playlist?list=PL_pbwdIyffsnkay6X91BWb9rrfLATUMr3](https://www.youtube.com/playlist?list=PL_pbwdIyffsnkay6X91BWb9rrfLATUMr3)

Playlist of #StableDiffusion Tutorials, Automatic1111 and Google Colab Guides, DreamBooth, Textual Inversion / Embedding, LoRA, AI Upscaling, Pix2Pix, Img2Img ‚§µÔ∏è

[https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3](https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3)

[00:00:00](https://youtu.be/FnMHbhvWUhE?t=0) Introduction to the 0 to Hero ComfyUI tutorial

[00:01:26](https://youtu.be/FnMHbhvWUhE?t=86) How to install ComfyUI on Windows

[00:02:15](https://youtu.be/FnMHbhvWUhE?t=135) How to update ComfyUI

[00:02:55](https://youtu.be/FnMHbhvWUhE?t=175) To to install Stable Diffusion models to the ComfyUI

[00:03:14](https://youtu.be/FnMHbhvWUhE?t=194) How to download Stable Diffusion models from Hugging Face

[00:04:08](https://youtu.be/FnMHbhvWUhE?t=248) How to download Stable Diffusion x large (SDXL)

[00:05:17](https://youtu.be/FnMHbhvWUhE?t=317) Where to put downloaded VAE and Stable Diffusion model checkpoint files in ComfyUI installation

[00:06:07](https://youtu.be/FnMHbhvWUhE?t=367) How to start / run ComfyUI after installation

[00:06:30](https://youtu.be/FnMHbhvWUhE?t=390) Start using ComfyUI - explanation of nodes and everything

[00:07:52](https://youtu.be/FnMHbhvWUhE?t=472) How to add a custom VAE decoder to the ComfyUI

[00:08:22](https://youtu.be/FnMHbhvWUhE?t=502) Image saving and saved image naming convention in ComfyUI

[00:08:44](https://youtu.be/FnMHbhvWUhE?t=524) Queue system of ComfyUI - best feature

[00:09:48](https://youtu.be/FnMHbhvWUhE?t=588) How to save workflow in ComfyUI

[00:10:07](https://youtu.be/FnMHbhvWUhE?t=607) How to use generated images to load workflow

[00:10:54](https://youtu.be/FnMHbhvWUhE?t=654) How to use SDXL with ComfyUI

[00:13:29](https://youtu.be/FnMHbhvWUhE?t=809) How to batch add operations to the ComfyUI queue

[00:13:57](https://youtu.be/FnMHbhvWUhE?t=837) How to generate multiple images at the same size

[00:15:01](https://youtu.be/FnMHbhvWUhE?t=901) File name prefixs of generated images

[00:15:22](https://youtu.be/FnMHbhvWUhE?t=922) SDXL base image vs refiner improved image comparison

[00:15:49](https://youtu.be/FnMHbhvWUhE?t=949) How to disable refiner or nodes of ComfyUI

[00:16:30](https://youtu.be/FnMHbhvWUhE?t=990) Where you can find shorts of ComfyUI

[00:17:18](https://youtu.be/FnMHbhvWUhE?t=1038) How to enable back nodes

[00:17:38](https://youtu.be/FnMHbhvWUhE?t=1058) How to use inpainting with SDXL with ComfyUI

[00:20:43](https://youtu.be/FnMHbhvWUhE?t=1243) How to use SDXL refiner as the base model

[00:20:57](https://youtu.be/FnMHbhvWUhE?t=1257) How to use LoRAs with SDXL

[00:23:06](https://youtu.be/FnMHbhvWUhE?t=1386) How to see ComfyUI is processing the which part of the workflow

[00:23:48](https://youtu.be/FnMHbhvWUhE?t=1428) How to learn more about how to use ComfyUI

[00:24:47](https://youtu.be/FnMHbhvWUhE?t=1487) Where is the ComfyUI support channel

[00:25:01](https://youtu.be/FnMHbhvWUhE?t=1501) How to install and use ComfyUI on a free Google Colab

[00:28:10](https://youtu.be/FnMHbhvWUhE?t=1690) How to download SDXL model into Google Colab ComfyUI

[00:30:33](https://youtu.be/FnMHbhvWUhE?t=1833) How to use ComfyUI with SDXL on Google Colab after the installation

[00:32:45](https://youtu.be/FnMHbhvWUhE?t=1965) Testing out SDXL on a free Google Colab

[00:33:40](https://youtu.be/FnMHbhvWUhE?t=2020) You can use SDXL on a low VRAM machine but how

[00:34:10](https://youtu.be/FnMHbhvWUhE?t=2050) How to download all images generated on Google Colab

[00:36:18](https://youtu.be/FnMHbhvWUhE?t=2178) How to install and use ComfyUI (latest version) on RunPod including SDXL

[00:37:19](https://youtu.be/FnMHbhvWUhE?t=2239) Where to learn how to use RunPod

[00:38:40](https://youtu.be/FnMHbhvWUhE?t=2320) Instructions to the manual installation of ComfyUI on a RunPod

[00:41:52](https://youtu.be/FnMHbhvWUhE?t=2512) How to start ComfyUI after the installation

[00:43:19](https://youtu.be/FnMHbhvWUhE?t=2599) How to very fast download generated images on a RunPod with runpodctl

[00:44:06](https://youtu.be/FnMHbhvWUhE?t=2646) How to download SDXL on RunPod manually

Thumbnail artworks from moldadorite from deviantart



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=0) Greetings everyone. In this video, I will show you how to install and use ComfyUI on your

- [00:00:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=6) computer. Moreover, I will explain most important fundamentals of ComfyUI. Then I will show you how

- [00:00:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=13) you can use SDXL with ComfyUI without refiner and with refiner. Then I will show how you can

- [00:00:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=21) use SDXL with LoRAs like you are seeing right now. This is a LoRA that is trained on myself.

- [00:00:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=28) Hopefully, my next tutorial will be about this: how to train LoRAs with SDXL. Then I will show how

- [00:00:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=35) you can use inpainting with SDXL as you are seeing right now. Then I will show how to install and use

- [00:00:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=42) ComfyUI on a free Google Colab with SDXL. Then I will show you how you can install and use ComfyUI

- [00:00:51](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=51) on RunPod with SDXL support as well. So I have prepared a very detailed GitHub readme file. All

- [00:00:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=59) of the commands and links that you are going to need will be posted here. Moreover, if something

- [00:01:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=66) gets changed in the future, I will update this readme file so you will always have up-to-date

- [00:01:14](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=74) instructions. The link of this file will be in the description of the video and also comment section

- [00:01:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=80) of the video. So let's begin with installing on our PC. PC installation is very easy. Just click

- [00:01:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=88) this link. In here you will see releases page and direct download link. I will click direct download

- [00:01:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=95) link. This is a 7-zip file. So the download is completed. You see it is here. Let's show

- [00:01:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=102) in folder. Cut the downloaded file. It is 1.4 GB. Move into any folder where you want to install. I

- [00:01:51](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=111) will install it inside my F drive. Right click and extract here. Since this is a 7-zip file,

- [00:01:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=118) you need Winrar or 7-zip to extract it. I have put the Winrar link here. Just open it and download

- [00:02:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=125) Winrar x64 version and install it. The files are extracted. This is all you need to do for

- [00:02:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=133) using ComfyUI. But before using it, let's also update. So enter inside update folder and click

- [00:02:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=141) update ComfyUI.bat file and it has updated. This readme file is important. It gives you some of

- [00:02:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=150) the information. You should use update of ComfyUI with dependencies only if you are having issues.

- [00:02:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=157) Moreover, if you have NVIDIA GPU, run with NVIDIA GPU. If you don't have NVIDIA GPU, run with CPU.

- [00:02:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=165) I don't know if it is supporting AMD GPUs. So I will begin using ComfyUI with NVIDIA GPU. However,

- [00:02:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=173) we don't have any checkpoints yet. So go inside ComfyUI. Go inside models. Here you will see

- [00:03:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=180) checkpoints. We need to put checkpoints here. I have added Realistic Vision version 4 direct

- [00:03:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=185) download link. So let's click and download it. You see the download started. I will also use the best

- [00:03:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=191) VAE file. Let's also click and download it. You can download models from CivitAI or from Hugging

- [00:03:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=198) Face. I prefer to use Hugging Face for downloading models. When you click models, it will list

- [00:03:24](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=204) your models. In here for example, go to Stable Diffusion 1.5 version. You will see a label like

- [00:03:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=210) this Stable Diffusion when you click it. It will list you all of the trending by default Stable

- [00:03:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=216) Diffusion models like this. You can also sort it by other things. I am not preferring CivitAI

- [00:03:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=223) because it is extremely saturated. Therefore, I prefer downloading my models from Hugging Face.

- [00:03:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=230) And let's say you want to download DreamLike photo real. Enter here, go to files and versions in here

- [00:03:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=237) look for the safetensors file and download the biggest safetensors files usually. For downloading

- [00:04:04](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=244) click this link and the download will start. But the main purpose of this tutorial is for

- [00:04:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=249) Stable Diffusion x large. So we need to download Stable Diffusion x large model. How you are going

- [00:04:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=255) to do it is that you need to have a Hugging Face account. So if you don't have an account, click

- [00:04:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=260) here and join. If you have an account, click here and login. After that, this is really important.

- [00:04:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=265) Currently, the Stable Diffusion x large version is only available as research purposes. So you need

- [00:04:32](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=272) to open both of these links and accept their terms and services. Then click files and versions here.

- [00:04:40](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=280) And then click this download icon to download SDXL base version. Also download the refiner version

- [00:04:49](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=289) from files and versions you see SDXL refiner version. Just click and download. Let me show you

- [00:04:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=296) the currently the downloading files. SDXL refiner is 5.7 gigabytes. SDXL safetensors base model is

- [00:05:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=305) 12.9 gigabytes. We are also downloading Dream Like photo two gigabytes. This is pruned version. Our

- [00:05:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=312) VAE file is downloaded. Also Realistic Vision version 4 is being downloaded with 4 gigabytes.

- [00:05:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=317) All downloads are completed. Let's first copy the VAE file. This VAE file is necessary for Stable

- [00:05:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=326) Diffusion 1.5 version. So I will cut it, move into our installation folder, which is here, ComfyUI,

- [00:05:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=335) ComfyUI inside here models, inside here VAE and paste it there. Then our model files are also

- [00:05:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=342) here. Let's select all of them and cut them. Then move to the models, move into checkpoints. This is

- [00:05:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=348) where you need to put the model checkpoint files. Either they are safetensors or either they are

- [00:05:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=353) ckpt files. If you have a LoRA file, then you need to put the LoRAs here. If you have Hyper Networks,

- [00:05:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=359) you need to put them here. If you have Embeddings, you need to put them here. This is also supporting

- [00:06:04](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=364) Diffusers as well. Then you need to put them here. Once you have put the necessary model files, just

- [00:06:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=371) run with Nvidia GPU. It won't install anything and it will start this UI immediately. So let me

- [00:06:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=380) clear it. Okay. When you clear the UI, it is like this. This is a node based UI. It is a little bit

- [00:06:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=387) hard to use if you are accustomed to Automatic1111 web UI. So click load default and it will load the

- [00:06:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=395) default workflow. By default workflow. you see our base models here. Currently the Realistic Vision

- [00:06:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=402) version 4 is selected. This is SD1.5 version based model. It is able to generate very cool images

- [00:06:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=410) with 768 and 768 so I changed the resolution here. This is a default text that it comes. So

- [00:06:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=419) this is our seed. Based on seed, the generated image will change control after generate so it

- [00:07:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=425) will change the seed every time you generated an image. Number of steps to generate image. The CFG

- [00:07:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=432) value to generate image. Sampler name. You can see the samplers here. For Stable Diffusion 1.5

- [00:07:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=438) models I prefer eular a as sampler. Scheduler normal. Denoise. Normally we use denoise for

- [00:07:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=446) image to image, but in text to image we are also using it because of the structure of the Stable

- [00:07:33](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=453) Diffusion model, but when we use text to image, it is by default 1. Why? Because we are turning

- [00:07:40](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=460) the latent noise into a full image, therefore denoise 1 is necessary. It is going to use this

- [00:07:46](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=466) VAE Decode and the VAE is provided from the model itself. However, if you want to use the VAE that

- [00:07:54](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=474) you have downloaded so right click here. Add node. In here you will see many options. So we are going

- [00:08:02](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=482) to use loaders. Load VAE. In here you see our downloaded VAE is selected. So all we need to

- [00:08:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=489) do is change this VAE to here like this. So VAE Decode will use the VAE we selected. You can of

- [00:08:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=498) course always use the model embedded VAE but if you want to use specific VAE this is the way. So

- [00:08:24](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=504) save image. This is going to save our image. The save file naming is pretty different. So you need

- [00:08:32](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=512) to define a prefix if you wish. Let's define as Realistic Vision. So all of the images we generate

- [00:08:40](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=520) will have the file name prefix of Realistic Vision. The very cool thing of Comfy web UI

- [00:08:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=528) is the queue system. I like it very much. So let's queue this. It is added to the queue. By the way,

- [00:08:54](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=534) if you want to increase the batch size let them increase, you can increase it here. So let's

- [00:08:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=539) queue another one. So you see now we have another queue. Let's say I also want to test this sampler

- [00:09:04](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=544) name queue it. Let's say you want to test the cfg queue it. Let's say you want to test steps

- [00:09:10](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=550) 25 queue it. You see they are all being added to the queue. Then you can see the queue here. This

- [00:09:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=557) is very cool. You can change the settings, you can change the prompt like fast car added to queue.

- [00:09:23](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=563) You see you can do anything you wish. Add to the queue and everything will be processed according

- [00:09:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=568) to the queue. You see the previews are displayed here. I think we can expand this. Let's expand

- [00:09:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=575) it. You see when you expand it you will see them bigger. You can also zoom in and zoom out. For

- [00:09:41](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=581) zooming in and for zooming out I keep pressing the left control button on my keyboard and I

- [00:09:47](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=587) am using my mouse wheel. So let's say you want to save this workflow. Here you can just click save,

- [00:09:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=593) give it a name as Realistic Vision for example. Click ok. The file will be saved as a json file.

- [00:09:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=599) Then you can load this json file. You can share it. It is only 6 kilobytes. However, this is

- [00:10:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=606) not also necessary. The files are saved inside ComfyUI folder inside output. So all of the images

- [00:10:14](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=614) generated will be saved here and these images have metadata of your configuration. So you can

- [00:10:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=622) drag and drop and load the all of the workflow by using these images. This is really convenient and

- [00:10:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=629) these are the generated images. For example let's clear our workflow. Let's drag and drop one of

- [00:10:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=636) the image and you see all of the workflow of that image is loaded with its seed value. So basically

- [00:10:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=644) when we queue again, we should get the same image generated again. All of the settings are here.

- [00:10:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=650) Selected model and selected VAE and everything. But how are you going to use SD xlarge? You can

- [00:10:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=658) add the nodes yourself one by one, but it is really hard. There is a learning curve and

- [00:11:03](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=663) examples of ComfyUI are shared here. You can open this link and you will see the examples here, but

- [00:11:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=671) I also shared some of the workflows in my GitHub file. So SDXL_1 is the base file that has both

- [00:11:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=680) refiner and base model. How you are going to use it. Right click and save link as. It will download

- [00:11:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=686) the image. Let's download it as sdxl111. Okay, it is saved, then drag and drop into your ComfyUI and

- [00:11:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=694) our Stable Diffusion xlarge. SDXL workflow is loaded. So this may look a little bit confusing

- [00:11:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=702) and hard to understand. And yes, it is like that, but when you look all of the elements one by one,

- [00:11:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=708) you can understand it actually. It begins with base latent image which is a noise. By default,

- [00:11:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=716) SDXL is supporting 1024 and 1024. Therefore, our generated image settings are set here as a latent

- [00:12:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=726) noise. Then we enter our prompts. So this is the prompt that I have decided. Masterpiece, realistic

- [00:12:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=732) photo expensive sports car. You can type anything. This is our negative prompts. And here our models

- [00:12:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=738) are selected. We have refiner you see SDXL refiner and we have base model SDXL base model. Then we

- [00:12:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=747) have our samplers. For example, this is a sampler of the base model. These are the settings that

- [00:12:33](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=753) I find better. Sampler name dpmpp_2s_ancestral. Number of steps 30. CFG 7. Then we have refiner.

- [00:12:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=763) Now the refiner is image to image we know from Automatic1111 web UI. So it will get the base

- [00:12:51](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=771) image generated by the base model. Then it will improve it. So we have denoise 25% here. You

- [00:13:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=780) need to change this and see which one is working best for you. Number of refining steps by default:

- [00:13:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=786) 15 the seed and the sampler. So let's generate several images. First I queue the first item,

- [00:13:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=793) then let's make the denoise 30% create the second item, then let's make the denoise 20% queued the

- [00:13:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=801) third item. You see I can add everything to the queue very quickly and it will do everything

- [00:13:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=807) automatically with the order. You can also see the queue from view queue here. And let's say you want

- [00:13:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=814) to generate 100 images with the current settings. So what you need. Click these extra options and

- [00:13:40](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=820) set the batch count so it will generate the number of times your settings. And let's make

- [00:13:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=828) this as 5 and queue. So you see it has added this workflow 5 times to the queue. This batch size

- [00:13:55](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=835) is one by one executed. If you want to generate multiple images at the same time, then you need

- [00:14:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=841) to increase this batch size here. Currently, while recording video with NVIDIA broadcast

- [00:14:07](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=847) open and also some other applications, this is my VRAM usage. It is working very well. If you have

- [00:14:14](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=854) 8 gigabyte VRAM I think you should be able to use maybe even with 6 gigabyte. I haven't tested it,

- [00:14:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=860) but you should be able to use SDXL very well on your computer. The speed is not that great.

- [00:14:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=867) Currently it is 1.5 it per second for RTX3090. This is when base model is generating. Let me

- [00:14:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=876) zoom in so 1.5 it per second when generating base image and when doing refiner it is even slower.

- [00:14:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=885) 1.4 it per second. Automatic1111 is also working on implementing SDXL and I think it will be much

- [00:14:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=893) faster than this. So our images are being saved here with refiner output and also base output.

- [00:15:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=901) You see you define the file name prefix from here. Whatever you define will be used as a

- [00:15:08](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=908) prefix of the generated images. And image quality of SDXL is amazing. You see. Here another image

- [00:15:16](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=916) you see. It even has the reflection. It is not very correct but it is here. It is amazing. So

- [00:15:23](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=923) the base image is here and here we see the refined image. You see it is amazing. A lot of details and

- [00:15:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=930) quality has been added to the image. It is much more clear, the blueness has gone. It is looking

- [00:15:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=936) much better than the base image. You can also delete the pending queue. Or you can cancel the

- [00:15:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=942) current running queue from here and let's say you want to disable refiner. How you can do that. You

- [00:15:51](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=951) need to move these icons here as you are seeing so you need to open some space. Okay let's move

- [00:15:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=958) them. Let's check for it. Let's move them. Okay we are opening some space. So how refiner is

- [00:16:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=965) working. You see this is the sampler of refiner. So what we need to do is we need to cancel this

- [00:16:14](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=974) sampler to be working. How we are going to do that. We can disable this refiner. We and we

- [00:16:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=981) can disable this sampler. How did I do it? While pressing left ctrl hit m key and it will disable

- [00:16:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=988) the node. So where you can find these shortcuts. I added a shortcut link here. Open it. You will

- [00:16:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=996) see all of the shortcuts. You see mute, unmute selected nodes, select all nodes, load workflow,

- [00:16:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1002) save workflow, and other shortcuts are all shared here. And since I have disabled these two nodes,

- [00:16:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1008) the refiner will not be executed. But now it shows us an error because this node is supposed to be

- [00:16:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1016) executed. Therefore, we need to also disable it. And let's queue again. Now it is telling me that

- [00:17:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1021) I also need to disable this node and now all of the nodes are disabled. It will only generate the

- [00:17:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1029) base image. Okay, now it should work very well. The base image is selected. We can queue more. It

- [00:17:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1035) is queuing 5 times because we have batch count 5. So this is how you disable nodes or for enabling

- [00:17:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1042) back them. Select them and hit ctrl m and they will get enabled again. What about if you want

- [00:17:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1049) to use LoRA or inpainting with SDXL with ComfyUI. I also shared 4 other workflows for them. Let's

- [00:17:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1059) begin with SDXL inpaint. So right click. Save link as download as you wish. Let's say SDXL in paint.

- [00:17:49](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1069) Then let's go back to our UI. Cancel all of the pending operations, just drag and drop the image

- [00:17:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1076) here and you will see the workflow is loaded. It is not very organized. This is what came up

- [00:18:02](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1082) with. So this is base model and how you are going to do inpainting. You need to choose your file to

- [00:18:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1089) inpaint and let's pick a file. Let's go to our ComfyUI generated images inside output folder.

- [00:18:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1097) Let's look at them bigger size. Okay let's try refined image. I will use this one. So this is

- [00:18:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1105) the image that we are going to inpaint. Which part you may be wanting to inpaint. So right

- [00:18:31](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1111) click here and you will see open in mask editor and it will load masking screen. With using mouse

- [00:18:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1119) wheel you can increase or decrease the size of the inpainting circle. You can also change

- [00:18:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1125) the thickness from here. Let's mask this area. If you hit clear it will clear the mask. Okay,

- [00:18:51](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1131) I will just mask this area save to node so you see now we have masked area. You can also upload

- [00:18:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1138) mask I think but I didn't look for it yet so I will use this masked image. Then we need to

- [00:19:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1145) change our prompt. So currently this is a positive prompt. Let's type something there. For example

- [00:19:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1151) an emblem of Lamborghini on a car. I don't know how it will work. This is a pretty small area. We

- [00:19:19](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1159) have the settings here. Okay now denoise is very important. Based on the noise, it will change the

- [00:19:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1165) image. I don't know which one would work best you need to test. Moreover, there is one more

- [00:19:31](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1171) important setting here. This is grow mask by. This is like the padding pixels of Stable Diffusion

- [00:19:38](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1178) Automatic1111 web UI image the image inpainting. So I make this 64 pixels. You can also change it

- [00:19:46](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1186) and you can give a new name here. For example inpainted image and okay and hit queue. Now it

- [00:19:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1196) added 5 queue. By the way since we are using fixed seed they will be all same. So let's make this as

- [00:20:03](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1203) different. Let's change this to randomize and hit queue again. When you click here you will see all

- [00:20:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1209) of the options so you can click these input boxes and you will see the value enterings. You can also

- [00:20:16](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1216) select them from here or by using these arrow keys as you are seeing. So it may get really confusing

- [00:20:23](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1223) in the output folder. Right click, sort by, sort by date and you will see the last generated image

- [00:20:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1228) in the beginning. So this is our inpainted. Okay, I see. Yes nice. It is looking pretty decent. You

- [00:20:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1236) see the emblem is added here. So this is how you do inpainting with SDXL. So what if you want to

- [00:20:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1245) use refiner as a base model instead of the base model? Click here and select refiner from here.

- [00:20:51](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1251) With this way you will use refiner model as an inpainting model. That's it. So how you can use

- [00:20:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1259) LoRA with SDXL? I also have a workflow for that. Right click. Save link as SDXL LoRA png. So let's

- [00:21:08](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1268) drag and drop our image to here and our LoRA workflow will get loaded. So the difference is

- [00:21:14](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1274) that we are adding a load LoRA node anywhere we wish and we connect the model of base to the LoRA

- [00:21:23](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1283) model like this. We connect the clip to the LoRA model. Like this and instead of from model to clip

- [00:21:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1289) text encode, we change the direction from LoRA to clip text encode like this as you are seeing.

- [00:21:38](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1298) If you look for how the nodes are connected, you start to understand the working logic of

- [00:21:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1305) ComfyUI. Actually, this gives you more freedom and more options. However, it is really hard to

- [00:21:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1312) understand at the beginning so you really need to look carefully how the nodes are connected to

- [00:21:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1318) each other. So with this way you can use LoRA. This is a LoRA of myself. I have done over 15

- [00:22:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1326) trainings. So you see my testing LoRAs are here. I am using Kohya UI for doing LoRA training and I

- [00:22:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1333) am trying to find the best workflow for training yourself with extreme realism. Hopefully after

- [00:22:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1340) this video it is my next video. So stay tuned, stay subscribed. So this is the way of loading

- [00:22:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1346) LoRA. Nothing else you need. The LoRA model output goes to our sampler and that's it. So this LoRA

- [00:22:33](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1353) exists in another folder. I will copy one of the LoRA.For example, test8 and let's put it into our

- [00:22:41](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1361) new installation which is here ComfyUI, models, LoRAs. Okay, I paste it here so when I click here,

- [00:22:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1370) it won't be displayed. So I need to refresh my page and after that I need to click it and you

- [00:22:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1377) will see the file is here. Now I can generate myself. Actually, i'm going to do that right

- [00:23:03](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1383) now. Okay, we have this prompt so let's queue it. In ComfyUI it will highlight in the which

- [00:23:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1389) node it is doing processing right now. So we are at the sampler node right now. After that it will

- [00:23:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1395) decode with VAE and we will see the image here. Whatever is happening will be displayed on the

- [00:23:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1402) command line instance of the ComfyUI. So you can see the messages here. If you get error,

- [00:23:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1407) you should look here. Okay, you see, this is me. According to the prompt. This is decent. This is

- [00:23:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1414) not the best, but this is decent. I am still working on the best workflow for training LoRA

- [00:23:40](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1420) models with SDXL and hopefully it will be on the channel very soon. So let's say you want to learn

- [00:23:47](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1427) more about how to use ComfyUI. As I said, you can look the examples posted here for example,

- [00:23:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1433) image to image. Let's open it. You will see that they will display the workflow for image to

- [00:24:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1440) image here. This file is actually containing the workflow metadata. So right. Click. Save image as

- [00:24:08](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1448) save it as your download folder. Got your download and drag and drop the image and it will load the

- [00:24:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1455) workflow displayed there like this. So with this way you can download these examples and load them

- [00:24:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1462) if you wish. This is extremely convenient way. ComfyUI also has a Discord channel like system

- [00:24:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1469) so open their main GitHub repository. Go to the very bottom. In here you will see their chatting

- [00:24:38](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1478) system, support and development channel. It is matrix space. I already joined it. It is free to

- [00:24:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1484) join. When you open it you will get the rooms like this. Join the rooms and you can ask questions to

- [00:24:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1492) the developer and other experts of ComfyUI. They can give you feedback. They can give you workflow

- [00:24:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1498) files. You can load and use them as you wish. Now I will show you how to install and use ComfyUI on

- [00:25:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1506) Google Colab a free Google Colab. Click this link. It will open you this Google Colab page.

- [00:25:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1512) Click connect. Once you are connected, click here and verify that you have GPU ram. Which means you

- [00:25:19](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1519) are assigned to a GPU. If you don't have a GPU, you can change the runtime from here. Click it and

- [00:25:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1525) select python from here. GPU from here and this is the GPU type. Since I am on a free account,

- [00:25:31](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1531) I am not able to select these other GPUs and hit save. You can use Google Drive to save your files,

- [00:25:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1539) upload them, save them. Or if you don't use Google Drive, they will be saved in here. Left,

- [00:25:46](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1546) click here. This is runtime repository. Everything here will get deleted when you terminate your

- [00:25:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1552) runtime from here. Click here and disconnect and delete runtime and everything here will

- [00:25:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1557) get deleted forever. Okay, the setup is pretty easy. First run this cell. Click run anyway. Wait

- [00:26:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1565) until it is fully executed. You will also see new folders are appearing here. It will also display

- [00:26:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1572) the progress in the bottom of this cell as you are seeing right now. This is the progress. It is

- [00:26:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1578) downloading everything and installing everything. You see the ComfyUI appeared here. When I refresh

- [00:26:24](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1584) I will also see whatever is coming new. Okay, the cell execution has been completed. It took only 33

- [00:26:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1590) seconds. Now we can move to the next point. Here they have added quickly download links. If you

- [00:26:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1599) want to download any of these certain models, just remove the # in front of them and they will get

- [00:26:46](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1606) downloaded. So by default they are downloading SD 1.5 version. Let's say you want to use Realistic

- [00:26:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1613) Vision. So how you are going to use it. Find Realistic Vision Hugging Face to your Google.

- [00:26:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1619) Go to the Realistic Vision. In here click this username that is the person who uploads Realistic

- [00:27:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1626) Vision models. Select the realistic vision version that you like. Go to files and versions. In here

- [00:27:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1632) use the biggest file with safetensors. Right click this download icon, copy link,

- [00:27:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1637) and then all you need to do is copy this command. Paste it so it is copy pasted. Then let's copy the

- [00:27:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1646) link again because it is gone. Okay, delete this file and that's all you need to do. Now it will

- [00:27:32](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1652) also download Realistic Vision. Actually, let's disable the other download and let's just download

- [00:27:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1657) Realistic Vision as a beginning so you see it will also download the best VAE file. And there are

- [00:27:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1663) many other models they have added. So I will just download these two models. They will automatically

- [00:27:49](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1669) get downloaded into the correct folder with wget command. Actually we can open the ComfyUI,

- [00:27:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1676) in here models, in here we will see checkpoints and you see they are getting downloaded. You can

- [00:28:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1681) also see the download progress here. It is very fast. Over 200 megabytes per second and the models

- [00:28:07](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1687) are downloaded. So this is the way of downloading models. But we want to use SDXL. So how are we

- [00:28:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1693) going to download it? The procedure is totally same. So let's return back to our GitHub file.

- [00:28:19](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1699) Open the SDXL base files. So this was the base file. Let's go to files and versions. Right click,

- [00:28:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1706) copy link and this time let's change this file link into SDXL file. Let's also copy paste it

- [00:28:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1715) one more time. Like this, let's also open the refiner okay files and versions. Right

- [00:28:41](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1721) click the safetensors, copy link and let's also change this link. Okay, but will this work? No,

- [00:28:49](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1729) this won't work. Because these files are behind a verification. Research agreement. So what you need

- [00:28:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1739) to do is: you have to generate token. How are you going to do that? This is my profile. Click your

- [00:29:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1746) profile link, click settings. In here you will see access tokens. Okay. Go to access tokens

- [00:29:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1753) new token, test read, selected, generate, copy the token to clipboard and also memorize your username

- [00:29:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1761) from here. Then go back to the GitHub readme file. In the bottom of the readme file you will see

- [00:29:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1768) these commands that I have shared. So actually copy this link. We will replace this link with

- [00:29:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1775) that like this and in here we will change username to the username of Hugging Face and also we need

- [00:29:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1784) to copy our token again and paste the token here and it is done. So the same thing applies to the

- [00:29:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1792) below link as well. So copy this part that starts from Hugging Face and paste it here so you see it

- [00:30:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1800) has become exactly same. By the way I also need to delete extra wget command. So you see this is

- [00:30:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1806) the final version of downloading the SDXL models with wget, then click this play icon again. In the

- [00:30:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1815) bottom we should see they will get downloaded. You see it started downloading SDXL model to

- [00:30:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1822) the Google Colab. When we refresh our folder we should see them in the checkpoint. Yes, they are

- [00:30:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1827) coming. Okay, both files are downloaded. It didn't download the previously downloaded file again. Now

- [00:30:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1834) we can start using ComfyUI on a free Google Colab. So just click this play icon. This is

- [00:30:40](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1840) the suggested way of using it and it is working. I tested it previously. Just patiently wait. So you

- [00:30:46](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1846) see it has enabled automatically high VRAM mode because my GPU has more VRAM than my computer ram.

- [00:30:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1853) Because the computer ram is you see lesser than the GPU ram. Then all you need to do is open this

- [00:31:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1860) link and copy this IP. This is really important. Selected ctrl-c to copy and paste it here. You

- [00:31:07](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1867) can also look and type it and click submit in the opened page, then it will open the ComfyUI. This

- [00:31:16](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1876) is really slow when compared to our computer. Okay, in the first time it didn't load properly

- [00:31:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1882) so I will just refresh. Okay still I can't see so let's try with load default. Okay. Okay it says

- [00:31:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1890) that cannot read properties. Okay, it just came. Nice. Nice. It is loaded. You see by default it

- [00:31:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1897) has selected Realistic Vision and I also see other models. Let's do a test with Realistic Vision.

- [00:31:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1903) So click queue. It is queued. We should see the messages here. Yes we are seeing. This is the GPU

- [00:31:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1910) ram being used. Okay, we are still waiting for the output. Okay, it started to load the model. I see

- [00:31:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1917) the GPU ram is increasing. Okay, now we are seeing the it per second. It is 7it per second and then

- [00:32:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1925) we should see the image here. It will be slower than computer obviously because the data will

- [00:32:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1931) be transferred, we are still waiting. Okay image arrived. Now you can right click and open image

- [00:32:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1937) in a new tab and you can save it if you wish. Alternatively, it will be saved in this left part.

- [00:32:23](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1943) You see I click here. This is our runtime. In here output and our image is saved here. You can double

- [00:32:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1950) click it and open it. You can right click and download. If I have selected Google Drive, I think

- [00:32:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1957) these files would be saved inside my Google Drive and by default I would be having all of them. So

- [00:32:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1965) let's try SDXL on Google Colab. This was the image that we downloaded from my GitHub file. Let's drag

- [00:32:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1973) and drop it. Okay, it is loaded and let's try. Okay, hit queue. By the way currently we are

- [00:33:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1980) trying to use refiner as well, but it should work I think. Let's just patiently wait. Okay,

- [00:33:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1986) GPU ram usage is increasing. Currently it is loading the checkpoint you see it is highlighted.

- [00:33:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1992) Loading is also taking time. It is also displaying the messages here while loading. Okay then it is

- [00:33:19](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=1999) going to start generating image. It is 1.5 seconds per it and using 8.4 gigabytes VRAM right now. The

- [00:33:27](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2007) first image has been generated. Now it should appear here. Yes, we can see the image now it

- [00:33:33](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2013) will try to generate refined image. The GPU ram usage is increasing. Okay, it has loaded refiner

- [00:33:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2019) model as well now using 12 gigabytes VRAM. So if you want to use this on a low VRAM machine

- [00:33:47](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2027) like 8 gigabytes having VRAM, then you need to have higher system ram so that the models

- [00:33:54](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2034) will be loaded onto ram and you will be able to use it. Okay this time it is 1.8 seconds per it

- [00:34:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2041) and it is also generated and the image is here. Now it should also appear here as well. Okay,

- [00:34:08](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2048) it has appeared here as well. What if if you want to download this entire folder so right? Click

- [00:34:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2055) copy path then I will open ChatGPT and ask to the ChatGPT. Give me a Google Colab code that will

- [00:34:24](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2064) download the following folder: okay, I copy pasted it. It is giving me the code, copy code and click

- [00:34:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2074) here. Add code, paste the code and hit execute. But since this execution is permanent, this part

- [00:34:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2083) of the code won't be executed. So let's terminate this. Once we terminate this, our ComfyUI will

- [00:34:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2090) stop. Then we can download the entire folder. Let's play. Okay, we have got some errors so we

- [00:34:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2097) need to fix them. So for fixing I will just copy this message and give it back to the ChatGPT. It

- [00:35:04](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2104) will give me updated code, copy it. I am showing all of this so you will also learn then hit

- [00:35:10](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2110) play icon again. Okay we got a download link but this link is not working so this is saved inside

- [00:35:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2118) content download which should be somewhere around here. Yes! So this second file is the download.

- [00:35:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2125) Click download and now you can download all of the images. So I have generated this download code

- [00:35:33](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2133) on my Patreon post. You will see the link here when you open it in the very bottom you will see

- [00:35:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2139) download colab.txt click it. It will download the txt file, open it. You will find the entire code,

- [00:35:46](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2146) copy it, then go to the very bottom of the page. You will get plus code icon here when you hover

- [00:35:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2152) your mouse so add a code. Alternatively from here insert code cell you see insert code cell,

- [00:35:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2159) copy paste the code and play and you will get the download zip of the entire generated images like

- [00:36:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2166) this. So why I share here? Because I need your support with Patreon. This Patreon post is also

- [00:36:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2173) including auto installer script for RunPod. Now I will show you RunPod installation. For ComfyUI

- [00:36:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2181) RunPod installation I prepared an automated script and also step-by-step instructions.

- [00:36:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2188) Let's begin with automated script. So register or login your RunPod from this link, click login. Go

- [00:36:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2196) to community cloud, the ComfyUI and SDXL working very well on RTX3090 which is only 29 cents per

- [00:36:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2204) hour. So click deploy. In here type test. You will see RunPod Fast Stable Diffusion template. This

- [00:36:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2210) is important selected. You can also customize deployment and increase your volume disk size

- [00:36:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2216) if you wish. So just click continue, click deploy. Why I am using this template because this template

- [00:37:03](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2223) has the necessary files to install and run and it is also very lightweight and easy to use. Just

- [00:37:09](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2229) patiently wait until it is loaded. Okay, you see this was very fast why because it was previously

- [00:37:16](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2236) cached probably by someone else. So click connect, click Jupyter lab. If you don't know how to use

- [00:37:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2242) RunPod, I have this master tutorial. Why master: when you open it you will see it is over 100

- [00:37:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2250) minutes and when you expand the description you will see all of these chapters. This video

- [00:37:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2257) will significantly help you to learn how to use RunPod. Okay, we have connected our Jupyter lab

- [00:37:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2264) so open this Patreon post, click here and download ComfyUI.sh file. Alternatively in the very bottom

- [00:37:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2272) you will see attached files. You can also click here and download it. Then in your jupyter lab,

- [00:37:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2277) click this upload icon, select Comfyui.sh file. You will see it here. Then all you need to do

- [00:38:04](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2284) is copy this, open a new terminal, paste and hit enter and it will install ComfyUI fully

- [00:38:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2291) automatically for you. Let's also start another machine for manually installing ComfyUI. Deploy. I

- [00:38:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2298) will do the same Fast Stable Diffusion. Continue deploy. Let's name this machine as manual like

- [00:38:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2305) this and the other machine will be auto like this. Okay, manually is also getting loaded.

- [00:38:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2310) You don't have to do anything else for automatic installation, just running the initial command.

- [00:38:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2316) Okay, manual machine is ready. Let's connect from jupyter lab. So I also prepared a very

- [00:38:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2322) detailed instructions for manual installation as well. But if you support me on Patreon, I would

- [00:38:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2328) appreciate that very much because my Youtube revenue is very bad. Your Patreon support is

- [00:38:54](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2334) tremendously important for me. Okay, jupyter lab started. So first we need to move into workspace.

- [00:39:00](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2340) We are already in that. So start a terminal. You see this is where we are. Copy this, hit enter and

- [00:39:08](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2348) it will clone. Then you need to move into ComfyUI. So for moving into ComfyUI, refresh folders here,

- [00:39:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2355) ComfyUI and open a new launcher here and terminal. You see now we are inside ComfyUI. Copy this code,

- [00:39:23](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2363) copy paste and hit enter. It will generate a new virtual environment. Then we need to move inside

- [00:39:30](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2370) virtual environment folder so you will see the virtual environment folder here. Enter inside it

- [00:39:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2376) venv open a new terminal. Copy this command, paste and hit enter. Now this virtual environment is

- [00:39:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2384) activated. Then we need to execute this command, copy paste and hit execute, wait until it is

- [00:39:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2390) completed. RunPod automatic ComfyUI installer will also download best VAE file and Realistic Vision

- [00:39:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2397) model and SDXL models automatically for you so you don't need to do anything for them as well. Okay,

- [00:40:04](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2404) we can continue with manual installation. As a next step we need to install. This will install

- [00:40:10](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2410) latest xFormers. This is also a special command that I have searched and found for you. So you

- [00:40:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2417) see it has installed development 564 version of xFormers. Then we need to copy this and execute

- [00:40:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2425) it. Then we will install requirements, copy execute. I am installing requirements while

- [00:40:31](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2431) the virtual environment is activated. This is really important. Sometimes you are skipping

- [00:40:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2436) this step. Therefore, the applications on RunPod or Google Colab is not working. Okay, it has been

- [00:40:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2443) installed. Now we need to move into VAE folder. So let's move into VAE folder from here. ComfyUI,

- [00:40:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2450) models, VAE open a new terminal, copy this command. This will copy the VAE and download

- [00:40:58](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2458) it into this folder you see and then we can also download Realistic Vision. So copy this command,

- [00:41:06](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2466) move into checkpoints folder here. We are not able to enter inside it unfortunately. So let's open

- [00:41:13](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2473) a new terminal, copy paste it. The model will be downloaded in here. This is weird. I don't

- [00:41:19](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2479) know why I am not able to enter inside checkpoints folder, but this is happening. Once the file has

- [00:41:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2485) been downloaded, drag and drop it into checkpoints like this, and now it is inside checkpoints. But I

- [00:41:32](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2492) am still not able to see checkpoints folder. That is very weird. Probably this is a bug of jupyter

- [00:41:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2497) lab. However, you can open a new terminal here and move into checkpoints like this and you can

- [00:41:44](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2504) type this and it will show you what is inside this folder like this. Meanwhile, automatic

- [00:41:49](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2509) installation has been fully completed. So for using ComfyUI on RunPod after installation, copy

- [00:41:56](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2516) this command entirely, open a new terminal, paste the command and hit enter and it will start the

- [00:42:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2525) ComfyUI. Just patiently wait. Okay, it is started. Once you see this message it means it is started.

- [00:42:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2531) Go back to your mypods and in here click connect. Click connect to http service 3001 and now we will

- [00:42:20](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2540) get the ComfyUI interface. It is loading. Okay it has been loaded. It has been loaded with Realistic

- [00:42:26](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2546) Vision version 4: just click queue and you can see the progress in this new terminal that you

- [00:42:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2554) have started and it was super fast. You see it was 18 it per second. Let's load our SDXL. So

- [00:42:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2562) from downloads, drag and drop this png. SDXL is loaded. Let's clear and let's see the speed of

- [00:42:50](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2570) SDXL. So it is going to load the SDXL model. It is loading everything. Meanwhile we can see the

- [00:42:57](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2577) pod utilization from this screen. So currently it is using CUP. Okay wow! So base SDXL model it was

- [00:43:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2585) 1.98 it per second and now it is doing refiner. Refiner was 1.77 it per second. You see how faster

- [00:43:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2595) when compared to free Google Colab and we should see images here. Yes they are now here. On RunPod

- [00:43:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2602) downloading is much more easier. Enter inside ComfyUI, then click this plus icon, open a new

- [00:43:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2609) terminal type runpodctl send and type the name of the folder that you want to download which

- [00:43:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2616) is output. It will give you a link like this, then open a cmd wherever you want to download,

- [00:43:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2623) copy paste it and it will download inside that opened folder like this as you are seeing right

- [00:43:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2628) now. By the way for this to work, for RunPodctl to work on your computer. Watch this tutorial

- [00:43:54](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2634) and you will learn how to use RunPodctl on your computer. Alternatively, without using RunPodctl

- [00:44:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2641) right click this folder download as an archive. It will download it. However, if you have too many

- [00:44:07](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2647) images then it will be very slow. Okay, we can continue with our manual installation. So where

- [00:44:14](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2654) we were left. We were left in this part where you need to download SDXL. So you need to have

- [00:44:22](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2662) an Hugging Face account. I already explained this in the Google Colab part but let's say you just

- [00:44:28](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2668) jumped to RunPod part so I will explain again. You need to open these two links and accept terms

- [00:44:34](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2674) and services. Click the links to open them. Once you have accessed the files and versions, go to

- [00:44:39](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2679) your account, go to settings. In here you have to generate access token. So go to access token. New

- [00:44:45](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2685) token test, test, test2. You can give any name, generate token, copy the token, open a new notepad

- [00:44:53](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2693) file, copy paste it like this. Then copy the first command written here. Paste it into your notepad.

- [00:45:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2701) Check out your username from here. This is my username MonsterMMORPG. Then change the username

- [00:45:07](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2707) here and copy paste the token here. Then copy this command and you need to now download it into

- [00:45:15](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2715) checkpoints. So now we are inside checkpoints. Just copy paste it and it will download the

- [00:45:21](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2721) SDXL into the checkpoint, then repeat the same progress for refiner as well. After this you are

- [00:45:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2729) ready to use it on RunPod because installation is completed. Just run this command. This command is

- [00:45:36](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2736) same as the automatic installation. Because after installation it is same and you will be able to

- [00:45:43](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2743) use ComfyUI on RunPod like this. Once you are able to use ComfyUI, it is same with Windows or

- [00:45:52](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2752) RunPod or Google Colab. Only where the files are saved only where the files are uploaded changes.

- [00:45:59](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2759) Everything else is same. It is working perfectly fine. Thank you so much for watching. I hope you

- [00:46:05](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2765) have enjoyed. Please join my Youtube channel and support me. It is tremendously important for me.

- [00:46:11](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2771) Why? Because my Youtube views are terrible as you are seeing right now. I am spending huge time.

- [00:46:17](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2777) For example, I have been working on training LoRA models on SDXL for days now and maybe it will be

- [00:46:25](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2785) watched very few, but your join support and your Patreon support significantly helping me. When

- [00:46:31](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2791) you open this link, you will get to my Patreon page. You will also see the Patreon link in the

- [00:46:37](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2797) description of the video and also in the comment section of the video. You see I have over 300

- [00:46:42](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2802) supporters. I appreciate them very much. They are giving me support to continue producing videos.

- [00:46:48](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2808) On Patreon I have an index page. When you open this. This is a public page. You will see all of

- [00:46:55](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2815) my Patreon sharings. You will see their details, you will see their links. I am sharing very useful

- [00:47:01](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2821) resources here. I am explaining them in the videos as well, but this will make your life easier. So

- [00:47:07](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2827) this is a little bit incentive for you to support me. But if you support me, I appreciate that very

- [00:47:12](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2832) much. Please also comment share like ask me anything you want. If something gets broken

- [00:47:18](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2838) just comment to this video and I will update this readme file with the newest instructions. Also in

- [00:47:24](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2844) this readme file you will see our Youtube channel, Patreon page and my LinkedIn and

- [00:47:29](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2849) my Twitter profile. Open them and you can start following me on Twitter. Or you can connect me

- [00:47:35](https://www.youtube.com/watch?v=FnMHbhvWUhE&t=2855) and follow me on LinkedIn. So hopefully see you in another amazing tutorial video. Thank you so much.

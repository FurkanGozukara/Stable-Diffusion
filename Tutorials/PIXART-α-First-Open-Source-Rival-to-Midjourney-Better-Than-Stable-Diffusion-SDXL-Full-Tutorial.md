# PIXART-α : First Open Source Rival to Midjourney - Better Than Stable Diffusion SDXL - Full Tutorial

## Full tutorial link > https://www.youtube.com/watch?v=ZiUXf_idIR4

[![PIXART-α : First Open Source Rival to Midjourney - Better Than Stable Diffusion SDXL - Full Tutorial](https://img.youtube.com/vi/ZiUXf_idIR4/sddefault.jpg)](https://www.youtube.com/watch?v=ZiUXf_idIR4 "PIXART-α : First Open Source Rival to Midjourney - Better Than Stable Diffusion SDXL - Full Tutorial")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/PIXART-α-First-Open-Source-Rival-to-Midjourney-Better-Than-Stable-Diffusion-SDXL-Full-Tutorial.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/PIXART-α-First-Open-Source-Rival-to-Midjourney-Better-Than-Stable-Diffusion-SDXL-Full-Tutorial.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan Gözükara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan Gözükara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan Gözükara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan Gözükara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Introduction to the new PixArt-α (PixArt Alpha) text to image model which is for real better than Stable Diffusion models even from SDXL. PixArt-α is close to the Midjourney level meanwhile being open source and supporting full fine tuning and DreamBooth training. In this tutorial I show how to install and use PixArt-α both locally and on a cloud service RunPod with automatic installers and step by step guidance.

The link to download resources ⤵️

[https://www.patreon.com/posts/pixart-alpha-for-93614549](https://www.patreon.com/posts/pixart-alpha-for-93614549)

Stable Diffusion GitHub repository ⤵️

[https://github.com/FurkanGozukara/Stable-Diffusion](https://github.com/FurkanGozukara/Stable-Diffusion)

SECourses Discord To Get Full Support ⤵️

[https://discord.com/servers/software-engineering-courses-secourses-772774097734074388](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388)

PixArt Repo ⤵️

[https://github.com/PixArt-alpha/PixArt-alpha](https://github.com/PixArt-alpha/PixArt-alpha)

#PixArt #StableDiffusion #SDXL

[00:00:00](https://youtu.be/ZiUXf_idIR4?t=0) Introduction to PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis and the tutorial content

[00:02:38](https://youtu.be/ZiUXf_idIR4?t=158) What are the requirements to follow this tutorial and install PixArt Alpha

[00:03:05](https://youtu.be/ZiUXf_idIR4?t=185) How to install PixArt Alpha on your machine and start using it

[00:03:59](https://youtu.be/ZiUXf_idIR4?t=239) Where Hugging Face models are downloaded by default and how to change this default cache folder

[00:05:44](https://youtu.be/ZiUXf_idIR4?t=344) How to return back to using default Hugging Face cache folder

[00:06:08](https://youtu.be/ZiUXf_idIR4?t=368) How to fix corrupted files error during installation

[00:06:29](https://youtu.be/ZiUXf_idIR4?t=389) How to start PixArt Web APP after installation has been completed

[00:07:24](https://youtu.be/ZiUXf_idIR4?t=444) How to use PixArt Web APP and its features

[00:07:59](https://youtu.be/ZiUXf_idIR4?t=479) Comparing a dragon prompt with SDXL base version

[00:08:14](https://youtu.be/ZiUXf_idIR4?t=494) How to use provided styles csv file

[00:08:40](https://youtu.be/ZiUXf_idIR4?t=520) How to start Automatic1111 SD Web UI on your second GPU

[00:08:50](https://youtu.be/ZiUXf_idIR4?t=530) Where the PixArt Web APP generated images are saved

[00:09:30](https://youtu.be/ZiUXf_idIR4?t=570) How to set parameters in your Automatic1111 SD Web UI to generate high quality images

[00:09:49](https://youtu.be/ZiUXf_idIR4?t=589) PixArt generated image vs SDXL generated image for same simple prompt

[00:10:15](https://youtu.be/ZiUXf_idIR4?t=615) Anime style same prompt comparison

[00:10:55](https://youtu.be/ZiUXf_idIR4?t=655) One another strong aspect of the PixArt Alpha model

[00:11:29](https://youtu.be/ZiUXf_idIR4?t=689) Fantasy art style comparison of SDXL vs PixArt-α

[00:11:52](https://youtu.be/ZiUXf_idIR4?t=712) 3D style comparison of SDXL vs PixArt-α

[00:12:16](https://youtu.be/ZiUXf_idIR4?t=736) Manga style image generation comparison between SDXL vs PixArt-α

[00:12:44](https://youtu.be/ZiUXf_idIR4?t=764) Comparing PixArt vs SDXL vs Midjourney with same prompt

[00:13:41](https://youtu.be/ZiUXf_idIR4?t=821) How to use LLaVA for captioning and obtaining prompt ideas and generating more amazing images

[00:16:12](https://youtu.be/ZiUXf_idIR4?t=972) Comparison of PixArt vs SDXL prompt following in details

[00:17:29](https://youtu.be/ZiUXf_idIR4?t=1049) Getting prompt idea from ChatGPT and comparing SDXL and PixArt prompt following

[00:19:46](https://youtu.be/ZiUXf_idIR4?t=1186) PixArt owns hard the SDXL with this new detailed prompt

[00:22:00](https://youtu.be/ZiUXf_idIR4?t=1320) How to install PixArt on a RunPod pod / machine

[00:23:54](https://youtu.be/ZiUXf_idIR4?t=1434) How to set default Hugging Face cache folder on RunPod / Linux machines

[00:25:05](https://youtu.be/ZiUXf_idIR4?t=1505) How to understand RunPod machine / pod is not working correctly and fix it

[00:26:00](https://youtu.be/ZiUXf_idIR4?t=1560) How to properly delete files / folders on RunPod machines / pods

[00:26:51](https://youtu.be/ZiUXf_idIR4?t=1611) How to connect and use PixArt web UI on a RunPod machine after it was started

[00:28:20](https://youtu.be/ZiUXf_idIR4?t=1700) How to download all of the generated images on RunPod with runpodctl very fast

The paper introduces PIXART-α, a Transformer-based text-to-image (T2I) diffusion model designed to significantly lower training costs while maintaining high image generation quality, competitive with leading models like Imagen and Midjourney. It achieves high-resolution synthesis up to 1024x1024 pixels at reduced training costs.

Key Innovations:

Training Strategy Decomposition: The process is divided into three steps focusing on pixel dependency, text-image alignment, and image aesthetic quality. This approach reduces learning costs by starting with a low-cost class-condition model and then pretraining and fine-tuning on data rich in information density and aesthetic quality.

Efficient T2I Transformer: Built on the Diffusion Transformer (DiT) framework, it includes cross-attention modules for text conditions and streamlines computation. A reparameterization technique enables loading parameters from class-condition models, leveraging prior knowledge from ImageNet, thus accelerating training.

High-informative Data: To overcome deficiencies in existing text-image datasets, the paper introduces an auto-labeling pipeline using a vision-language model (LLaVA) to generate captions on the SAM dataset. This dataset is selected for its diverse collection of objects, aiding in creating high-information-density text-image pairs for efficient alignment learning.

Image Quality: The model excels in image quality, artistry, and semantic control, surpassing existing models in user studies and benchmarks.

Broader Implications: The paper suggests that PIXART-α's approach allows individual researchers and startups to develop high-quality T2I models at lower costs, potentially democratizing access to advanced AI-generated content.

The paper concludes with the hope that PIXART-α will inspire the AIGC community and enable more entities to build their own generative models efficiently and affordably.



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=0) Greetings, everyone.

- [00:00:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1) In this video, I will introduce you to a new generative AI model to generate images from

- [00:00:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=7) prompts: PixArt A, PixArt Alpha, and it is truly a rival for Stable Diffusion XL (SDXL).

- [00:00:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=15) Actually, it is better than SDXL, and I will show you that.

- [00:00:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=18) The power of PixArt is that it is able to follow prompts much better than Stable Diffusion

- [00:00:24](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=24) XL.

- [00:00:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=25) This power comes from the Text Encoder that PixArt uses.

- [00:00:30](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=30) It is using a T5 Text Encoder, which is the most powerful Text Encoder.

- [00:00:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=36) They also utilized LLaVA captioning during their training, which helped them significantly.

- [00:00:41](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=41) So, in this tutorial, I will show you how to install PixArt on your computer and run

- [00:00:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=46) it with just one-click installers that I have prepared for you.

- [00:00:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=51) I will compare it with Stable Diffusion XL base version.

- [00:00:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=54) I will compare it with Midjourney with the same prompting.

- [00:00:57](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=57) I will show you how you can change your default Hugging Face caching folder where the models

- [00:01:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=64) will be downloaded.

- [00:01:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=65) I will share these styles file that you can use on your Automatic1111 Web UI, which comes

- [00:01:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=71) with the PixArt Gradio.

- [00:01:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=73) Moreover, I will show you how to use LLaVA for captioning images.

- [00:01:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=79) Moreover, in this video, I will show you how to install and use PixArt on a RunPod machine

- [00:01:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=85) as well.

- [00:01:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=86) By following the same steps of RunPod installation, you can install PixArt on a Linux machine

- [00:01:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=92) as well.

- [00:01:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=93) So if you are a Linux user, then you can follow this tutorial to learn how to install and

- [00:01:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=99) use PixArt on a Linux machine, or if you don't have a strong GPU, then you can follow this

- [00:01:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=105) tutorial to install and use the PixArt on a RunPod machine.

- [00:01:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=110) And finally, I keep working on the interface.

- [00:01:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=113) After the tutorial has been completed, I made several improvements.

- [00:01:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=118) You see, now it is using a better space of the screen.

- [00:02:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=122) You can now see the entire prompt.

- [00:02:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=125) Now it will display the generated images like this, as a gallery.

- [00:02:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=129) Also, when you click this X icon, it will display the original resolution of the images.

- [00:02:16](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=136) When you click any image back, it will return to the gallery option.

- [00:02:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=140) Hopefully, I will keep improving the Gradio application.

- [00:02:24](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=144) So, everything we are going to need is shared in this post.

- [00:02:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=148) I am going to share the link of this post in the description of the video and also in

- [00:02:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=153) the comment section of the video.

- [00:02:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=156) I have prepared amazing installer files.

- [00:02:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=158) All you need to do is install Python and Git if you haven't yet.

- [00:02:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=164) I have this amazing tutorial for how to install Python and Git.

- [00:02:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=168) When you type Python, you should get this message: 3.10.x version.

- [00:02:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=174) I am preferring 11.

- [00:02:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=176) I haven't tested with other Python versions.

- [00:02:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=178) It may work, but it may not also work.

- [00:03:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=181) And when you type Git, you should get that this message the Git is installed.

- [00:03:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=186) After that, just download the PixArt installer.zip file.

- [00:03:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=190) When you click here or click the attachment, you will get the attachment downloaded.

- [00:03:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=197) Move it into wherever you want to install.

- [00:03:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=200) Let's make a new folder in G drive: Test PixArt.

- [00:03:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=205) Paste it there.

- [00:03:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=206) Extract it.

- [00:03:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=207) This is a zip file, so you can extract it on Windows automatically.

- [00:03:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=211) And just double-click install.bat file, and it will install everything fully automatically

- [00:03:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=216) for you.

- [00:03:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=217) If you are a Linux user, then follow the instructions for the RunPod installer.sh file.

- [00:03:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=224) I will also show how to install the RunPod in this tutorial, so you can look at the video

- [00:03:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=228) chapters and seek to that section as well.

- [00:03:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=232) The installer will automatically install everything for us.

- [00:03:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=236) Then the models will get automatically downloaded.

- [00:03:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=238) If you have previously used any Hugging Face models, then you will know that they are getting

- [00:04:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=244) downloaded into the cache folder.

- [00:04:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=246) The cache folder is inside C drive, inside users, inside your username, inside cache,

- [00:04:14](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=254) inside Hugging Face, inside hub.

- [00:04:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=257) This is where all of the model files are by default downloaded.

- [00:04:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=262) So let me show you the size of my cache folder in my C drive.

- [00:04:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=266) You see, I am using 406 gigabytes in my cache folder.

- [00:04:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=271) So some people were asking me how they can change the cache folder where the model files

- [00:04:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=278) will be automatically downloaded.

- [00:04:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=279) To change it, start a new cmd as administrator.

- [00:04:42](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=282) So I type cmd, right-click, and run as administrator.

- [00:04:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=286) Click yes.

- [00:04:47](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=287) Then execute this command according to where you want the cache folder to be.

- [00:04:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=293) So let me show you closely.

- [00:04:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=295) Let's say I want my cache folder to be Hugging Face models folder.

- [00:04:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=299) So I right-click and new, generate folder, and enter here.

- [00:05:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=304) Copy the path and paste it here.

- [00:05:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=306) Then I copy this, paste it into the command line interface.

- [00:05:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=309) Hit enter.

- [00:05:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=311) This will generate a key in system environment variables.

- [00:05:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=315) So when I open edit system environment variables, click environment variables, I will see that

- [00:05:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=322) HF_HOME.

- [00:05:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=323) This is Hugging Face home.

- [00:05:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=325) This is where the Hugging Face libraries will look to download the models as a cache.

- [00:05:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=331) So now all of the models will be downloaded into this drive.

- [00:05:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=335) Let's okay and okay.

- [00:05:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=336) This is done.

- [00:05:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=337) Let's see the installer status.

- [00:05:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=339) It is still installing.

- [00:05:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=340) This totally depends on your hard drive speed and your internet connection speed.

- [00:05:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=344) So let's say you wanted to delete this custom model and return to the default cache folder.

- [00:05:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=351) What you need to do: open the environment variables again, environment variables, and

- [00:05:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=355) just delete this variable.

- [00:05:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=356) When you click delete, it will delete the cache folder, and it will download into the

- [00:06:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=362) default cache.

- [00:06:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=364) I tested this, and it is working.

- [00:06:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=365) Okay, installer almost completed.

- [00:06:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=368) Let's say during the installation something happened and some of your files are corrupted.

- [00:06:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=373) Then you need to delete this temporary folder.

- [00:06:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=375) This is usually where the downloaded libraries are temporarily saved.

- [00:06:21](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=381) So if you delete this temporary folder in your case, then it should fix your installation

- [00:06:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=386) errors if you encounter any error.

- [00:06:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=389) Okay, the installation has been completed.

- [00:06:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=391) This is the screen.

- [00:06:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=392) Just hit anywhere, and it will close automatically.

- [00:06:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=395) Let's return back to our installation folder.

- [00:06:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=398) Now there are several options.

- [00:06:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=400) I suggest you use the 1024 pixel model.

- [00:06:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=403) The 512 pixel model is really bad.

- [00:06:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=405) So, it doesn't worth to spend your time.

- [00:06:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=408) There are two options: run as 8-bit and run as 16-bit.

- [00:06:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=412) The 8-bit version will load the Text Encoder in 8-bit instead of 16-bit.

- [00:06:57](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=417) So, it will use lesser VRAM.

- [00:07:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=420) However, it may have a little bit degraded quality.

- [00:07:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=424) I will run the 16-bit version.

- [00:07:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=427) I have RTX 3090 TI, so I don't need the 8-bit version.

- [00:07:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=433) Since I have previously downloaded the model files, it didn't re-download.

- [00:07:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=437) I can already see them here.

- [00:07:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=439) You see, this is the 1024 pixel model.

- [00:07:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=443) It is 20 GB.

- [00:07:24](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=444) So, this is the screen which we will use.

- [00:07:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=447) I have edited this screen and added new functionality from the official repository.

- [00:07:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=452) Such as that, you have batch count.

- [00:07:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=454) This batch count will generate any number of images that you want.

- [00:07:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=459) Alright, let's try a prompt: a dragon, and nothing else.

- [00:07:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=463) Let's run it.

- [00:07:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=464) I also modified the command line interface screen so it will give us more information.

- [00:07:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=469) It says starting generating 1 images.

- [00:07:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=473) It will also show the average step duration and the average image duration like this,

- [00:07:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=478) and we got the image.

- [00:08:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=480) And you see, just a dragon.

- [00:08:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=481) We got an amazing result.

- [00:08:03](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=483) This is an amazing image.

- [00:08:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=485) Let's compare this with SDXL as well.

- [00:08:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=489) By the way, currently no style is selected.

- [00:08:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=492) I also made the style csv file in here.

- [00:08:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=495) You see, style csv.

- [00:08:16](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=496) This is the same as this repository using.

- [00:08:21](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=501) So when I double-click and edit the app.py file, you can see the styles are provided

- [00:08:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=507) already here.

- [00:08:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=508) So I made a file exactly the same with that, and I will put this into my Automatic1111

- [00:08:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=515) Web UI installation to compare with SDXL.

- [00:08:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=519) So I just copy-paste it.

- [00:08:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=520) Then I need to start my SDXL.

- [00:08:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=523) I will start it on my second gpu, which is RTX 3060 here.

- [00:08:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=529) So we can use both of them at the same time.

- [00:08:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=532) Also, I modified this application to save the generated images inside outputs folder

- [00:08:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=538) here.

- [00:08:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=539) It will generate with this format: the day of the image generated and the random name.

- [00:09:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=545) So you can right-click and sort by date to see the latest generations at the top.

- [00:09:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=550) So this is the image generated.

- [00:09:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=552) Let's generate the same image in the SDXL.

- [00:09:14](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=554) This was the first image, not a cherry-picking or anything else.

- [00:09:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=558) This model also has fine-tuning as well, like DreamBooth training, but I am still searching

- [00:09:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=565) them.

- [00:09:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=566) Hopefully, I will make tutorials for fine-tuning as well.

- [00:09:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=568) It also supports ControlNet as far as I know.

- [00:09:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=571) So, let's load our SDXL base model from here.

- [00:09:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=576) Let's select the VAE fp16 VAE.

- [00:09:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=579) Let's select the sampler.

- [00:09:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=580) This is the best sampler that I find.

- [00:09:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=583) Let's select the resolution and let's type the same prompt, and nothing else, and generate.

- [00:09:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=589) And this is the same prompt output we got from the SDXL base version.

- [00:09:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=594) Do you see the difference?

- [00:09:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=596) This model generates this.

- [00:09:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=598) It is like Midjourney, and this model generates this, SDXL base version.

- [00:10:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=604) Let's make this somewhat styled.

- [00:10:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=606) Let's try anime, for example, and let's also select the anime.

- [00:10:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=610) So, it will be exactly the same prompt.

- [00:10:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=612) Okay, let's hit generate in both of them.

- [00:10:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=615) This model is also pretty fast, and I find that DPM Solver Inference steps 60 is best.

- [00:10:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=622) You can also play with other variables here, and this is the anime version of the image.

- [00:10:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=628) Let's open this in a new tab.

- [00:10:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=629) Yeah, this is the default resolution.

- [00:10:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=631) This is the anime output, and this is the anime output from SDXL.

- [00:10:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=636) I think SDXL performed better this time in terms of quality.

- [00:10:41](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=641) Let's try another one.

- [00:10:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=643) So, let's try fantasy art.

- [00:10:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=645) Okay, run.

- [00:10:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=646) Let's select the fantasy art from here and run.

- [00:10:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=649) There is also one another very strong aspect of the PixArt Alpha model: It can follow prompts

- [00:10:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=656) much better than the SDXL Stable Diffusion XL.

- [00:10:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=659) When we read the paper, we can see it.

- [00:11:03](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=663) They are using a T5 Text Encoder, which is an extremely strong text encoder.

- [00:11:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=668) So, you can also read this paper.

- [00:11:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=671) The official links are shared here.

- [00:11:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=673) Open them, and you will see the links.

- [00:11:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=675) So, in this case, in the fantasy art, this is the output that PixArt generated.

- [00:11:21](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=681) Let's see it from here.

- [00:11:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=683) This is the output PixArt generated, and this is the SDXL generated image.

- [00:11:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=689) Let's compare them.

- [00:11:30](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=690) So, really, really cool.

- [00:11:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=691) I don't know which one is the winner.

- [00:11:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=693) I think PixArt is better than the SDXL model.

- [00:11:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=697) Let's try another style.

- [00:11:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=699) Let's try a 3D model generate, and let's also try a 3D model from here and generate.

- [00:11:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=705) By the way, using the same seed will not have the same effect because of the model's differences.

- [00:11:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=711) Okay, it generated this as a 3D output, and this is the 3D output of the SDXL.

- [00:11:57](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=717) I think this time the winner is PixArt.

- [00:12:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=721) Maybe we should generate multiple images.

- [00:12:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=724) Let's try manga and let's make the batch count 4.

- [00:12:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=728) Let's generate 4 images.

- [00:12:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=729) Let's do the same in Automatic1111 Web UI for the SDXL base.

- [00:12:14](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=734) Let's generate.

- [00:12:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=735) Okay, images have been generated.

- [00:12:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=737) Let's compare them.

- [00:12:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=738) So, this is the first image of the PixArt.

- [00:12:21](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=741) In the Gradio interface, you can also move between images like this, as you are seeing.

- [00:12:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=747) So, these are all of the images generated with the PixArt, and here we see the images

- [00:12:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=752) generated by the SDXL base version.

- [00:12:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=755) You see, these are the manga images.

- [00:12:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=757) I think PixArt is the winner here.

- [00:12:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=760) Now, I want to compare them with Midjourney.

- [00:12:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=763) So, there is a Midjourney prompt here.

- [00:12:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=766) Let's copy it.

- [00:12:47](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=767) You see, this is the output of the Midjourney.

- [00:12:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=769) Let's open it in a browser, so we can see it in full resolution.

- [00:12:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=773) So, for this prompt, Midjourney generated this output.

- [00:12:57](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=777) Let's try the same in here.

- [00:12:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=779) I will try with a default prompt.

- [00:13:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=782) Let's generate in Automatic1111 Web UI, and let's also generate here with no style and

- [00:13:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=787) run.

- [00:13:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=788) Okay, we got the results.

- [00:13:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=790) Let's compare.

- [00:13:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=791) So, these are the images generated by the PixArt Alpha version.

- [00:13:16](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=796) These are the images generated by the SDXL, and these are the images generated by Midjourney.

- [00:13:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=803) So, if we see them in a single image, they are looking like this: First one is SDXL,

- [00:13:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=808) the second one is PixArt Alpha, and the third one is Midjourney.

- [00:13:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=813) However, as I said, the power of PixArt comes from the prompting itself.

- [00:13:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=819) So, what I am going to do is, I am going to use the LLaVA captioning.

- [00:13:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=825) I just updated it in my Patreon post.

- [00:13:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=828) Now, you can automatically install and caption with LLaVA.

- [00:13:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=832) Now, I will start my LLaVA to caption the image of Midjourney, and I will use that caption

- [00:13:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=838) in PixArt and SDXL, and we will see the difference.

- [00:14:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=841) So, I will run the first part.

- [00:14:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=844) This is from my automatic installation, and I will start the second part.

- [00:14:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=848) Hopefully, I will also make a full tutorial for all of the captioning models I shared

- [00:14:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=853) here.

- [00:14:14](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=854) This is the very best captioning arsenal.

- [00:14:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=857) I have prepared everything for you guys.

- [00:14:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=859) So, part one started.

- [00:14:21](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=861) Part two started.

- [00:14:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=862) Let's start part three.

- [00:14:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=863) By the way, this will take a huge amount of RAM.

- [00:14:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=866) So, I will use the 8-bit version of the 13b model.

- [00:14:30](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=870) So, let's start it.

- [00:14:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=872) This LLaVA also has RunPod installation.

- [00:14:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=874) It is working amazingly on RunPod.

- [00:14:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=877) If you rent an A6000 from RunPod, it's only 70 cents per hour, even cheaper.

- [00:14:42](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=882) You can use this amazingly on RunPod.

- [00:14:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=885) Okay, it is starting.

- [00:14:47](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=887) These are also all modified and made into one-click installation by me.

- [00:14:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=893) Okay, the Web UI started.

- [00:14:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=895) Let's open the LLaVA chatbot.

- [00:14:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=898) You can also chat with it.

- [00:14:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=899) You can use it for captioning images.

- [00:15:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=902) You can use it for any task you want with LLaVA.

- [00:15:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=905) You see the model loaded.

- [00:15:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=907) Let's select the image from downloads here.

- [00:15:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=910) Okay, so I will use this prompt.

- [00:15:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=911) Okay, I need to select again.

- [00:15:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=913) Okay, I will use this prompt.

- [00:15:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=915) This is a prompt that I have found to caption images.

- [00:15:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=919) Just caption the image with details, colors, items, objects, emotions, art style, drawing

- [00:15:24](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=924) style.

- [00:15:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=925) You can also try other prompts to generate captions.

- [00:15:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=927) Okay, we are getting a detailed caption right now.

- [00:15:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=931) You see, the LLaVA is able to caption images amazingly, and it is for free.

- [00:15:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=936) Okay, let's copy this.

- [00:15:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=937) Then, I will terminate my LLaVA and rerun the PixArt Alpha.

- [00:15:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=943) Okay, let's run it again.

- [00:15:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=945) My Stable Diffusion is still running on my second GPU.

- [00:15:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=949) It is 112 tokens in the Stable Diffusion tokenizer.

- [00:15:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=954) Okay, the Stable Diffusion started.

- [00:15:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=956) The PixArt also started.

- [00:15:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=958) Let's enter the prompt and let's generate four images and run.

- [00:16:03](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=963) Let's see this time what we will get.

- [00:16:05](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=965) So, this is an amazing methodology to get detailed prompts and generate images.

- [00:16:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=970) Okay, we got the images.

- [00:16:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=972) Now, time to compare how well the prompt is followed by the model.

- [00:16:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=978) First, let's begin with the PixArt output.

- [00:16:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=982) So, the image features a robot with a fiery orange background.

- [00:16:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=986) Very accurate.

- [00:16:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=987) The robot is wearing black and orange armor, and its face is glowing red.

- [00:16:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=992) Accurate.

- [00:16:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=993) The robot is standing in front of a building, which appears to be on fire.

- [00:16:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=997) This is also accurate.

- [00:16:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=998) The scene is set against a dark sky, adding to the dramatic atmosphere.

- [00:16:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1003) Accurate.

- [00:16:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1004) The overall color palette of the image is predominantly orange and black, with some

- [00:16:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1009) red accents.

- [00:16:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1010) Accurate.

- [00:16:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1011) The art style seems to be a mix of futuristic and post-apocalyptic, with the robot's design

- [00:16:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1016) and burning building creating a sense of danger and intensity.

- [00:17:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1021) You see how well it followed the prompt.

- [00:17:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1024) It is exactly as the prompt.

- [00:17:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1027) Now, let's compare it with the SDXL output.

- [00:17:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1031) The SDXL output looks much weaker than the PixArt.

- [00:17:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1035) Maybe this is the best one.

- [00:17:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1037) So, we can compare it with the prompt.

- [00:17:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1040) The SDXL also tried to follow the prompt, but not as accurately as I think the PixArt.

- [00:17:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1048) Now, let's try another, and more beautiful, prompt.

- [00:17:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1052) Actually, for this prompt, I will use ChatGPT.

- [00:17:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1054) Write me a detailed prompt to generate an amazing image of a horse running on a beautiful

- [00:17:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1066) mountain on a beautiful day.

- [00:17:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1068) Okay, I fixed the typo errors, and let's see the result of the ChatGPT.

- [00:17:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1074) So, I will use this prompt to generate images both on the Stable Diffusion XL and also on

- [00:18:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1081) the PixArt.

- [00:18:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1082) Okay, here, this is a big prompt, so the tokenizer of PixArt may not work.

- [00:18:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1088) Let's generate this and let's see the command line interface.

- [00:18:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1091) Yes, the tokenizer of PixArt is currently limited to 120 tokens.

- [00:18:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1097) So, after this part of the prompt is truncated.

- [00:18:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1102) Let's use the Automatic1111 Web UI and generate the images, then compare the results.

- [00:18:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1107) Okay, the PixArt images are generated.

- [00:18:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1109) Let's compare and see how well it followed the prompt.

- [00:18:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1114) However, the prompt was truncated.

- [00:18:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1115) Visualize a majestic horse with a glossy chestnut coat, running spiritedly along a lush, vibrant

- [00:18:42](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1122) green mountain trail.

- [00:18:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1124) Looking accurate, the scene is set on a gorgeous day, with a clear azure sky above and a few

- [00:18:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1130) fluffy white clouds drifting lazily.

- [00:18:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1133) Looking accurate.

- [00:18:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1134) The sun is shining brightly, casting a warm golden glow over the landscape.

- [00:18:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1139) Surrounding the trails are white flowers in a kaleidoscope of colors, swaying gently in

- [00:19:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1146) the light breeze.

- [00:19:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1147) It is looking amazing, and it was truncated from "stead in snow."

- [00:19:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1153) So, where was it?

- [00:19:15](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1155) Okay, it was truncated from "stead in snow."

- [00:19:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1160) Okay, it was truncated from here, so it was only up to this part, this image generated.

- [00:19:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1168) However, there is some quality loss on the horse.

- [00:19:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1173) Let's also try an increased number of steps.

- [00:19:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1178) I will try with 60 steps.

- [00:19:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1179) I think 60 steps is the best.

- [00:19:42](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1182) Let's generate again, and meanwhile, let's see the results of the Stable Diffusion XL.

- [00:19:47](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1187) The Stable Diffusion XL prompt is like this.

- [00:19:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1190) It is nothing like, nothing like the PixArt.

- [00:19:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1193) You see, this is PixArt.

- [00:19:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1195) This is like Midjourney level, and this is the SDXL.

- [00:19:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1198) It cannot even be compared with the PixArt.

- [00:20:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1202) PixArt is much better at following and also at the quality, and let's also see the results

- [00:20:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1208) of 60 steps.

- [00:20:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1209) So, this is a 60-step image.

- [00:20:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1212) You see, with 60 steps, there is a significant improvement in the quality of the horse.

- [00:20:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1218) This is 20 steps, and this is 60 steps.

- [00:20:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1220) The 60 steps is much better, much clearer.

- [00:20:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1223) Still, it is able to follow the prompt very well.

- [00:20:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1226) It will take longer to generate images, but finally, we can get better quality images

- [00:20:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1233) with just a lesser number of trying.

- [00:20:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1235) So, the 60 steps definitely improved the quality of the image.

- [00:20:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1240) You see, PixArt is the future.

- [00:20:42](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1242) PixArt is also supporting DreamBooth training.

- [00:20:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1245) However, there aren't enough resources for how to do it yet.

- [00:20:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1249) It is requiring you to prepare a specific config file with images.

- [00:20:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1255) So, I am not sure yet how to train it.

- [00:20:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1258) However, I will look for it.

- [00:21:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1260) Hopefully, Kohya will add this to its training pipeline so we can directly train PixArt and

- [00:21:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1267) see the difference of DreamBooth training in PixArt.

- [00:21:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1271) We are already able to train DreamBooth of Stable Diffusion XL very well.

- [00:21:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1277) I would like to see that in PixArt too.

- [00:21:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1279) Wow, the final image of the PixArt is very different than the others.

- [00:21:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1283) By the way, we can also apply styles, but we didn't apply it yet.

- [00:21:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1288) So, with PixArt, you can generate ideas, prompts from ChatGPT, or wherever you want and make

- [00:21:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1294) it follow.

- [00:21:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1295) And the difference is just humongous between the Stable Diffusion XL and the PixArt when

- [00:21:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1300) it comes to following the prompts.

- [00:21:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1303) So, PixArt is definitely better than Stable Diffusion XL, if you ask my opinion.

- [00:21:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1309) It really needs to be added to the Automatic1111 Web UI pipeline and the Kohya training pipeline.

- [00:21:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1316) I hope they add this PixArt into their repositories.

- [00:22:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1320) So, now I will show you how to install and use PixArt on a RunPod machine.

- [00:22:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1326) If you are new to RunPod, watch this amazing beginner's RunPod tutorial.

- [00:22:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1331) It is over 100 minutes.

- [00:22:14](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1334) It will teach you pretty much everything with RunPod.

- [00:22:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1337) Use this link to register or login.

- [00:22:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1340) I will log into my account.

- [00:22:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1342) I will go to community cloud.

- [00:22:24](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1344) Select the extreme speed from here.

- [00:22:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1346) I will use RTX 3090.

- [00:22:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1348) This is an amazing GPU.

- [00:22:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1351) It works with a lot of things.

- [00:22:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1353) From here, search for PyTorch.

- [00:22:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1354) I will use RunPod PyTorch 2.0.1.

- [00:22:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1358) It doesn't matter.

- [00:22:39](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1359) Customize deployment.

- [00:22:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1360) Make the volume disk 50 gigabytes and continue and deploy.

- [00:22:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1365) Let's go to my pods.

- [00:22:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1366) Let's delete this older one and let's see the logs.

- [00:22:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1370) The logs are really important.

- [00:22:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1371) Watch the logs.

- [00:22:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1373) If the machine is broken, if something is not working, you will see messages here.

- [00:22:58](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1378) So, this is an easy to load template as you are seeing right now.

- [00:23:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1381) The pod is loaded.

- [00:23:03](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1383) Click connect.

- [00:23:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1384) Connect to JupyterLab.

- [00:23:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1386) Let's download the installer again if you haven't downloaded yet.

- [00:23:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1390) Extract it into any folder.

- [00:23:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1392) Enter inside extraction.

- [00:23:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1393) Drag and drop the RunPod installer sh file here.

- [00:23:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1398) Open a new terminal.

- [00:23:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1399) Open the RunPod instructions file.

- [00:23:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1402) All of the instructions are written here.

- [00:23:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1405) If you are a Linux user, all you need to do is change the file paths from here.

- [00:23:30](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1410) Nothing else.

- [00:23:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1411) This will generate a new virtual environment folder and install everything there.

- [00:23:37](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1417) Make sure that you are using Python 3.10 version because I haven't tested with other different

- [00:23:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1423) Python versions.

- [00:23:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1424) So, I don't know whether they will work or not.

- [00:23:47](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1427) The first command that we will execute is this one.

- [00:23:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1431) And after that, for using we will use this one.

- [00:23:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1434) So, you see we did set the Hugging Face home the cache folder as workspace.

- [00:23:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1439) This is really important.

- [00:24:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1441) This is where the models will get downloaded.

- [00:24:03](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1443) Then, we will use this command to run it after the installation has been completed.

- [00:24:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1450) The installation has been completed.

- [00:24:11](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1451) Let's open a new terminal.

- [00:24:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1453) Let's copy the start command and execute it.

- [00:24:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1457) Copy paste.

- [00:24:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1458) When you first time start the web UI, it will download the model into the cache folder.

- [00:24:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1465) We will see in a moment.

- [00:24:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1467) It is here.

- [00:24:28](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1468) You see, inside hub folder.

- [00:24:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1469) It will download the model files and it will start the web UI with Gradio live sharing.

- [00:24:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1476) Unfortunately, connecting via the proxy of RunPod via certain port is not working.

- [00:24:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1483) I have opened an issue thread for this on a Gradio GitHub.

- [00:24:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1488) Let me show you Gradio GitHub.

- [00:24:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1491) And let me show you the issue that I have opened.

- [00:24:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1494) If they fix this error, hopefully, you can also use the RunPod and PixArt Alpha with

- [00:25:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1501) proxy connection.

- [00:25:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1502) But for now, we will use Gradio sharing.

- [00:25:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1504) So, the models will get downloaded.

- [00:25:07](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1507) By the way, is this machine not working correctly?

- [00:25:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1509) Yes, the download speeds of this machine are horrific.

- [00:25:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1513) If this happens, you need to get a new machine, usually because you see the downloads are

- [00:25:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1519) really, really slow for some reason.

- [00:25:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1522) Maybe we can restart and see if the speed will get fixed.

- [00:25:26](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1526) But this is how you install and run.

- [00:25:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1529) Meanwhile, I will start another pod.

- [00:25:31](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1531) Sometimes, you may also have these problems.

- [00:25:34](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1534) I will go with RTX A5000 this time.

- [00:25:36](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1536) Maybe this machine will work better.

- [00:25:40](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1540) Okay.

- [00:25:41](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1541) Set overrides and deploy.

- [00:25:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1543) Okay.

- [00:25:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1544) This machine has better hard drive speed perhaps.

- [00:25:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1548) Let's see which one is faster.

- [00:25:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1550) Let's go to the JupyterLab.

- [00:25:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1552) You see the RunPod prices are really, really competitive.

- [00:25:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1555) They are really the best prices having cloud GPU.

- [00:25:59](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1559) Okay.

- [00:26:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1560) I will delete the hub folder with this command.

- [00:26:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1562) This is really important.

- [00:26:04](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1564) rm -r hub.

- [00:26:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1566) Do not use the Jupyter interface to delete folders.

- [00:26:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1570) Okay, let's copy paste and start again.

- [00:26:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1573) And let's connect the second machine meanwhile and try it.

- [00:26:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1577) Okay.

- [00:26:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1578) The speed is yeah.

- [00:26:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1580) The speed is fixed after I closed the server and opened back.

- [00:26:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1583) Now it is downloading the files accurately.

- [00:26:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1585) So, we don't need the second machine, which is this one.

- [00:26:30](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1590) Let's stop it and delete it.

- [00:26:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1592) With the RunPods, you may have also similar problems.

- [00:26:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1595) So, you should join our Discord channel and ask me questions or join the official RunPod

- [00:26:41](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1601) Discord channel and ask questions there.

- [00:26:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1603) This should be quickly completed because the download speed is really, really good around

- [00:26:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1608) 100 megabytes per second.

- [00:26:50](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1610) Okay.

- [00:26:51](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1611) The models are downloaded.

- [00:26:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1612) Now we have a Gradio public link.

- [00:26:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1615) Let's open it.

- [00:26:56](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1616) Do not worry.

- [00:26:57](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1617) No one can find this link if you don't share it.

- [00:27:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1621) So, it is pretty safe.

- [00:27:02](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1622) You can also define passwords to connect and that's it.

- [00:27:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1626) Just type your prompts and run it.

- [00:27:08](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1628) It will generate an image.

- [00:27:10](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1630) You can also follow this terminal to see what is happening.

- [00:27:14](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1634) You can see memory usage, the GPU utilization, and everything.

- [00:27:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1639) And the image is here.

- [00:27:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1640) It was really, really fast.

- [00:27:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1642) Okay.

- [00:27:23](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1643) Let's generate more images, like batch count 10 run.

- [00:27:27](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1647) So, the speed is amazing.

- [00:27:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1649) Average step count is only 350 milliseconds.

- [00:27:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1653) Each image is being generated with seven seconds with 20 steps.

- [00:27:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1658) We can see the outputs getting saved inside this folder.

- [00:27:44](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1664) Let's see the images.

- [00:27:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1665) Okay.

- [00:27:46](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1666) We are seeing the images generated on RunPod.

- [00:27:48](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1668) Really, really cool.

- [00:27:49](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1669) Really, really amazing quality.

- [00:27:52](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1672) Just amazing.

- [00:27:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1673) We just typed a car, nothing else.

- [00:27:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1675) And it is using its imagination to generate these images.

- [00:28:00](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1680) You can also define much advanced prompt.

- [00:28:03](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1683) So, this is how we install the PixArt on RunPod and use it.

- [00:28:09](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1689) Exactly the same installer will work on Linux machines as well.

- [00:28:13](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1693) So, if you have a Linux machine, you can follow the exactly same steps and install it on a

- [00:28:19](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1699) Linux machine.

- [00:28:20](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1700) And let's say you want to download all of the images.

- [00:28:22](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1702) I suggest you to use runpodctl.

- [00:28:24](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1704) So, runpodctl, send the folder name, type it, it will give you a link and you can download

- [00:28:32](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1712) it anywhere you want.

- [00:28:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1713) And let's download it here.

- [00:28:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1715) Open a new cmd here, copy paste the link, and it will download all of the images into

- [00:28:41](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1721) here.

- [00:28:42](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1722) You see all of the generated images are downloaded into this folder.

- [00:28:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1725) If you don't know how to use runpodctl, on this tutorial, runpodctl is explained with

- [00:28:53](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1733) full details.

- [00:28:54](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1734) I hope you have enjoyed.

- [00:28:55](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1735) If you sponsor me, if you fork my repository, star it, I would appreciate that very much.

- [00:29:01](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1741) In our GitHub repository, you will find all of the links and tutorials like this.

- [00:29:06](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1746) You see, they are all written in structure from sorted by the date they were released.

- [00:29:12](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1752) So, if you're a beginner of Stable Diffusion, you can watch all of the tutorials here.

- [00:29:17](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1757) They are all amazing.

- [00:29:18](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1758) They will teach you how the AI field is progressing with the timely manner.

- [00:29:25](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1765) I am adding the new tutorials as I record them to the here, to the list, to the end

- [00:29:29](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1769) of the list.

- [00:29:30](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1770) So, you will not be disappointed.

- [00:29:33](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1773) You should also join our Discord from here.

- [00:29:35](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1775) You can support me also with buy me a coffee.

- [00:29:38](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1778) You can follow me on Medium, CivitAI, DeviantArt.

- [00:29:41](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1781) You should definitely subscribe to our YouTube channel.

- [00:29:43](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1783) You can follow me on LinkedIn.

- [00:29:45](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1785) You can also purchase my Udemy course and you can follow me on Twitter as well.

- [00:29:47](https://www.youtube.com/watch?v=ZiUXf_idIR4&t=1787) Hopefully, see you in another amazing tutorial video.

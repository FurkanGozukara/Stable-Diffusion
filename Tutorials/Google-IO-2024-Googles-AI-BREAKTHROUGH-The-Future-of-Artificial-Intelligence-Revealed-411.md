# Google I/O 2024 - Google's AI BREAKTHROUGH: The Future of Artificial Intelligence Revealed - 4/11

## Full tutorial link > https://www.youtube.com/watch?v=aMTjpx3mg-4

[![Google I/O 2024 - Google's AI BREAKTHROUGH: The Future of Artificial Intelligence Revealed - 4/11](https://img.youtube.com/vi/aMTjpx3mg-4/sddefault.jpg)](https://www.youtube.com/watch?v=aMTjpx3mg-4 "Google I/O 2024 - Google's AI BREAKTHROUGH: The Future of Artificial Intelligence Revealed - 4/11")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Google-IO-2024-Googles-AI-BREAKTHROUGH-The-Future-of-Artificial-Intelligence-Revealed-411.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Google-IO-2024-Googles-AI-BREAKTHROUGH-The-Future-of-Artificial-Intelligence-Revealed-411.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan Gözükara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan Gözükara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan Gözükara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan Gözükara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


Join us at Google I/O 2024 as we delve into the groundbreaking advancements in AI, featuring the unveiling of Project Astra, a revolutionary approach to AI assistance, and explore the latest updates in generative media tools.

In this groundbreaking video from Google I/O 2024, Demis Hassabis, co-founder of Google DeepMind, unveils the latest advancements in artificial intelligence. Discover how Google's cutting-edge AI models, including Gemini 1.5 Pro and the newly introduced Gemini 1.5 Flash, are revolutionizing the field of AI. Learn about Project Astra, a universal AI agent designed to be truly helpful in everyday life, and witness a live demo showcasing its incredible capabilities. Plus, get a sneak peek at the future of generative media tools with updates covering image, music, and video. Don't miss this exclusive look at the future of AI and how it will transform our world!

[00:00:00](https://youtu.be/aMTjpx3mg-4?t=0) - Introduction by Sundar Pichai

[00:00:13](https://youtu.be/aMTjpx3mg-4?t=13) - Demis Hassabis on the path to AGI

[00:01:54](https://youtu.be/aMTjpx3mg-4?t=114) - Introducing Gemini 1.5 Flash

[00:03:05](https://youtu.be/aMTjpx3mg-4?t=185) - Pushing the state of the art with Gemini models

[00:03:36](https://youtu.be/aMTjpx3mg-4?t=216) - The future of AI assistance: Project Astra

[00:05:23](https://youtu.be/aMTjpx3mg-4?t=323) - Live demo of Project Astra prototype

[00:07:38](https://youtu.be/aMTjpx3mg-4?t=458) - The future of AI and its impact

[00:08:16](https://youtu.be/aMTjpx3mg-4?t=496) - Updates in generative media tools

[00:08:38](https://youtu.be/aMTjpx3mg-4?t=518) - Over to Doug for more on generative media

In this video from Google I/O 2024, Demis Hassabis, co-founder of Google DeepMind, shares the latest advancements in artificial intelligence and how they are shaping the future. Hassabis discusses his lifelong fascination with the nature of intelligence and his goal of building artificial general intelligence (AGI) that has human-level cognitive capabilities. He highlights the milestones achieved by Google DeepMind, including the development of AI systems capable of solving complex problems in various domains, such as robotics, virtual environments, mathematics, and biology.

Hassabis introduces Gemini 1.5 Flash, a lighter-weight model designed for low latency and cost-efficient serving at scale while maintaining multimodal reasoning capabilities and long context. Flash is optimized for tasks where speed and efficiency are crucial, and developers can now access both Gemini 1.5 Flash and 1.5 Pro with up to 1 million tokens in Google AI Studio and Vertex AI.

The video also provides a glimpse into the future of AI assistance through Project Astra, a universal AI agent that aims to be truly helpful in everyday life. Built on the Gemini model, these agents can process information faster, understand context, and respond quickly in conversation, making interactions feel more natural. A live demo showcases the prototype's impressive capabilities, including understanding spatial information, processing video and speech input, and efficiently recalling information.

Hassabis emphasizes the potential impact of AI on transformative experiences and announces that some of these agent capabilities will be integrated into Google products like the Gemini app later in the year. Attendees at Google I/O can experience a live demo version of this AI assistant in the AI sandbox area.

The video concludes with a brief introduction to updates in generative media tools, covering advancements in image, music, and video. These updates focus on enhancing quality, improving safety, and increasing access to these powerful tools.

Overall, this presentation highlights the remarkable progress made in artificial intelligence and offers an exciting glimpse into the future of AI-powered experiences that will transform the way we interact with technology and the world around us.



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=0) Ok, we continue to the Google I.O. 2024 with the part 4.

- [00:00:13](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=13) Thanks Sundar, it's so great to be here.

- [00:00:17](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=17) Ever since I was a kid, playing chess for the England junior team, I've been thinking about the nature of intelligence.

- [00:00:24](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=24) I was captivated by the idea of a computer that could think like a person.

- [00:00:28](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=28) It's ultimately why I became a programmer and studied neuroscience.

- [00:00:33](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=33) I co-founded DeepMind in 2010 with the goal of one day building AGI, artificial general intelligence, a system that has human level cognitive capabilities.

- [00:00:45](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=45) I've always believed that if we could build this technology responsibly, its impact would be truly profound and it could benefit humanity in incredible ways.

- [00:00:55](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=55) Last year, we reached a milestone on that path when we formed Google DeepMind, combining AI talent from across the company into one super unit.

- [00:01:04](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=64) Since then, we've built AI systems that can do an amazing range of things.

- [00:01:09](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=69) From turning language and vision into action for robots, navigating complex virtual 3D environments, solving Olympiad level math problems and even discovering thousands of new materials.

- [00:01:23](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=83) Just last week, we announced our next generation AlphaFold model.

- [00:01:28](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=88) It can predict the structure and interactions of nearly all of life's molecules, including how proteins interact with strands of DNA and RNA.

- [00:01:37](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=97) This will accelerate vitally important biological and medical research from disease understanding to drug discovery.

- [00:01:44](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=104) And all of this was made possible with the best infrastructure for the AI era, including our highly optimized tensor processing units.

- [00:01:54](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=114) At the center of our efforts is our Gemini model.

- [00:01:58](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=118) It's built up from the ground up to be natively multimodal because that's how we interact with and understand the world around us.

- [00:02:05](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=125) We've built a variety of models for different use cases.

- [00:02:08](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=128) You've seen how powerful Gemini 1.5 Pro is, but we also know from user feedback that some applications need lower latency and a lower cost to serve.

- [00:02:19](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=139) So today we're introducing Gemini 1.5 Flash.

- [00:02:31](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=151) Flash is a lighter weight model compared to Pro.

- [00:02:34](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=154) It's designed to be fast and cost efficient to serve at scale while still featuring multimodal reasoning capabilities and breakthrough long context.

- [00:02:43](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=163) Flash is optimized for tasks where low latency and efficiency matter most.

- [00:02:48](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=168) Starting today, you can use 1.5 Flash and 1.5 Pro with up to 1 million tokens in Google AI Studio and Vertex AI.

- [00:02:57](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=177) And developers can sign up to try 2 million tokens.

- [00:03:01](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=181) We're so excited to see what all of you will create with it.

- [00:03:05](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=185) And you'll hear a little more about Flash later on from Josh.

- [00:03:09](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=189) We're very excited by the progress we've made so far with our family of Gemini models, but we're always striving to push the state of the art even further.

- [00:03:19](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=199) At any one time, we have many different models in training and we use our very large and powerful ones to help teach and train our production ready models.

- [00:03:28](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=208) Together with user feedback, this cutting edge research will help us to build amazing new products for billions of people.

- [00:03:36](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=216) For example, in December, we shared a glimpse into the future of how people would interact with multimodal AI.

- [00:03:43](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=223) And how this would end up powering a new set of transformative experiences.

- [00:03:48](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=228) Today we have some exciting new progress to share about the future of AI assistance that we're calling Project Astra.

- [00:03:55](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=235) For a long time, we've wanted to build a universal AI agent that can be truly helpful in everyday life.

- [00:04:07](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=247) Our work making this vision a reality goes back many years.

- [00:04:11](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=251) It's why we made Gemini multimodal from the very beginning.

- [00:04:15](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=255) An agent like this has to understand and respond to our complex and dynamic world just like we do.

- [00:04:21](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=261) It would need to take in and remember what it sees so it can understand context and take action.

- [00:04:27](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=267) And it would have to be proactive, teachable and personal so you can talk to it naturally without lag or delay.

- [00:04:34](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=274) While we've made some great strides in developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge.

- [00:04:45](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=285) Building on our Gemini model, we've developed agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events and caching this for efficient recall.

- [00:04:59](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=299) We've also enhanced how they sound with a wider range of intonations.

- [00:05:04](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=304) These agents better understand the context you're in and can respond quickly in conversation, making the pace and quality of interaction feel much more natural.

- [00:05:13](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=313) Here's a video of our prototype which you'll see has two parts. Each part was captured in a single take in real time.

- [00:05:23](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=323) Okay, let's do some tests.

- [00:05:26](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=326) Tell me when you see something that makes sound.

- [00:05:31](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=331) I see a speaker which makes sound.

- [00:05:35](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=335) What is that part of the speaker called?

- [00:05:37](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=337) That is the tweeter. It produces high frequency sounds.

- [00:05:45](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=345) Give me a creative alliteration about these.

- [00:05:49](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=349) Creative crayons color cheerfully. They certainly craft colorful creations.

- [00:05:59](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=359) What does that part of the code do?

- [00:06:01](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=361) This code defines encryption and decryption functions.

- [00:06:05](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=365) It seems to use AESCBC encryption to encode and decode data based on a key and an initialization vector, IV.

- [00:06:16](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=376) That's right.

- [00:06:19](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=379) What neighborhood do you think I'm in?

- [00:06:23](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=383) This appears to be the King's Cross area of London.

- [00:06:27](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=387) This appears to be the King's Cross area of London. It is known for its railway station and transportation connections.

- [00:06:36](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=396) Do you remember where you saw my glasses?

- [00:06:40](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=400) Yes, I do. Your glasses were on the desk near Red Apple.

- [00:06:57](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=417) What can I add here to make this system faster?

- [00:07:03](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=423) Adding a cache between the server and database could improve speed.

- [00:07:08](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=428) What does this remind you of?

- [00:07:13](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=433) Schrodinger's cat.

- [00:07:17](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=437) Alright, give me a band name for this duo.

- [00:07:24](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=444) Golden Stripes.

- [00:07:26](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=446) Nice. Thanks, Gemini.

- [00:07:38](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=458) I think you'll agree it's amazing to see how far AI has come.

- [00:07:43](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=463) Especially when it comes to spatial understanding, video processing, and memory.

- [00:07:48](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=468) It's easy to envisage a future where you can have an expert assistant by your side through your phone or new exciting form factors.

- [00:07:57](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=477) Some of these agent capabilities will come to Google products like Gemini app later this year.

- [00:08:03](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=483) For those of you on site today, you can try out a live demo version of this experience in the AI sandbox area.

- [00:08:16](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=496) Next, let's take a look at how our innovations are helping people bring new creative ideas to life.

- [00:08:23](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=503) Today, we're introducing a series of updates across our generative media tools with new models covering image, music, and video.

- [00:08:32](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=512) Over the past year, we've been enhancing quality, improving safety, and increasing access.

- [00:08:38](https://www.youtube.com/watch?v=aMTjpx3mg-4&t=518) To help tell this story, here's Doug.

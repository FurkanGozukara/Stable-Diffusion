# How To Install And Use Kohya LoRA GUI / Web UI on RunPod IO With Stable Diffusion & Automatic1111

## Full tutorial link > https://www.youtube.com/watch?v=3uzCNrQao3o

[![How To Install And Use Kohya LoRA GUI / Web UI on RunPod IO With Stable Diffusion & Automatic1111](https://img.youtube.com/vi/3uzCNrQao3o/sddefault.jpg)](https://www.youtube.com/watch?v=3uzCNrQao3o "How To Install And Use Kohya LoRA GUI / Web UI on RunPod IO With Stable Diffusion & Automatic1111")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Install-And-Use-Kohya-LoRA-GUI-Web-UI-on-RunPod-IO-With-Stable-Diffusion-and-Automatic1111.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Install-And-Use-Kohya-LoRA-GUI-Web-UI-on-RunPod-IO-With-Stable-Diffusion-and-Automatic1111.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


How to install famous Kohya SS LoRA GUI on RunPod IO pods and do training on cloud seamlessly as in your PC. Then use Automatic1111 Web UI to generate images with your trained LoRA files. Everything is explained step by step and amazing resource GitHub file is provided with necessary commands. If you want to use Kohya's Stable Diffusion trainers on RunPod this tutorial is for that.

Source GitHub File ‚§µÔ∏è

[https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Install-Kohya-LoRA-Web-UI-On-RunPod.md](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Install-Kohya-LoRA-Web-UI-On-RunPod.md)

Auto Installer Script ‚§µÔ∏è

[https://www.patreon.com/posts/84898806](https://www.patreon.com/posts/84898806)

Sign up RunPod ‚§µÔ∏è

[https://bit.ly/RunPodIO](https://bit.ly/RunPodIO)

Our Discord server ‚§µÔ∏è

[https://bit.ly/SECoursesDiscord](https://bit.ly/SECoursesDiscord)

If I have been of assistance to you and you would like to show your support for my work, please consider becoming a patron on ü•∞ ‚§µÔ∏è

[https://www.patreon.com/SECourses](https://www.patreon.com/SECourses)

Technology & Science: News, Tips, Tutorials, Tricks, Best Applications, Guides, Reviews ‚§µÔ∏è

[https://www.youtube.com/playlist?list=PL_pbwdIyffsnkay6X91BWb9rrfLATUMr3](https://www.youtube.com/playlist?list=PL_pbwdIyffsnkay6X91BWb9rrfLATUMr3)

Playlist of StableDiffusion Tutorials, Automatic1111 and Google Colab Guides, DreamBooth, Textual Inversion / Embedding, LoRA, AI Upscaling, Pix2Pix, Img2Img ‚§µÔ∏è

[https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3](https://www.youtube.com/playlist?list=PL_pbwdIyffsmclLl0O144nQRnezKlNdx3)

[00:00:00](https://youtu.be/3uzCNrQao3o?t=0) Introduction to how to install Kohya GUI on RunPod tutorial

[00:00:20](https://youtu.be/3uzCNrQao3o?t=20) Pick which RunPod server and template

[00:01:20](https://youtu.be/3uzCNrQao3o?t=80) Starting installation of Kohya LoRA on RunPod

[00:03:42](https://youtu.be/3uzCNrQao3o?t=222) How to start Kohya Web GUI after installation

[00:04:16](https://youtu.be/3uzCNrQao3o?t=256) How to download models on RunPod and start Kohya LoRA training

[00:05:36](https://youtu.be/3uzCNrQao3o?t=336) LoRA training parameters

[00:06:57](https://youtu.be/3uzCNrQao3o?t=417) Starting Kohya LoRA training on RunPod

[00:07:46](https://youtu.be/3uzCNrQao3o?t=466) Where are Kohya LoRA training checkpoints saved

[00:08:05](https://youtu.be/3uzCNrQao3o?t=485) How to use LoRA saved checkpoints on RunPod

[00:08:29](https://youtu.be/3uzCNrQao3o?t=509) How to use LoRA checkpoints in Automatic1111 Web UI

[00:09:12](https://youtu.be/3uzCNrQao3o?t=552) Noticing a very crucial mistake during training

[00:10:59](https://youtu.be/3uzCNrQao3o?t=659) Testing different checkpoints after fixing the previous training mistake

[00:11:36](https://youtu.be/3uzCNrQao3o?t=696) How to understand model overtraining

[00:12:28](https://youtu.be/3uzCNrQao3o?t=748) How to fix overtraining problem

Title: Install Kohya GUI on RunPod for LoRA Training: Step-by-Step Tutorial

Description:

Welcome to my comprehensive guide on how to install Kohya GUI on RunPod for LoRA training. I take you through each step, explaining clearly to ensure you can follow along with ease. This tutorial will help you set up a powerful development environment using an RTX 3090 GPU and a RunPod with 30GB RAM.

In this video, we will:

Deploy a community cloud with a specific template.

Edit template overrides and set the container disk.

Connect to JupyterLab and clone a GitHub repository.

Generate a new virtual environment and activate it.

Install Kohya on RunPod and handle common errors.

Set up and start the Kohya web UI on RunPod.

Execute a quick demonstration of training a realistic vision model.

Troubleshoot common errors during the training process.

Optimize the training process and improve training quality.

Navigate through our GitHub repository for further learning.

Remember, if you're unfamiliar with how to use Kohya or RunPod, I've included links to excellent tutorials in the video description.

Whether you're just getting started with Kohya, RunPod, or LoRA training, or looking to enhance your existing skills, this tutorial offers valuable insights.

Don't forget to like, share, and subscribe for more tutorials like this!

#StableDiffusion #Kohya #RunPod #LoRATraining #Tutorial #MachineLearning #AI



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=3uzCNrQao3o&t=0) Greetings everyone. In this video I will show&nbsp; you how to install Kohya GUI on RunPod to do&nbsp;&nbsp;

- [00:00:07](https://www.youtube.com/watch?v=3uzCNrQao3o&t=7) LoRA training. This has been asked to me many&nbsp; times. Sorry for the delay. Hopefully I will&nbsp;&nbsp;

- [00:00:12](https://www.youtube.com/watch?v=3uzCNrQao3o&t=12) explain that today. So this is the beginning&nbsp; screen of the RunPod IO. Let's go to the&nbsp;&nbsp;

- [00:00:18](https://www.youtube.com/watch?v=3uzCNrQao3o&t=18) community cloud. I will use RTX 3090 which is&nbsp; a very powerful GPU. Also this RunPod has 30GB&nbsp;&nbsp;

- [00:00:26](https://www.youtube.com/watch?v=3uzCNrQao3o&t=26) RAM. Click deploy. Select a template here. Select&nbsp; web automatic template. This is really important.&nbsp;&nbsp;

- [00:00:32](https://www.youtube.com/watch?v=3uzCNrQao3o&t=32) Currently it is 6.0.1. When you are watching&nbsp; this tutorial. It may be higher. Then go to&nbsp;&nbsp;

- [00:00:39](https://www.youtube.com/watch?v=3uzCNrQao3o&t=39) the edit template overrides. Make the container&nbsp; disk 10GB. You can set the volume disk as much as&nbsp;&nbsp;

- [00:00:44](https://www.youtube.com/watch?v=3uzCNrQao3o&t=44) you want. Set overrides and click continue.&nbsp; Click deploy. Okay container started. Let's&nbsp;&nbsp;

- [00:00:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=51) connect with JupyterLab. Now I am using a GitHub&nbsp; repository to put descriptions and used commands&nbsp;&nbsp;

- [00:00:58](https://www.youtube.com/watch?v=3uzCNrQao3o&t=58) in my tutorials. The link of this file will be in&nbsp; the description. Every command is written here. If&nbsp;&nbsp;

- [00:01:04](https://www.youtube.com/watch?v=3uzCNrQao3o&t=64) you don't know how to use Kohya I have excellent&nbsp; tutorial here. You can click this link and watch&nbsp;&nbsp;

- [00:01:09](https://www.youtube.com/watch?v=3uzCNrQao3o&t=69) it. Also if you don't know how to use RunPod I&nbsp; have another excellent tutorial here. You can&nbsp;&nbsp;

- [00:01:14](https://www.youtube.com/watch?v=3uzCNrQao3o&t=74) click and watch it. So the commands are ready&nbsp; here. Kohya LoRA GUI on RunPod. First thing is,&nbsp;&nbsp;

- [00:01:20](https://www.youtube.com/watch?v=3uzCNrQao3o&t=80) we will clone the repository with this command.&nbsp; Select it copy. Then in the JupyterLab terminal&nbsp;&nbsp;

- [00:01:26](https://www.youtube.com/watch?v=3uzCNrQao3o&t=86) in the workspace. Let's clone the repository like&nbsp; this. The repository is cloned. Then this command.&nbsp;&nbsp;

- [00:01:33](https://www.youtube.com/watch?v=3uzCNrQao3o&t=93) Now we are inside Kohya SS. Then we will generate&nbsp; a new virtual environment in this folder with&nbsp;&nbsp;

- [00:01:40](https://www.youtube.com/watch?v=3uzCNrQao3o&t=100) this command. The virtual environment is generated&nbsp; inside Kohya SS folder here. Then we will execute&nbsp;&nbsp;

- [00:01:46](https://www.youtube.com/watch?v=3uzCNrQao3o&t=106) this command. Now the new virtual environment&nbsp; is activated. Now we will run this command. This&nbsp;&nbsp;

- [00:01:53](https://www.youtube.com/watch?v=3uzCNrQao3o&t=113) won't affect our Stable Diffusion installation&nbsp; on our RunPod. So this is a very convenient way&nbsp;&nbsp;

- [00:01:59](https://www.youtube.com/watch?v=3uzCNrQao3o&t=119) to install Kohya on RunPod. Okay in the first&nbsp; try, we have got an error because obviously the&nbsp;&nbsp;

- [00:02:07](https://www.youtube.com/watch?v=3uzCNrQao3o&t=127) download of the file failed. So what I am going&nbsp; to do is I will repeat the operation. So I will&nbsp;&nbsp;

- [00:02:13](https://www.youtube.com/watch?v=3uzCNrQao3o&t=133) rerun the command to be sure. To rerun the command&nbsp; I just did like this while the virtual environment&nbsp;&nbsp;

- [00:02:19](https://www.youtube.com/watch?v=3uzCNrQao3o&t=139) is activated. Okay this time we didn't get the&nbsp; previous error. However we have got the tkinter&nbsp;&nbsp;

- [00:02:26](https://www.youtube.com/watch?v=3uzCNrQao3o&t=146) error. This is the most common error that you were&nbsp; encountering. I have a solution for that. While&nbsp;&nbsp;

- [00:02:32](https://www.youtube.com/watch?v=3uzCNrQao3o&t=152) virtual environment is activated you don't need&nbsp; to run this again. However if you start a new CMD&nbsp;&nbsp;

- [00:02:38](https://www.youtube.com/watch?v=3uzCNrQao3o&t=158) you need to do. Then just copy this command&nbsp; while virtual environment is activated paste&nbsp;&nbsp;

- [00:02:43](https://www.youtube.com/watch?v=3uzCNrQao3o&t=163) it like this. Then copy this command. This will&nbsp; install this tkinter. It is installed. And finally&nbsp;&nbsp;

- [00:02:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=171) we will install latest torch. Copy while virtual&nbsp; environment is activated. Install. This is really&nbsp;&nbsp;

- [00:02:58](https://www.youtube.com/watch?v=3uzCNrQao3o&t=178) important. You need to have Kohya SS virtual&nbsp; environment to be activated while executing all&nbsp;&nbsp;

- [00:03:06](https://www.youtube.com/watch?v=3uzCNrQao3o&t=186) of these commands. So if your virtual environment&nbsp; is activated, you don't need to run this once&nbsp;&nbsp;

- [00:03:11](https://www.youtube.com/watch?v=3uzCNrQao3o&t=191) again. The torch installation is pretty fast. It&nbsp; is installing 2.0.1 version which is the latest&nbsp;&nbsp;

- [00:03:18](https://www.youtube.com/watch?v=3uzCNrQao3o&t=198) official version. This is being installed in our&nbsp; Kohya virtual environment. This won't affect our&nbsp;&nbsp;

- [00:03:24](https://www.youtube.com/watch?v=3uzCNrQao3o&t=204) Stable Diffusion installation. By default Kohya&nbsp; is installing 1.12 which works pretty slow on&nbsp;&nbsp;

- [00:03:31](https://www.youtube.com/watch?v=3uzCNrQao3o&t=211) the newest GPUs. Okay the installation has been&nbsp; completed. You can ignore this message because&nbsp;&nbsp;

- [00:03:37](https://www.youtube.com/watch?v=3uzCNrQao3o&t=217) we won't use xformers while training. It is just&nbsp; slowing us down. Then we will start the Kohya web&nbsp;&nbsp;

- [00:03:43](https://www.youtube.com/watch?v=3uzCNrQao3o&t=223) UI. Copy this. For starting this, you don't need&nbsp; to have virtual environment activated. Actually&nbsp;&nbsp;

- [00:03:48](https://www.youtube.com/watch?v=3uzCNrQao3o&t=228) it is preferably not to activate it. Open a new&nbsp; terminal inside Kohya SS like this. Just copy&nbsp;&nbsp;

- [00:03:55](https://www.youtube.com/watch?v=3uzCNrQao3o&t=235) paste it. It will automatically activate the&nbsp; virtual environment and also it will give you&nbsp;&nbsp;

- [00:04:00](https://www.youtube.com/watch?v=3uzCNrQao3o&t=240) a Gradio link like this. Open it and the Kohya&nbsp; GUI web UI started on RunPod and ready to use.&nbsp;&nbsp;

- [00:04:07](https://www.youtube.com/watch?v=3uzCNrQao3o&t=247) As I said if you don't know how to use Kohya to do&nbsp; training, you can watch this amazing tutorial. I&nbsp;&nbsp;

- [00:04:13](https://www.youtube.com/watch?v=3uzCNrQao3o&t=253) will do quick demonstration of training. So&nbsp; I will use realistic vision full model. To&nbsp;&nbsp;

- [00:04:18](https://www.youtube.com/watch?v=3uzCNrQao3o&t=258) download it just copy this. Run it inside Stable&nbsp; Diffusion models folder so we can use it with our&nbsp;&nbsp;

- [00:04:24](https://www.youtube.com/watch?v=3uzCNrQao3o&t=264) Automatic1111 web UI. I will also download the&nbsp; best VAE file from this link. It will get into&nbsp;&nbsp;

- [00:04:30](https://www.youtube.com/watch?v=3uzCNrQao3o&t=270) VAE folder. You can also download realistic&nbsp; vision version 2 classification images from&nbsp;&nbsp;

- [00:04:36](https://www.youtube.com/watch?v=3uzCNrQao3o&t=276) this post. Posted on our Patreon. So I will use&nbsp; these training images same as in the last video.&nbsp;&nbsp;

- [00:04:43](https://www.youtube.com/watch?v=3uzCNrQao3o&t=283) I have uploaded them to here. Also classification&nbsp; images are ready as well. So in the Kohya web UI&nbsp;&nbsp;

- [00:04:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=291) obviously these icons won't work because we are on&nbsp; run pod. Therefore we need to copy paste the model&nbsp;&nbsp;

- [00:04:58](https://www.youtube.com/watch?v=3uzCNrQao3o&t=298) path ourselves or you can use the automatic models&nbsp; from this drop down. So I will get the path of the&nbsp;&nbsp;

- [00:05:05](https://www.youtube.com/watch?v=3uzCNrQao3o&t=305) model from Stable Diffusion realistic vision. Copy&nbsp; path pasted here. Put a backslash to the beginning&nbsp;&nbsp;

- [00:05:12](https://www.youtube.com/watch?v=3uzCNrQao3o&t=312) of it and our model is ready. Then as shown in the&nbsp; previous video ohwx man. I will set the training&nbsp;&nbsp;

- [00:05:20](https://www.youtube.com/watch?v=3uzCNrQao3o&t=320) images directory manually which is here copy path.&nbsp; Let's also set the regularization images. Copy&nbsp;&nbsp;

- [00:05:27](https://www.youtube.com/watch?v=3uzCNrQao3o&t=327) path like this and the destination directory&nbsp; will be: test1. Prepare training data. Okay,&nbsp;&nbsp;

- [00:05:33](https://www.youtube.com/watch?v=3uzCNrQao3o&t=333) test one appeared here. Copy info to folders&nbsp; tab. Okay, everything is copied and in the&nbsp;&nbsp;

- [00:05:39](https://www.youtube.com/watch?v=3uzCNrQao3o&t=339) training parameters. I will use everything.&nbsp; Default only network rank 256 these are the&nbsp;&nbsp;

- [00:05:46](https://www.youtube.com/watch?v=3uzCNrQao3o&t=346) best settings that I have found. In the advanced&nbsp; tab. Now this is important. Don't use xformers,&nbsp;&nbsp;

- [00:05:52](https://www.youtube.com/watch?v=3uzCNrQao3o&t=352) uncheck it. And finally, let's also save our&nbsp; configuration. So for saving, open a notepad&nbsp;&nbsp;

- [00:06:01](https://www.youtube.com/watch?v=3uzCNrQao3o&t=361) file type workspace/kohya_test1.json. It will&nbsp; be saved here. Copy paste it here. Save and&nbsp;&nbsp;

- [00:06:10](https://www.youtube.com/watch?v=3uzCNrQao3o&t=370) you will see kohya_test1.json file is generated.&nbsp; From there you can just load it by typing this,&nbsp;&nbsp;

- [00:06:18](https://www.youtube.com/watch?v=3uzCNrQao3o&t=378) type here and click load and it will load the&nbsp; settings. Okay, everything ready. Let's train&nbsp;&nbsp;

- [00:06:23](https://www.youtube.com/watch?v=3uzCNrQao3o&t=383) model and we will see entire training in here.&nbsp; By the way, we have forgotten to set number of&nbsp;&nbsp;

- [00:06:30](https://www.youtube.com/watch?v=3uzCNrQao3o&t=390) epochs. Therefore, I will kill and restart or shut&nbsp; down all of the terminals. Okay, let's go back to&nbsp;&nbsp;

- [00:06:37](https://www.youtube.com/watch?v=3uzCNrQao3o&t=397) Kohya folder. Open a new terminal, start the web&nbsp; UI with this command. Once again like this, open&nbsp;&nbsp;

- [00:06:44](https://www.youtube.com/watch?v=3uzCNrQao3o&t=404) the new link. Let's copy our saved configuration&nbsp; file like this: put a slash to beginning of it,&nbsp;&nbsp;

- [00:06:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=411) click load settings are loaded. Let's also set&nbsp; the epochs like 14. Save every one epoch, save&nbsp;&nbsp;

- [00:06:58](https://www.youtube.com/watch?v=3uzCNrQao3o&t=418) and click training okay. Ok, training started. You&nbsp; see there are some errors and warning messages.&nbsp;&nbsp;

- [00:07:05](https://www.youtube.com/watch?v=3uzCNrQao3o&t=425) These are fine. It is just working very well.&nbsp; The important thing is do not use xformers. Okay,&nbsp;&nbsp;

- [00:07:12](https://www.youtube.com/watch?v=3uzCNrQao3o&t=432) it has started and the it per second you are&nbsp; seeing 5.4 with batch size one. I can also&nbsp;&nbsp;

- [00:07:20](https://www.youtube.com/watch?v=3uzCNrQao3o&t=440) increase batch size. Currently gpu memory used&nbsp; is only 60% because Automatic1111 web ui is also&nbsp;&nbsp;

- [00:07:28](https://www.youtube.com/watch?v=3uzCNrQao3o&t=448) running at the same time on the same gpu. This&nbsp; is also using some vram you see I have opened&nbsp;&nbsp;

- [00:07:34](https://www.youtube.com/watch?v=3uzCNrQao3o&t=454) it. The first checkpoint already saved, the second&nbsp; checkpoint already saved. Now it is processing the&nbsp;&nbsp;

- [00:07:40](https://www.youtube.com/watch?v=3uzCNrQao3o&t=460) third checkpoint with 5.15 it per second. Okay,&nbsp; entire training is done in three minutes and only&nbsp;&nbsp;

- [00:07:48](https://www.youtube.com/watch?v=3uzCNrQao3o&t=468) 53 seconds. The files are generated inside test1&nbsp; folder inside model and here our checkpoints.&nbsp;&nbsp;

- [00:07:57](https://www.youtube.com/watch?v=3uzCNrQao3o&t=477) Let's also save the last checkpoint as 14, then&nbsp; I will select all while hitting left shift with&nbsp;&nbsp;

- [00:08:05](https://www.youtube.com/watch?v=3uzCNrQao3o&t=485) cut and then I will move them into my Stable&nbsp; Diffusion web UI inside models inside LoRA folder.&nbsp;&nbsp;

- [00:08:12](https://www.youtube.com/watch?v=3uzCNrQao3o&t=492) Paste here and all pasted. Let's refresh our web&nbsp; ui. Refresh models folder. Let's pick realistic&nbsp;&nbsp;

- [00:08:20](https://www.youtube.com/watch?v=3uzCNrQao3o&t=500) vision. Okay, realistic vision is selected. Click&nbsp; show hide extra networks. In here click LoRA click&nbsp;&nbsp;

- [00:08:27](https://www.youtube.com/watch?v=3uzCNrQao3o&t=507) refresh. Okay LoRA checkpoints arrived. Let's see&nbsp; last checkpoint and see our result photo of ohwx&nbsp;&nbsp;

- [00:08:35](https://www.youtube.com/watch?v=3uzCNrQao3o&t=515) man. Generate and here our picture. It doesn't&nbsp; look very good. We need to do some beautifying&nbsp;&nbsp;

- [00:08:41](https://www.youtube.com/watch?v=3uzCNrQao3o&t=521) and also some checkpoint comparison. So I will go&nbsp; to the tutorials in my GitHub page. I will go to&nbsp;&nbsp;

- [00:08:48](https://www.youtube.com/watch?v=3uzCNrQao3o&t=528) the generate studio quality realistic photos. In&nbsp; here I have some prompts. I will copy the negative&nbsp;&nbsp;

- [00:08:54](https://www.youtube.com/watch?v=3uzCNrQao3o&t=534) prompt as well and let's say dpm SDE Karras,&nbsp; 30 steps cfg scale 5 let's try again. Okay,&nbsp;&nbsp;

- [00:09:04](https://www.youtube.com/watch?v=3uzCNrQao3o&t=544) still not looking very good so let's try different&nbsp; checkpoints. Interestingly, the results are not&nbsp;&nbsp;

- [00:09:11](https://www.youtube.com/watch?v=3uzCNrQao3o&t=551) very good. I have found the reason because I have&nbsp; uploaded only one training image and based on this&nbsp;&nbsp;

- [00:09:19](https://www.youtube.com/watch?v=3uzCNrQao3o&t=559) image, the model was trained. How did I notice&nbsp; it? I noticed it from these processing messages&nbsp;&nbsp;

- [00:09:27](https://www.youtube.com/watch?v=3uzCNrQao3o&t=567) displayed on the command line interface. You see&nbsp; it says that 40 ohwx man is containing one image&nbsp;&nbsp;

- [00:09:36](https://www.youtube.com/watch?v=3uzCNrQao3o&t=576) files so you may also encounter such problem. Be&nbsp; careful. Now i will repeat the training and see&nbsp;&nbsp;

- [00:09:42](https://www.youtube.com/watch?v=3uzCNrQao3o&t=582) what will happen and nothing else is different&nbsp; only I will change the model output name as&nbsp;&nbsp;

- [00:09:49](https://www.youtube.com/watch?v=3uzCNrQao3o&t=589) test3 save hit train. This time it will take more&nbsp; time because it was doing training only on single&nbsp;&nbsp;

- [00:09:56](https://www.youtube.com/watch?v=3uzCNrQao3o&t=596) image. Now the training. Okay it is still seeing&nbsp; only single image. Oh I see because we need to&nbsp;&nbsp;

- [00:10:03](https://www.youtube.com/watch?v=3uzCNrQao3o&t=603) update this folder as well. Don't forget that. So&nbsp; let's kill this too. So I go to the test1 folder.&nbsp;&nbsp;

- [00:10:09](https://www.youtube.com/watch?v=3uzCNrQao3o&t=609) Go to the image folder in here. I will upload&nbsp; the training images into this folder otherwise&nbsp;&nbsp;

- [00:10:16](https://www.youtube.com/watch?v=3uzCNrQao3o&t=616) it won't be effective. Let's go back to the Kohya&nbsp; ss and restart. Okay, test4 save, train and you&nbsp;&nbsp;

- [00:10:24](https://www.youtube.com/watch?v=3uzCNrQao3o&t=624) see now it has found 13 images. Correct, number of&nbsp; steps is correct, total number of steps and other&nbsp;&nbsp;

- [00:10:31](https://www.youtube.com/watch?v=3uzCNrQao3o&t=631) things are correct. Of course this time it will&nbsp; take 13 times more time. I am not deleting any&nbsp;&nbsp;

- [00:10:37](https://www.youtube.com/watch?v=3uzCNrQao3o&t=637) of these parts of the video because you may also&nbsp; encounter such problems. You may also make same&nbsp;&nbsp;

- [00:10:44](https://www.youtube.com/watch?v=3uzCNrQao3o&t=644) mistakes. This is how you debug your mistake,&nbsp; debug your error, and fix it. Training started&nbsp;&nbsp;

- [00:10:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=651) and this time it is taking like 48 minutes. It&nbsp; has been 10 epochs since the training started.&nbsp;&nbsp;

- [00:10:57](https://www.youtube.com/watch?v=3uzCNrQao3o&t=657) I think this is enough for testing purposes and&nbsp; demonstration. So I will terminate this terminal.&nbsp;&nbsp;

- [00:11:04](https://www.youtube.com/watch?v=3uzCNrQao3o&t=664) The model files are saved inside test1 folder,&nbsp; inside model with the name as test4. So I will cut&nbsp;&nbsp;

- [00:11:13](https://www.youtube.com/watch?v=3uzCNrQao3o&t=673) them, paste into the LoRA folder. Paste it. Let's&nbsp; connect to our Stable Diffusion web UI. Let's load&nbsp;&nbsp;

- [00:11:20](https://www.youtube.com/watch?v=3uzCNrQao3o&t=680) the last prompt. So this time we will use the new&nbsp; LoRA. To do that let's click the show hide extra&nbsp;&nbsp;

- [00:11:28](https://www.youtube.com/watch?v=3uzCNrQao3o&t=688) networks LoRA refresh. Okay, test for LoRA has&nbsp; arrived. Let's look for the checkpoint 6. Okay, it&nbsp;&nbsp;

- [00:11:36](https://www.youtube.com/watch?v=3uzCNrQao3o&t=696) looks like memorized, overtrained because there is&nbsp; no stylization. Let's look for lower checkpoint.&nbsp;&nbsp;

- [00:11:43](https://www.youtube.com/watch?v=3uzCNrQao3o&t=703) With checkpoint 2, we are able to get somewhat&nbsp; okay results. However, this is still not very&nbsp;&nbsp;

- [00:11:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=711) good. I know the reason. Because I have repeating&nbsp; backgrounds and same clothing in my training&nbsp;&nbsp;

- [00:11:59](https://www.youtube.com/watch?v=3uzCNrQao3o&t=719) images and when I check the generated images I&nbsp; see that it is almost generating same backgrounds&nbsp;&nbsp;

- [00:12:05](https://www.youtube.com/watch?v=3uzCNrQao3o&t=725) in the images. Which means it is memorized. One&nbsp; another thing is, even if I use checkpoint 3, you&nbsp;&nbsp;

- [00:12:14](https://www.youtube.com/watch?v=3uzCNrQao3o&t=734) see it is the same place of the training images.&nbsp; That means this model is already over trained with&nbsp;&nbsp;

- [00:12:21](https://www.youtube.com/watch?v=3uzCNrQao3o&t=741) checkpoint 3, checkpoint 2 is also already over&nbsp; trained I think. Therefore, what we need to do is&nbsp;&nbsp;

- [00:12:29](https://www.youtube.com/watch?v=3uzCNrQao3o&t=749) we need to have better training data set. First of&nbsp; all, this is really important. Another thing is we&nbsp;&nbsp;

- [00:12:36](https://www.youtube.com/watch?v=3uzCNrQao3o&t=756) need to reduce number of repeating because with&nbsp; number of repeating 40, we are not able to save&nbsp;&nbsp;

- [00:12:44](https://www.youtube.com/watch?v=3uzCNrQao3o&t=764) more frequent checkpointing with lesser training&nbsp; data. It is saving checkpoints after every 40&nbsp;&nbsp;

- [00:12:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=771) multiplied with 30 steps. Therefore, it is 520&nbsp; steps over for every checkpoint saving. Therefore,&nbsp;&nbsp;

- [00:12:58](https://www.youtube.com/watch?v=3uzCNrQao3o&t=778) we can reduce this to 20 and have more frequent,&nbsp; more fine-tuned checkpoints. Other than that&nbsp;&nbsp;

- [00:13:07](https://www.youtube.com/watch?v=3uzCNrQao3o&t=787) network, rank 128 may work better on unix.&nbsp; Maybe we can try other optimizers you see,&nbsp;&nbsp;

- [00:13:15](https://www.youtube.com/watch?v=3uzCNrQao3o&t=795) there are so many optimizers, but improving our&nbsp; training data set is the number one thing that&nbsp;&nbsp;

- [00:13:21](https://www.youtube.com/watch?v=3uzCNrQao3o&t=801) will improve our training quality. This is all&nbsp; for today. So the link of this page will be in&nbsp;&nbsp;

- [00:13:27](https://www.youtube.com/watch?v=3uzCNrQao3o&t=807) the description and also in the pinned comment of&nbsp; the video. Everything you need is written here:&nbsp;&nbsp;

- [00:13:33](https://www.youtube.com/watch?v=3uzCNrQao3o&t=813) I didn't compare realistic vision half model&nbsp; versus full model so you can test both of them.&nbsp;&nbsp;

- [00:13:39](https://www.youtube.com/watch?v=3uzCNrQao3o&t=819) I will also add the full model link here. If you&nbsp; support us on Patreon I would appreciate that very&nbsp;&nbsp;

- [00:13:44](https://www.youtube.com/watch?v=3uzCNrQao3o&t=824) much. Also, on our channel, we have amazing other&nbsp; Stable Diffusion related videos as well. Just go&nbsp;&nbsp;

- [00:13:51](https://www.youtube.com/watch?v=3uzCNrQao3o&t=831) to the playlist, you will see our Stable Diffusion&nbsp; playlist. All of the Stable Diffusion related&nbsp;&nbsp;

- [00:13:57](https://www.youtube.com/watch?v=3uzCNrQao3o&t=837) videos are in here. Check it out! Also, please&nbsp; support us on Patreon and by joining our youtube&nbsp;&nbsp;

- [00:14:03](https://www.youtube.com/watch?v=3uzCNrQao3o&t=843) channel. I would appreciate those very much. And&nbsp; if you star our repository, fork it and watch it.&nbsp;&nbsp;

- [00:14:10](https://www.youtube.com/watch?v=3uzCNrQao3o&t=850) I would appreciate that too. You will find a lot&nbsp; of useful stuff on our GitHub repository. You will&nbsp;&nbsp;

- [00:14:17](https://www.youtube.com/watch?v=3uzCNrQao3o&t=857) find tutorials, other useful readme files, and&nbsp; in our GitHub page all of our Stable Diffusion&nbsp;&nbsp;

- [00:14:25](https://www.youtube.com/watch?v=3uzCNrQao3o&t=865) tutorials are listed like you are seeing right&nbsp; now. Neatly organized with their thumbnails,&nbsp;&nbsp;

- [00:14:31](https://www.youtube.com/watch?v=3uzCNrQao3o&t=871) their titles so you can check out these links and&nbsp; see which one of them you want to learn. Hopefully&nbsp;&nbsp;

- [00:14:38](https://www.youtube.com/watch?v=3uzCNrQao3o&t=878) see you in another amazing video tutorial.&nbsp; And don't forget to join our Discord channel.

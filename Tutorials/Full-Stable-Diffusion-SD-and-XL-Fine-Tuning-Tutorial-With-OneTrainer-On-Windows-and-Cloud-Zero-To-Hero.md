# Full Stable Diffusion SD & XL Fine Tuning Tutorial With OneTrainer On Windows & Cloud - Zero To Hero

## Full tutorial link > https://www.youtube.com/watch?v=0t5l6CP9eBg

[![Full Stable Diffusion SD & XL Fine Tuning Tutorial With OneTrainer On Windows & Cloud - Zero To Hero](https://img.youtube.com/vi/0t5l6CP9eBg/sddefault.jpg)](https://www.youtube.com/watch?v=0t5l6CP9eBg "Full Stable Diffusion SD & XL Fine Tuning Tutorial With OneTrainer On Windows & Cloud - Zero To Hero")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Full-Stable-Diffusion-SD-and-XL-Fine-Tuning-Tutorial-With-OneTrainer-On-Windows-and-Cloud-Zero-To-Hero.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/Full-Stable-Diffusion-SD-and-XL-Fine-Tuning-Tutorial-With-OneTrainer-On-Windows-and-Cloud-Zero-To-Hero.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan Gözükara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan Gözükara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan Gözükara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan Gözükara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


In this tutorial, I am going to show you how to install OneTrainer from scratch on your computer and do a Stable Diffusion SDXL (Full Fine-Tuning 10.3 GB VRAM) and SD 1.5 (Full Fine-Tuning 7GB VRAM) based models training on your computer and also do the same training on a very cheap cloud machine from MassedCompute if you don't have such computer.

SDXL Configs Updated to Better Version After 20 New Experiment ⤵️

[https://www.patreon.com/posts/96028218](https://www.patreon.com/posts/96028218)

Tutorial Readme File ⤵️

[https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/OneTrainer-Master-SD-1_5-SDXL-Windows-Cloud-Tutorial.md](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/OneTrainer-Master-SD-1_5-SDXL-Windows-Cloud-Tutorial.md)

Register Massed Compute From Below Link (could be necessary to use our Special Coupon for A6000 GPU for 31 cents per hour) ⤵️

* [https://bit.ly/SECoursesMassedCompute](https://bit.ly/SECoursesMassedCompute)

* [https://vm.massedcompute.com/signup?linkId=lp_034338&sourceId=secourses&tenantId=massed-compute](https://vm.massedcompute.com/signup?linkId=lp_034338&sourceId=secourses&tenantId=massed-compute)

Coupon Code for A6000 GPU is : SECourses

[00:00:00](https://youtu.be/0t5l6CP9eBg?t=0) Introduction

[00:03:54](https://youtu.be/0t5l6CP9eBg?t=234) Intro to instructions GitHub readme

[00:04:32](https://youtu.be/0t5l6CP9eBg?t=272) How to register Massed Compute (MC) and start virtual machine (VM)

[00:05:48](https://youtu.be/0t5l6CP9eBg?t=348) Which template to choose on MC

[00:06:36](https://youtu.be/0t5l6CP9eBg?t=396) How to apply MC coupon

[00:08:41](https://youtu.be/0t5l6CP9eBg?t=521) How to install OT on your computer to train

[00:09:15](https://youtu.be/0t5l6CP9eBg?t=555) How to verify your Python, Git, FFmpeg and Git installation

[00:12:00](https://youtu.be/0t5l6CP9eBg?t=720) How to install ThinLinc and start using your MC VM

[00:12:26](https://youtu.be/0t5l6CP9eBg?t=746) How to setup folder synchronization and file sharing computer and MC VM

[00:13:56](https://youtu.be/0t5l6CP9eBg?t=836) End existing session in ThinClient

[00:14:06](https://youtu.be/0t5l6CP9eBg?t=846) How to turn off MC VM

[00:14:24](https://youtu.be/0t5l6CP9eBg?t=864) How to connect and start using VM

[00:14:41](https://youtu.be/0t5l6CP9eBg?t=881) When use end existing session

[00:16:38](https://youtu.be/0t5l6CP9eBg?t=998) How to download very best OT preset training configuration for SD 1.5 & SDXL models

[00:18:00](https://youtu.be/0t5l6CP9eBg?t=1080) How to load configuration preset

[00:18:38](https://youtu.be/0t5l6CP9eBg?t=1118) Full explanation of OT configuration and best hyper params for SDXL

[00:24:10](https://youtu.be/0t5l6CP9eBg?t=1450) How to setup training concepts accurately in OT

[00:24:52](https://youtu.be/0t5l6CP9eBg?t=1492) How to caption images for SD training

[00:30:17](https://youtu.be/0t5l6CP9eBg?t=1817) Why my training images dataset is not great and what is a better dataset

[00:31:41](https://youtu.be/0t5l6CP9eBg?t=1901) How to make DreamBooth effect in OT with reg images concept

[00:32:44](https://youtu.be/0t5l6CP9eBg?t=1964) Effect of using ground truth regularization images dataset

[00:34:41](https://youtu.be/0t5l6CP9eBg?t=2081) How to set regularization images repeating

[00:35:55](https://youtu.be/0t5l6CP9eBg?t=2155) Explanation of training tab configuration and parameters

[00:41:58](https://youtu.be/0t5l6CP9eBg?t=2518) What does masked training do and how to do masked training and generate masks

[00:44:53](https://youtu.be/0t5l6CP9eBg?t=2693) Generate samples during training setup

[00:46:05](https://youtu.be/0t5l6CP9eBg?t=2765) How to save checkpoints during training to compare and find best one later

[00:47:11](https://youtu.be/0t5l6CP9eBg?t=2831) How to save your configuration in OT

[00:47:22](https://youtu.be/0t5l6CP9eBg?t=2842) How to install and utilize nvitop to see VRAM usage

[00:48:06](https://youtu.be/0t5l6CP9eBg?t=2886) Why super slow training happens due to shared VRAM and how to fix it

[00:48:40](https://youtu.be/0t5l6CP9eBg?t=2920) How to reduce VRAM usage before starting training

[00:49:01](https://youtu.be/0t5l6CP9eBg?t=2941) Start training on Windows

[00:49:11](https://youtu.be/0t5l6CP9eBg?t=2951) Starting to setup everything on MC same as on Windows

[00:49:37](https://youtu.be/0t5l6CP9eBg?t=2977) Upload data to MC

[00:51:11](https://youtu.be/0t5l6CP9eBg?t=3071) Update OT on MC

[00:52:33](https://youtu.be/0t5l6CP9eBg?t=3153) How to download regularization images

[00:53:42](https://youtu.be/0t5l6CP9eBg?t=3222) How to minimize all windows on MC

[00:54:00](https://youtu.be/0t5l6CP9eBg?t=3240) Start OT on MC

[00:54:20](https://youtu.be/0t5l6CP9eBg?t=3260) Setting everything on MC same as Windows

[00:55:22](https://youtu.be/0t5l6CP9eBg?t=3322) How to set folders on MC VM

[00:56:31](https://youtu.be/0t5l6CP9eBg?t=3391) How to properly crop and resize your training images

[00:57:47](https://youtu.be/0t5l6CP9eBg?t=3467) Accurate Auto1111 Models folder on MC

[00:58:05](https://youtu.be/0t5l6CP9eBg?t=3485) Copy file & folder path on MC

[00:58:54](https://youtu.be/0t5l6CP9eBg?t=3534) All of the rest of the config on MC

[01:03:29](https://youtu.be/0t5l6CP9eBg?t=3809) How to utilize second GPU if you have

[01:05:45](https://youtu.be/0t5l6CP9eBg?t=3945) Checking back again our Windows training

[01:06:06](https://youtu.be/0t5l6CP9eBg?t=3966) How to use Automatic1111 (A1111) SD Web UI on MC and Windows

[01:11:35](https://youtu.be/0t5l6CP9eBg?t=4295) How to use default Python on MC

[01:11:55](https://youtu.be/0t5l6CP9eBg?t=4315) Checking training speed and explaining what it means

[01:12:13](https://youtu.be/0t5l6CP9eBg?t=4333) How many steps we are going to train explanation

[01:13:40](https://youtu.be/0t5l6CP9eBg?t=4420) First checkpoint and howe checkpoints named

[01:14:15](https://youtu.be/0t5l6CP9eBg?t=4455) How to fix A1111 errors

[01:15:44](https://youtu.be/0t5l6CP9eBg?t=4544) How to start A1111 Web UI and use it with Gradio Live share and locally

[01:17:45](https://youtu.be/0t5l6CP9eBg?t=4665) What to do if model loading takes forever on Gradio and how to fix it

[01:19:01](https://youtu.be/0t5l6CP9eBg?t=4741) Where to see status of the training of OT

[01:19:43](https://youtu.be/0t5l6CP9eBg?t=4783) How to upload checkpoints / anything into Hugging Face for permanently saving

[01:26:21](https://youtu.be/0t5l6CP9eBg?t=5181) How to auto upgrade A1111 and install ADetailer and ControlNet extensions

[01:29:10](https://youtu.be/0t5l6CP9eBg?t=5350) How to use trained model checkpoints on Massed Compute

[01:30:08](https://youtu.be/0t5l6CP9eBg?t=5408) How to test checkpoints to find best one

[01:32:15](https://youtu.be/0t5l6CP9eBg?t=5535) Why you should use After Detailer (adetailer) and how to use it properly

[01:34:48](https://youtu.be/0t5l6CP9eBg?t=5688) How to do proper highres fix upscale

[01:36:19](https://youtu.be/0t5l6CP9eBg?t=5779) Why anatomy inaccuracy happens

[01:37:07](https://youtu.be/0t5l6CP9eBg?t=5827) How to generate images forever in A1111

[01:38:02](https://youtu.be/0t5l6CP9eBg?t=5882) Where the generated images are saved and download them

[01:40:30](https://youtu.be/0t5l6CP9eBg?t=6030) Super Important

[01:45:16](https://youtu.be/0t5l6CP9eBg?t=6316) Analyzing x/y/z checkpoint comparison results to find best checkpoint

[01:48:20](https://youtu.be/0t5l6CP9eBg?t=6500) How to understand if model is overtrained

[01:52:27](https://youtu.be/0t5l6CP9eBg?t=6747) How to generate different expressions having photos

[01:54:53](https://youtu.be/0t5l6CP9eBg?t=6893) How to do inpainting in Stable Diffusion A1111

[01:56:34](https://youtu.be/0t5l6CP9eBg?t=6994) How to generate LoRA from your trained checkpoint

[01:58:03](https://youtu.be/0t5l6CP9eBg?t=7083) Windows OneTrainer training completed so how to use them on your computer

[02:00:24](https://youtu.be/0t5l6CP9eBg?t=7224) Best SD 1.5 models Fine-Tuning / DreamBooth training configuration / hyper-parameters

[02:03:50](https://youtu.be/0t5l6CP9eBg?t=7430) How can you know you have sufficient VRAM?

[02:05:36](https://youtu.be/0t5l6CP9eBg?t=7536) What to do before terminating MC VM

[02:06:55](https://youtu.be/0t5l6CP9eBg?t=7615) How to terminate your VM to not spend anymore money

[02:08:35](https://youtu.be/0t5l6CP9eBg?t=7715) How to do style, object, etc training

[02:09:47](https://youtu.be/0t5l6CP9eBg?t=7787) What to do if your thin client don't synch



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=0) Hello, everyone.

- [00:00:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1) Welcome to the most in-depth tutorial ever made for Stable Diffusion training.

- [00:00:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6) I have been doing Stable Diffusion training since 2022.

- [00:00:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=10) So, this tutorial is a cumulative experience of more than 16 months.

- [00:00:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=16) As a result, I can confidently say that this tutorial is like an entire course that you

- [00:00:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=23) would purchase for hundreds of dollars.

- [00:00:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=26) In this tutorial, I am going to show you how to install OneTrainer from scratch on your

- [00:00:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=32) computer and do a Stable Diffusion SDXL and SD1.5 based models training on your computer.

- [00:00:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=42) I will show the very best configuration parameters that I have found after doing more than 200

- [00:00:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=49) empirical research trainings without any paywall including masked training and proper setup

- [00:00:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=58) of training concepts.

- [00:00:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=59) Moreover, I am going to show you how to do training on Massed Compute cloud virtual machines

- [00:01:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=66) for amazing discounted prices if your computer is not good enough with perfect privacy.

- [00:01:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=73) The discounted price is 31 cents per hour for an A6000 GPU machine which costs more

- [00:01:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=82) than 70 cents on RunPod as a comparison.

- [00:01:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=84) The virtual machine we prepared on Massed Compute is a desktop interface having an operating

- [00:01:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=92) system so it will be as easy as using it on your own computer.

- [00:01:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=98) Furthermore, I will show you how to utilize more than one GPU at the same time for different

- [00:01:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=105) tasks on Massed Compute such as doing two separate trainings.

- [00:01:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=110) The same strategy applies if you have more than one GPU on your computer as well.

- [00:01:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=116) In addition, I will show you how to caption your training datasets properly.

- [00:02:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=121) Also, I will explain why your training is extremely slow due to shared VRAM issues.

- [00:02:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=128) Moreover, I will show how to use the very latest version of Automatic1111 SD Web UI

- [00:02:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=135) on Windows, Linux, and on Massed Compute with amazing extensions such as After Detailer

- [00:02:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=143) and ControlNet.

- [00:02:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=144) Additionally, I will show how to get amazing pictures of your training with accurate settings

- [00:02:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=150) of After Detailer to improve faces in distance shots image generation.

- [00:02:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=156) This will help you generate high-quality images with ease.

- [00:02:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=159) Finally, I will show how to upload and save generated model checkpoints and literally

- [00:02:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=165) anything onto Hugging Face with a very easy Jupyter Lab notebook.

- [00:02:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=171) Before we start this massive tutorial, I would like to ask you one thing: go to the Stable

- [00:02:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=176) Diffusion link here and star our repository, fork it, watch it, and sponsor if you like.

- [00:03:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=183) I appreciate that very much.

- [00:03:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=185) I am also giving one-to-one private lectures if you are interested in.

- [00:03:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=189) You can join our Discord and message me there.

- [00:03:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=193) Also, we are giving huge support to everyone

- [00:03:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=197) joined our Discord channel. You can join from this link.

- [00:03:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=200) Moreover, all the images I have shown during this introduction is shared in this link.

- [00:03:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=207) Go to this link and you will be able to look at every image details with their PNG info data.

- [00:03:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=215) Just click the image and you will see the prompt and every details that you need.

- [00:03:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=220) So, let's begin.

- [00:03:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=221) As usual, I have prepared an amazing GitHub readme file for this tutorial.

- [00:03:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=227) This file will have all the links and instructions that you are going to need to follow this

- [00:03:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=233) tutorial.

- [00:03:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=234) The link of this file will be in the description of the video and also in the pinned comment

- [00:03:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=239) of the video.

- [00:04:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=240) Moreover, since the video will be very long, I am going to put sections into the description

- [00:04:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=246) of the video so you can jump into any section that you are seeking for.

- [00:04:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=251) Furthermore, I am going to put fully manually written English captions and also in other languages.

- [00:04:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=259) So, if you are having a problem understanding my English, please watch the video with captions on.

- [00:04:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=266) I am going to show you how to install on Windows and also on Massed Compute step by step.

- [00:04:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=272) First of all, I am going to begin with registering into Massed Compute and starting our virtual machine.

- [00:04:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=280) Then, I will start installing the OneTrainer on my Windows 10.

- [00:04:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=285) It doesn't matter if you have Windows 10 or Windows 11.

- [00:04:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=289) On both of them, it works perfectly fine and the same.

- [00:04:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=292) If your GPU is sufficient, you don't need Massed Compute or cloud computing.

- [00:04:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=297) You can just use the OneTrainer on your computer with your GPU.

- [00:05:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=301) So, please register the Massed Compute with this link because we are going to use a coupon.

- [00:05:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=306) So, I am not sure whether you need to register with this link or not.

- [00:05:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=310) This is my referral link.

- [00:05:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=312) Once you have registered, you need to enter your billing information here.

- [00:05:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=317) You can add your payment method, charge it, and delete it if you want.

- [00:05:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=321) Then, we are going to do deployment.

- [00:05:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=323) This part is extremely important.

- [00:05:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=326) Our coupon is only valid for A6000 GPUs and A6000 GPUs are extremely sufficient to do

- [00:05:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=334) efficient training.

- [00:05:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=335) For this tutorial, I am going to start for A6000 GPUs.

- [00:05:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=340) I am going to show you how you can do a different thing in each one of them and you need to

- [00:05:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=346) choose our virtual machine template.

- [00:05:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=348) So, select the creator from here, select SECourses from here.

- [00:05:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=353) You will see my image here.

- [00:05:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=354) By the way, this is also the DreamBooth pretty accurate one.

- [00:05:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=358) Then, you type our coupon like this.

- [00:06:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=361) You can also copy the coupon from here SECourses then put it here then click verify.

- [00:06:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=368) It will show you the new price of the GPU.

- [00:06:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=371) You see currently 4 GPUs are not available therefore let's reduce to 2 and it is not

- [00:06:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=377) available either and 1.

- [00:06:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=378) Okay, when I make it 1 I can get 2 GPU 2 instances but when I make 2 I can't get any.

- [00:06:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=385) The Massed Compute team is keep adding more GPUs so even though currently it is not available

- [00:06:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=393) to get 4 GPUs with A6000 it is fine.

- [00:06:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=396) So, after you put your coupon code like this and click verify you are going to get a huge

- [00:06:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=404) price reduction.

- [00:06:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=405) You see currently it is 0.62 per hour when I click verify it will become 0.31 per hour

- [00:06:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=414) with 48 gigabyte RAM and with 256 gigabyte storage and also with six virtual CPUs.

- [00:07:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=424) If we compare the price with RunPod, you see the RunPod price is 69 cents per hour.

- [00:07:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=431) This is the community cloud price but on Massed Compute, we are going to get the same GPU

- [00:07:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=437) with only 31 cents per hour.

- [00:07:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=439) It is even cheaper than half price of the RunPod.

- [00:07:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=444) Therefore, Massed Compute is giving us an amazing price for an amazing GPU.

- [00:07:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=449) So, therefore, what I am going to do for this tutorial is I am going to pick L40 but you

- [00:07:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=454) don't need it and you don't need more than 1 GPU just to show you how you can utilize

- [00:07:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=460) more than 1 GPU.

- [00:07:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=461) I am going to get 4 GPUs but as I said you just need A6000 and only single GPU to

- [00:07:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=468) follow this tutorial and do your training.

- [00:07:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=470) Okay, so let's select creator let's select SECourses.

- [00:07:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=474) Unfortunately, the coupon will not work on other GPUs so click deploy.

- [00:08:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=480) Okay, it says that I have reached the limit of running instances.

- [00:08:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=484) You will get this message when there isn't a sufficient amount of GPUs so I have to reduce it.

- [00:08:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=492) Unfortunately, they are also on high demand so let's see.

- [00:08:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=496) Yes, I can get 4 H100 GPUs.

- [00:08:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=499) It will be 10 dollar per hour.

- [00:08:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=501) It is just too expensive so I don't want to risk it.

- [00:08:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=504) Okay, let's go with only 2 L40 GPUs.

- [00:08:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=507) Still, you will understand the logic of using more than 1 GPU and you will get to this screen.

- [00:08:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=514) It will start initializing the virtual machine.

- [00:08:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=517) Now, time to install the OneTrainer on our Windows computer.

- [00:08:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=521) To be able to follow this tutorial and install OneTrainer on your computer you need to have

- [00:08:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=527) installed Python, Git, and C++ and FFmpeg are optional.

- [00:08:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=533) If you also install them it is better.

- [00:08:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=535) So, if you don't know how to install Python, please watch this amazing tutorial.

- [00:09:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=540) In this tutorial, I have explained everything about how to install Python, how to set its

- [00:09:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=546) virtual environment, how to set its path, and everything that you are going to need.

- [00:09:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=550) And also install Git.

- [00:09:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=552) So, how you can verify your Python installation?

- [00:09:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=555) Open a CMD, command line interface like this and type Python and you should see 3.10.11.

- [00:09:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=563) By the way, 3.10.11 works with Automatic1111 Web UI and also Kohya or any other major AI

- [00:09:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=572) application that you are going to use.

- [00:09:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=574) This is the most compatible.

- [00:09:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=576) This is the best Python version that you can use.

- [00:09:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=580) This is the version that I use for all of my tutorials.

- [00:09:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=583) Then, how you can verify you have Git installed?

- [00:09:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=587) Just type Git and you should get a message like this.

- [00:09:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=590) If you also installed FFmpeg, you should get a message like this: FFmpeg.

- [00:09:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=595) Its properties.

- [00:09:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=596) Unfortunately, there is no easy way to verify C++ tools installation but everything is explained

- [00:10:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=603) in this video so watch this video and install your Python and set it up accurately.

- [00:10:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=608) Once you have set up your Python all you need to do is first clone OneTrainer.

- [00:10:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=614) OneTrainer is an open source Stable Diffusion or actually it supports a lot of different

- [00:10:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=620) text-to-image models like Stable Cascade as well.

- [00:10:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=624) Open source trainer scripts.

- [00:10:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=625) It has an excellent documentation also wiki.

- [00:10:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=628) Moreover, the developer is extremely active in Discord so you can join their Discord channel

- [00:10:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=636) and ask any questions that you have.

- [00:10:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=638) Also, don't forget to join our Discord channel as well.

- [00:10:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=641) You see we have over 1000 active AI learners.

- [00:10:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=645) So, I copied this then enter inside the folder where you want to install it.

- [00:10:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=650) I am going to install it into my F drive.

- [00:10:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=652) I already have OneTrainer here so I will make a new subfolder.

- [00:10:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=657) Let's say tutorial OneTrainer.

- [00:11:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=660) By the way, do not make your subfolder name the same as the original name.

- [00:11:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=666) Since the original name is OneTrainer, do not make the subfolder name OneTrainer as well.

- [00:11:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=672) It may cause issues.

- [00:11:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=673) Then, right-click and it will paste your copied text and hit enter and it will clone it into

- [00:11:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=678) this folder.

- [00:11:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=680) Then, enter inside OneTrainer.

- [00:11:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=681) OneTrainer has automatic installation and automatic starting bat files so I will just

- [00:11:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=688) click the install.bat file and it will generate a new virtual environment and install everything

- [00:11:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=694) automatically for me.

- [00:11:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=695) What does this mean?

- [00:11:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=696) This means that whatever it installs will not affect your other AI installations, such

- [00:11:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=703) as Automatic1111 Web UI or Kohya or whatever you are using.

- [00:11:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=707) So, everything will be located inside this virtual environment folder.

- [00:11:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=711) Okay, let's return back to Massed Compute, and we see that our instance machine started.

- [00:11:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=717) So, how we are going to use this instance machine?

- [00:12:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=720) To use the Massed Compute, we need to use the ThinLinc application.

- [00:12:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=725) The link is here.

- [00:12:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=726) When you click it, it will direct you to download options.

- [00:12:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=731) I am going to download and use the Windows version.

- [00:12:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=734) After download, just click it, open it, and just click next and next and next to install.

- [00:12:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=740) It will automatically install everything.

- [00:12:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=742) Then just run the Thin Client, and you will get to this interface.

- [00:12:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=746) So, this is the connection interface, and what is important here is click Advanced and

- [00:12:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=752) also Options.

- [00:12:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=753) Thin Client allows you to synchronize your folders with the virtual machine.

- [00:12:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=758) This is how you can transfer files from your computer to the virtual machine that we are

- [00:12:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=763) going to use.

- [00:12:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=764) So, there are options: windowed, full screen, there are local devices, whichever you want

- [00:12:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=769) to connect, and you need to set your folder, which will be synchronized with your Thin

- [00:12:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=775) Client and your virtual machine, with your computer and with your virtual machine.

- [00:12:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=779) So, click this details, make sure that you have ticked the Drives checkbox, and you need

- [00:13:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=785) to add a path of your folder.

- [00:13:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=787) You see, I have added this folder.

- [00:13:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=790) Let me add it again.

- [00:13:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=791) So, I click add, and I need to select the folder from here.

- [00:13:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=796) It will be inside R drive.

- [00:13:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=797) It will be inside Massed Compute.

- [00:13:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=801) Let's see, here.

- [00:13:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=803) And this will be my folder.

- [00:13:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=804) So, I click OK, and it says Read Only.

- [00:13:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=807) If you want your virtual machine to be only read from your folder, not able to write,

- [00:13:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=813) let it stay as Read Only.

- [00:13:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=815) But if you want to download files from the virtual machine automatically into your folder,

- [00:13:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=821) then you need to make it Read and Write.

- [00:13:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=823) I am going to make that way.

- [00:13:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=825) And there are some optimizations if you wish.

- [00:13:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=827) There are some security options.

- [00:13:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=829) I am just leaving everything default, only drives are set.

- [00:13:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=834) Okay, and there is end existing session.

- [00:13:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=837) This means that it will restart your virtual machine.

- [00:14:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=840) So, be careful with that.

- [00:14:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=842) Moreover, there is no turn-off this virtual machine.

- [00:14:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=845) There is only Terminate.

- [00:14:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=847) So, you need to back up all the files that you need before you terminate your virtual machine.

- [00:14:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=854) This is the only downside compared to RunPod, but we are going to have a desktop environment

- [00:14:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=859) and very cheap, very powerful GPU here.

- [00:14:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=862) So, how we are going to connect?

- [00:14:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=864) Copy your login IP from here, paste it into the server.

- [00:14:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=868) You see, username is Ubuntu, automatically set for us.

- [00:14:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=871) Then copy the password.

- [00:14:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=873) You don't need to show it.

- [00:14:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=875) Paste password here.

- [00:14:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=876) And when you set end existing session, it will restart the virtual machine.

- [00:14:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=881) Moreover, if you get problems with the folder synchronization, you should use end existing

- [00:14:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=887) session, and it will allow you to synchronize folders.

- [00:14:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=892) But be careful, this will close all of the running applications.

- [00:14:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=896) So, if you are training at that moment, they will be all terminated.

- [00:15:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=900) So, be careful with that.

- [00:15:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=902) Since we are just starting the virtual machine, I will just select this option.

- [00:15:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=906) Click Connect.

- [00:15:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=907) Then you will get this message.

- [00:15:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=909) Click Connect.

- [00:15:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=910) Then you will get to this screen.

- [00:15:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=912) In this screen, it may freeze or may look like frozen.

- [00:15:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=916) So, click Start to just skip that part, and you will get to this screen.

- [00:15:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=922) And in a moment, we are going to get, yes, this is our virtual machine.

- [00:15:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=927) You see, it is like a desktop computer.

- [00:15:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=930) It has Ubuntu image.

- [00:15:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=931) So, this is Ubuntu Desktop operating system.

- [00:15:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=936) And we have automatically installed Kohya, Automatic1111 Web UI, and also OneTrainer here.

- [00:15:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=943) So, you can directly start using them.

- [00:15:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=945) For example, if I start OneTrainer, it will start the OneTrainer automatically for me,

- [00:15:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=949) because they are all added into this virtual machine.

- [00:15:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=952) We have worked with Massed Compute to make it super easy to use for you.

- [00:15:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=957) So, looks like our Windows installation has been completed, because I don't see the installer file.

- [00:16:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=964) So, when I click the Start UI.bat it should start, and it started.

- [00:16:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=969) You see, it says that no file training presets, but the presets are here.

- [00:16:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=973) I don't know why it did give this error.

- [00:16:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=976) So, this is the interface of OneTrainer.

- [00:16:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=978) So, we have installed both OneTrainer, and we did set up both Massed Compute virtual machine.

- [00:16:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=986) As a next step, what we are going to do? First of all, let's start the training on my computer.

- [00:16:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=991) So, to start the training on my computer, I am going to load my preset configuration.

- [00:16:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=998) Don't worry, I am going to show all of the configurations in this tutorial.

- [00:16:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1002) They will not be hidden.

- [00:16:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1004) However, I may find better configurations in future, because I am in research all the time.

- [00:16:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1010) I did over 100 trainings for this tutorial.

- [00:16:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1012) So, I am going to download the SDX. SDXL and SD 1.5 training are all the same.

- [00:16:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1019) What changes is the resolution and the base model that you are going to use.

- [00:17:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1024) And one more thing, which is the model that you choose from here.

- [00:17:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1028) For Stable Diffusion 1.5, you choose 1.5.

- [00:17:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1031) For Stable Diffusion XL, you choose this.

- [00:17:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1033) You see, it also supports Stable Cascade, Pixart Alpha, and Wuerstchen version 2 trainings.

- [00:17:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1041) I haven't looked into these yet.

- [00:17:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1044) I am only in Stable Diffusion training for now, but I have amazing configuration for

- [00:17:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1051) both Stable Diffusion 1.5 and both Stable Diffusion XL.

- [00:17:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1054) I did huge research for both of the models.

- [00:17:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1057) So, let's go to our Patreon post to download our best configuration.

- [00:17:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1062) In the bottom, you will see attachments: Tier One 10 Gigabyte training and Tier One 15 Gigabyte training.

- [00:17:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1070) So, if your GPU is more than 16 Gigabyte, you can use this one.

- [00:17:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1073) This is a faster one.

- [00:17:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1075) But let's start with the slow.

- [00:17:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1076) I will show you and explain you all of the options.

- [00:18:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1080) So, after downloading it, cut it, move into your OneTrainer, and you will see that Training

- [00:18:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1086) Presets folder here.

- [00:18:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1087) So, paste it there.

- [00:18:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1089) I am going to delete all of the other presets, because we don't need them right now.

- [00:18:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1093) Actually, I tested the Stable Diffusion presets, and they weren't good, nothing like my presets.

- [00:18:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1098) So, after that change, we need to restart the OneTrainer.

- [00:18:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1103) So, I turn it off, and I click Start UI.bat file.

- [00:18:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1107) And now, I can see the preset.

- [00:18:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1110) So, after I selected that preset, it will load everything automatically for me.

- [00:18:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1116) So, what are these options?

- [00:18:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1118) Workspace Directory is where the checkpoints and generated backups or the generated sample

- [00:18:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1124) images will be saved.

- [00:18:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1126) So, this is the main saving directory. For each training

- [00:18:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1130) you can set a different directory that may be easier to manage and see everything.

- [00:18:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1135) So, let's click this 3 dots icon, and let's go to our new installation.

- [00:19:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1140) You see, I have OneTrainer Workspace folder here.

- [00:19:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1143) I am going to make another one: OneTrainer Video Workspace.

- [00:19:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1146) Okay, I made a folder like this.

- [00:19:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1148) I enter inside it and click Select Folder.

- [00:19:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1151) You can also copy-paste the path.

- [00:19:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1153) So, let's make another one for the cache.

- [00:19:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1156) So, let's say Cache 1.

- [00:19:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1158) By the way, caching is extremely important.

- [00:19:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1160) I suggest you to set a different caching folder whenever you use different settings.

- [00:19:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1167) Which settings, you may be wondering?

- [00:19:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1168) Some of the settings requires re-caching.

- [00:19:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1170) Unfortunately, there is not a list of them, but anything that modifies the training dataset

- [00:19:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1176) requires re-caching.

- [00:19:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1177) So, if you select only cache, it will only cache.

- [00:19:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1180) Continue from last backup, we don't need it.

- [00:19:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1182) I never used it.

- [00:19:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1183) Debug mode, there is for debugging.

- [00:19:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1185) So, there is nothing else you need to enable here.

- [00:19:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1188) I don't find TensorBoard is useful for Stable Diffusion training.

- [00:19:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1193) Also, there is Train Device.

- [00:19:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1194) You can also set this CPU.

- [00:19:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1196) I never tried it, but it would be super slow.

- [00:19:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1199) Okay, now we are going to select our base model.

- [00:20:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1203) You see, my configuration is set with the base model of Hugging Face.

- [00:20:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1206) If I kept it this way, it will download it into my Hugging Face cache folder and load

- [00:20:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1212) it from there.

- [00:20:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1213) However, I suggest you to use a model that you downloaded on your computer.

- [00:20:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1218) I find that SDXL RealVisXL version 4 is very good for realistic training.

- [00:20:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1226) If you are looking for a stylized training, then you should use a stylized model.

- [00:20:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1230) But I am focused on mostly for realism.

- [00:20:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1232) Okay, from the Hugging Face, you can click this icon, and it will start download.

- [00:20:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1237) Also, this can be downloaded on not interface having computers, platforms, such as on RunPod.

- [00:20:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1245) You can right-click and copy link address, then you can use wget to download, like wget

- [00:20:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1250) and the link.

- [00:20:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1251) And you can download.

- [00:20:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1252) Also, delete this part.

- [00:20:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1253) But on Windows, you don't need.

- [00:20:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1256) Moreover, by clicking this link, you can download the Hyper Realism version 3.

- [00:21:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1261) This is the best model for SD 1.5 that I have found.

- [00:21:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1265) I have a recent video where I have compared 160 SD 1.5 based models to find the best realistic model.

- [00:21:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1274) If you watch this video, you will learn which models are best for realism, for stylization,

- [00:21:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1278) for anime, for 3D.

- [00:21:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1280) So, this is an extremely useful video for you to watch.

- [00:21:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1284) That is how I have determined the best SD 1.5 model.

- [00:21:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1288) I also did some testing for realistic vision for SDXL, but I don't have a video for that yet.

- [00:21:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1296) So, the model is getting downloaded.

- [00:21:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1297) So, the model has been downloaded.

- [00:21:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1300) Let's move it into our Automatic1111 Web UI installation.

- [00:21:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1304) I have fully automatic installers for Automatic1111 Web UI installation.

- [00:21:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1310) So, I am putting it into my Stable Diffusion models folder, like this.

- [00:21:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1315) It was already there, but I just downloaded again to show you.

- [00:22:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1320) Then click this three dots icon, move into the your downloaded folder position.

- [00:22:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1327) You can put it into any folder you wish.

- [00:22:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1329) It is not mandatory to put here.

- [00:22:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1331) Select it.

- [00:22:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1332) You can also give its full path, like this.

- [00:22:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1335) When you are using such custom model, do not set VAE.

- [00:22:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1340) Moreover, only this Hugging Face VAE is working.

- [00:22:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1343) If you download VAE into your computer, it will not work yet on OneTrainer.

- [00:22:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1348) So, when you use such custom model, you don't need VAE.

- [00:22:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1352) You can use the embedded VAE.

- [00:22:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1354) Now, this is super important.

- [00:22:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1355) This is where the finally saved model checkpoint will be.

- [00:22:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1361) So, wherever you want to save your final checkpoint, you need to set it.

- [00:22:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1365) I will set the final checkpoint inside my Stable Diffusion Web UI folder.

- [00:22:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1370) Let's say tutorial1.safetensors.

- [00:22:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1374) Also, don't forget to set its extension, like .safetensors to not have any issues.

- [00:23:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1382) You see, .safetensors.

- [00:23:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1385) Okay, so these are the very best settings that I have found for this configuration.

- [00:23:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1391) It may change for different models and also different configuration setups.

- [00:23:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1396) These are the best configurations.

- [00:23:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1399) Just pause the video and look at the configurations.

- [00:23:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1402) Then move to the Data tab.

- [00:23:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1404) And in here, I only use Latent Caching.

- [00:23:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1407) If you have different resolutions, you can also enable Aspect Ratio Bucketing.

- [00:23:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1413) However, I suggest you to use single resolution images first.

- [00:23:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1419) Then after you got some decent results, you can try with Aspect Ratio Bucketing enabled

- [00:23:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1424) and different resolution training and compare them.

- [00:23:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1427) So, Clear Cache Before Training means that it will re-cache every time you start training,

- [00:23:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1433) even though you didn't change anything regarding the dataset.

- [00:23:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1438) If you are unsure that you need to re-cache or not, you can enable this to be sure.

- [00:24:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1443) But if you are not changing anything but just trying different parameters with the same

- [00:24:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1448) training dataset, you don't need to enable it.

- [00:24:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1450) Now, the Concepts.

- [00:24:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1452) This is a super important part to set up accurately.

- [00:24:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1456) First of all, I am going to add my training dataset concept.

- [00:24:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1460) So, click Add Concept, then click Add this icon.

- [00:24:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1465) And in here, I am going to give the name of training.

- [00:24:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1468) It is enabled.

- [00:24:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1469) If you don't enable it, it will not be used.

- [00:24:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1471) So, you need to give the path folder path of the your training images.

- [00:24:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1476) My training images are inside here, which are automatically generated with my scripts,

- [00:24:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1482) which scripts I am going to show you.

- [00:24:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1485) By the way, this is not the accurate one; I need to use this one.

- [00:24:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1489) Yes, then you need to set their captions.

- [00:24:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1493) OneTrainer supports three different captioning: first one is from text file per sample, which

- [00:24:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1498) means that you can use any captioner to caption each image, and then it will read the caption

- [00:25:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1504) file with the same name as the file.

- [00:25:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1507) What does this mean?

- [00:25:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1508) Let's say you are using our Kosmos 2 image captioner.

- [00:25:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1513) The link of this is in the Patreon.

- [00:25:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1515) So, this is an automated installation and batch captioner that I have prepared for Kosmos 2

- [00:25:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1522) Let's just start it.

- [00:25:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1523) You see, the Kosmos 2 is extremely efficient one.

- [00:25:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1526) So let's start as full precision because we have VRAM, and let's go to my training

- [00:25:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1532) images dataset, which is inside here.

- [00:25:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1535) You see, there are also masks, which I will explain.

- [00:25:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1538) So, I am going to delete the masks.

- [00:25:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1541) So, let's say "delete," and also, let's delete the prompt.

- [00:25:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1545) Maybe, let's keep the prompt.

- [00:25:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1547) So, I will just or delete it, so you will understand it.

- [00:25:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1550) So, this is my raw folder.

- [00:25:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1552) Then the automatic captioner started.

- [00:25:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1555) So, just enter the path and batch caption images.

- [00:25:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1558) Kosmos 2 is extremely good captioner, but I don't suggest you to caption your training

- [00:26:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1564) images if you are training a person.

- [00:26:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1566) Okay, this error shouldn't be important.

- [00:26:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1569) Let's look at the captioners.

- [00:26:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1571) Yes, so each file is captioned.

- [00:26:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1573) Let's open this.

- [00:26:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1574) This is the batch captioning result, and each file is captioned like this.

- [00:26:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1578) You see, a man with dark hair and glasses is standing in a room, looking at the camera.

- [00:26:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1583) He is wearing a blue shirt and appears to be in a home office.

- [00:26:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1586) And it generated caption as each file.

- [00:26:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1589) However, you also need to add a prefix for each one of the captions, such as "ohwx man,"

- [00:26:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1596) and comma.

- [00:26:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1597) So, this way, you will have a unique identifier for your captions if you use this methodology.

- [00:26:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1604) But I don't suggest this.

- [00:26:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1605) Do you know why?

- [00:26:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1606) I have a public Patreon post where I have explained it and compared

- [00:26:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1611) image captioning effect: When you caption your images for a person training, it reduces

- [00:26:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1618) the likeliness greatly.

- [00:27:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1620) So, therefore, I don't suggest image captioning if you are training a person

- [00:27:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1625) with as low as 15 images, 20 images, 10 images, you can also compare the image captioning effect.

- [00:27:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1633) But I don't suggest you to caption when you are training a person.

- [00:27:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1636) You can read this article in details and see how it reduced the likeliness of the model.

- [00:27:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1643) So, we set the folder, which was this folder.

- [00:27:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1647) Let's open it.

- [00:27:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1648) So, this is the folder.

- [00:27:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1649) So, what I am going to do is I am going to use "from single text file."

- [00:27:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1652) There is also "from image file name."

- [00:27:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1655) If you select this, the captions will be like this: "image 2023 04 30" and such.

- [00:27:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1661) So, don't use that unless you are sure.

- [00:27:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1664) Use "from single file text."

- [00:27:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1667) Now, what does this mean?

- [00:27:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1669) This means that you generate a new file wherever you want.

- [00:27:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1672) It doesn't matter.

- [00:27:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1673) Let's say "ohwx man" and then edit it.

- [00:27:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1677) Let's edit it.

- [00:27:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1679) ohwx man

- [00:28:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1680) This is it.

- [00:28:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1681) So, why am I using this as a caption?

- [00:28:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1684) "ohwx" is a rare token, which will learn my unique characteristics into this token.

- [00:28:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1691) This is a rare token.

- [00:28:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1692) Rare token means that there weren't many images during the initial training on this token,

- [00:28:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1698) and "man" is the class that I am going to train my characteristics on.

- [00:28:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1703) So, the model will know that I am a "man" class, a man, and I am "ohwx man"

- [00:28:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1711) So, this is super important to understand.

- [00:28:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1714) This is the logic of training something unique, something new, into the Stable Diffusion model.

- [00:28:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1720) The specific characteristics are learned into this rare token, and it utilizes the existing

- [00:28:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1728) knowledge of the model with the "man" class.

- [00:28:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1730) I have a more in-depth tutorial for this on my channel if you need, but this is sufficient

- [00:28:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1736) for now.

- [00:28:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1737) So, I selected "from single text file."

- [00:29:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1740) There are image variations.

- [00:29:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1741) When you hover your mouse on this, it will show you the explanation of them.

- [00:29:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1746) However, I am not using it.

- [00:29:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1748) There are also text variations.

- [00:29:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1750) I am also not using it.

- [00:29:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1752) Repeating is extremely important.

- [00:29:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1753) This means that it will repeat one time each image in each epoch, and we will use a different

- [00:29:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1760) repeating for regularization images' effect.

- [00:29:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1764) The OneTrainer does not support DreamBooth training, so we are using fully fine-tuning.

- [00:29:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1769) However, we are going to make the effect of DreamBooth with another concept, and there

- [00:29:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1775) is also "loss weight."

- [00:29:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1776) This means that how much weight these images will get.

- [00:29:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1778) So, if you have an unbalanced training dataset, you can give different weights to each dataset

- [00:29:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1786) and try to balance them.

- [00:29:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1787) However, having an original number of images equal is better.

- [00:29:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1792) Image augmentation: I don't use crop jitter, or random flop.

- [00:29:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1796) There are also some other options, so I don't use anything here.

- [00:29:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1798) When you click "update preview" you will see the images and text augmentation.

- [00:30:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1802) Since I am not using captioning, this is also not important.

- [00:30:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1806) So, this is my first training concept about training images dataset.

- [00:30:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1810) Now, this is super important.

- [00:30:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1812) People are preparing very, very low-quality images for training.

- [00:30:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1817) This dataset is also not a great quality.

- [00:30:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1820) Why?

- [00:30:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1821) Because it has repeating backgrounds, it has repeating clothing.

- [00:30:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1825) I have taken all of these images with my mobile phone myself, which is not also a great phone.

- [00:30:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1831) It is Poco X3, in less than one hour.

- [00:30:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1835) However, this dataset still has some quality.

- [00:30:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1838) What I mean by that, for example, let's open this image.

- [00:30:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1842) So, you see, it is extremely sharp, well-focused, and it has great lightning.

- [00:30:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1848) These are super important to have.

- [00:30:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1850) You need to have extremely well-focused, not blurry images.

- [00:30:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1854) You need to have extremely good lightning, and in your training dataset images, you shouldn't

- [00:31:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1860) have other people, always you.

- [00:31:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1862) If you can also make the training background different, also clothing different, different

- [00:31:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1869) timing, then you will have a much better dataset.

- [00:31:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1871) There is also no limit of dataset images, as long as they are higher quality.

- [00:31:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1876) But for now, I am using this medium-quality dataset to demonstrate you, because I have

- [00:31:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1882) seen much worse datasets.

- [00:31:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1884) People are having a huge hard time to prepare a good dataset.

- [00:31:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1888) Hopefully, I will make a dedicated tutorial for how to prepare a dataset.

- [00:31:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1893) But for now, we are going to use this dataset.

- [00:31:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1895) Now, OneTrainer does not have DreamBooth as I said, but we are going to make DreamBooth effect.

- [00:31:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1901) We are going to add regularization images' concept.

- [00:31:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1904) So, let's add another concept, and in here, I am going to give any name I want, select

- [00:31:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1910) the path.

- [00:31:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1911) So, my regularization images are inside here.

- [00:31:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1914) I am going to use 1024 to 1024 because all of my images are 1024, so I select it.

- [00:32:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1921) I will show you the folder, and in here, I will use again "from single text file"

- [00:32:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1927) which will be only "man".

- [00:32:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1928) So, you see, these are my regularization images.

- [00:32:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1932) There are 5200 regularization images, and every one of them is manually prepared by me.

- [00:32:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1939) I have spent literally weeks for this dataset.

- [00:32:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1943) You can find this dataset link here.

- [00:32:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1944) When you open this post, you will see all the details that you need to where to download

- [00:32:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1950) them, how to download them, how to use them.

- [00:32:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1953) So, the dataset is here.

- [00:32:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1955) This is not mandatory because you can train without them.

- [00:32:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1960) However, if you train without them, you will get lesser quality.

- [00:32:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1963) I also tested it. In this public Patreon post

- [00:32:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1967) you will see the effect of using regularization images as a concept.

- [00:32:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1973) So, it will improve our quality, our flexibility, likeliness, and everything.

- [00:33:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1980) Since these are ground truth images, these are perfect quality images, not AI-generated

- [00:33:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1985) images.

- [00:33:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1986) These are all real images collected from Unsplash.

- [00:33:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1989) Unsplash is allowing for such usage.

- [00:33:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1993) Okay, for these images, I am going to use "man"

- [00:33:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1995) So, this is the "man.txt"

- [00:33:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1998) What is inside this "man.txt"?

- [00:33:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=1999) When I edit it, you will see that just "man" because this is the class token that we are

- [00:33:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2006) going to train ourselves on.

- [00:33:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2008) Therefore, as we train ourselves on the "man" class, the model will forget what is "man"

- [00:33:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2014) because it will see only our images as a "man"

- [00:33:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2018) Therefore, as we do training, it will overwrite the previous knowledge of the model.

- [00:33:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2024) However, with using ground truth regularization images, we are going to re-feed the model with

- [00:33:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2031) whatever the original "man" is, and we will make the model better.

- [00:33:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2036) But there is one tricky issue here.

- [00:33:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2037) All of my images are real images.

- [00:34:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2040) Therefore, it will forget,

- [00:34:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2042) it will still forget images that contain "man" but not real.

- [00:34:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2047) What I mean is like anime "man" drawing or 3D "man" drawing, or such.

- [00:34:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2052) You understand that, like cartoon.

- [00:34:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2053) So, this training is focused for realism.

- [00:34:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2057) If you do training with stylization, you may not use this dataset, or you can extract "Lora"

- [00:34:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2064) from the trained DreamBooth model and use it on a, let's say, stylized model.

- [00:34:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2069) So, this is my regularization images setup.

- [00:34:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2072) You see, there is also an option of "include subdirectories," but I don't have.

- [00:34:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2076) So, there is an extremely crucial thing in the setup of regularization images.

- [00:34:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2081) You see, "repeating" is currently set as 1.0, which means that in every epoch, it will train

- [00:34:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2088) all 5200 images, which we do not want.

- [00:34:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2092) What we want is training an equal number of "man" images with our training images.

- [00:34:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2098) So, how you can calculate it: open a calculator and type your training images number, which

- [00:35:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2104) is 15 in my case, divided by the 5200 images because we have 5200 images.

- [00:35:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2111) You will get 0.0028.

- [00:35:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2114) So, I am going to type like this, copy-paste it, and just change the final number one upper,

- [00:35:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2121) so it will use exactly 15 images in each epoch from the regularization images dataset, randomly

- [00:35:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2130) selected in each epoch.

- [00:35:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2131) I also disabled these two, "update preview," and it is done.

- [00:35:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2135) So, we did also set the, let's return back to "OneTrainer."

- [00:35:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2139) So, we also did set our regularization images concept as well.

- [00:35:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2144) You can add as many as concepts you want and train all of them at the same time.

- [00:35:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2149) This is the beauty of "OneTrainer."

- [00:35:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2151) Its interface is easier in some cases to use.

- [00:35:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2155) Okay, training.

- [00:35:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2156) Now, this is super important.

- [00:35:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2158) I have done over 100 trainings, literally 100 trainings, empirically, to find the best

- [00:36:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2164) hyperparameters.

- [00:36:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2165) These hyperparameters may not work if you change anything of them.

- [00:36:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2169) So, I am using optimizer Adafactor and the Adafactor settings are super

- [00:36:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2174) important.

- [00:36:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2175) These are the settings.

- [00:36:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2176) Do not enable "relative steps, scale parameter."

- [00:36:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2179) "Stochastic rounding," by the way, "stochastic rounding" makes the effect of full precision

- [00:36:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2184) training.

- [00:36:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2185) Hopefully, I will also research that, and I will update the best configuration, but

- [00:36:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2189) for now, this is the best.

- [00:36:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2191) And "fused backpass". This is the newest optimization that "OneTrainer" brought, but "Kohya" still

- [00:36:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2197) don't have.

- [00:36:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2198) With this optimization, we are able to train with only 10 gigabytes of VRAM usage.

- [00:36:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2203) So, if you have a higher VRAM GPU, don't enable this to speed up your training, but if you

- [00:36:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2209) have a lower VRAM GPU, such as RTX 3060, then use this.

- [00:36:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2214) "Learning rate scheduler": "constant."

- [00:36:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2217) "Learning rate" is 1e-05.

- [00:37:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2220) "Learning rate warm-ups" doesn't matter because we don't use a linear, cosine, or anything.

- [00:37:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2226) We are using "constant". Learning rate

- [00:37:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2229) cycles is 1.

- [00:37:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2230) "Epochs" now this is super important.

- [00:37:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2233) Let's say you are training yourself with 100 images, then 200 epochs may cause overtraining,

- [00:37:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2239) or let's say you are training with 10 images, then 200 epochs may be, let's say, not enough

- [00:37:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2245) training.

- [00:37:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2246) So, there is not a number that works for all, but 200 is usually good.

- [00:37:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2251) Still, you can make this 400 and save frequent checkpoints, compare them, which I will show

- [00:37:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2258) you, and find the best checkpoint.

- [00:37:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2260) But for this tutorial, I will make it 200.

- [00:37:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2263) You can change this.

- [00:37:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2264) "Batch size" if you need speed, you can increase the batch size.

- [00:37:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2267) However, batch size 1 is the best quality for training a subject in machine learning.

- [00:37:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2273) And this is "gradient accumulation steps"

- [00:37:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2275) I think "gradient accumulation steps" is not working with "fused backpass" due to optimization.

- [00:37:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2279) This is a fake batch size.

- [00:38:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2282) I never use it.

- [00:38:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2283) "Learning Rate Scaler" is none.

- [00:38:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2285) We train only "Text Encoder 1" in "Stable Diffusion XL model."

- [00:38:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2289) You may be wondering why, because training "Text Encoder 2" causes overtraining and

- [00:38:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2294) doesn't bring any benefit.

- [00:38:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2296) So, after I have tested every combination, thoroughly, I only train "Text Encoder 1".

- [00:38:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2303) By the way, you can also apply these hyperparameters to "Kohya" and hopefully, I will make another

- [00:38:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2308) tutorial for "Kohya" as well.

- [00:38:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2310) So, "stop training" after 200 epochs.

- [00:38:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2312) To be sure, you can make this 10,000 and select this "never", so it will train the "Text Encoder 1"

- [00:38:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2319) during the entire operation of the 200 epochs.

- [00:38:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2324) However, let's say you only want to train 10 epochs "Text Encoder 1" then you can

- [00:38:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2329) select this, it like this.

- [00:38:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2330) But in all my trainings, I trained the "Text Encoder" equally to training the model.

- [00:38:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2337) This is also a beauty of "OneTrainer" that you can set any specific number of training epochs.

- [00:39:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2343) The "Text Encoder" learning rate is different, much lower than the learning rate, so be very

- [00:39:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2348) careful with that.

- [00:39:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2349) If you use the same learning rate, it will cook the model.

- [00:39:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2352) And there is also "Clip Skip 1".

- [00:39:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2354) I don't use it.

- [00:39:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2355) This is useful when you are training anime.

- [00:39:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2357) It is really or maybe training for stylization, like generating yourself as anime drawing

- [00:39:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2363) then it may be useful.

- [00:39:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2365) Okay, Train "Text Encoder 2" is set as "offline" and set as 0. Attention.

- [00:39:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2371) Now, when we use this "fused backpass", I think it is using a special attention mechanism,

- [00:39:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2378) or maybe SDP

- [00:39:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2380) by default. It doesn't make a difference.

- [00:39:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2382) So, I let it default.

- [00:39:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2384) EMA.

- [00:39:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2385) EMA is extremely useful for training Stable Diffusion 1.5 models.

- [00:39:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2389) However, for SDXL, it doesn't bring any benefit, so it is off. Now:

- [00:39:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2394) Gradient checkpointing, if you are training on A6000 GPU, such as on Massed Compute, don't

- [00:40:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2400) enable this.

- [00:40:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2401) This will speed up your training.

- [00:40:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2403) However, gradient checkpointing doesn't make any difference in quality.

- [00:40:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2406) It is only speed versus used VRAM.

- [00:40:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2410) Training data type: Float BF16, and Float 32.

- [00:40:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2414) Now, there is a very important thing: Currently with my settings

- [00:40:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2419) if your GPU is an old GPU that doesn't have bfloat support, then with this configuration,

- [00:40:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2425) you will not get the very best results.

- [00:40:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2427) It really requires you to have bfloat support.

- [00:40:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2430) So, if you don't have bfloat support, use the SD 1.5 configuration, which I will show

- [00:40:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2438) at the end of the tutorial.

- [00:40:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2440) Everything is the same, just the parameters change. And the resolution is 1024.

- [00:40:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2443) This is the base resolution.

- [00:40:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2445) If your images are of different resolutions, if you use bucketing, I think it will downscale,

- [00:40:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2452) or I am not sure how it handles. Actually

- [00:40:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2455) you should ask this to the OneTrainer developer on his Discord or on GitHub.

- [00:41:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2460) Therefore, I prefer to train with a single resolution, but you can train with different

- [00:41:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2465) resolutions, enabling bucketing and see how it is performing.

- [00:41:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2469) Okay, we train U-NET until the very end of the training, so you can set this as 10,000,

- [00:41:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2476) and never. The U-NET

- [00:41:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2477) learning rate is the same as the learning rate here.

- [00:41:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2480) By the way, if you don't set them, it is supposed to use the learning rate you did set here,

- [00:41:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2484) but to be sure, I set them also, and I don't use Rescale Noise

- [00:41:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2489) Scheduler. Actually, I never tested it, so I don't know.

- [00:41:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2491) I don't change any of the default parameters here, as you are seeing.

- [00:41:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2496) I don't use AlignProp.

- [00:41:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2498) When you hover your mouse, you can see what it does, but not much information.

- [00:41:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2502) To learn this, you need to check out the wiki of the OneTrainer.

- [00:41:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2506) You see, there are just so many things that you can research.

- [00:41:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2508) And masked training, now this is important.

- [00:41:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2511) I have recently tested this with doing a lot of research, and this really improves the

- [00:41:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2516) flexibility of the model.

- [00:41:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2518) So when you look at our readme file, you will see that I have tested the mask training.

- [00:42:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2522) This is also a public post.

- [00:42:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2525) When you open it, you will see the images of masked training.

- [00:42:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2530) You can download the full 1.5 gigabyte file and look at every image full size, or you

- [00:42:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2535) can download the files.

- [00:42:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2537) These are half size and look at them like this.

- [00:42:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2540) So, what I did find is, I think, masked training weight 60% is a sweet spot, so you can use

- [00:42:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2548) this.

- [00:42:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2549) Why don't use lower weight?

- [00:42:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2551) Because when you use lower weight, the body proportions get broken.

- [00:42:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2555) The head looks artificial on your body because it is not able to learn the proportions of

- [00:42:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2561) your body and your head.

- [00:42:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2563) Therefore, this is my finding.

- [00:42:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2565) So, you don't need to use it because, without even masked training, you get very good results.

- [00:42:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2571) But if you want more flexibility, and if your dataset is bad, especially this, if your dataset

- [00:42:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2577) is perfect, you don't need it.

- [00:42:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2579) What is perfect dataset?

- [00:43:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2580) Dataset never repeating clothing, never repeating background.

- [00:43:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2583) So, if your dataset is perfect, you don't need that.

- [00:43:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2587) But if your dataset is not perfect, you may get benefit from this.

- [00:43:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2590) So, enable masked training and unmasked weight.

- [00:43:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2593) Unmasked weight means that the non-masked areas will get 60% weight instead of 100%.

- [00:43:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2601) So, the backgrounds and my clothing will get 60% weight during training, and my head will

- [00:43:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2609) get 100% weight.

- [00:43:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2610) This is how we get some more flexibility.

- [00:43:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2615) And I also leave this area default.

- [00:43:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2617) I don't change them.

- [00:43:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2618) So, we also need to generate masks.

- [00:43:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2622) How do we generate them?

- [00:43:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2623) Let's go back to the...

- [00:43:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2624) Let's go to the tools, and in here, you will see dataset tools, convert model tools, and

- [00:43:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2628) sampling tool.

- [00:43:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2629) We are going to use dataset tool.

- [00:43:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2632) Open folder and open folder of your training images, which was this folder, SDXL.

- [00:44:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2640) Then you will get the images like this.

- [00:44:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2643) And in here, we will generate masks.

- [00:44:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2645) Okay.

- [00:44:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2646) And in the this section, you see the folder is selected.

- [00:44:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2650) You need to type a prompt.

- [00:44:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2652) Based on this prompt, it will generate the masks.

- [00:44:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2654) So, I type "head" because I want my head to be masked.

- [00:44:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2659) I don't change anything.

- [00:44:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2660) Create masks.

- [00:44:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2661) So, you see, the now masks are generated like this.

- [00:44:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2665) My head is masked in all of the images.

- [00:44:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2669) You should verify all images have accurate masks or not.

- [00:44:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2672) Then also, you see, the masks are saved here.

- [00:44:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2676) So, the white area means that it will get trained.

- [00:44:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2679) Black area means that it is the unmasked area.

- [00:44:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2683) Therefore, in here, you will see that only 60% weight, 60% importance, they will get,

- [00:44:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2691) instead of 100% importance.

- [00:44:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2693) Now, you can generate samples during training.

- [00:44:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2696) You can add a very detailed prompt, like, prompt, let's say, actually, we need to add

- [00:45:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2702) first sample.

- [00:45:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2704) Yes, you can set like 1024, 1024, any seed, and type of prompt like "photo of ohwx man"

- [00:45:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2712) and such.

- [00:45:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2713) Or, you can click here and type much detailed prompt like "photo of a ohwx man, negative prompt

- [00:45:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2719) is like blurry," and you can set seed, CFG scale, number of steps like 40, random seed,

- [00:45:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2726) if you wish, and you can even select the sampler like this.

- [00:45:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2729) I find this the best sampler.

- [00:45:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2731) So, during training, if you don't know how many epochs you should train, or if you want

- [00:45:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2735) to see the point where the model training gets over-trained and the quality starts degrading,

- [00:45:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2743) then you can generate samples.

- [00:45:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2744) This would slow, of course, your training.

- [00:45:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2747) You can also add multiple prompts like this.

- [00:45:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2751) You see, you can add multiple prompts.

- [00:45:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2753) All of them will be used.

- [00:45:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2754) You can enable/disable any one of them.

- [00:45:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2757) But I don't use these because I do x/y/z checkpoint comparison at the end of the training.

- [00:46:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2763) How do I do that?

- [00:46:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2765) In the backup, you don't need backup.

- [00:46:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2766) After this is backupping, I think, the diffuser files, what you need is "save after."

- [00:46:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2772) So, I am going to "save after" every 15 epoch, which means it will generate 10 checkpoints,

- [00:46:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2780) and each checkpoint will be like 6.5 gigabytes because we are saving them in half precision.

- [00:46:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2787) You can see output data type is Bfloat 16.

- [00:46:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2790) This is half precision.

- [00:46:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2791) So, I am going to generate 10 checkpoints, and the prefix, this is very useful.

- [00:46:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2798) After I contacted the developer of OneTrainer, he added it, thankfully.

- [00:46:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2802) I thank him.

- [00:46:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2803) So, let's give a name.

- [00:46:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2805) Let's say, what was our name?

- [00:46:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2807) Tutorial one.

- [00:46:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2808) So, let's say, Tutorial one.

- [00:46:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2810) So, this will be the prefix of the generated backup files.

- [00:46:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2815) It will save like this.

- [00:46:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2816) If you don't want it, you can save never, or if you want, based on the number of steps,

- [00:47:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2821) you can set it number of steps, you can set it number of seconds, minutes.

- [00:47:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2825) It is really, really convenient to use.

- [00:47:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2827) I will do that, 15 epoch.

- [00:47:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2829) Okay, everything is ready.

- [00:47:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2831) Save your configuration as Config one, for example, or whatever the name you want.

- [00:47:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2836) And let's see our VRAM configuration.

- [00:47:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2838) I have installed pip install nvitop.

- [00:47:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2841) This is a super useful library.

- [00:47:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2844) You can install it, then type nvitop, and it will open this screen.

- [00:47:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2850) In this screen, you can see how much VRAM I am using currently.

- [00:47:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2853) I am using 15 gigabyte VRAM.

- [00:47:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2856) And let's see, because of why?

- [00:47:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2859) Because we have 2 open something, I think.

- [00:47:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2863) Oh, because one of them is my Kosmos, which was my UI that I started, and one of them

- [00:47:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2869) is the OneTrainer.

- [00:47:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2871) So, this was the Kosmos error.

- [00:47:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2874) I should check this error and fix it later.

- [00:47:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2876) So, let's turn off the Kosmos, and you see, now I am using 7.8 gigabyte.

- [00:48:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2881) Now, people are complaining to me that their training is super slow.

- [00:48:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2886) Super slow training happens if your VRAM is not sufficient, and it starts using shared VRAM.

- [00:48:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2893) When you open your Task Manager, you will see that there is shared VRAM.

- [00:48:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2897) If it is going over 0.6 gigabytes, that means your computer started using shared VRAM.

- [00:48:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2905) Shared VRAM means that it is using your RAM memory, and it will be at least 20 times slower

- [00:48:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2912) than the original VRAM.

- [00:48:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2913) So, make sure that your VRAM usage is minimal before starting.

- [00:48:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2918) How you can make it minimize it?

- [00:48:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2920) You can turn off all of your startup items from here, restart your computer, and see

- [00:48:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2928) that to get it below 500 megabytes.

- [00:48:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2931) You can easily get it under 500 megabytes, and you will have full empty VRAM to start training.

- [00:48:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2938) Okay, let's...

- [00:48:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2939) Okay, we have saved the configuration.

- [00:49:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2941) Let's start training.

- [00:49:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2942) First, it will cache the images, then it will start training.

- [00:49:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2947) This will take time.

- [00:49:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2949) And since we did set up everything on Windows, now I am going to set up everything on Massed Compute.

- [00:49:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2955) However, if you are starting at this point, I don't suggest that.

- [00:49:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2959) You should also see the previous part to not miss anything.

- [00:49:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2964) Even though I will also put a video section here.

- [00:49:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2967) When you get this error, just cancel.

- [00:49:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2970) You don't need to install any updates.

- [00:49:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2972) Just cancel.

- [00:49:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2973) Okay, I'm going to close this because I'm going to start from the beginning.

- [00:49:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2977) First, we will begin with uploading our training dataset into the Massed Compute Virtual Machine.

- [00:49:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2984) For this task, I am going to use the shared folder that I have generated.

- [00:49:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2991) So, it was inside this folder.

- [00:49:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2992) You see, there are already files that I have, and I have even the training images here.

- [00:49:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=2998) I already copy-pasted. I copy-pasted them, just a regular way.

- [00:50:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3002) I also put the configuration files.

- [00:50:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3006) Let's also put the newest configuration file that we made.

- [00:50:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3009) So, the configuration was inside presets.

- [00:50:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3012) Don't forget that.

- [00:50:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3014) And I will paste it into the Massed Compute shared folder here.

- [00:50:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3017) Then, in this screen, the main window that we are going to use, home button, and you

- [00:50:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3022) will see all the folders here.

- [00:50:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3024) Thin drives.

- [00:50:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3025) So, when you enter inside Thin Drive, you will see the folder name of your computer

- [00:50:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3030) and the files and folders that I put inside this folder will be synchronized to here.

- [00:50:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3036) It is totally depending on your upload speed, of course.

- [00:50:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3039) And I can see all of my folders and files here.

- [00:50:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3042) So, let's copy this folder into wherever you want.

- [00:50:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3047) I am going to copy it into the home, into Applications folder here.

- [00:50:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3052) This is the folder where the applications are installed.

- [00:50:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3055) So, I did copy-paste with Ctrl C and Ctrl V. Before starting the OneTrainer, I am going

- [00:51:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3063) to update it.

- [00:51:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3064) So, the update instructions are written on this readme file.

- [00:51:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3069) Let's find OneTrainer update.

- [00:51:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3070) So, I'm going to search it for...

- [00:51:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3071) Okay, how to update OneTrainer to the latest version.

- [00:51:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3075) Just copy this, and let's start a new terminal here.

- [00:51:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3081) Just paste it.

- [00:51:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3082) Okay, it is not copied yet.

- [00:51:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3084) This is happening for some reason.

- [00:51:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3086) So, I copy again, and paste again.

- [00:51:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3089) Okay, still not copied.

- [00:51:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3090) For some reason, copy again.

- [00:51:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3092) Okay, why it is failing?

- [00:51:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3095) Let's open a notepad.

- [00:51:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3096) Okay, it appears that the copy button of the readme file is broken.

- [00:51:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3101) So, I select and right-click and copy, then paste here.

- [00:51:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3105) Still not visible.

- [00:51:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3107) Okay, probably I have an error.

- [00:51:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3109) Yeah, it is copied here.

- [00:51:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3110) So, let's try.

- [00:51:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3111) Interesting.

- [00:51:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3112) Let's start another one.

- [00:51:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3113) Okay, let's...

- [00:51:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3114) The copy-paste is currently not working, so I will reconnect.

- [00:51:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3117) So, I turn it off to Thin Client.

- [00:51:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3119) I am not going to do end existing session this time, because it will turn off everything.

- [00:52:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3125) But if it's still not works, I have to do that.

- [00:52:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3127) So, let's copy the password one more time.

- [00:52:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3130) This is the password.

- [00:52:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3132) Copy it, paste it into here, and connect.

- [00:52:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3134) Okay, it is connected.

- [00:52:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3135) Then, I am going to copy this command one more time.

- [00:52:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3138) This is not mandatory, but you should do it, because there are a lot of bug fixes happening

- [00:52:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3144) every time.

- [00:52:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3145) And now you see, copy-paste is working, and it is going to update the OneTrainer to the

- [00:52:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3150) latest version automatically for you.

- [00:52:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3153) Meanwhile, let's also download our regularization images dataset into the Massed Compute.

- [00:52:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3160) So, the regularization images link was here.

- [00:52:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3162) You can log in to the Patreon from your Massed Compute, or else what you can do, you can

- [00:52:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3168) right-click and copy link address, then open a Firefox here.

- [00:52:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3173) Paste it there.

- [00:52:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3175) Okay, it still didn't copy.

- [00:52:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3176) I don't know why the first times it doesn't work.

- [00:52:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3178) So, I will right-click and copy link address, then I will paste it here, and it will automatically

- [00:53:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3184) start downloading for you.

- [00:53:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3186) Let's watch the download from here.

- [00:53:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3188) Show downloads.

- [00:53:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3189) It is getting downloaded into downloads folder.

- [00:53:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3192) Then, let's go to the downloads folder.

- [00:53:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3194) In here, you don't need to move it anywhere.

- [00:53:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3197) Right-click and you need to select "Extract Here".

- [00:53:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3200) So, I will right-click and select "Extract".

- [00:53:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3203) You will see the extract operation is happening here.

- [00:53:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3206) You see, this is where you can watch what is happening at that moment.

- [00:53:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3211) So, with 200 megabytes per second, it is extracting it, and our regularization images are ready to use.

- [00:53:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3217) So, let's see the update process.

- [00:53:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3220) Okay, it has been updated.

- [00:53:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3222) To move into the desktop to hide all of the started icons, either you can click this icon

- [00:53:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3228) to minimize them or Ctrl+Alt+D. Yes, Ctrl+Alt+D. I also written this on here, Ctrl+Alt+D to

- [00:53:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3239) minimize all.

- [00:54:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3240) Then, double-click and start OneTrainer.

- [00:54:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3242) Run OneTrainer.

- [00:54:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3244) It will start the OneTrainer automatically for us, like this.

- [00:54:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3247) The rest is totally same with the first part of the tutorial, same as setting them up on

- [00:54:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3255) Windows, but I will set them here as well.

- [00:54:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3258) So, my configuration is not visible.

- [00:54:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3261) Why?

- [00:54:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3262) Because I didn't copy-paste the preset.

- [00:54:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3263) So, let's close this off, and I had put the preset inside my ThinDrive, which was inside

- [00:54:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3269) home, ThinDrives, Massed Compute.

- [00:54:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3272) You can give any folder name.

- [00:54:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3274) And which was my configuration, which was this was.

- [00:54:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3278) So, copy it.

- [00:54:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3279) Where you need to copy it?

- [00:54:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3280) Go to the home, apps.

- [00:54:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3282) This is where the applications are installed.

- [00:54:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3285) Inside OneTrainer, inside presets, and paste it.

- [00:54:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3289) So, I will just do Ctrl+V, and it is pasted.

- [00:54:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3292) All right, you can also delete these all other configurations, if you wish.

- [00:54:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3297) Okay, let's start.

- [00:54:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3299) OneTrainer again and it is starting.

- [00:55:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3301) Let's select the configuration from here.

- [00:55:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3305) Let's see.

- [00:55:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3306) Okay, let's select the configuration from here like this, and it will load everything.

- [00:55:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3310) Unfortunately, the responsiveness of the UI in the virtual machine is not as smooth as

- [00:55:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3316) on Windows, so we need to re-set the workspace directory and everything.

- [00:55:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3320) You can select the folders.

- [00:55:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3322) This is the folder structure of the virtual machine, so I will make it desktop.

- [00:55:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3327) Okay, then I will say that OneTrainer workspace, so it will be saved inside my desktop on the

- [00:55:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3334) virtual machine.

- [00:55:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3335) This virtual machine is completely separate from your own computer; therefore, nothing

- [00:55:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3342) you do here will affect your computer.

- [00:55:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3344) This is totally running on a different machine, in a remote machine.

- [00:55:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3347) So, let's copy this.

- [00:55:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3349) Let's delete this.

- [00:55:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3351) Paste and let's say OneTrainer cache.

- [00:55:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3353) Okay, these are the same.

- [00:55:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3355) Okay, in here you can also download the model and use it, or you can use the Stability AI-base model.

- [00:56:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3363) So, let's use the RealVis on the Massed Compute again.

- [00:56:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3367) So, the download links were here.

- [00:56:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3369) Let's see, this one.

- [00:56:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3371) Let's copy the link address.

- [00:56:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3372) Let's open a browser, close this, open a browser, and let's paste and go, and we are there.

- [00:56:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3379) Let's download it.

- [00:56:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3380) It is getting downloaded.

- [00:56:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3382) At the end of the tutorial, I will show SD 1.5 configuration as well.

- [00:56:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3387) Everything is the same, only the resolution of images changes.

- [00:56:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3391) By the way, I have forgotten to explain how to resize your images into the accurate resolution.

- [00:56:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3399) So, very important thing about your training images dataset, you need to prepare them with

- [00:56:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3406) accurate resolution.

- [00:56:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3408) I prefer to use all of them as 1024 to 1024.

- [00:56:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3413) If you watch this tutorial, you will understand that zooming in them without resizing is extremely

- [00:56:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3419) important.

- [00:57:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3420) I have automated scripts to do that.

- [00:57:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3423) In this tutorial, you will see them, or you can manually also resize them into the accurate resolution.

- [00:57:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3431) For example, these images are currently not at accurate resolution.

- [00:57:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3435) I can resize them, or let's see, the raw.

- [00:57:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3437) These are all ratio generated with my automated scripts.

- [00:57:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3441) So, you can watch this tutorial to learn how to resize them, or you can manually resize them.

- [00:57:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3447) This is totally up to you.

- [00:57:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3448) You can also use birme.net, but I don't suggest to use it because, at that time, the images

- [00:57:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3455) will not be accurately zoomed in.

- [00:57:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3457) Therefore, watching this tutorial is really useful for you to get and prepare the very

- [00:57:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3463) best training images dataset.

- [00:57:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3465) Okay, the model is downloaded.

- [00:57:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3467) Then, I will move it into the installed Automatic1111 Web UI folder.

- [00:57:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3472) So, cut it.

- [00:57:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3473) Let's go to the home.

- [00:57:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3474) Let's go to the apps, Stable Diffusion Web UI, inside models.

- [00:57:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3479) Where is it?

- [00:58:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3480) Here, inside Stable Diffusion.

- [00:58:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3482) This is where you put your models, and paste.

- [00:58:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3484) And this is it.

- [00:58:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3485) Then you can do ctrl + c.

- [00:58:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3487) This both copies the file and also its path.

- [00:58:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3491) Let's return back the OneTrainer.

- [00:58:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3492) This is here.

- [00:58:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3493) This is the icon.

- [00:58:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3494) And delete this, and ctrl + v to paste it.

- [00:58:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3498) You see, it copy-pasted the entire path of the model automatically for me.

- [00:58:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3503) You can also pick it from this navigation.

- [00:58:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3506) Let's delete the VAE, and the output.

- [00:58:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3508) The folder changes, of course.

- [00:58:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3510) So, where I want to change it, I want to save it into here.

- [00:58:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3513) So, I do ctrl + L, which select the folder path, copy, and just delete this part.

- [00:58:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3520) Paste it.

- [00:58:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3521) You see, I copy-pasted the part like this.

- [00:58:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3523) You can also type it as you wish.

- [00:58:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3526) And let's say, this one, Massed Compute, Massed Compute.

- [00:58:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3528) Okay, this will be the full path.

- [00:58:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3532) Okay, let's copy.

- [00:58:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3533) Everything is the same.

- [00:58:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3534) I have shown everything, explained everything in the first part of the video, so I will

- [00:58:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3539) quickly add the concepts.

- [00:59:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3541) The first concept is train.

- [00:59:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3543) Please watch the first part of the video, the Windows part, where I have explained everything.

- [00:59:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3548) So, click the path.

- [00:59:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3549) Okay, I think, yeah, it started here.

- [00:59:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3551) You see, it was invisible, so I clicked it here to see it.

- [00:59:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3555) Where did we copy them?

- [00:59:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3557) We copied them into the apps folder, here.

- [00:59:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3559) Okay, then let's go to the tools and set the masked training here as well.

- [00:59:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3564) By the way, why this is still lagging?

- [00:59:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3568) Yeah, because it is here, still.

- [00:59:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3570) Okay, let's select from a single text file.

- [00:59:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3572) Why this is happening like that, it is opening them at the behind.

- [00:59:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3576) So, move the windows like this.

- [00:59:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3578) You can write it anywhere you wish.

- [00:59:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3580) Currently, it is here, so I need to save a new text file.

- [00:59:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3584) I opened this Visual Studio Code editor.

- [00:59:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3586) By the way, this was inaccurately changed, so I need to change this back.

- [00:59:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3591) Yeah, original was like this.

- [00:59:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3594) So, I type here, ohwx man, like this.

- [00:59:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3597) Let me, okay, we cant zoom.

- [01:00:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3600) This is not good.

- [01:00:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3601) So, let's open text editor.

- [01:00:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3603) ohwx man, okay, I can't zoom in to show you a bigger font, but it's like this.

- [01:00:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3608) ohwx man.

- [01:00:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3609) Click save, and save it anywhere you wish.

- [01:00:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3612) Let's save it inside the apps folder.

- [01:00:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3613) ohwx man, sorry about that, it is here.

- [01:00:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3617) This is the name of the, and txt, this is important.

- [01:00:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3620) ohwx man.txt.

- [01:00:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3622) It is saved inside apps with ohwx man.

- [01:00:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3625) Let's return back.

- [01:00:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3626) Up, yes, ohwx man is selected.

- [01:00:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3629) Okay, it is still open another window here.

- [01:00:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3632) Okay, train dataset.

- [01:00:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3634) This is the folder.

- [01:00:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3635) This is the prompt, and I turn them off.

- [01:00:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3638) Click preview, and it is set.

- [01:00:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3641) Let's also generate the masks like we did.

- [01:00:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3645) Let's open the folder automatically and generate the mask.

- [01:00:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3649) Let's type head, create masks.

- [01:00:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3651) When we first time click create masks, it will download the model.

- [01:00:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3655) We can see it here.

- [01:00:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3656) Yeah, it is downloading and generating masks.

- [01:00:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3659) It is super fast, and the masks are generated.

- [01:01:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3661) Okay, we are ready.

- [01:01:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3663) And let's also add our regularization images concept.

- [01:01:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3668) So, it is reg, here.

- [01:01:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3670) The path of the regularization images is inside the downloads folder.

- [01:01:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3674) So, which is here, downloads folder, selected.

- [01:01:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3677) Now, we set the repeating as we have calculated in the first part of the tutorial, 0.029,

- [01:01:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3685) so it will use only 15 images at each epoch like this, and image augmentation, turn them

- [01:01:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3693) off.

- [01:01:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3694) We also need to have a prompt for it.

- [01:01:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3696) So, it will be just man.

- [01:01:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3697) Let's save it, ctrl + s, and just save as man.txt file.

- [01:01:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3703) Let's go back here, pick the folders.

- [01:01:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3706) Yeah, it is opened somewhere.

- [01:01:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3708) See, oh, you need to set the accurate option, otherwise, you can't, from a single text file, yes.

- [01:01:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3715) And let's pick the man, and repeating is set, everything is set, image augmentation turned off.

- [01:02:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3722) Let's create the preview.

- [01:02:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3723) Yes, and, okay.

- [01:02:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3724) So, we did set the concepts on OneTrainer as well.

- [01:02:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3727) The settings are same, however, on here, since we have a huge amount of VRAM, I am going

- [01:02:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3733) to use speed-up settings.

- [01:02:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3735) So, let's type nvitop, and you can see, we have 45 gigabyte VRAM.

- [01:02:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3741) Actually, it is 48, but I think it is getting like this.

- [01:02:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3745) So, disable gradient checkpointing to speed up, and also in here, disable fused back,

- [01:02:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3751) so it will use a huge amount of VRAM, but it will be much faster.

- [01:02:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3755) Let's enable, and let's set it as like this.

- [01:02:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3758) I have explained everything on the first part, so do not skip it.

- [01:02:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3763) And let's make this like the first part.

- [01:02:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3765) Okay, let's make this never, as usual, we don't change anything, and let's also set

- [01:02:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3772) the backup.

- [01:02:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3773) So, I will take 10 checkpoints, as the Windows training, and here, Massed Compute, ctrl + c

- [01:03:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3782) and let's give it as a file prefix.

- [01:03:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3785) Okay, so this will be saved inside the workspace directory that we did set, and the final model

- [01:03:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3792) will be saved inside this folder, where we set.

- [01:03:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3796) Let's save, fast like this, whatever you name, that you like.

- [01:03:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3800) Okay, you see, the interface is a little bit slower, and start training.

- [01:03:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3804) Currently, this will do the training on my first GPU.

- [01:03:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3807) What if, if I want to do another training with another GPU, because I have two GPUs?

- [01:03:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3813) So, all you need to do is click home, from here, you can click here, from home, scripts.

- [01:03:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3819) In here, you will see that OneTrainer.sh file, this is what it starts.

- [01:03:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3825) Open it with text editor, and you are going to write here a command.

- [01:03:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3830) Which command?

- [01:03:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3831) I have written it here.

- [01:03:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3833) Let's see, export this one.

- [01:03:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3834) So, this will tell that the script to be able to only see the GPU one.

- [01:04:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3841) So, the index of GPUs start from zero.

- [01:04:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3845) This is the first GPU, you see, it shows index zero, and this is the second GPU.

- [01:04:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3849) So, I just copy-paste it here, and when I start another OneTrainer, it will be automatically

- [01:04:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3856) using the second GPU.

- [01:04:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3858) So, let's minimize everything with ctrl + alt + d, start another OneTrainer.

- [01:04:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3863) I will demonstrate it to you.

- [01:04:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3865) So, let's also open the other window that we have, that shows this VRAM usages.

- [01:04:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3871) I will just load the preset that I have made.

- [01:04:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3874) Not this one, preset loading is a little bit slow, unfortunately.

- [01:04:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3878) Let's load the fast, and hit start training, and you will see that it will start using

- [01:04:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3884) the second GPU.

- [01:04:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3885) I just want to demonstrate.

- [01:04:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3886) I will turn it off.

- [01:04:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3887) Now, it started on GPU one.

- [01:04:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3888) You see, in the second process, that it is started to use my GPU, is using the GPU one.

- [01:04:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3896) You see, I am able to utilize both of the GPUs.

- [01:04:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3899) By the way, this may have caused overriding the caching folder, so I am not sure if it

- [01:05:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3906) did broke or not.

- [01:05:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3907) The cache is here.

- [01:05:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3909) I hope it didn't broke the caching process.

- [01:05:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3911) Maybe it broke it.

- [01:05:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3912) So, what can we do?

- [01:05:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3914) We can restart the process to be sure.

- [01:05:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3916) So, let's also see that.

- [01:05:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3918) Okay, I close them off, and currently, the new OneTrainer that I am going to start will

- [01:05:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3924) be using the GPU one, by default.

- [01:05:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3927) Let's open, and select fast, and I will make it re-cache.

- [01:05:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3932) So, even though it has cached files, I will make it recache with clear cache before training,

- [01:05:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3939) so it will start caching from zero, and we are set.

- [01:05:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3943) Everything is set, it will do the training.

- [01:05:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3945) Let's look at our Windows training.

- [01:05:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3947) You see, it is using 17 gigabytes VRAM currently, and it was using already 7 gigabytes before

- [01:05:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3954) we started training, so it is only using 10.2 gigabytes VRAM because this was our configuration,

- [01:06:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3961) but on Massed Compute, it will use a huge amount of VRAM.

- [01:06:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3965) We will see.

- [01:06:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3966) So, let's also start the Automatic1111 Web UI on Massed Compute to see how it works.

- [01:06:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3973) On Windows, it is so easy to use.

- [01:06:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3976) In this tutorial, I have shown how to install also Automatic1111 Web UI.

- [01:06:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3982) However, if you want to use the auto installers, I have auto installers for them as well.

- [01:06:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3987) So, to automatically install Automatic1111 Web UI on Windows, go to this post, and you

- [01:06:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3993) will see all of the details that we have, the changes, the information, the scripts.

- [01:06:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=3998) Let's download the scripts.

- [01:06:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4000) Let's extract it into our F drive, let's say, video_auto_1111, it is pasted.

- [01:06:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4009) Extract files here, and you will see that several bat files.

- [01:06:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4013) So, I am going to install Automatic1111 Web UI with double-clicking.

- [01:06:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4017) It will do everything automatically for me.

- [01:07:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4020) It will install, and you will see a bunch of other files, and what are they?

- [01:07:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4024) So, I suggest you use Update Torch xFormers Install After Detailer Automatically bat file

- [01:07:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4032) when after this installation has been completed.

- [01:07:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4035) This installer also downloads some of the best models automatically for you, as you

- [01:07:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4040) are seeing right now.

- [01:07:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4041) If you are interested in TensorRT, you can also use this to automatically install it.

- [01:07:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4047) If you are interested in ControlNet, you can use this to install automatically, download

- [01:07:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4054) all of the ControlNet models, which are over, let's see, how many they were, which are over

- [01:07:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4059) 50 models already.

- [01:07:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4060) So, these scripts will automatically download all of the models into the accurate folders,

- [01:07:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4067) including IP Adapter and Instant ID, which are really hard to install.

- [01:07:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4072) This is extremely useful script.

- [01:07:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4074) I also prepared the same scripts for Massed Compute.

- [01:07:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4077) Let's open this link.

- [01:07:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4079) This is the link that you need for Massed Compute, and in here, you will find the Massed

- [01:08:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4083) Compute version one zip file.

- [01:08:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4085) Download this zip file.

- [01:08:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4087) You will find the files and extract them into your Massed Compute folder, like here.

- [01:08:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4094) These are the content of the zip file, which I can access already on Massed Compute.

- [01:08:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4099) So, how to use them?

- [01:08:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4101) Let's go to the thin drives, which is our synchronizer drive.

- [01:08:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4105) Let's go to the Massed Compute.

- [01:08:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4106) So, which files do I need, if I want to download and use ControlNet, IP Adapter, and everything?

- [01:08:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4112) So, let's select, actually, from here to here.

- [01:08:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4115) So, let's copy.

- [01:08:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4117) Some of them are extra files that you are seeing.

- [01:08:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4119) I will show them too, don't worry.

- [01:08:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4121) Let's go to the apps, and paste them here.

- [01:08:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4124) So, you will see that they are getting pasted.

- [01:08:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4127) The operation is here, as you see.

- [01:08:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4129) Okay, they are done.

- [01:08:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4130) So, on Massed Compute, what do I suggest to you?

- [01:08:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4133) I suggest you update the Automatic1111 Web UI to the latest version.

- [01:08:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4139) Also, in some cases, xFormers may not be automatically updated for OneTrainer on Massed Compute.

- [01:09:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4147) You can use this command to update it.

- [01:09:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4149) And, how do we update Automatic1111 Web UI with this command.

- [01:09:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4152) So, this is copy, open a new terminal, like new window, right-click, and paste it, and

- [01:09:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4159) hit enter.

- [01:09:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4160) It will update the Automatic1111 Web UI to the latest version automatically.

- [01:09:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4163) But, you need to do this before starting the Automatic1111 Web UI.

- [01:09:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4167) Then, you need to also add this to do its starting file.

- [01:09:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4172) So, let's copy this.

- [01:09:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4174) How do we do that?

- [01:09:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4175) Let's go back to the desktop of the Automatic1111 Web UI in Massed Compute.

- [01:09:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4180) In here, start Stable Diffusion settings file.

- [01:09:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4183) It will open the this sh file, to modify, and paste it here.

- [01:09:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4188) Okay, it didn't copy it.

- [01:09:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4190) So, let's copy again.

- [01:09:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4191) With this way, you can start using the latest version of Automatic1111 Web UI on Massed

- [01:09:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4197) Compute.

- [01:09:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4198) However, if you need more, like, what you may say, if you need more of TensorRT, this

- [01:10:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4205) is currently not working for some reason, or install After Detailer, ControlNet, and

- [01:10:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4211) Face Fusion, then you should execute this command.

- [01:10:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4214) How? Copy it.

- [01:10:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4216) By the way, you need to put these files inside apps folder, which is inside here.

- [01:10:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4222) Let's go to the apps folder.

- [01:10:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4223) You see, the scripts are here.

- [01:10:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4225) Let's open a new terminal, and paste.

- [01:10:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4228) Okay, it didn't copy again.

- [01:10:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4230) I hate this.

- [01:10:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4231) Copy, and paste, and it will update Automatic1111 Web UI with certain extensions.

- [01:10:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4237) I am also going to show you the content of this file, so even if you are my not Patreon

- [01:10:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4242) supporter, you can still use it.

- [01:10:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4245) So, let's open with text editor.

- [01:10:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4247) And, this is the content of this file.

- [01:10:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4249) So, it is going to download and install After Detailer, ControlNet extension, Face Fusion extension.

- [01:10:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4256) It's also going to install necessary libraries for Face Fusion.

- [01:11:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4260) This is it.

- [01:11:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4261) This is the content of it.

- [01:11:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4263) If you support me on Patreon, I would appreciate that very much, because, with that way, you

- [01:11:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4268) will get always most up-to-date version of the scripts, and helping me to continue in

- [01:11:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4274) this journey.

- [01:11:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4275) So, you see, it is doing the necessary updates of Automatic1111 Web UI with the necessary libraries.

- [01:11:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4282) This will also update it to the Torch version 2.2.0, and xFormers 0.0.24.

- [01:11:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4288) One another very beautiful thing of this virtual machine image template is, by default, it

- [01:11:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4293) comes with Python 3.10.

- [01:11:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4295) Point, I need to type Python3 I think, 3.10.12.

- [01:11:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4299) So, this is a very rare template.

- [01:11:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4302) In most of the templates that you will find, they are installing different Pythons, but

- [01:11:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4307) on this machine, we have Python 3.10.12, automatically installed.

- [01:11:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4312) Okay, the update is continuing.

- [01:11:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4315) Meanwhile, let's look at the training speed on our Windows.

- [01:11:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4319) So, it started training, and the speed is 2.5 seconds per it.

- [01:12:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4325) And what does this mean?

- [01:12:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4327) This means that each step is going to take this much and how many steps that I am going

- [01:12:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4332) to train.

- [01:12:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4333) I am going to train 200 epochs, so let's calculate.

- [01:12:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4336) So, every image in my concepts will be trained 200 epochs.

- [01:12:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4341) How many concepts I have : 2

- [01:12:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4343) In each concept, I am training 15 images because I have training images 15, repeating 1,

- [01:12:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4349) and I have 5200 images with repeating 0.029.

- [01:12:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4352) So, 15 + 15 = 30 images is trained per epoch. So 200 multiplied with 30

- [01:12:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4360) = 6,000 steps that we we are going to do training total, and since each step is taking like two seconds / it now,

- [01:12:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4368) I don't know why it became faster somehow, it means this 6000 with 2 seconds, it is

- [01:12:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4375) going to take 12,000 seconds, with when we divide it by 60, it becomes 200 minutes taking

- [01:13:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4382) on my windows.

- [01:13:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4384) And is this done?

- [01:13:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4385) Yes, let's close this terminal.

- [01:13:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4387) Let's look at the training speed on the Massed Compute if started.

- [01:13:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4391) No, still caching.

- [01:13:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4393) So let's start the Automatic1111 Web UI after we made all these changes.

- [01:13:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4397) Run Stable Diffusion, and it will start the Automatic1111 web UI latest version with the

- [01:13:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4404) most commonly used extensions.

- [01:13:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4406) You can also install any extension like on your computer here.

- [01:13:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4410) It is exactly the same, nothing changes, only the folders change.

- [01:13:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4414) So you see, it is making the necessary updates since it is starting the first time.

- [01:13:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4420) Our training on windows, continuing, and you see, we got a checkpoint at 450 steps, which

- [01:13:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4427) is equal to 15 epochs.

- [01:13:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4429) You see, it also shows the epoch in the naming, 450 steps, 15 epochs.

- [01:13:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4435) And if your training stops when you are touching the cmd, just hit enter, it will continue.

- [01:14:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4440) Okay, we got some, yeah, we have basic as our error.

- [01:14:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4445) I think I had fixed this, but it looks like it is not fixed.

- [01:14:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4450) So let's fix this error.

- [01:14:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4452) How we are going to fix it?

- [01:14:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4454) We need to activate the virtual environment of the Stable Diffusion and install it manually.

- [01:14:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4461) Okay, so let's do it.

- [01:14:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4463) Let's go to the home, apps, Stable Diffusion web UI, start a new terminal here, and for

- [01:14:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4470) activating this virtual environment here, we are going to use this command: source ./venv/bin/activate

- [01:14:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4477) Let's copy this and paste it here.

- [01:14:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4479) Yes, it is activated.

- [01:14:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4481) pip install basicsr and it is getting installed.

- [01:14:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4485) Yes, it is installed.

- [01:14:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4487) Okay, let's move back and start the Stable Diffusion Web UI.

- [01:14:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4491) I am going to add this to my automatic scripts, so you won't have this issue.

- [01:14:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4495) I will update the scripts.

- [01:14:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4497) Oh, we got another error.

- [01:14:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4499) This is weird.

- [01:15:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4500) These are all errors of the Fase Fusion, so this is why you should support me because

- [01:15:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4507) you will not have these errors, or if you have these errors, you will message me and

- [01:15:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4512) I will fix it.

- [01:15:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4514) So let's edit this, install basicsr, and which was the missing one?

- [01:15:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4519) It was realesrgan, pip install realesrgan.

- [01:15:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4523) So let's also install this with our activated virtual environment.

- [01:15:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4527) Okay, it's installed.

- [01:15:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4529) Now we need to restart the web UI.

- [01:15:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4532) Okay, which was the restart web UI?

- [01:15:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4534) Okay, let's close this terminal.

- [01:15:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4536) Not this one.

- [01:15:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4537) Okay, this is OneTrainer updated terminal.

- [01:15:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4540) This is OneTrainer training.

- [01:15:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4542) Okay, not this one either.

- [01:15:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4544) Okay, I think we had closed it, so start Stable Diffusion web UI again.

- [01:15:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4548) Okay, it is started, and I don't see any error.

- [01:15:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4552) Yeah, I think these are not very important, and you see, you can either use it locally

- [01:15:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4558) with this URL.

- [01:15:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4559) How to use it?

- [01:16:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4560) So, open the link, it will open it in the browser, so you can use it locally on the

- [01:16:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4565) remote computer, or you can use it on your computer or even on your mobile phone with

- [01:16:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4571) the Gradio share.

- [01:16:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4572) You see, copy the link, and I can open it in my browser.

- [01:16:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4577) Let's open it here.

- [01:16:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4578) So whatever I generate here will be generated on the cloud machine, not on my computer.

- [01:16:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4584) If you don't want Gradio share, what you need to do is, when copy-pasting the startup parameters,

- [01:16:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4591) which was here, just remove the share from here that we have added in the beginning.

- [01:16:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4597) If you remove it, then it will not start Gradio live share.

- [01:16:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4600) And you see, I can just type, let's generate 100 images.

- [01:16:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4604) Let's see the speed of image generation.

- [01:16:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4607) By the way, currently, OneTrainer is running on the second GPU, and the Automatic web UI

- [01:16:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4613) is running on the first GPU, so they are not blocking each other.

- [01:16:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4618) How can I be sure?

- [01:16:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4619) nvitop, and I can see that.

- [01:17:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4621) So you see, the second GPU, which is OneTrainer, is using 34 gigabyte VRAM because we have

- [01:17:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4627) disabled all the VRAM optimizations, and its speed is 1.2 seconds per it.

- [01:17:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4634) And on my computer, its speed is, what was it?

- [01:17:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4638) Two seconds per it.

- [01:17:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4639) You see the difference.

- [01:17:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4640) It is faster.

- [01:17:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4642) And this is the speed of the image generation on the first GPU.

- [01:17:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4645) It is 20 it per second for Stable Diffusion 1.5 model, which is here.

- [01:17:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4651) Let's interrupt it.

- [01:17:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4653) There will be, of course, some delay with the Gradio live share because it will download

- [01:17:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4659) the images from the Gradio live. It was really fast.

- [01:17:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4662) Okay, let's load the RealVis XL model.

- [01:17:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4665) If this screen takes forever, if this screen doesn't work when you are loading, it can

- [01:17:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4672) happen on your Windows or anywhere.

- [01:17:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4674) That means the Gradio is bugged in your browser.

- [01:17:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4677) So, turn off all of your browsers and reopen, and it will fix it.

- [01:18:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4682) Okay, it is loaded.

- [01:18:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4683) This is 1024 since this is SDXL model, and let's say this is the best sampling method

- [01:18:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4690) that I like, and generate images.

- [01:18:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4692) Massed Compute is totally secure, so no one can see whatever you are doing.

- [01:18:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4698) Okay, it is getting generated.

- [01:18:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4700) It is like 6 it per second.

- [01:18:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4701) You see, this is the image generation speed.

- [01:18:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4704) It is almost equal to RTX 4090.

- [01:18:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4706) Actually, it's a pretty decent speed, really, really good speed, actually.

- [01:18:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4713) 6 it per second.

- [01:18:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4714) I don't know why, but TensorRT is currently not working for some reason.

- [01:18:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4718) I couldn't solve it yet, but hopefully, I will solve it and update the Patreon scripts.

- [01:18:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4724) And training is continuing.

- [01:18:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4725) So all I need to do is now just waiting, the checkpoints being generated, and comparing

- [01:18:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4732) them both on my computer or on the Massed Compute.

- [01:18:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4736) Both is same.

- [01:18:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4737) It has been a while, so let's check out the status of the training.

- [01:19:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4741) When you are training, in the left bottom of the screen, you will see the status of

- [01:19:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4746) the epoch, the number of epochs completed, and the current step of that epoch.

- [01:19:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4752) So this is where you will see the status of the training.

- [01:19:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4757) In the cmd window, also, you will see some of the messages.

- [01:19:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4760) However, it doesn't show the current epoch.

- [01:19:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4763) It only shows the current step at that particular epoch.

- [01:19:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4769) So let's see the status of the Massed Compute training.

- [01:19:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4772) To see that, I click this.

- [01:19:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4774) This is the interface of the OneTrainer, and already, 158 epochs have been completed.

- [01:19:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4783) While training, I suggest you to start uploading files into the Hugging Face because if you

- [01:19:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4790) use folder synchronization to download models, it may not work, or it may be very slow.

- [01:19:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4798) So how you are going to use that?

- [01:20:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4800) It is so easy.

- [01:20:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4801) We are going to start the Jupyter Lab.

- [01:20:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4803) You see, there is "Run Jupyter Notebook".

- [01:20:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4806) So let's run it.

- [01:20:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4807) It will start the Jupyter interface like this.

- [01:20:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4810) Now, you can either load the file that you have downloaded from Patreon, or you can make

- [01:20:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4817) a new notebook.

- [01:20:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4819) Either way works.

- [01:20:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4821) You select Python3 ipykernel.

- [01:20:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4823) So to load it, it was inside our thin drive, Massed Compute.

- [01:20:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4829) This is my folder.

- [01:20:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4830) It may be different in your case, whatever you set it up.

- [01:20:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4833) And you see, there is "Upload Hugging Face Notebook File".

- [01:20:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4838) If you double-click it, it will not be opened accurately.

- [01:20:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4841) So how you are going to open it?

- [01:20:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4843) To open it in this interface, we click this "Upload".

- [01:20:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4847) So we have to select it from this interface.

- [01:20:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4850) Let's go to the home, go to the thin drives, Massed Compute, and select the notebook file,

- [01:20:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4857) "Upload Hugging Face".

- [01:20:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4858) Open.

- [01:20:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4859) So this will open it accurately.

- [01:21:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4862) You see, now it is appeared here.

- [01:21:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4864) Double-click it.

- [01:21:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4865) It will open it like this.

- [01:21:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4867) And these are the codes that you need to run.

- [01:21:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4870) There are several cells, and each one is doing something different.

- [01:21:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4874) So, first of all, let's install the Hugging Face Hub and ipy widgets.

- [01:21:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4879) Okay, the cell has been executed.

- [01:21:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4882) When you click here, yes, you see, we got this screen.

- [01:21:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4886) So what we are going to do right now is, go to your Hugging Face settings, and in here,

- [01:21:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4892) click "Access Tokens", and make a new token with read and write permission, like "test

- [01:21:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4898) test test", whatever the one you want, and then copy it.

- [01:21:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4902) By the way, you need to register a Hugging Face account.

- [01:21:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4905) It is free.

- [01:21:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4906) Then paste it here at login.

- [01:21:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4909) Once you're logged in, then you can upload model files or generated images into a private

- [01:21:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4916) repository.

- [01:21:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4917) So, there are these codes.

- [01:22:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4920) What do they do?

- [01:22:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4921) This first one allows you to upload a single checkpoint into your destination repository

- [01:22:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4929) in your Hugging Face account.

- [01:22:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4930) This one lets you upload a folder, and this one lets you upload a folder.

- [01:22:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4936) This is a better way of uploading a folder.

- [01:22:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4938) So, if you're going to upload an entire folder, you should use this method.

- [01:22:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4942) If you're not going to upload an entire folder, just a single checkpoint, you should use this.

- [01:22:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4947) So, let's upload a single checkpoint first.

- [01:22:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4950) Where is our checkpoint saved?

- [01:22:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4953) They are inside home, actually, inside desktop, inside OneTrainer, workspace, inside save.

- [01:22:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4958) So our checkpoints are saved here.

- [01:22:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4961) Let's upload the first checkpoint.

- [01:22:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4962) So, I do Ctrl+C. It will copy the path of the file, then I will paste it here.

- [01:22:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4968) Okay, maybe the copy-paste not worked.

- [01:22:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4971) Okay, copy-paste worked, but it doesn't allow me to paste.

- [01:22:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4975) Let's open a new window.

- [01:22:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4977) Yes, it is copied, but in here, why I can...

- [01:23:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4980) Okay, now I can paste it.

- [01:23:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4981) So, first, I have to copy-paste it into an editor, then I can copy-paste it.

- [01:23:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4986) So, this is the full path, and then we need to give the model name in the repository that

- [01:23:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4992) we are going to upload.

- [01:23:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4993) So, this is the name.

- [01:23:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4994) I copy it, delete this one, and paste it like this.

- [01:23:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=4999) And the repo ID, so this is the repository that you are going to set on your Hugging Face.

- [01:23:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5005) Let's click "New Model".

- [01:23:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5007) You can make it either public or private.

- [01:23:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5009) Test11111.

- [01:23:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5012) Let's make it as private, so no one else can access it.

- [01:23:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5016) Click here to copy your Hugging Face repository.

- [01:23:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5019) You see, username and repo name.

- [01:23:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5022) Delete it, and click "Play" to upload.

- [01:23:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5025) I will restart the notebook.

- [01:23:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5026) Okay, so let's close the Jupyter Lab interface.

- [01:23:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5029) Then, let's return back to the desktop, Ctrl+Alt+D. Start the Jupyter Notebook.

- [01:23:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5034) Okay, it is getting opened.

- [01:23:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5037) Let's open the upload Hugging Face and play again.

- [01:24:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5041) It is done.

- [01:24:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5042) Let's click "Play".

- [01:24:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5044) Okay, you see, the widget is now started.

- [01:24:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5046) Perhaps we had to restart the terminal to get this widget.

- [01:24:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5051) Then, let's copy our token one more time, which was...

- [01:24:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5055) Let's go to our settings.

- [01:24:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5057) I'm going to delete this access token after the video, so it's fine.

- [01:24:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5062) Copy it, paste it, login, and yes, token is valid.

- [01:24:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5067) Now, I can start uploading.

- [01:24:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5068) Okay, this is also saved.

- [01:24:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5070) So, let's just click this and just wait.

- [01:24:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5073) By the way, we should see that it is playing this cell, but the color of this cell is also

- [01:24:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5080) not accurate.

- [01:24:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5081) I wonder why.

- [01:24:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5082) Oh, because this is raw.

- [01:24:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5084) We have to make this as code.

- [01:24:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5085) I was just playing with it.

- [01:24:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5086) So, you need to select "Code" from here.

- [01:24:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5089) Then, let's just click "Play".

- [01:24:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5091) Okay, now it is going to start uploading into the Hugging Face repository.

- [01:24:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5097) I suggest you do this while training. Why?

- [01:25:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5101) Because this way, you will save your time.

- [01:25:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5103) You will not wait upload.

- [01:25:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5105) You can upload files while training.

- [01:25:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5109) And also, let's say you wanted to upload an entire folder.

- [01:25:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5112) So, you can set the folder here.

- [01:25:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5114) You can upload either the images or all of the generated models.

- [01:25:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5120) You just change it here, the folder path.

- [01:25:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5123) You change your repository name like here, whatever the repository you did set.

- [01:25:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5128) For example, I did set this and play this.

- [01:25:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5131) So, this will upload one by one, everything.

- [01:25:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5133) You see, the upload speed is pretty decent.

- [01:25:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5136) It is like 50 megabytes per second, which translates into 500 megabits per second, almost.

- [01:25:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5143) And with this way, you will be saving your time.

- [01:25:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5146) One another thing is that our newly fresh installed Automatic1111 web UI has started.

- [01:25:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5153) If you remember, we had installed it from here.

- [01:25:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5157) So, after the initial installation, I can also install ControlNet or I can update xFormers,

- [01:26:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5166) install After Detailer, and the Face Fusion.

- [01:26:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5169) So, you can see that currently, it is using Torch 2.1.2 with xFormers 0.0.23, and After

- [01:26:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5177) Detailer extension or ControlNet extension is not here.

- [01:26:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5181) So, I am going to install those extensions and update everything automatically.

- [01:26:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5187) I am also going to show you the code right now because I said that there is no paywall

- [01:26:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5193) in this tutorial.

- [01:26:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5194) So, this is the code that installs everything automatically.

- [01:26:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5198) You can code it if you wish.

- [01:26:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5201) And I am also going to show you the updater code because I said there is no paywall in

- [01:26:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5206) this tutorial.

- [01:26:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5207) So, let's edit it.

- [01:26:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5208) This is the code that is going to install After Detailer automatically and update the

- [01:26:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5214) Torch version and the xFormers version for me.

- [01:26:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5218) If you need Face Fusion on here, I can also add it into my automatic installer.

- [01:27:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5225) Just message me from Patreon, and I will add for you.

- [01:27:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5228) There is also automatic installation and downloader for ControlNet with setting everything into

- [01:27:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5234) accurate folders because it is hard.

- [01:27:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5237) But don't worry, I have a full tutorial on my channel regarding the ControlNet.

- [01:27:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5242) So, just type "YouTube SECourses ControlNet".

- [01:27:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5246) And this is my grand master ControlNet tutorial.

- [01:27:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5249) You see, it is 90 minutes.

- [01:27:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5253) You can watch this to learn more about Control Net if you are interested in.

- [01:27:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5257) However, if you use my automatic installers, it is better for you.

- [01:27:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5262) There is also some extra information here regarding how to use newest instant ID and

- [01:27:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5269) also IP adapter face ID.

- [01:27:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5271) But if you ask my opinion, the ControlNet extension, IP adapter face ID, and instant

- [01:27:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5277) ID implementations are way behind their original repository implementation.

- [01:28:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5283) I have one-click installer for instant ID and also IP adapter face ID.

- [01:28:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5289) When we go to the Patreon exclusive post index and search for instant ID, you see, I have

- [01:28:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5296) instant ID for Windows, Runpod, and Linux, and Kaggle notebook.

- [01:28:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5300) And also for face ID, we have the same.

- [01:28:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5303) Let's find it here.

- [01:28:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5305) IP adapter face ID plus version 2, 0-shot face transfer.

- [01:28:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5309) This is also another standalone Gradio installer for them.

- [01:28:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5313) Hopefully, I will make a new tutorial for instant ID.

- [01:28:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5316) I already have a tutorial for face ID.

- [01:28:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5319) If you want to watch it, just type "SECourses face ID".

- [01:28:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5324) And this is the tutorial for it.

- [01:28:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5325) Okay, so our model has been uploaded into our repository.

- [01:28:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5330) Let's check it out.

- [01:28:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5331) When I return back to my repository and refresh here, I should see the model inside files

- [01:28:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5337) and versions.

- [01:28:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5338) And yes, I can see it.

- [01:29:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5340) Now, I can download it and start using it on my computer.

- [01:29:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5344) If I want, I can also already use it on Massed Compute.

- [01:29:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5348) How?

- [01:29:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5349) I can move the model file into the models, or I can give this as a path of model loading.

- [01:29:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5355) So, let's move the saved models into the models folder.

- [01:29:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5361) You don't need these YAML files.

- [01:29:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5362) Automatic1111 web UI automatically generating YAML files. To select all of the models here:

- [01:29:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5368) while keep pressing the shift key, I select the first one, and then I select the last

- [01:29:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5374) one, and it selects all.

- [01:29:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5376) Alternatively, you can right-click and select all, and then copy or cut.

- [01:29:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5382) We don't need to copy; we should move them, so cut and let's go to the home, inside apps,

- [01:29:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5389) inside Stable Diffusion Web UI, inside models, inside Stable Diffusion folder, paste, and

- [01:29:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5395) now I can start using them on Massed Compute.

- [01:29:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5399) It is not finished yet; it is still generating checkpoints.

- [01:30:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5403) However, you see, we have already got the checkpoint of 180 epochs. So how we are going

- [01:30:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5409) to test them.

- [01:30:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5411) If you remember, we had started Automatic1111 Web UI on the Massed Compute.

- [01:30:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5415) We can see its terminal somewhere around here.

- [01:30:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5418) Yes, here.

- [01:30:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5419) So there was a Gradio live and also local. Currently it is running on local URL as well, so which

- [01:30:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5426) is 127.0.0.1:7860 port.

- [01:30:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5432) This is the port of the Automatic1111 Web UI which starts default, and now I can do

- [01:30:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5438) testing.

- [01:30:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5439) How am I doing testing?

- [01:30:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5440) First of all, I need to refresh models here so they appear, you see, and then I refresh

- [01:30:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5446) this interface so that these models will appear in the x/y/z checkpoint, and then you need

- [01:30:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5453) to type your prompts.

- [01:30:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5454) For example, let's check out the first checkpoint, 150, because 150 epoch is a sweet spot that

- [01:31:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5462) I find with my configuration, but it may not be the same for you; it depends.

- [01:31:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5468) Then what I'm going to do is type a prompt that I like.

- [01:31:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5471) You can find a lot of good prompts on my CivitAI profile, so type CivitAI SECourses like

- [01:31:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5479) this, then you will get my page.

- [01:31:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5482) On my profile, click my profile, go to my images, and you will see my generated images

- [01:31:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5489) here with their png info.

- [01:31:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5491) For example, for testing, let's pick a prompt from here.

- [01:31:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5495) Okay, like this one.

- [01:31:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5496) This is an SD 1.5 image; I am going to use this prompt. For SDXL

- [01:31:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5502) I don't need very much negative prompts, and later I decided to remove canon word because

- [01:31:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5507) I think it is not really necessary.

- [01:31:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5510) Okay, it's looking accurate.

- [01:31:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5511) I prefer to do 40 steps for sampling.

- [01:31:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5515) I am using DPM++ 2M SDE Karras.

- [01:32:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5521) This is the best sampling method that I find.

- [01:32:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5523) Then we are going to generate in 1024 because this is our base training resolution, and

- [01:32:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5530) a very important thing is that you should use After Detailer.

- [01:32:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5533) Let me demonstrate to you why.

- [01:32:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5535) So let's generate like 4 images to see what we get and why we should use After Detailer.

- [01:32:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5543) The reason is that the model learns our face and our body with a very limited number of

- [01:32:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5549) images and limited number of resolution; therefore, the face details are not very accurate when

- [01:32:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5555) you generate a distant shot images, not close shot, distant shot.

- [01:32:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5559) So we in-paint face automatically to improve it; that is what After Detailer does.

- [01:32:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5565) Okay, we got images.

- [01:32:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5567) For example, this one, this one, or let's see this one.

- [01:32:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5571) Okay, I am going to improve this one's quality, and there is this one.

- [01:32:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5575) I don't know; we can also improve this one too, whatever the one you wish.

- [01:32:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5579) So where is the seed of this?

- [01:33:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5581) Here, let's copy the seed, let's paste it here, and let's make it batch size one and

- [01:33:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5587) regenerate.

- [01:33:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5588) So I am going to show you the effect of the After Detailer.

- [01:33:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5591) Okay, we are getting the same image.

- [01:33:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5593) Okay, this is the image we got.

- [01:33:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5596) You see, the face is not accurate; however, the overall shape is accurate.

- [01:33:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5599) So After Detailer can fix up to a certain degree.

- [01:33:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5603) To get perfect images, you need to have a good training, and you can see that the model

- [01:33:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5608) is not over-trained because the clothing details are perfect; the background details are perfect.

- [01:33:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5614) So this is not over-trained, and the anatomy of the image is looking accurate.

- [01:33:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5620) It depends on your taste.

- [01:33:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5621) If you don't find this very natural, you can generate more images to get a better image.

- [01:33:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5626) So what we are going to do is, we are going to type a prompt here which is very important.

- [01:33:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5631) Photo of ohwx man, this is super important because this is the most likely to improve

- [01:33:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5638) your face.

- [01:33:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5639) If you want a different pose of the image, you need to also change here,

- [01:34:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5643) I will show. In the detection, make it detect only the first face, and in the in-painting

- [01:34:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5649) tab, I prefer to make it 0.5 percent denoising strength, and there is only one thing that

- [01:34:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5656) I change, use separate steps to improve the quality of the face like 70, and let's try again.

- [01:34:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5663) Now we will see that it will automatically in-paint effects.

- [01:34:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5666) Okay, we forgotten to enable the After Detailer, so let's enable it and try again. With SD 1.5,

- [01:34:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5674) if you do 1024 training, and it is fixing the face, and we got the image.

- [01:34:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5680) You see, the face is much better.

- [01:34:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5682) This image is not perfect; I would generate more images to get a better one, but you see

- [01:34:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5687) the logic.

- [01:34:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5688) Also, if you want to do upscale with high resolution fix; you can do that too.

- [01:34:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5693) The crucial part is you need to select some other upscaler here.

- [01:34:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5697) If you select Latent, it will drive away the image a lot.

- [01:35:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5701) For example, let's use our R-ESRGAN 4X plus, and let's upscale like 1.5, and we don't need

- [01:35:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5710) to change denoising, but let's try.

- [01:35:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5712) So let's upscale it.

- [01:35:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5714) Currently, we are running on L40 GPU, so this is faster than the A6000 GPU, which I suggest

- [01:35:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5721) you to use.

- [01:35:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5722) It is faster, but A6000 GPU is also not very slow.

- [01:35:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5726) Okay, the upscale is getting done into 1.5X.

- [01:35:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5730) I think 1.5X broken some of the anatomy; let's see.

- [01:35:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5736) So it is going to apply the face improvement to the upscaled image, and this is the upscaled

- [01:35:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5742) image.

- [01:35:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5743) Yes, I think the anatomy is broken with 1.5X.

- [01:35:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5746) So you can do this like 1.25X and try again.

- [01:35:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5750) These are the numbers that you need to play.

- [01:35:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5753) If you find it too different, you can also reduce the denoising strength.

- [01:35:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5756) So you can play with these parameters until you find your liking, but I use this in my

- [01:36:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5763) images, the After Detailer.

- [01:36:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5765) Okay, you see there are some new faces, but they won't be changed because I have selected

- [01:36:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5771) mask only the top k largest, and we got the image.

- [01:36:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5775) The anatomy is not accurate.

- [01:36:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5777) So how can we fix anatomy?

- [01:36:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5779) By the way, this anatomy inaccuracy is also being caused by the masked training. Because

- [01:36:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5785) we have reduced the weight of the background and the body; therefore, it is not fully accurate.

- [01:36:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5792) So if you don't want to get any anatomical problem, you shouldn't use masked training.

- [01:36:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5798) However, the masked training improves the flexibility of the model; it allows you to generate better images.

- [01:36:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5806) Also, if you don't like the generated image, you can skip it directly before waiting it

- [01:36:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5811) to be finished.

- [01:36:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5812) And moreover, there is a way to generate an infinite number of images.

- [01:36:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5817) I am going to show that in a moment, once this image is done.

- [01:37:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5821) Okay, it is fixing the face.

- [01:37:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5823) The face quality is pretty decent.

- [01:37:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5825) Yeah, the back face is not good though

- [01:37:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5827) in this case. So you can right-click here and generate forever.

- [01:37:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5832) So this is a way of generating forever.

- [01:37:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5835) And how do we find the best checkpoint?

- [01:37:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5837) So once you decided your prompt for comparison, you go to the x/y/z in script menu, in the

- [01:37:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5845) very bottom, you see x/y/z plot, you enable it, and in here, you will see that checkpoint,

- [01:37:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5852) checkpoint name, and select the checkpoints from beginning to end, like 15, 30, 45, 60,

- [01:37:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5859) 75, 90, select all of them.

- [01:37:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5861) Then I put 50 grid margins, 50 pixel, and I generate 4 images for each case.

- [01:37:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5869) Since this GPU is very powerful, we can also make the batch size 4, and let's hit generate,

- [01:37:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5875) and we can watch the progress from here.

- [01:37:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5878) It will tell us how many images will be generated.

- [01:38:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5882) These generated images will be saved in the outputs folder, so I click that folder, and

- [01:38:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5887) I can see images here.

- [01:38:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5890) Let's change the view.

- [01:38:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5892) Yeah, I think show list is better, and we had generated some car images, so can we make

- [01:38:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5898) them look bigger?

- [01:38:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5900) Yes, there is zooming.

- [01:38:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5901) Okay, let's make this more zoomed in.

- [01:38:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5904) Okay, so you can see the images here.

- [01:38:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5907) So how you can download all of these images, since these are small images, you can do synchronization

- [01:38:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5914) with your computer.

- [01:38:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5916) So let's try it, or you can upload them into the Hugging Face.

- [01:38:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5919) So let's copy this folder and let's go to home, let's go to Thin Drives, Massed Compute,

- [01:38:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5925) and paste the folder here.

- [01:38:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5927) After I copy-pasted the folder here, you need to wait first.

- [01:38:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5931) This copying files to Massed Compute folder, I can go to my Massed Compute folder, and

- [01:38:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5937) you see, the folder started appearing here.

- [01:38:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5939) So now it is synchronizing the remote cloud folder with my local folder.

- [01:39:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5946) They are getting downloaded as you are seeing right now.

- [01:39:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5948) I suggest you to use this way for the images, or still, you can upload them into the Hugging Face.

- [01:39:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5955) If I were going to upload them into Hugging Face, what would I do?

- [01:39:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5959) What would I do is, I would first zip all of the images.

- [01:39:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5964) So how would I zip them?

- [01:39:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5965) Right-click and let's see.

- [01:39:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5968) Yes, there is compress, and you can give any name of zip like test one, then it will be

- [01:39:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5973) a single file, then you can copy the path of this file with Ctrl C, then go to the text

- [01:39:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5979) editor, open a new tab, paste it, then copy the path from here, Ctrl C, return back to

- [01:39:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5985) your upload Hugging Face, and delete this file path, then paste the new file path, and

- [01:39:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5992) give any name you want.

- [01:39:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=5994) So you can entirely upload the new zip file into your Hugging Face repository.

- [01:40:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6000) Let's click play.

- [01:40:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6001) This is a very small file, so it doesn't worth it, but you can do it is 200 megabytes, and

- [01:40:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6007) you see, it is uploaded.

- [01:40:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6008) Now, when I go back to my Hugging Face folder, it should appear here, and yes, here.

- [01:40:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6014) So I can download it directly from this way as well.

- [01:40:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6018) Hugging Face is really became the backbone of AI.

- [01:40:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6022) They give all of this to us for free.

- [01:40:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6025) They are amazing, amazing.

- [01:40:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6027) I hope that they get better and better every day.

- [01:40:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6030) So I suggest you to follow me on CivitAI.

- [01:40:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6033) You will see my username as SECourses.

- [01:40:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6037) Also, please star our GitHub repository.

- [01:40:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6041) It is super important.

- [01:40:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6042) When you click here, you will get to our main page, and in here, please star it.

- [01:40:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6047) This is super important for me.

- [01:40:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6050) Please fork it.

- [01:40:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6051) Please also watch it.

- [01:40:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6052) If you also become my sponsor on GitHub, I appreciate that very much.

- [01:40:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6058) Moreover, in the top of this GitHub readme file, you will see that you can support me

- [01:41:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6063) on Patreon, you can buy me a coffee, you should follow me on Medium, you should follow me

- [01:41:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6067) on DeviantArt, you should subscribe to our LinkedIn channel, you should follow me on

- [01:41:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6072) LinkedIn, you should follow me on Twitter if you wish.

- [01:41:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6076) Unfortunately, our Udemy course is not available right now, but I am working on it.

- [01:41:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6080) So you can see my LinkedIn profile.

- [01:41:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6083) You can follow me here.

- [01:41:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6084) I have 4000+ followers.

- [01:41:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6087) Hopefully, it will get even better.

- [01:41:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6089) If you have any questions regarding this tutorial, ask me by replying to the video, or you can

- [01:41:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6097) also join our Discord and message me there.

- [01:41:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6101) Either way works fine.

- [01:41:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6103) And our x/y/z plot is getting generated right now.

- [01:41:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6106) Okay, meanwhile, x/y/z checkpoint comparison is getting generated.

- [01:41:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6111) You see the training has been finished.

- [01:41:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6113) So what can we do?

- [01:41:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6116) The last file is already saved inside the given folder.

- [01:42:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6122) Let's also move the last save checkpoint.

- [01:42:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6126) Let's go to the home, apps, inside Stable Diffusion Web UI, inside models, inside Stable Diffusion.

- [01:42:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6135) Let's paste it.

- [01:42:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6136) Let's also switch back to the list like this.

- [01:42:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6139) Yeah, this is good.

- [01:42:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6141) And let's find the last checkpoint.

- [01:42:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6144) What was our name for the last checkpoint?

- [01:42:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6146) It was this.

- [01:42:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6147) So this is the 200 epochs checkpoint.

- [01:42:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6150) Before terminating my Massed Compute, I need to upload everything, or the one that I like

- [01:42:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6157) it most.

- [01:42:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6158) So to upload everything, I am going to do Ctrl L. It is going to select this folder

- [01:42:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6164) path.

- [01:42:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6165) Right-click and copy.

- [01:42:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6166) Then I will return back to my Hugging Face uploading.

- [01:42:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6170) I will change the path.

- [01:42:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6172) Currently, it is like that since this is downloaded from Patreon, but if you need that, you can do it.

- [01:42:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6177) So what was our repository name?

- [01:43:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6180) It was this.

- [01:43:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6181) Let's copy it.

- [01:43:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6182) Unfortunately, there is no copy, so select and Ctrl C, and then here, let's put it here.

- [01:43:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6188) You see, there is multi commits, multi commits verbose, and just hit play, and this will

- [01:43:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6193) start uploading every file in that folder with accurate folder names into my Hugging

- [01:43:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6200) Face repository.

- [01:43:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6201) Initially, it may take some time to prepare the commit, then it will start uploading everything,

- [01:43:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6208) and meanwhile, our x/y/z checkpoint comparison is almost completed.

- [01:43:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6214) We can watch the progress here.

- [01:43:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6216) By the way, since I am uploading at the same time, it is loading the checkpoint, so it

- [01:43:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6221) will become a little bit slower.

- [01:43:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6223) Let's do Ctrl D. Okay, it is like this.

- [01:43:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6227) Okay, you see, currently, it is using 41 gigabytes of RAM.

- [01:43:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6231) It says, okay, this is...

- [01:43:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6234) Yeah, we have 252 gigabyte RAM, and we have 1.2 terabyte hard drive with this Virtual Machine.

- [01:44:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6243) We are only using like 200 gigabytes of the hard drive.

- [01:44:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6247) We can see the values here.

- [01:44:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6248) Also, we can see them on the nvitop, which I have shown you here.

- [01:44:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6253) Yes, we can see how much RAM we are using, how much CPU and GPU we are using.

- [01:44:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6259) You can also start multiple Web UI instances with the way I have shown, for the OneTrainer

- [01:44:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6266) export CUDA visible devices.

- [01:44:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6269) That's all you need to do.

- [01:44:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6270) Okay, let's watch the progress.

- [01:44:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6272) I can also connect this on my computer with Gradio Live Share, so it is a choice of yours.

- [01:44:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6278) Okay, it started uploading the files.

- [01:44:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6280) While this way, you uploading, you will not see the files here until it is completed,

- [01:44:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6289) but when you go to the community, you will see that WIP work in progress upload folders

- [01:44:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6295) using Hugging Face Hub multi commit.

- [01:44:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6297) So this has a resume capability as well.

- [01:45:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6300) You will see that it is uploading the files, and as they get uploaded, these checkboxes

- [01:45:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6305) will be checked.

- [01:45:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6307) So it is uploading . I have to wait fully finish it to see the files here.

- [01:45:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6311) Okay, it is uploading.

- [01:45:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6313) Our x/y/z plot is almost completed as well.

- [01:45:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6316) So the x/y/z checkpoint comparison has been completed.

- [01:45:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6320) Sometimes you may not get the final image here.

- [01:45:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6324) When it is saved, when you click this icon, it will open the folders, and then you will

- [01:45:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6329) go to the text2image grids, like this is actually inside the grids, and in the very

- [01:45:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6335) bottom, you will see a saved png file.

- [01:45:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6339) It is a big file, 70 megabytes, so I will copy it and paste it into my Thin Drive.

- [01:45:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6344) Therefore, I will be able to open it on my computer.

- [01:45:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6350) So let's do that.

- [01:45:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6351) We will see that it is pasting here.

- [01:45:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6354) I think it is synchronous synchronization not asynchronous, so it just pasted.

- [01:46:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6361) Let's look at our Massed Compute device here.

- [01:46:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6365) Okay, the grid is here.

- [01:46:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6367) Let's open it.

- [01:46:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6368) I am using Paint.NET, which is a free software.

- [01:46:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6372) So here, look at each image.

- [01:46:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6375) You see, in the first checkpoint, the face is not like me, so as we move between the

- [01:46:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6380) checkpoints, it will become more like me.

- [01:46:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6382) Still not. Okay 45 epochs, still not like me.

- [01:46:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6387) By the way, you need to compare this face with the training dataset face, not my current

- [01:46:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6393) face, because there are some differences.

- [01:46:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6395) You see, okay, not here.

- [01:46:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6397) Okay, it becomes more likely, as you are seeing, in the 75 epochs.

- [01:46:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6403) Likeliness should improve as we pass more epochs.

- [01:46:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6407) Yes, for example, here, here, we got...

- [01:46:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6411) I think 135, pretty decent.

- [01:46:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6414) This is a personal thing, so I can't say this will work best.

- [01:46:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6419) So this is 150 epochs, which I like in most cases, then 165, but model is far from being

- [01:47:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6427) over-trained.

- [01:47:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6428) Okay, I think a little bit over-trained here.

- [01:47:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6430) So this is the way of comparing each checkpoint.

- [01:47:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6433) I think the clothing is also got over-trained in the 180 epochs.

- [01:47:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6439) You can see the quality of the clothing degraded.

- [01:47:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6442) Let's compare it with 150, for example, or 135.

- [01:47:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6445) I think the clothing is better in this one, so you can see which checkpoint is performing best.

- [01:47:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6452) The best clothing will be in the first checkpoint because it is the least overtrained checkpoint.

- [01:47:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6458) As you see, the clothing is looking better than the last checkpoint, so this is the way

- [01:47:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6464) of comparison.

- [01:47:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6466) There is a trade-off between the likeliness and the flexibility, so if you want more likeliness,

- [01:47:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6473) then you need to do more training, and it will become less flexible.

- [01:47:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6477) However, it is still perfectly able to follow the prompt.

- [01:48:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6480) For example, let's try another prompt, another complex one.

- [01:48:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6485) Okay, I am going to disable x/y/z checkpoint comparison because you should have understood

- [01:48:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6491) the logic.

- [01:48:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6492) So, make this none, and let's generate 4 images.

- [01:48:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6496) Yes, yes decent, let's say it will use the.

- [01:48:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6500) Okay, it is currently at the 90 checkpoint, so let's pick the 150 checkpoint and let's

- [01:48:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6505) say, photo of ohwx man wearing a yellow suit and a red tie and a white shirt in an expensive

- [01:48:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6517) hotel room.

- [01:48:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6519) You see, none of my clothing was like this, so I have picked fully different colors to

- [01:48:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6525) see how much the model is able to follow my prompt.

- [01:48:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6529) Let's generate.

- [01:48:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6530) I am, of course, using the photo of ohwx man as a face prompt.

- [01:48:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6536) I am not using the same thing because this way it is more focusing on the face.

- [01:49:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6541) Okay, initial images are getting generated.

- [01:49:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6543) How much the After Detailer can fix the face totally depends on the quality of your training,

- [01:49:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6549) and let's see how much it obeyed our prompt.

- [01:49:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6553) If it obeyed perfectly, then that means the model is not overtrained.

- [01:49:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6557) People often ask me that, try different expressions.

- [01:49:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6562) If you want different expressions, then you really should include them in your training dataset.

- [01:49:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6568) Currently, my training dataset does not have such different expressions, so the model capability

- [01:49:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6573) of such different expressions will be limited.

- [01:49:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6576) You need to add them into your training dataset.

- [01:49:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6578) However, as you can see, it followed the prompt perfectly accurately.

- [01:49:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6583) The face is not the greatest one; however, the jacket is here, the shirt is here, the

- [01:49:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6589) tie is here, all colors are accurate.

- [01:49:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6591) So, I can generate more images to get the best one.

- [01:49:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6594) Also, I can add some beautifying prompts like hd, hdr, uhd, 2k, 4k.

- [01:50:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6600) I can add some LoRAs if I want.

- [01:50:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6602) It's all up to you, and 8k.

- [01:50:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6605) So, it is all up to you to add more prompts and negative prompts and LoRAs to improve

- [01:50:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6612) your output.

- [01:50:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6613) This is something more related to how well you can prompt, and you can generate more

- [01:50:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6618) images and find the best ones.

- [01:50:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6621) For example, for the introduction part of this video, I am going to generate a lot of

- [01:50:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6625) images and pick some of the bests to show you.

- [01:50:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6629) This is how Stable Diffusion works.

- [01:50:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6630) We can generate in masses, and we can use the very best ones.

- [01:50:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6635) Also, the base model that you use will make a difference.

- [01:50:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6638) Not all base models are perfectly trainable.

- [01:50:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6641) For example, on Juggernaut XL, I didn't get such good likeliness, so not all the models

- [01:50:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6649) are properly trainable.

- [01:50:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6651) Some models are better, and some models are not.

- [01:50:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6654) Moreover, masked training can cause irregular anatomy.

- [01:50:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6658) Therefore, I suggest you improve your training dataset rather than depending on the masked training.

- [01:51:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6666) So, let's see.

- [01:51:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6667) I think this checkpoint could be a little bit overtrained because on the face, I see

- [01:51:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6672) some deformities.

- [01:51:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6674) So, let's reduce it, like to 120 epochs, and I will use the same seed by clicking here.

- [01:51:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6682) We are doing 50 percent denoise.

- [01:51:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6684) We are doing 70 separate steps for the face inpainting.

- [01:51:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6688) Okay, let's try again.

- [01:51:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6690) The power of L40 is like, I think, RTX 4090 in terms of speed for inference.

- [01:51:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6699) For training, it's a little bit slower in the batch size 1, but you can increase the

- [01:51:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6703) batch size to significantly increase training speed if you need.

- [01:51:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6707) Okay, we are getting the results, and I will show you a different expression and how to

- [01:51:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6713) do it with After Detailer.

- [01:51:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6714) While it is generating, you can also open the folder and watch the images here.

- [01:52:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6720) Let's sort them by modified dates.

- [01:52:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6723) Okay, you can see the last saved image here.

- [01:52:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6725) Open it and see without waiting.

- [01:52:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6728) The accuracy of the anatomy will depend on how good images you edit into your training

- [01:52:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6734) dataset because it will learn the proportions of the anatomy.

- [01:52:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6738) For example, this image is looking pretty good, pretty decent.

- [01:52:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6742) Let's see the results.

- [01:52:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6744) This, so it is up to you, whatever you like.

- [01:52:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6747) And if you want a different expression like smiling, photo of ohwx man, then you should

- [01:52:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6753) add the expression here as well; otherwise, the expression will be gone.

- [01:52:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6757) Like, smiling photo of ohwx man, let's see what we are going to get.

- [01:52:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6762) But I don't have any smiling expressions in my training dataset; therefore, it will be

- [01:52:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6767) hard for the model to get a very high-quality smiling expression.

- [01:52:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6772) And some expressions are harder than others.

- [01:52:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6775) Smiling expression is rather easy for the model.

- [01:52:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6779) There is also, hopefully, Stable Diffusion 3 is upcoming, and I think it will be much better.

- [01:53:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6784) I will be hopefully the first one doing a full training tutorial for it, releasing the

- [01:53:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6790) training hyperparameters setup.

- [01:53:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6792) So, follow me on Patreon.

- [01:53:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6794) You see, the smiling expression is not that great because the dataset does not have such

- [01:53:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6800) great expressions.

- [01:53:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6801) The dataset is all single expression, so if you want different expressions, you should

- [01:53:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6809) include the expression in the dataset.

- [01:53:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6811) That is the way of doing it.

- [01:53:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6813) Still, they could be counted as perhaps acceptable.

- [01:53:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6817) Yeah, maybe in this one.

- [01:53:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6820) So, it is up to you, maybe slightly because slightly is, I think, performing better than

- [01:53:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6826) the full smiling, in my case.

- [01:53:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6829) For example, let's try again.

- [01:53:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6831) So, this is the logic of it.

- [01:53:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6832) This is how you do.

- [01:53:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6833) There could be a better way of prompting, including some LoRAs; however, it is up to you.

- [01:54:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6842) I am not that much expert with prompting, to be fair.

- [01:54:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6844) I am just using in my use cases, in my demos.

- [01:54:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6847) Let's see what we are going to get with slight smiling.

- [01:54:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6850) I also like slight smiling rather than smiling.

- [01:54:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6853) So, expression should be both written here and also here.

- [01:54:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6857) This is not as good as manual face inpainting in the inpainting tab, but this is an automated way.

- [01:54:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6866) So, you can generate in masses and pick the best one.

- [01:54:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6869) However, if you inpaint manually, you can get better results.

- [01:54:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6873) That is for sure.

- [01:54:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6874) Also, YOLO doesn't have head; it still has only face.

- [01:54:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6878) I don't know why they didn't add the head here.

- [01:54:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6881) That could produce better results, to be fair.

- [01:54:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6884) Okay, you see, the slightly smiling is much better because I have slightly smiling expression

- [01:54:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6891) in the training dataset.

- [01:54:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6893) So, how do we do inpainting?

- [01:54:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6895) When you click this icon, it will go to the inpaint tab with the image.

- [01:54:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6899) So, you can change the size and carefully mask the face.

- [01:55:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6904) I'm not very careful right now.

- [01:55:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6907) Carefully mask the face and type prompt, which will be slightly smiling photo of ohwx man,

- [01:55:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6913) nothing else.

- [01:55:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6914) Then in here, we select only masked.

- [01:55:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6917) We select the best sampler.

- [01:55:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6919) You can select any number of steps, like 60 steps, and you can make it resize by 1.

- [01:55:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6925) We are not upscaling.

- [01:55:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6927) Denoising strength, whatever you wish, like 50%.

- [01:55:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6930) You can also increase it.

- [01:55:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6931) You should make the seed random, so that you can get different results and pick the best one.

- [01:55:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6938) And that should be the number of images, which is here.

- [01:55:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6940) Yeah, let's generate, batch size 4, and let's see.

- [01:55:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6943) Okay, let's just wait a little bit.

- [01:55:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6945) You can always follow what is happening on the terminal.

- [01:55:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6949) This is the way of using AI applications.

- [01:55:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6952) See, yeah, the terminal is here.

- [01:55:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6955) This is the inpainting speed, but you need to multiply this with 4 because we have

- [01:56:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6960) batch size 4.

- [01:56:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6961) It is over 6 it per second, and the inpainting is generated.

- [01:56:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6965) Let's look at the different ones.

- [01:56:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6967) You see, there is a difference.

- [01:56:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6969) I think the first one is best.

- [01:56:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6970) You see, like this.

- [01:56:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6971) So, this is the way of generating different inpaintings, and with this way, you can get

- [01:56:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6976) a very best result.

- [01:56:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6978) And then you can use our SUPIR upscaler to improve the face with this selected base model

- [01:56:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6984) to improve everything.

- [01:56:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6986) Hopefully, I will also make a new tutorial for our SUPIR application.

- [01:56:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6990) That is really amazing.

- [01:56:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6992) That's mind-blowing.

- [01:56:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6994) What if you want to make a LoRA out of these models?

- [01:56:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=6997) So, it looks like OneTrainer convert models is not a good option.

- [01:56:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7001) You really should stick to the Kohya conversion.

- [01:56:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7004) I have an explanation of how to convert Kohya if you wonder.

- [01:56:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7010) It is on my Patreon.

- [01:56:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7011) This is a public post, so I go to the Patreon post index, and this is the article.

- [01:56:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7018) Yes, in here, I explain it, how to convert lora models from base model.

- [01:57:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7024) You select these options in the Kohya menu, and you save it.

- [01:57:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7028) Let's see, LoRA extraction, yeah, here, extract LoRA, inside utilities, LoRA, extract LoRA

- [01:57:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7034) save precision, load precision, and everything is existing here.

- [01:57:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7039) Let's verify if the models are uploaded into Hugging Face.

- [01:57:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7042) Not yet.

- [01:57:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7043) You really should verify everything uploaded before you terminate your virtual machine.

- [01:57:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7048) Massed Compute.

- [01:57:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7049) You see, it still says 8 to go, but these are not all models.

- [01:57:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7053) There are also some other files.

- [01:57:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7055) We can also see the commit from the community in WIP.

- [01:57:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7059) Yes, you see, it shows the file uploaded and waiting files to be uploaded.

- [01:57:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7066) Meanwhile, our Windows OneTrainer training also completed.

- [01:57:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7071) How do we know?

- [01:57:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7072) You see, 200 epochs to 200 epochs.

- [01:57:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7075) It took more than, way more than the message compute because we used optimized VRAM here,

- [01:58:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7081) not the speed.

- [01:58:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7082) Therefore, it was way slower.

- [01:58:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7083) So, where did we save the files?

- [01:58:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7086) The folder was OneTrainer video workspace.

- [01:58:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7090) So, when I enter inside this folder, I will see that the saved checkpoints are here.

- [01:58:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7095) To use them, I will move them into my freshly installed Automatic1111 web UI.

- [01:58:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7102) It is inside here, inside models, inside Stable Diffusion, and when I move them here, I will

- [01:58:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7109) be able to use them.

- [01:58:31](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7111) Moreover, what was the final file?

- [01:58:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7114) It was saved inside my other Automatic1111 installation.

- [01:58:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7119) So, I just need to start my Automatic1111 web UI, and the models will be there to use.

- [01:58:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7127) It is exactly the same as on Massed Compute.

- [01:58:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7131) There is no difference.

- [01:58:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7132) Everything is exactly the same, so I am not going to repeat them on Windows again, but

- [01:58:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7136) it is fully the same.

- [01:58:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7138) You see, all the models are here.

- [01:58:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7139) I can generate any image of mine, photo of ohwx man wearing a leather jacket in a desert.

- [01:59:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7150) Whatever the prompt you want, sampling steps, selected sampling method, width, and height.

- [01:59:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7156) These are super important.

- [01:59:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7157) If you do SD 1.5 basic training, don't forget to set your resolution accordingly.

- [01:59:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7163) Enable After Detailer, photo of ohwx man, and detection.

- [01:59:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7168) Only first face is mine.

- [01:59:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7170) It allows you to inpaint different faces with different locations as well.

- [01:59:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7175) It is available on the After Detailer extension page.

- [01:59:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7179) Inpaint denoising strength, I find this very good. Use

- [01:59:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7182) separate steps and hit generate.

- [01:59:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7185) So, this is my local computer, local training, nothing different except this is running on

- [01:59:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7191) my computer.

- [01:59:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7192) The other one was running on the cloud, on the Massed Compute cloud, and we are getting

- [01:59:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7197) the image.

- [01:59:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7198) The initial image is generated.

- [02:00:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7200) Now, it is going to inpaint face.

- [02:00:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7202) So, you see, this was the initial image face.

- [02:00:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7205) However, even though the face details are not great, you see, the head is my head; that matters.

- [02:00:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7211) And the face is now fixed, and we got the image.

- [02:00:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7214) It's a great image.

- [02:00:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7216) You can change your prompt to get better images.

- [02:00:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7218) This is how you do it, how you use it on your local computer.

- [02:00:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7224) Okay, let's meanwhile look at the SD 1.5 configuration.

- [02:00:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7228) So, where is the SD 1.5 configuration?

- [02:00:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7232) In this post, I have also shared it here, if you remember.

- [02:00:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7237) And there are several configurations.

- [02:00:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7240) This is Kohya, by the way.

- [02:00:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7243) So, where is the OneTrainer?

- [02:00:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7244) These are Kohya.

- [02:00:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7245) Yeah, OneTrainer is here.

- [02:00:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7246) OneTrainer, SD 1.5.

- [02:00:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7247) Yeah, this is where you can download.

- [02:00:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7250) We have tier 1 and tier 2.

- [02:00:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7252) So, what is the difference?

- [02:00:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7253) If you have a GPU that is 8 GB, then you should use tier 2 configuration.

- [02:01:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7260) Actually, I compared tier 1 and tier 2.

- [02:01:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7261) There wasn't very much difference with the latest version of xFormers, so don't worry

- [02:01:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7266) about that.

- [02:01:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7267) You can count both of them as tier 1.

- [02:01:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7270) There isn't a difference.

- [02:01:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7271) I compared it.

- [02:01:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7272) There is a link here.

- [02:01:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7274) And if you don't have a BF16 supporting GPU, you still should use SD 1.5 training.

- [02:01:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7280) SD 1.5 training is also amazing.

- [02:01:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7283) We get amazing quality.

- [02:01:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7284) So, let me show you the configuration of SD 1.5.

- [02:01:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7288) The configuration is different, not the same as SDXL.

- [02:01:33](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7293) Remember that.

- [02:01:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7294) I am going to open my OneTrainer.

- [02:01:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7297) I have the configuration here.

- [02:01:38](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7298) Let's start it.

- [02:01:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7299) Okay, let's pick the configuration.

- [02:01:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7301) Where is it?

- [02:01:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7303) SD 1.5 slows.

- [02:01:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7304) Yes, I'm going to show you the list where I'm using.

- [02:01:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7309) So, this is the first part.

- [02:01:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7311) This is the same in all.

- [02:01:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7313) And in here, you select your base model.

- [02:01:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7315) This is Hyperrealism Version 3.

- [02:01:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7317) You can select VAE, but you don't need.

- [02:02:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7320) They are all embedded, so you shouldn't select.

- [02:02:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7323) Model output, these are all the same.

- [02:02:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7325) Now, the important part is weight data types.

- [02:02:08](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7328) With SD 1.5, you really need to train them in full precision, float 32.

- [02:02:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7334) This is mandatory.

- [02:02:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7336) Others are not working good.

- [02:02:17](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7337) Also, you need to select base Stable Diffusion 1.5 here.

- [02:02:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7341) Fine-tune is selected.

- [02:02:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7343) I didn't search for LoRA or embedding.

- [02:02:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7345) My configuration is for fine-tuning only because it is the best one.

- [02:02:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7349) And in data, that is the same.

- [02:02:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7352) Concepts are the same, but what differs is you really should use 768-pixel resolution

- [02:02:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7359) for training for this Hyperrealism Version 3 model.

- [02:02:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7362) Some models support over 1024 pixels.

- [02:02:46](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7366) However, I compared them, and I find that 768 is the sweet spot.

- [02:02:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7372) So, that is the different thing.

- [02:02:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7373) Also, you need to use the same resolution regularization images.

- [02:02:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7377) So, you see, man images dataset, 768 to 768.

- [02:03:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7383) My training dataset is 768 to 768.

- [02:03:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7386) Then, in the training, this is also different.

- [02:03:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7389) First of all the Adafactor settings are the same as the SD 1.5.

- [02:03:15](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7395) If you have a high VRAM, you can disable this to speed up.

- [02:03:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7398) The learning rate is 7e-07.

- [02:03:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7399) The rest is the same, like batch size, epochs, and whatever.

- [02:03:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7404) I don't suggest using more than 1 batch size.

- [02:03:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7406) Train text encoder, we do that.

- [02:03:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7408) We never stop the training.

- [02:03:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7410) Let's make this like 10,000 to be sure.

- [02:03:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7412) Text encoder learning rate is the same with the learning rate in SD 1.5.

- [02:03:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7417) Moreover, with SD 1.5, we use EMA.

- [02:03:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7421) This is super important.

- [02:03:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7422) You can use it on CPU if you don't have sufficient VRAM.

- [02:03:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7427) However, if you have sufficient VRAM, use it on GPU.

- [02:03:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7430) How you know you have sufficient VRAM?

- [02:03:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7432) When you do training, if it starts using shared VRAM, then that means you don't have sufficient VRAM.

- [02:04:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7441) You need to reduce the VRAM requirements because it will become 20 times slower.

- [02:04:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7446) So, these are the EMA settings.

- [02:04:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7447) EMA decay is 0.999, and EMA update step interval is 1.

- [02:04:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7453) Gradient checkpointing, this is again for saving the VRAM but will make it slower.

- [02:04:19](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7459) The resolution is 768.

- [02:04:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7461) Attention, now you should pick xFormers.

- [02:04:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7464) Actually, I compared the attention with the latest version of xFormers, and it didn't

- [02:04:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7469) make a difference.

- [02:04:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7470) In the past, it was making a huge difference, but in my recent training, it didn't make.

- [02:04:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7475) Still, you can make this default to get the best quality, but it will make it slower,

- [02:04:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7482) and it will make it use huge VRAM.

- [02:04:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7484) So use it xFormers, so use this on GPU if your VRAM is sufficient; if not, use this

- [02:04:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7490) on CPU and train U-NET.

- [02:04:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7492) Yes we train until to the very end, like this, U-NET learning rate is same.

- [02:04:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7498) I didn't test the effect of rescale noise scheduler; I didn't test any of these yet.

- [02:05:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7504) I also didn't test align prop. Masked

- [02:05:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7507) Training is same as SDXL, so you can also train Masked or not.

- [02:05:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7512) When you do Masked training, your anatomy may not be perfect, so that's the trade-off.

- [02:05:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7518) I also didn't test this area, so these are the very best settings that I have found for SD 1.5.

- [02:05:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7525) The rest is same as the SDXL; there is no difference.

- [02:05:29](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7529) Okay, we are almost finished uploading everything into the Hugging Face repository.

- [02:05:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7536) As I said, with the Massed Compute, it is extremely important that you backup everything

- [02:05:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7543) before you terminate your session because once you click this terminate icon, it will

- [02:05:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7551) delete everything.

- [02:05:52](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7552) There is no stop option or permanent storage option on Massed Compute yet.

- [02:05:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7557) However, I am believing that they will add.

- [02:06:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7560) Moreover, I am in contact with the Massed Compute developers, and they will add, hopefully,

- [02:06:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7566) more GPUs.

- [02:06:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7567) You see, it became 5 available A6000 GPU

- [02:06:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7570) while we are recording. We can see the billing.

- [02:06:14](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7574) Currently, my cost per hour is 2 dollars because I am using L40 GPU.

- [02:06:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7581) If we were using A6000 GPU 2 instances, let's select our creator image, which is SECourses,

- [02:06:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7588) apply our coupon, verify, and deploy.

- [02:06:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7592) Okay, if you get this message, that means that there aren't available GPUs on the same

- [02:06:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7597) machine, so let's verify.

- [02:06:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7599) Don't forget to verify and see the price here; that is super important.

- [02:06:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7603) Deploy, yes, it is deployed.

- [02:06:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7605) This will only take 31 cents per hour.

- [02:06:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7608) I mean, this will only take 31 cents per hour.

- [02:06:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7611) Yeah, they are not separately displayed, but you see that.

- [02:06:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7615) Okay, let's terminate this one because we don't need it.

- [02:06:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7618) It will show you the instance name and instance ID to be sure that they are matching, and

- [02:07:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7624) it says that selecting terminate will delete all data on this VM and recycle the machine.

- [02:07:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7629) There is no way back.

- [02:07:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7631) Let's terminate, and it is gone.

- [02:07:12](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7632) My currently running instance is here, and it is uploading with the 55 megabytes per

- [02:07:21](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7641) second, which is a very decent speed.

- [02:07:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7642) So, you really should read this readme file very carefully.

- [02:07:26](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7646) Read all of the links I shared here very carefully; it will help you tremendously.

- [02:07:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7652) This is super important.

- [02:07:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7654) Don't skip reading this readme file very carefully.

- [02:07:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7657) It is really, really important.

- [02:07:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7659) Watch these videos that I have shared here.

- [02:07:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7661) Ask me any questions from the Discord or from the replies of the video.

- [02:07:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7668) Hopefully, I will reply to every one of them.

- [02:07:51](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7671) And if anything gets broken while you are trying to use my Patreon scripts, please message

- [02:07:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7676) me from Patreon.

- [02:07:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7677) I fix them as soon as possible.

- [02:08:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7680) Actually, the majority of my current time, current employment, is maintaining the scripts.

- [02:08:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7686) I have a lot of scripts, and it is really hard to maintain everything.

- [02:08:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7690) I am full-time working on this stuff, so this is my main income, main source for continuing

- [02:08:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7698) my life, paying my bills.

- [02:08:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7700) Therefore, I hope that you understand it.

- [02:08:22](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7702) I hope that you understand the importance of supporting me.

- [02:08:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7708) This tutorial is made after doing research for weeks, so it was a huge tutorial, it was

- [02:08:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7715) a huge task.

- [02:08:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7716) This tutorial is literally the experience of over 15 months, and if you are a company,

- [02:08:43](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7723) or if you are interested in more professional training like a bigger dataset, like training

- [02:08:48](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7728) style, like training objects, or other stuff, I am also giving private consultation.

- [02:08:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7736) Just message me from LinkedIn or from Discord.

- [02:08:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7739) I am also open to project-based working.

- [02:09:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7743) I am open to every kind of collaboration, so we can collaborate.

- [02:09:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7747) Okay, you see, it says that it was merged.

- [02:09:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7750) If I open this in this machine, it will tell that not exist because it is a private repository,

- [02:09:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7758) but if I open it in my computer, I can see all the model files that we did training is

- [02:09:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7764) uploaded, along with whatever else we have in that folder.

- [02:09:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7768) We have, for example, 1.5 base model, we have RealVis XL model, so this is the way of

- [02:09:35](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7775) doing it.

- [02:09:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7777) I hope you have enjoyed this tutorial, and if your synchronization with thin client doesn't

- [02:09:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7784) work, what you need to do is let me demonstrate.

- [02:09:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7787) You close thin client, open ThinLink again.

- [02:09:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7790) Sorry, I said thin client, actually ThinLink client.

- [02:09:53](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7793) It is not very inaccurate.

- [02:09:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7795) Then we need to get our password one more time, copy it, connect, and check this, and

- [02:10:01](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7801) existing session, and let's see what happens when we do that because this is very dangerous.

- [02:10:07](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7807) It will terminate everything running on the pod.

- [02:10:10](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7810) Therefore, all your unsaved progress will be lost.

- [02:10:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7816) Moreover, all your applications will be closed.

- [02:10:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7818) Therefore, your training will be terminated; your generation and other things will be terminated.

- [02:10:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7823) Okay, something happens.

- [02:10:25](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7825) Sometimes this may happen.

- [02:10:27](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7827) Let's try again, and existing session, let's connect, let's verify if our IP is accurate.

- [02:10:32](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7832) Yes, it is accurate.

- [02:10:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7834) You should always verify IP, username is matching, starts.

- [02:10:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7837) You see, it says mounting local drives.

- [02:10:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7841) Wow, something is happening.

- [02:10:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7842) I hope that this error is not a common one.

- [02:10:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7847) Maybe we need to try several more times.

- [02:10:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7849) This time I'm not going to select end existing session because I did that already.

- [02:10:54](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7854) Maybe that is the reason.

- [02:10:56](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7856) It needs to wait more, so let's try again without end existing session, start, mounting

- [02:11:02](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7862) local drives, starting session.

- [02:11:04](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7864) I think this time it will start.

- [02:11:06](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7866) Yes, and you see, all of the applications are gone, RAM usage is now 4 gigabytes.

- [02:11:13](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7873) The data is, of course, remaining, but all the running applications are terminated.

- [02:11:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7878) However, there is no problem, no issues with the data.

- [02:11:23](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7883) I can see all the data here.

- [02:11:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7884) I can start Stable Diffusion web UI and start using it.

- [02:11:28](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7888) This is almost as equal as from this menu, from right top, power off, restart.

- [02:11:34](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7894) If you do power off, probably you will lose everything.

- [02:11:37](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7897) There is no way to back.

- [02:11:39](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7899) I am not sure, so I don't suggest that.

- [02:11:41](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7901) Okay, there is also power settings.

- [02:11:42](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7902) I think you should make this by default, power modes.

- [02:11:45](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7905) Yeah, there is no problem.

- [02:11:47](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7907) Okay, this is it.

- [02:11:49](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7909) Now, when I terminate this session, everything will be deleted, everything will be gone forever,

- [02:11:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7915) and I won't be able to recover it.

- [02:11:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7918) However, I have saved everything in my Hugging Face repository.

- [02:12:03](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7923) Therefore, there is no issues.

- [02:12:05](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7925) I didn't save all the generated images, but you know how to save it.

- [02:12:09](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7929) I hope you have enjoyed this video.

- [02:12:11](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7931) Please like it, subscribe to our channel, support me on Patreon.

- [02:12:16](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7936) You can see all our links here.

- [02:12:18](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7938) Please also follow me on these links.

- [02:12:20](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7940) I appreciate it, and also leave a comment about my new voice.

- [02:12:24](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7944) And by the way, maybe you noticed that my voice changed because it is already 7 a.m.

- [02:12:30](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7950) here, so my voice is degrading in quality, but I would like to hear your opinion about

- [02:12:36](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7956) my new microphone that I have purchased to increase the sound quality.

- [02:12:40](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7960) Hopefully, new more amazing tutorials are on the way.

- [02:12:44](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7964) Please also open the bell notification to not miss anything, and in my channel, you

- [02:12:50](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7970) can use this search icon to search anything like ControlNet if you want to learn.

- [02:12:55](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7975) You will see the ControlNet, like Stable Diffusion if you want to learn, like type SDXL, and

- [02:12:57](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7977) you will see the SDXL tutorials.

- [02:12:58](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7978) I also have amazing playlists, so you can look at all of my playlists.

- [02:12:59](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7979) Hopefully, new amazing tutorials are on the horizon.

- [02:13:00](https://www.youtube.com/watch?v=0t5l6CP9eBg&t=7980) See you later.

# How to Use SwarmUI & Stable Diffusion 3 on Cloud Services Kaggle (free), Massed Compute & RunPod

## Full tutorial link > https://www.youtube.com/watch?v=XFUZof6Skkw

[![How to Use SwarmUI & Stable Diffusion 3 on Cloud Services Kaggle (free), Massed Compute & RunPod](https://img.youtube.com/vi/XFUZof6Skkw/sddefault.jpg)](https://www.youtube.com/watch?v=XFUZof6Skkw "How to Use SwarmUI & Stable Diffusion 3 on Cloud Services Kaggle (free), Massed Compute & RunPod")

[![image](https://img.shields.io/discord/772774097734074388?label=Discord&logo=discord)](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388) [![Hits](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-to-Use-SwarmUI-and-Stable-Diffusion-3-on-Cloud-Services-Kaggle-free-Massed-Compute-and-RunPod.md.svg?style=plastic&label=Hits%20Since%2025.08.27&labelColor=007ec6&logo=SECourses)](https://hits.sh/github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-to-Use-SwarmUI-and-Stable-Diffusion-3-on-Cloud-Services-Kaggle-free-Massed-Compute-and-RunPod.md)
[![Patreon](https://img.shields.io/badge/Patreon-Support%20Me-F2EB0E?style=for-the-badge&logo=patreon)](https://www.patreon.com/c/SECourses) [![BuyMeACoffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/DrFurkan) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/Medium-Follow%20Me-800080?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@furkangozukara) [![Codio](https://img.shields.io/static/v1?style=for-the-badge&message=Articles&color=4574E0&logo=Codio&logoColor=FFFFFF&label=CivitAI)](https://civitai.com/user/SECourses/articles) [![Furkan G√∂z√ºkara Medium](https://img.shields.io/badge/DeviantArt-Follow%20Me-990000?style=for-the-badge&logo=deviantart&logoColor=white)](https://www.deviantart.com/monstermmorpg)

[![YouTube Channel](https://img.shields.io/badge/YouTube-SECourses-C50C0C?style=for-the-badge&logo=youtube)](https://www.youtube.com/SECourses)  [![Furkan G√∂z√ºkara LinkedIn](https://img.shields.io/badge/LinkedIn-Follow%20Me-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/furkangozukara/)   [![Udemy](https://img.shields.io/static/v1?style=for-the-badge&message=Stable%20Diffusion%20Course&color=A435F0&logo=Udemy&logoColor=FFFFFF&label=Udemy)](https://www.udemy.com/course/stable-diffusion-dreambooth-lora-zero-to-hero/?referralCode=E327407C9BDF0CEA8156) [![Twitter Follow Furkan G√∂z√ºkara](https://img.shields.io/badge/Twitter-Follow%20Me-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/GozukaraFurkan)


In this video, I demonstrate how to install and use #SwarmUI on cloud services. If you lack a powerful GPU or wish to harness more GPU power, this video is essential. You'll learn how to install and utilize SwarmUI, one of the most powerful Generative AI interfaces, on Massed Compute, RunPod, and Kaggle (which offers free dual T4 GPU access for 30 hours weekly). This tutorial will enable you to use SwarmUI on cloud GPU providers as easily and efficiently as on your local PC. Moreover, I will show how to use Stable Diffusion 3 (#SD3) on cloud. SwarmUI uses #ComfyUI backend.

üîó The Public Post (no login or account required) Shown In The Video With The Links ‚û°Ô∏è [https://www.patreon.com/posts/stableswarmui-3-106135985](https://www.patreon.com/posts/stableswarmui-3-106135985)

üîó Windows Tutorial for Learn How to Use SwarmUI ‚û°Ô∏è [https://youtu.be/HKX8_F1Er_w](https://youtu.be/HKX8_F1Er_w)

üîó How to download models very fast to Massed Compute, RunPod and Kaggle and how to upload models or files to Hugging Face very fast tutorial ‚û°Ô∏è [https://youtu.be/X5WVZ0NMaTg](https://youtu.be/X5WVZ0NMaTg)

üîó SECourses Discord ‚û°Ô∏è [https://discord.com/servers/software-engineering-courses-secourses-772774097734074388](https://discord.com/servers/software-engineering-courses-secourses-772774097734074388)

üîó Stable Diffusion GitHub Repo (Please Star, Fork and Watch) ‚û°Ô∏è [https://github.com/FurkanGozukara/Stable-Diffusion](https://github.com/FurkanGozukara/Stable-Diffusion)

Coupon Code for Massed Compute : SECourses

Coupon works on Alt Config RTX A6000 and also RTX A6000 GPUs

[00:00:00](https://youtu.be/XFUZof6Skkw?t=0) Introduction to SwarmUI on cloud services tutorial (Massed Compute, RunPod & Kaggle)

[00:03:18](https://youtu.be/XFUZof6Skkw?t=198) How to install (pre-installed we just 1-click update) and use SwarmUI on Massed Compute virtual Ubuntu machines like in your local PC

[00:04:52](https://youtu.be/XFUZof6Skkw?t=292) How to install and setup synchronization folder of ThinLinc client to access and use Massed Compute virtual machine

[00:06:34](https://youtu.be/XFUZof6Skkw?t=394) How to connect and start using Massed Compute virtual machine after it is initialized and status is running

[00:07:05](https://youtu.be/XFUZof6Skkw?t=425) How to 1-click update SwarmUI on Massed Compute before start using it

[00:07:46](https://youtu.be/XFUZof6Skkw?t=466) How to setup multiple GPUs on SwarmUI backend to generate images on each GPU at the same time with amazing queue system

[00:07:57](https://youtu.be/XFUZof6Skkw?t=477) How to see status of all GPUs with nvitop command

[00:08:43](https://youtu.be/XFUZof6Skkw?t=523) Which pre installed Stable Diffusion models we have on Massed Compute

[00:09:53](https://youtu.be/XFUZof6Skkw?t=593) New model downloading speed of Massed Compute

[00:10:44](https://youtu.be/XFUZof6Skkw?t=644) How do I notice GPU backend setup error of 4 GPU setup

[00:11:42](https://youtu.be/XFUZof6Skkw?t=702) How to monitor status of all running 4 GPUs

[00:12:22](https://youtu.be/XFUZof6Skkw?t=742) Image generation speed, step speed on RTX A6000 on Massed Compute for SD3

[00:12:50](https://youtu.be/XFUZof6Skkw?t=770) How to setup and use CivitAI API key to be able to download gated (behind a login) models from CivitAI

[00:13:55](https://youtu.be/XFUZof6Skkw?t=835) How to quickly download all of the generated images from Massed Compute

[00:15:22](https://youtu.be/XFUZof6Skkw?t=922) How to install latest SwarmUI on RunPod with accurate template selection

[00:16:50](https://youtu.be/XFUZof6Skkw?t=1010) Port setup to be able to connect SwarmUI after installation

[00:17:50](https://youtu.be/XFUZof6Skkw?t=1070) How to download and run installer sh file for RunPod to install SwarmUI

[00:19:47](https://youtu.be/XFUZof6Skkw?t=1187) How to restart Pod 1 time to fix backends loading forever error

[00:20:22](https://youtu.be/XFUZof6Skkw?t=1222) How to start SwarmUI again on RunPod

[00:21:14](https://youtu.be/XFUZof6Skkw?t=1274) How to download and use Stable Diffusion 3 (SD3) on RunPod

[00:22:01](https://youtu.be/XFUZof6Skkw?t=1321) How to setup multiple GPU backends system on RunPod

[00:23:22](https://youtu.be/XFUZof6Skkw?t=1402) Generation speed on RTX 4090 (step speed for SD3)

[00:24:04](https://youtu.be/XFUZof6Skkw?t=1444) How to quickly download all generated images on RunPod to your computer / device

[00:24:50](https://youtu.be/XFUZof6Skkw?t=1490) How to install and use SwarmUI and Stable Diffusion 3 on a free Kaggle account

[00:28:39](https://youtu.be/XFUZof6Skkw?t=1719) How to change model root folder path on SwarmUI on Kaggle to use temporary disk space

[00:29:21](https://youtu.be/XFUZof6Skkw?t=1761) Add another backend to utilize second T4 GPU on Kaggle

[00:29:32](https://youtu.be/XFUZof6Skkw?t=1772) How to cancel run and start SwarmUI again (restarting)

[00:31:39](https://youtu.be/XFUZof6Skkw?t=1899) How to use Stable Diffusion 3 model on Kaggle and generate images

[00:33:06](https://youtu.be/XFUZof6Skkw?t=1986) Why we did get out of RAM error and how we fixed it on Kaggle

[00:33:45](https://youtu.be/XFUZof6Skkw?t=2025) How to disable one of the back ends to prevent RAM error when using T5 XXL text encoder twice

[00:34:04](https://youtu.be/XFUZof6Skkw?t=2044) Stable Diffusion 3 image generation speed on T4 GPU on Kaggle

[00:34:35](https://youtu.be/XFUZof6Skkw?t=2075) How to download all of the generated images on Kaggle at once to your computer / device



### Video Transcription


- [00:00:00](https://www.youtube.com/watch?v=XFUZof6Skkw&t=0) Greetings everyone. In this tutorial, I will&nbsp; show you how to use SwarmUI, Stable Diffusion 3,

- [00:00:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=6) other Stable Diffusion models on Massed&nbsp; Compute. Massed Compute is the very best,

- [00:00:12](https://www.youtube.com/watch?v=XFUZof6Skkw&t=12) cheapest and most powerful cloud server&nbsp; provider. So if you don't have a powerful GPU,

- [00:00:18](https://www.youtube.com/watch?v=XFUZof6Skkw&t=18) you will be able to use SwarmUI and Stable&nbsp; Diffusion 3 on the Massed Compute very easily

- [00:00:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=26) with amazing speeds as you are seeing right now.&nbsp; Additionally, on Massed Compute, it comes with

- [00:00:32](https://www.youtube.com/watch?v=XFUZof6Skkw&t=32) pre-installation so you won't be needed to install&nbsp; it. Also, it comes with the latest version,

- [00:00:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=39) so you will be just click and start using it right&nbsp; away. Moreover, I will show you how to use SwarmUI

- [00:00:47](https://www.youtube.com/watch?v=XFUZof6Skkw&t=47) on a RunPod. RunPod is also another cloud service&nbsp; provider. You can use the very best GPUs on RunPod

- [00:00:56](https://www.youtube.com/watch?v=XFUZof6Skkw&t=56) with amazing mind-blowing speeds as you are seeing&nbsp; right now. I have prepared all the instructions,

- [00:01:02](https://www.youtube.com/watch?v=XFUZof6Skkw&t=62) nothing paywalled. You will be able to install it&nbsp; in few minutes and start using on a RunPod amazing

- [00:01:09](https://www.youtube.com/watch?v=XFUZof6Skkw&t=69) pods. And finally, I will show you how to install&nbsp; and use SwarmUI on a free Kaggle account. You see

- [00:01:18](https://www.youtube.com/watch?v=XFUZof6Skkw&t=78) on my free Kaggle account, I am able to use both&nbsp; of the Kaggle provided T4 GPUs at the same time,

- [00:01:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=86) generate amazing images with SwarmUI. You can&nbsp; also use Stable Diffusion 3 with the very best

- [00:01:33](https://www.youtube.com/watch?v=XFUZof6Skkw&t=93) text encoders, T5 text encoders on a free Kaggle&nbsp; account as well. I will show you everything step

- [00:01:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=99) by step. However, in this tutorial, I will&nbsp; not show the details of how to use SwarmUI.

- [00:01:45](https://www.youtube.com/watch?v=XFUZof6Skkw&t=105) So first of all, you should watch this 90&nbsp; minutes masterpiece SwarmUI tutorial. This

- [00:01:52](https://www.youtube.com/watch?v=XFUZof6Skkw&t=112) shows everything regarding how to use SwarmUI.&nbsp; In this tutorial, I will show you just how to

- [00:01:58](https://www.youtube.com/watch?v=XFUZof6Skkw&t=118) install and start using the SwarmUI on cloud&nbsp; providers if you don't have a GPU. So first,

- [00:02:05](https://www.youtube.com/watch?v=XFUZof6Skkw&t=125) watch the Windows tutorial. Do not skip any part&nbsp; of it. Then watch this tutorial and you will be

- [00:02:11](https://www.youtube.com/watch?v=XFUZof6Skkw&t=131) able to use SwarmUI with excellent proficiency&nbsp; without any issues. You will be able to use all

- [00:02:18](https://www.youtube.com/watch?v=XFUZof6Skkw&t=138) the Stable Diffusion models, Stable Diffusion&nbsp; 1.5, SDXL and Stable Diffusion 3 on SwarmUI

- [00:02:24](https://www.youtube.com/watch?v=XFUZof6Skkw&t=144) without any issues. Moreover, this Windows&nbsp; tutorial has 90 chapters all written by me.

- [00:02:30](https://www.youtube.com/watch?v=XFUZof6Skkw&t=150) So look at the description of this tutorial and&nbsp; watch the chapters that you want to learn. This

- [00:02:36](https://www.youtube.com/watch?v=XFUZof6Skkw&t=156) tutorial that you are watching right now will&nbsp; also have chapters and manually fixed captions

- [00:02:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=162) so you can also enable captions and watch this&nbsp; tutorial as well. So I have prepared this post

- [00:02:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=168) where all of the instructions and links will be&nbsp; in. This is a public post. You don't need to have

- [00:02:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=174) an account or you don't need to register or you&nbsp; don't need to be a member of my Patreon account.

- [00:03:00](https://www.youtube.com/watch?v=XFUZof6Skkw&t=180) This is a fully public post. This post will&nbsp; get updated as it be necessary with the newer

- [00:03:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=186) instructions. The link of this post will be in&nbsp; the description of the video. So visit this post

- [00:03:13](https://www.youtube.com/watch?v=XFUZof6Skkw&t=193) to be able to follow this tutorial. I will begin&nbsp; with Massed Compute. With the Massed Compute we

- [00:03:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=199) already have a ready virtual machine image. So&nbsp; please use this link to register. It helps me

- [00:03:27](https://www.youtube.com/watch?v=XFUZof6Skkw&t=207) significantly. Let's go to this link. Then after&nbsp; you registered, enter your billing information,

- [00:03:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=214) load some balance, then go to the deploy here.&nbsp; We have a special coupon code for RTX A6000 Alt

- [00:03:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=222) config and RTX A6000. You may be wondering what&nbsp; is the difference. When you select RTX A6000 at

- [00:03:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=228) the bottom, you will see the configuration as like&nbsp; this. And when you select the A6000 Alt config,

- [00:03:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=234) you will see the configuration is like this. So&nbsp; the only difference is RAM amount. If there is

- [00:04:01](https://www.youtube.com/watch?v=XFUZof6Skkw&t=241) no available RTX A6000 GPU, you can use the Alt&nbsp; config. In this tutorial, I will run four GPUs at

- [00:04:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=248) the same time. So we will generate four images&nbsp; in parallel, but you only need one GPU to run

- [00:04:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=254) the SwarmUI. From category, select creator. From&nbsp; image, select SE courses. And you see the price is

- [00:04:21](https://www.youtube.com/watch?v=XFUZof6Skkw&t=261) $2.5 per hour right now. After I apply our special&nbsp; coupon SECourses verify, now it is $1.25 per

- [00:04:32](https://www.youtube.com/watch?v=XFUZof6Skkw&t=272) hour. This would be almost $3 on RunPod. Then click&nbsp; deploy. You see the new instance is generated.

- [00:04:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=279) Now just wait initialization. If there are not&nbsp; available GPUs, you will get an error. So reduce

- [00:04:45](https://www.youtube.com/watch?v=XFUZof6Skkw&t=285) the number of GPUs that you want to deploy. The&nbsp; instructions are also written in this post. Then

- [00:04:51](https://www.youtube.com/watch?v=XFUZof6Skkw&t=291) just wait. Meanwhile waiting, let's also download&nbsp; the ThinLinc client, which we are going to use to

- [00:04:58](https://www.youtube.com/watch?v=XFUZof6Skkw&t=298) access the Massed Compute virtual machine. So you&nbsp; see the link is here. Click this link. In this web

- [00:05:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=304) page, download the installer file according&nbsp; to your operating system. I am on Windows,

- [00:05:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=310) therefore I will download Windows. On Mac,&nbsp; download the Mac. On Linux, download the Linux

- [00:05:15](https://www.youtube.com/watch?v=XFUZof6Skkw&t=315) versions. If you are not a Windows user, you see&nbsp; the install instructions are available here. So

- [00:05:21](https://www.youtube.com/watch?v=XFUZof6Skkw&t=321) for other platforms, follow the instructions here.&nbsp; After the download has been completed, open it. It

- [00:05:27](https://www.youtube.com/watch?v=XFUZof6Skkw&t=327) will ask you permission. Click yes. Then click&nbsp; next. Click I accept terms. Click next. Install.

- [00:05:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=334) Nothing else. Just next, next, next. And run the&nbsp; ThinLinc client. Now this is the interface of

- [00:05:40](https://www.youtube.com/watch?v=XFUZof6Skkw&t=340) ThinLinc client. Before we login into our Massed&nbsp; Compute virtual machine, click options here and

- [00:05:47](https://www.youtube.com/watch?v=XFUZof6Skkw&t=347) go to the local devices. Uncheck all options and&nbsp; just check drives and click details. From here,

- [00:05:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=354) you need to add a folder for synchronization if&nbsp; you want to upload or download files. So I will

- [00:05:59](https://www.youtube.com/watch?v=XFUZof6Skkw&t=359) add mine again to show you. Just remove it. You&nbsp; see there is exported path. Click this three dots

- [00:06:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=366) icon. Select where you want your synchronization&nbsp; folder to be. So my folder is here. I am

- [00:06:13](https://www.youtube.com/watch?v=XFUZof6Skkw&t=373) just selecting. You see like this. There is&nbsp; also permission. You can make it read only,

- [00:06:17](https://www.youtube.com/watch?v=XFUZof6Skkw&t=377) read and write or not exported. I am going to make&nbsp; read and write so I can upload and download. Click

- [00:06:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=383) OK. Click OK. Then just wait for status to&nbsp; be initialized. OK, so the virtual machine is

- [00:06:30](https://www.youtube.com/watch?v=XFUZof6Skkw&t=390) ready. You see status running. How we are going to&nbsp; connect and use it. Go to ThinLinc client. Click

- [00:06:36](https://www.youtube.com/watch?v=XFUZof6Skkw&t=396) here to copy the login IP address. Paste it. You&nbsp; see the username is Ubuntu and also Ubuntu here.

- [00:06:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=403) Click here to copy your password. Paste it and&nbsp; click connect. Then you will get this pop up.

- [00:06:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=409) Click continue. Then you will get this screen.&nbsp; Click start and our virtual machine has started.

- [00:06:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=417) Let's make it full screen from here. So you see&nbsp; all of the applications are already installed and

- [00:07:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=423) also we have updater buttons here. Before we start&nbsp; using the SwarmUI, let's just update it. So double

- [00:07:09](https://www.youtube.com/watch?v=XFUZof6Skkw&t=429) click here. Then it will automatically update&nbsp; installed SwarmUI to the very latest version. And

- [00:07:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=436) you see automatic update has been completed and&nbsp; it started the SwarmUI. You can follow terminal

- [00:07:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=443) to see what is happening. The backends are&nbsp; starting and it is started. I will not show how

- [00:07:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=448) to use SwarmUI again because I have shown it in&nbsp; this tutorial video. Very thoroughly 90 minutes video

- [00:07:36](https://www.youtube.com/watch?v=XFUZof6Skkw&t=456) with 70 chapters. So follow it to learn how to use&nbsp; SwarmUI. I will just show how to enable multiple

- [00:07:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=463) GPUs and how to download generated images. So go&nbsp; to the server, backends. In here we are going to

- [00:07:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=470) add more backends to utilize more GPUs at the same&nbsp; time because we have started with 4 GPUs. We

- [00:07:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=477) can see our GPUs from the window and nvitop like&nbsp; this. This is the command and you see we have 4

- [00:08:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=484) GPUs right now. OK, so what we are going to do is&nbsp; we are going to add ComfyUI self starting. Click

- [00:08:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=490) this button. Click OK. One is added. Let's add two&nbsp; more. Click OK and click OK. Then all you need to

- [00:08:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=499) do is copy this start script, paste it and save.&nbsp; Then paste it and save. Then paste it and save.

- [00:08:29](https://www.youtube.com/watch?v=XFUZof6Skkw&t=509) And they will get automatically started. You&nbsp; see they are all enabled. And in the top left

- [00:08:35](https://www.youtube.com/watch?v=XFUZof6Skkw&t=515) you see some backends are ready but others are&nbsp; still loading. So in this pre-installed image,

- [00:08:41](https://www.youtube.com/watch?v=XFUZof6Skkw&t=521) we already have some of the very best models. Go&nbsp; to the models here and we have StableDiffusionXL

- [00:08:47](https://www.youtube.com/watch?v=XFUZof6Skkw&t=527) base version. We have RealVisXL version 4. We have&nbsp; Stable Diffusion HyperRealism version 3. This is

- [00:08:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=534) 1.5 based model and we have the StableDiffusion3&nbsp; medium model. So I will generate an image with the

- [00:09:02](https://www.youtube.com/watch?v=XFUZof6Skkw&t=542) Stable Diffusion 3 model. Let's select it from here.&nbsp; By the way, if you have noticed it, there are two

- [00:09:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=548) SDXL based models here listed. There is an error&nbsp; right now. Hopefully, it will get fixed when you

- [00:09:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=554) are watching this tutorial. The second one is&nbsp; working, not the first one. Okay, let's select

- [00:09:18](https://www.youtube.com/watch?v=XFUZof6Skkw&t=558) the Stable Diffusion 3. You can use any version of&nbsp; Stable Diffusion on SwarmUI and also some other new

- [00:09:25](https://www.youtube.com/watch?v=XFUZof6Skkw&t=565) architectures are coming too. Currently, the text&nbsp; encoders are not downloaded yet. So let's also

- [00:09:32](https://www.youtube.com/watch?v=XFUZof6Skkw&t=572) download them. I'm going to enable the sampler&nbsp; as UniPC from here. This is my best sampler.

- [00:09:38](https://www.youtube.com/watch?v=XFUZof6Skkw&t=578) Scheduler will be normal. And let's use the clip&nbsp; plus T5 text encoder. Super amazing sports car.

- [00:09:46](https://www.youtube.com/watch?v=XFUZof6Skkw&t=586) Let's generate one image. When we first time&nbsp; generate, it will download the necessary clip

- [00:09:52](https://www.youtube.com/watch?v=XFUZof6Skkw&t=592) models. Let's also see the speed of the Massed&nbsp; Compute from here. You see it is downloading

- [00:09:59](https://www.youtube.com/watch?v=XFUZof6Skkw&t=599) super fast. So it downloaded already the clip&nbsp; models. Now it is downloading the T5 XXL text

- [00:10:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=606) encoder with an amazing speed. Massed Compute is&nbsp; just amazing. The downloads are completed and the

- [00:10:12](https://www.youtube.com/watch?v=XFUZof6Skkw&t=612) first image is generated. It took less than two&nbsp; minutes to generate this image. Now we are ready.

- [00:10:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=619) Let's generate 20 images and see the power of 4 GPUs and the A6000 GPU. So I am going to set 20

- [00:10:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=628) images here. Let's generate. It will queue all of&nbsp; them and you see 4 running. So it is running

- [00:10:35](https://www.youtube.com/watch?v=XFUZof6Skkw&t=635) on 4 GPUs. Let's see the GPU status here. So&nbsp; first time it is loading the models on. Okay,

- [00:10:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=642) I have noticed a big error. You see we have&nbsp; added the backends on the same GPU. Therefore,

- [00:10:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=650) right now we are not able to utilize all of them.&nbsp; So we need to set the GPU IDs from here. Click

- [00:10:56](https://www.youtube.com/watch?v=XFUZof6Skkw&t=656) this edit icon. Make the GPU ID 1. Save. Click&nbsp; edit. Make the GPU ID 2. Save. Click edit. Make

- [00:11:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=664) the GPU ID 3. Otherwise, they were all loaded into&nbsp; the first GPU. You see it was using too much VRAM.

- [00:11:12](https://www.youtube.com/watch?v=XFUZof6Skkw&t=672) Now they will get into other GPUs. Okay, yes, they&nbsp; are loading. Let's go back to the generate tab

- [00:11:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=679) again. And let's cancel all of the operations from&nbsp; here. This is a common mistake. You also could do.

- [00:11:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=686) So therefore, I am not going to cut this part.&nbsp; Okay, let's generate 100 images. And let's make

- [00:11:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=694) the steps count 40. And let's hit generate.&nbsp; Okay, 100 current generations, 6 running,

- [00:11:40](https://www.youtube.com/watch?v=XFUZof6Skkw&t=700) 11 queued. Let's go to the nvitop window. You see&nbsp; now it will be run on all of the GPUs. We can see

- [00:11:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=710) that the first GPU, the second GPU. First, it&nbsp; is loading models on each GPU and it is starting

- [00:11:56](https://www.youtube.com/watch?v=XFUZof6Skkw&t=716) generation. And now we are utilizing 4 GPUs at&nbsp; the same time. Therefore, our speed is incredible.

- [00:12:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=723) We are generating 4 images simultaneously.&nbsp; You can see the generation speed here. It is like

- [00:12:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=730) real time. You see it is getting generated and&nbsp; generated and generated again. And this is very

- [00:12:15](https://www.youtube.com/watch?v=XFUZof6Skkw&t=735) cheap. It is only $1.25 per hour. You can generate&nbsp; thousands of images in this duration. Let's go to

- [00:12:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=743) the server and see the generation speed. Go to the&nbsp; logs. In here make this debug. And now let's go

- [00:12:29](https://www.youtube.com/watch?v=XFUZof6Skkw&t=749) to the very bottom from here. You see it is over&nbsp; 4.4 IT per second, which is amazing speed. It is

- [00:12:38](https://www.youtube.com/watch?v=XFUZof6Skkw&t=758) faster than RTX 3090. There is also one new thing&nbsp; that has arrived after my Windows tutorial where I

- [00:12:46](https://www.youtube.com/watch?v=XFUZof6Skkw&t=766) have shown how to use this amazing web application.&nbsp; In the user you will see that there is CivitAI

- [00:12:53](https://www.youtube.com/watch?v=XFUZof6Skkw&t=773) API key. Now you can put your API key here and you can&nbsp; download gated CivitAI models from utilities, model

- [00:13:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=783) downloader. This is a new feature. It wasn't&nbsp; exist when I was making the Windows tutorial.

- [00:13:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=788) So get your API key from CivitAI and put it into your&nbsp; user info. So how you can do that? In your CivitAI,

- [00:13:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=796) click your profile image at the right top and in&nbsp; the bottom you will see account settings. Click

- [00:13:22](https://www.youtube.com/watch?v=XFUZof6Skkw&t=802) it and inside account settings, go to the very&nbsp; bottom and in the very bottom you will see API keys.

- [00:13:29](https://www.youtube.com/watch?v=XFUZof6Skkw&t=809) Add an API key from here. Let's say demo, save. It will&nbsp; show you your API key, copy it, then go back to your

- [00:13:37](https://www.youtube.com/watch?v=XFUZof6Skkw&t=817) Massed Compute and paste it here and save. Once&nbsp; you do that, you will be able to download all of

- [00:13:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=823) the models from CivitAI, whether they require&nbsp; login or not. And since you have seen my API key,

- [00:13:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=829) I'm going to delete it. But your API key will be safe&nbsp; inside Massed Compute. It is totally private. So

- [00:13:55](https://www.youtube.com/watch?v=XFUZof6Skkw&t=835) how you can download generated images? From here go to the files folder. Then in the top, you will

- [00:14:02](https://www.youtube.com/watch?v=XFUZof6Skkw&t=842) see apps. Enter inside there. In here you will&nbsp; see Stable SwarmUI. You see, we also have Kohya,

- [00:14:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=848) one trainer, Stable Diffusion web UI, Automatic1111&nbsp; web UI, web UI Forge. So go to the Stable

- [00:14:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=854) SwarmUI. In here you will see output folder. So&nbsp; just right click and copy. Then go to the home,

- [00:14:21](https://www.youtube.com/watch?v=XFUZof6Skkw&t=861) go to the bottom and you will see thin drives. Go&nbsp; there. You see, this is my synchronization folder.

- [00:14:27](https://www.youtube.com/watch?v=XFUZof6Skkw&t=867) Enter inside it. Then right click an empty area&nbsp; and paste. So it will copy your output folder into

- [00:14:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=874) here. You can give any folder name. Then let's&nbsp; go to my synchronization folder, which was inside

- [00:14:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=879) my R drive inside here. You see mass compute. And in&nbsp; here I can see output folder, inside local, raw. And

- [00:14:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=888) this is the date. So all of the images generated&nbsp; on Massed Compute will be synchronized into my own

- [00:14:56](https://www.youtube.com/watch?v=XFUZof6Skkw&t=896) computer. You can also use Hugging Face upload&nbsp; method. I already have a tutorial for that. You

- [00:15:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=903) see how to download models very fast to RunPod&nbsp; and upload to the Hugging Face. This tutorial

- [00:15:09](https://www.youtube.com/watch?v=XFUZof6Skkw&t=909) watch it to learn how to upload all of the&nbsp; generated images into a Hugging Face repository

- [00:15:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=916) and download from there. And this is it for Massed&nbsp; Compute. Now let's go to the RunPod instructions.

- [00:15:22](https://www.youtube.com/watch?v=XFUZof6Skkw&t=922) So the RunPod instructions are here. Please&nbsp; use this link to register your RunPod account.

- [00:15:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=928) It helps me. After that login. After registering&nbsp; first set up your billing and load some credits.

- [00:15:37](https://www.youtube.com/watch?v=XFUZof6Skkw&t=937) Then once you are ready, go to the Pods here.&nbsp; Click deploy Pod. I use Community Cloud,

- [00:15:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=943) but if you want to have a permanent storage,&nbsp; I also have an amazing tutorial for that. You

- [00:15:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=948) see RunPod permanent network storage system&nbsp; tutorial. Watch this tutorial to learn it.

- [00:15:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=954) But for this tutorial, I won't use it. I'm going&nbsp; to use extreme speed from the filters. I am going

- [00:16:00](https://www.youtube.com/watch?v=XFUZof6Skkw&t=960) to use NVME. I am going to select 48 GB RAM, so&nbsp; it will be a very good machine. And I am going to

- [00:16:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=968) rent 3x 4090 GPU from here. Now this template&nbsp; selection matters. You need to select RunPod

- [00:16:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=976) PyTorch 2.1 with CUDA 11.8. This is the best&nbsp; template that you can use. It will support all

- [00:16:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=983) of the applications. So if this is not selected,&nbsp; how you're going to select change template,

- [00:16:29](https://www.youtube.com/watch?v=XFUZof6Skkw&t=989) then type torch. And once you type torch, you&nbsp; will see RunPod PyTorch. This is the template

- [00:16:36](https://www.youtube.com/watch?v=XFUZof6Skkw&t=996) that you need to select. Select it. How many&nbsp; GPU you need? I'm going to make 3 GPU for

- [00:16:41](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1001) this tutorial. Click edit template. How many disk&nbsp; volume you need? This depends on how many models

- [00:16:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1008) you want to download. Let's make it 100 and how we&nbsp; are going to connect to the interface of SwarmUI?

- [00:16:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1014) From 7801. So this is the port, the proxy port&nbsp; that we are going to use. Click set overrides.

- [00:17:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1023) Then click deploy on demand. Then go to my pods.&nbsp; Wait for pods to be initialized. You see, we got a

- [00:17:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1030) very decent pod if it is not broken, because you&nbsp; may get a broken pod on RunPod, unfortunately.

- [00:17:18](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1038) And if you are not an expert, it may be hard&nbsp; to understand that pod is broken. However,

- [00:17:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1043) on Massed Compute, I never got a such scenario&nbsp; ever yet. All of the machines I rented on Massed

- [00:17:31](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1051) Compute worked perfectly with perfect network&nbsp; speeds. And the pod is started. This template

- [00:17:37](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1057) is very lightweight, so it works very well.&nbsp; Click connect. Connect to JupyterLab. Now in

- [00:17:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1063) our Patreon post, I have install linux.sh&nbsp; file. This is from the official repository.

- [00:17:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1069) It is modified to run on RunPod. Click this.&nbsp; Return back to JupyterLab. Click upload icon

- [00:17:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1077) here. Select the installer file. Then you&nbsp; see install linux.sh file is here. Click

- [00:18:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1084) terminal. The commands are shared on this&nbsp; Patreon post. First, we are going to use

- [00:18:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1088) these commands. Just copy paste it like this. It&nbsp; will clone and start installer for the SwarmUI.

- [00:18:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1096) There is also a RunPod template, but I do not&nbsp; suggest templates. This is way, way better

- [00:18:22](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1102) because you are installing the latest version&nbsp; on a very good working PyTorch template. Also,

- [00:18:27](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1107) installation is very fast, so you do not need&nbsp; to wait for template to be loaded. Okay, so the

- [00:18:33](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1113) installation started. You see it says starting web&nbsp; server on 7801 port. Once you see this message,

- [00:18:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1122) go back to my pods and click connect to HTTP&nbsp; service port 7801. And we got the installer.

- [00:18:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1130) Click agree. Click customize settings. Select your&nbsp; template. I am going to use modern light. Click

- [00:18:56](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1136) next. Just click next here. Click next here. And&nbsp; which base models you want to download, you can

- [00:19:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1143) download any number of them. I am going to just&nbsp; download Stable Diffusion XL 1.0. Click next. Yes,

- [00:19:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1150) I am sure install now. The installation is very&nbsp; fast also. We just need to wait few minutes. You

- [00:19:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1156) can also follow the progress from JupyterLab&nbsp; interface. If you do not know how to download

- [00:19:22](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1162) models on RunPod, as I said, watch this amazing&nbsp; how to download models very fast to RunPod and

- [00:19:29](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1169) how to upload files / folders from RunPod to Hugging&nbsp; Face. This is a very good tutorial. Watch this to

- [00:19:35](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1175) learn in details. So the installation on RunPod&nbsp; has been completed and SwarmUI started. However,

- [00:19:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1182) you see backends are still loading on the server.&nbsp; Because when you first time install on RunPod,

- [00:19:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1189) it doesn't work directly. So we need to&nbsp; restart the pod one time. Go back to my

- [00:19:55](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1195) pod. Click here. More actions and restart pod.&nbsp; This is only necessary one time after the first

- [00:20:01](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1201) time installation. Then close this and go back to&nbsp; your JupyterLab. Wait for restart to be completed.

- [00:20:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1208) When I click workspace, it will not work until the&nbsp; restart is completed. Let's just wait a little bit

- [00:20:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1214) while then it should work. Alternatively, you can&nbsp; also click connect, connect to the JupyterLab and

- [00:20:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1219) wait new page to be loaded. And it is completed.&nbsp; Then click terminal. Go back to the Patreon post

- [00:20:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1226) and how we are going to start it. Copy these&nbsp; three lines with Control C or right click and

- [00:20:31](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1231) copy. Return back here and paste with Control V&nbsp; and it will start the SwarmUI again for us. OK, it

- [00:20:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1239) is started. Go to my pods and click connect to HTTP&nbsp; port again. And this time the backends should load

- [00:20:47](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1247) and which models we have when we go to the models&nbsp; and refresh, we only have StableDiffusionXL 1.0

- [00:20:53](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1253) right now. Backends are still loading. You see the&nbsp; RunPod storage system is slow, so it took a while

- [00:21:00](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1260) and now we are ready. So let's try a car image&nbsp; with SDXL base model. Let's generate. 1 current

- [00:21:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1268) generation, 1 running. And yes, it is ready. So&nbsp; how you can use Stable Diffusion 3 on RunPod. Go to

- [00:21:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1274) the utilities. Go to the model downloader. In our&nbsp; Patreon post, we have the direct download link.

- [00:21:21](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1281) When you watch the Windows tutorial, you will see&nbsp; it. It is here. Right click, copy link address,

- [00:21:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1286) paste and just download. It should download into&nbsp; the accurate folder. You see it is downloading.

- [00:21:31](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1291) Let's see the speed from here. OK, it doesn't&nbsp; show the download speed, but we can see. Yeah,

- [00:21:37](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1297) it is downloading very fast. OK, it is done. Let's&nbsp; go back to generate. Refresh the models. Yes,

- [00:21:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1303) now we can generate with StableDiffusion3.&nbsp; Let's generate something with default settings.

- [00:21:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1310) Currently, it will load the model. And it is&nbsp; generating the StableDiffusion3 image. And yes,

- [00:21:56](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1316) we got the Stable Diffusion 3 image like this with&nbsp; the just prompt car. Let's go to the server and

- [00:22:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1323) add our 2. Click Server. Click Backends to add&nbsp; new backends. Click ComfyUI self-starting.

- [00:22:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1330) OK. Click ComfyUI self-starting. OK. And copy&nbsp; this. Paste. And set the GPU ID 1 because we

- [00:22:17](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1337) have rented 3 GPUs. Save. Copy, paste. GPU&nbsp; ID 2. Save. Now we can generate more images at

- [00:22:25](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1345) the same time. Let's improve the prompt like a&nbsp; super-fast, ultra-expensive sports car. Let's

- [00:22:31](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1351) generate 100 images. Let's make the step&nbsp; count 40. And the sampling. Currently,

- [00:22:37](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1357) I will not use the other text encoders. But you&nbsp; can select them from here. If you select them, it

- [00:22:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1363) will download them. Automatically. Let's actually&nbsp; select it and generate. Now we can see that it is

- [00:22:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1369) downloading the T5XXL text encoder. It is very&nbsp; fast downloading. The beauty of my tutorial is

- [00:22:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1377) that you have the full control. You can see&nbsp; what is happening in this CMD terminal. Yes,

- [00:23:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1384) download completed. Now it will load models into&nbsp; each backend and generate them at the same time.

- [00:23:11](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1391) And we will see the speed in the real time. You&nbsp; see this speed is amazing. It is generating images

- [00:23:18](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1398) almost instantly. Let's see the step speed. Go to&nbsp; the server. Go to the logs. Let's make it debug.

- [00:23:25](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1405) And now we can see that it is 7 IT per second.&nbsp; Wow, this is just amazing. This is just beautiful.

- [00:23:33](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1413) Yes, let's see. This is just too fast. Wow. Yes,&nbsp; 7 IT per second. 7.4 IT per second. RTX 4090 is

- [00:23:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1422) working amazing with Stable Diffusion 3. And the&nbsp; images are getting generated. There is only one

- [00:23:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1428) additional thing that I didn't show on the Windows&nbsp; tutorial, which is CivitAI API key. I have shown how

- [00:23:55](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1435) to use this in the Massed Compute part. So if you&nbsp; have skipped that part, just look at that part

- [00:24:01](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1441) from the description of the video. You will see&nbsp; it. So how you can download the generated images

- [00:24:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1446) onto your computer. Enter inside SwarmUI folder.&nbsp; Double click it. You see there is output. The

- [00:24:13](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1453) most easiest way is right click and download as&nbsp; an archive. So it will zip all of the files and

- [00:24:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1459) download them. However, this may not be very fast.&nbsp; So the fastest way would be uploading them to the

- [00:24:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1466) Hugging Face. You can watch this tutorial to do&nbsp; that. Or you can use RunPodCTL, which I have

- [00:24:33](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1473) explained in this tutorial with amazing details.&nbsp; So you can use all these three methodologies to

- [00:24:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1479) download generated images. Now as a final thing,&nbsp; I will show you how to use this amazing UI on

- [00:24:48](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1488) the Kaggle, a free Kaggle account. So for a free&nbsp; Kaggle account, go to this post. The link is here.

- [00:24:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1494) Then you need to download this Kaggle notebook&nbsp; file. Click it to download. Then let's go to

- [00:25:01](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1501) the kaggle.com. So you need to register a free&nbsp; Kaggle account. Then you need to verify your phone

- [00:25:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1506) number. Otherwise, it will not work. Click Create.&nbsp; Click New Notebook. Then once you get this screen,

- [00:25:12](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1512) click File. Click Import Notebook. Browse&nbsp; Files. And this is the notebook file. Select

- [00:25:19](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1519) the downloaded notebook file. Click Import. Click&nbsp; X. So you will get to this page. Then you will get

- [00:25:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1526) this message. Click OK. Select your accelerator&nbsp; as GPU T4 x2. We are going to use both of the GPUs.

- [00:25:33](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1533) Then make sure that internet is on. That's it. You&nbsp; don't need anything else. Then all of the steps

- [00:25:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1539) are explained in this notebook. First of all, you&nbsp; need to start the session. So it is here. You see,

- [00:25:46](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1546) if I zoom in, it is gone. But when you zoom&nbsp; out, you will see. Click Start Session. Wait

- [00:25:51](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1551) for session to be started. With this first cell,&nbsp; we are going to download 4 models into the

- [00:25:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1557) accurate folder. You can add here more models. Or&nbsp; you can remove models from here. For removing you

- [00:26:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1564) can comment them like this. So you can comment&nbsp; and remove the models that you don't need. For

- [00:26:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1570) adding new models, go to the RunPod Instructions&nbsp; section. And you will see how to download models

- [00:26:15](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1575) very fast. This will explain you how to download&nbsp; models onto the Kaggle as well. So this tutorial

- [00:26:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1583) is amazing. Just watch it. So I will execute&nbsp; the first cell and wait it to be completed.

- [00:26:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1588) So how you will understand it is completed?&nbsp; Once you see this Cancel Run is disappeared,

- [00:26:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1594) it means it is completed. So just wait for this to&nbsp; be gone. Also, when you click here, you see here,

- [00:26:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1602) it will show you how much disk space you are&nbsp; using. This is showing a max. So it includes

- [00:26:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1609) your temporary disk space as well. And we are&nbsp; downloading models onto the temporary disk on

- [00:26:54](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1614) Kaggle. Because the main disk space they give us&nbsp; is much lesser. We can see that here you see the

- [00:27:02](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1622) main disk space is 20 GB. However, it gives us&nbsp; around 50 GB of temporary. And we have two GPUs

- [00:27:11](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1631) you see assigned to us. Kaggle will provide you&nbsp; 30 hours GPU time every week. So you see I have

- [00:27:17](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1637) 30 hours to use this week. It is 120 hours every&nbsp; month. It is just amazing. And we can see that

- [00:27:24](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1644) our disk space usage is increasing because we are&nbsp; downloading models into the temporary disk right

- [00:27:29](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1649) now. Okay, then you need to execute the cells.&nbsp; Step 2, Step 3 and Step 4. Unfortunately,

- [00:27:36](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1656) I won't be able to show them in this tutorial&nbsp; because Kaggle doesn't like web UIs. After you

- [00:27:44](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1664) executed step 4, you will get this part, this&nbsp; screen. Then what you need to do is go to the link

- [00:27:52](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1672) you got from Step 3 and click visit site.&nbsp; Once you clicked visit site, you will get to

- [00:27:59](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1679) this page. Click agree. Click customize settings.&nbsp; Click next. Select your template. I'm going to

- [00:28:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1684) use modern light. Click next. Click next. Click&nbsp; next. Then uncheck this and do not download any

- [00:28:11](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1691) models because we are downloading models into the&nbsp; temporary disk space. Click next. And just yes,

- [00:28:17](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1697) I am sure install now. Then you can just follow&nbsp; this page or you can follow here to see what

- [00:28:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1703) is happening. So you see it is downloading&nbsp; ComfyUI backend. The Kaggle is amazingly

- [00:28:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1708) fast when it comes to downloading something. So&nbsp; just wait. So the installation on Kaggle has been

- [00:28:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1714) completed. It took only few minutes. Are we ready&nbsp; to use? Not yet. First of all, go to the server,

- [00:28:41](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1721) server configuration. And in here, you will see&nbsp; model root. We have to change this. Change this

- [00:28:47](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1727) into /kaggle/temp like this. You see /kaggle/temp.&nbsp; This is mandatory because this is where we have

- [00:28:55](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1735) downloaded our models. This is where we have a&nbsp; lot of space to download new and more models.

- [00:29:01](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1741) After you make this change, click somewhere else&nbsp; and you will see save. Click save. After making

- [00:29:08](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1748) this change, unfortunately, we have to restart&nbsp; the SwarmUI. There is no other way. Even if you

- [00:29:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1754) use restart all backends or other stuff, it will&nbsp; not work. But let's also add the other backend

- [00:29:20](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1760) as well. So we will be able to utilize both of&nbsp; the T4 GPUs. So click here. Click OK. And copy

- [00:29:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1768) this link, paste and set the GPU ID 1 and save.&nbsp; Then return back to your Kaggle notebook. Click

- [00:29:35](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1775) cancel run. After making cancel run, right click&nbsp; and you can do clear all outputs. After that,

- [00:29:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1782) run the Step 3 again. Do not click the link&nbsp; you got and run this cell. This cell will restart

- [00:29:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1789) the SwarmUI. And then once you see this cell has&nbsp; been executed like this, return back to the link

- [00:29:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1797) you got from the Step 3. Click visit site&nbsp; and you will get this SwarmUI like this. So it

- [00:30:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1804) is ready in the server in the backends. We can&nbsp; see both of the backends in the generate. Go to

- [00:30:10](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1810) the models and we can see all the downloaded&nbsp; models. Let's generate an image with the SDXL

- [00:30:17](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1817) base version. Let's generate actually 10 images.&nbsp; So it will automatically queue them on both of the

- [00:30:24](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1824) GPUs. We can see that 10 current generations,&nbsp; 9 queued, waiting models to be loaded. You can

- [00:30:31](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1831) also watch what is happening on the Kaggle&nbsp; notebook. You see user locally requested

- [00:30:36](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1836) 10 images with model SDXL 1.0 base safesensors.&nbsp; You can also watch what is happening here. First,

- [00:30:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1843) it will read them from the temporary disk into the&nbsp; memory. Then it will start generating. We can also

- [00:30:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1850) see CPU usage is 100%. So as I said, if you want&nbsp; to learn how to use SwarmUI, you need to watch the

- [00:30:59](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1859) Windows tutorial. The link is on the Patreon post.&nbsp; Okay, both of the GPUs are loaded. We can see the

- [00:31:07](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1867) GPU memory usage and it started generating the&nbsp; images. It is pretty decent actually taking around

- [00:31:14](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1874) 20 seconds to generate SDXL images. And since&nbsp; we can generate two images at the same time,

- [00:31:21](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1881) it is actually around 9 seconds per SDXL image you&nbsp; see. We can also see the generated images here.

- [00:31:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1888) Let's cancel and let's select the models and let's&nbsp; select the Stable Diffusion 3. You can also use

- [00:31:34](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1894) other SDXL or SD 1.5 based models too. So this is&nbsp; the Stable Diffusion 3. Let's select the sampler

- [00:31:43](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1903) as UniPC. I find that this is best. And let's&nbsp; also use CLIP and T5 text encoders. Let's say

- [00:31:51](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1911) super amazing, ultra fast, expensive sports car&nbsp; and generate. Since we are first time generating,

- [00:31:58](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1918) it will download the T5 text encoder. We can see&nbsp; the download speed here. It should be extremely

- [00:32:04](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1924) fast. It also downloaded the CLIP model for the&nbsp; SDXL because it is using both CLIP of SDXL and the

- [00:32:12](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1932) T5 XXL text encoders. Okay, it is still loading&nbsp; the models. Now downloading the T5 XXL. You see

- [00:32:22](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1942) the download speed is just mind-blowingly fast.&nbsp; Download complete. Now it will load the Stable

- [00:32:27](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1947) Diffusion 3 and the T5 XXL model onto the VRAM.&nbsp; SwarmUI uses ComfyUI as a backend. Therefore,

- [00:32:35](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1955) it is extremely optimized both for speed and&nbsp; VRAM usage. It runs with even 6GB GPU. So if

- [00:32:44](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1964) you have a 6GB GPU, you can use it locally. It&nbsp; automatically set low VRAM mode or not. You see

- [00:32:51](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1971) 10 current generations, 2 running, 7 queued.&nbsp; We will be seeing what is happening here. Okay,

- [00:32:58](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1978) the images are getting generated right now. Okay,&nbsp; 4 running, 5 queued, 10 current generations. Okay,

- [00:33:06](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1986) since we have used two GPUs at the same time, we&nbsp; got RAM error. I didn't have this error last time.

- [00:33:15](https://www.youtube.com/watch?v=XFUZof6Skkw&t=1995) So it is restarting automatically. This is weird.&nbsp; Let's see if we will get that error again or not.

- [00:33:22](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2002) It says your notebook tried to allocate more&nbsp; memory than it is available. It has restarted.

- [00:33:26](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2006) Yeah, I think this happened because it tried to&nbsp; load both of the text encoders onto RAM memory.

- [00:33:33](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2013) So with SDXL, it works. But with Stable Diffusion&nbsp; 3, we get out of RAM memory. Therefore, if you are

- [00:33:39](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2019) going to use Stable Diffusion 3, you need to use&nbsp; only one backend, which I'm going to do right now.

- [00:33:45](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2025) Let's go to the server. And I'm just going to&nbsp; disable this backend. And then I will generate

- [00:33:50](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2030) again. By the way, it had generated the first&nbsp; image. Okay, now it is immediately generating

- [00:33:55](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2035) the Stable Diffusion 3 image. We can see the&nbsp; speed from logs. Let's go to the debug. And

- [00:34:01](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2041) the image generation speed is decent. One second&nbsp; per IT. But this is free. And it is done. Yes,

- [00:34:09](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2049) the image is generated Stable Diffusion 3 image on&nbsp; a free Kaggle account. So how you can download all

- [00:34:15](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2055) the generated images. Before doing that, I will&nbsp; show one another thing if you have skipped this

- [00:34:20](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2060) tutorial. In the user, you will now get CivitAI&nbsp; API key. This wasn't shown in the Windows tutorial.

- [00:34:28](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2068) I have shown how to use this in the Massed&nbsp; Compute part of this tutorial. So check out

- [00:34:32](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2072) the description to see it. So return back to&nbsp; your Kaggle notebook. And to download all of

- [00:34:37](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2077) the images. First of all, you need to cancel&nbsp; run. Then you can start again of course, you

- [00:34:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2082) don't need to start from beginning. Just do the&nbsp; Step 3 and start as I have shown. So cancel

- [00:34:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2089) run. And then click this cell. This cell will zip&nbsp; all of the generated images. You see it has zipped.

- [00:34:57](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2097) The zip file will be inside Kaggle working.&nbsp; Just refresh from here. Click. You see generated

- [00:35:03](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2103) zip file. And when you hover your mouse here, you&nbsp; will see three dots icon. Click download. And you

- [00:35:09](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2109) will see the download in your browser like this.&nbsp; So all of my generated images are now downloaded

- [00:35:16](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2116) like this. Then I am going to restart the SwarmUI.&nbsp; So right click and clear all outputs. Execute

- [00:35:23](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2123) Step 3 and click here. And it will start the&nbsp; SwarmUI again. Then go to the link you got from

- [00:35:30](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2130) the Step 3 and click visit site. And this is&nbsp; it for today. I hope you have enjoyed. Please join

- [00:35:35](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2135) our Discord server. You see we have over 7000&nbsp; members. If you are not my Patreon supporter,

- [00:35:42](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2142) you still should join and chat and ask your&nbsp; questions. Also go to here. This is our GitHub

- [00:35:49](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2149) repository. And star our repository. You see we&nbsp; have 1.9K stars. Fork our repository. Watch our

- [00:35:55](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2155) repository. If you sponsor me, I appreciate&nbsp; that. Also, we have a Patreon exclusive post

- [00:36:00](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2160) index. This is on GitHub. You can read all of&nbsp; my Patreon posts. And if you like any of them,

- [00:36:07](https://www.youtube.com/watch?v=XFUZof6Skkw&t=2167) you can check them out. Hopefully see you in&nbsp; upcoming amazing further, future tutorials.
